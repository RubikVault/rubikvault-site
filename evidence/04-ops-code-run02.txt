### OPS CODE DUMP

## FILE: functions/_lib/kv-safe.js
     1	export const ERR_BINDING_MISSING = "BINDING_MISSING";
     2	export const ERR_KV_READ = "KV_READ_ERROR";
     3	export const ERR_KV_WRITE = "KV_WRITE_ERROR";
     4	export const ERR_KV_WRITE_DISABLED = "KV_WRITE_DISABLED";
     5	
     6	const MAX_MEM = 200;
     7	
     8	const KV_WRITE_FUSE_KEY = "__RV_KV_WRITE_DISABLED_UNTIL";
     9	const DEFAULT_KV_WRITE_COOLDOWN_MS = 12 * 60 * 60 * 1000;
    10	const KV_SIMULATE_429_FLAG = "__RV_SIMULATE_KV_429_FIRED";
    11	
    12	function getWriteDisabledUntil() {
    13	  const value = globalThis[KV_WRITE_FUSE_KEY];
    14	  return Number.isFinite(value) ? value : 0;
    15	}
    16	
    17	function isWriteDisabledNow() {
    18	  return Date.now() < getWriteDisabledUntil();
    19	}
    20	
    21	function isKvRateLimitError(error) {
    22	  const status = error?.status ?? error?.code;
    23	  if (status === 429) return true;
    24	  const name = String(error?.name || "").toLowerCase();
    25	  const message = String(error?.message || "").toLowerCase();
    26	  if (name.includes("rate") && name.includes("limit")) return true;
    27	  return (
    28	    message.includes("429") ||
    29	    message.includes("rate limit") ||
    30	    message.includes("too many") ||
    31	    message.includes("exceeded")
    32	  );
    33	}
    34	
    35	function tripWriteFuse(env, error, cooldownMs = DEFAULT_KV_WRITE_COOLDOWN_MS) {
    36	  const until = Date.now() + cooldownMs;
    37	  globalThis[KV_WRITE_FUSE_KEY] = until;
    38	  if (env && typeof env === "object") {
    39	    env.__RV_ALLOW_WRITE__ = false;
    40	    env.__RV_KV_WRITE_DISABLED__ = true;
    41	    env.__RV_KV_WRITE_DISABLED_UNTIL__ = until;
    42	    env.__RV_KV_WRITE_DISABLED_REASON__ = error?.message || "rate_limited";
    43	  }
    44	}
    45	
    46	function getMemCache() {
    47	  if (!globalThis.RV_MEMCACHE) {
    48	    globalThis.RV_MEMCACHE = new Map();
    49	  }
    50	  return globalThis.RV_MEMCACHE;
    51	}
    52	
    53	function memGet(key) {
    54	  const cache = getMemCache();
    55	  if (!cache.has(key)) return { hit: false, value: null };
    56	  const entry = cache.get(key);
    57	  cache.delete(key);
    58	  cache.set(key, entry);
    59	  return { hit: true, value: entry.value };
    60	}
    61	
    62	function memSet(key, value) {
    63	  const cache = getMemCache();
    64	  if (cache.has(key)) cache.delete(key);
    65	  cache.set(key, { value, ts: Date.now() });
    66	  if (cache.size > MAX_MEM) {
    67	    const oldestKey = cache.keys().next().value;
    68	    cache.delete(oldestKey);
    69	  }
    70	}
    71	
    72	export function hash8(value) {
    73	  const text = String(value || "");
    74	  let hash = 0;
    75	  for (let i = 0; i < text.length; i += 1) {
    76	    hash = (hash * 31 + text.charCodeAt(i)) >>> 0;
    77	  }
    78	  return hash.toString(36).padStart(8, "0").slice(-8);
    79	}
    80	
    81	export function jsonResponse(payload, status = 200) {
    82	  return new Response(JSON.stringify(payload), {
    83	    status,
    84	    headers: {
    85	      "content-type": "application/json; charset=utf-8",
    86	      "cache-control": "no-store, max-age=0"
    87	    }
    88	  });
    89	}
    90	
    91	export async function kvGetJson(env, key) {
    92	  const started = Date.now();
    93	  const missing = !env?.RV_KV || typeof env.RV_KV.get !== "function";
    94	  if (missing) {
    95	    const mem = memGet(key);
    96	    return {
    97	      layer: mem.hit ? "mem" : "none",
    98	      hit: mem.hit,
    99	      value: mem.value,
   100	      durationMs: Date.now() - started,
   101	      error: { code: ERR_BINDING_MISSING, message: "KV binding missing", hash: hash8(key) }
   102	    };
   103	  }
   104	  try {
   105	    const value = await env.RV_KV.get(key, "json");
   106	    return {
   107	      layer: "kv",
   108	      hit: value !== null && value !== undefined,
   109	      value,
   110	      durationMs: Date.now() - started
   111	    };
   112	  } catch (error) {
   113	    const mem = memGet(key);
   114	    return {
   115	      layer: mem.hit ? "mem" : "none",
   116	      hit: mem.hit,
   117	      value: mem.value,
   118	      durationMs: Date.now() - started,
   119	      error: { code: ERR_KV_READ, message: "KV read failed", hash: hash8(key) }
   120	    };
   121	  }
   122	}
   123	
   124	export async function kvPutJson(env, key, value, ttlSeconds) {
   125	  const started = Date.now();
   126	  return {
   127	    layer: "none",
   128	    hit: false,
   129	    durationMs: Date.now() - started,
   130	    error: { code: ERR_KV_WRITE_DISABLED, message: "KV writes disabled", hash: hash8(key) }
   131	  };
   132	}

## FILE: functions/_ops/shape.js
     1	export function getBarNode(resp) {
     2	  if (!resp || typeof resp !== 'object') return null;
     3	  const data = resp.data && typeof resp.data === 'object' ? resp.data : null;
     4	  return data && typeof data.latest_bar === 'object' ? data.latest_bar : null;
     5	}
     6	
     7	export function getTruthChainsNode(summary) {
     8	  if (!summary || typeof summary !== 'object') return null;
     9	  const data = summary.data && typeof summary.data === 'object' ? summary.data : null;
    10	  return data && typeof data.truthChains === 'object' ? data.truthChains : null;
    11	}
    12	
    13	export function safeKeys(obj) {
    14	  return obj && typeof obj === 'object' ? Object.keys(obj) : [];
    15	}

## FILE: functions/_shared/budget.js
     1	class RequestBudget {
     2	  constructor(max = 40) {
     3	    this.max = Number.isFinite(max) ? max : 40;
     4	    this.used = 0;
     5	  }
     6	
     7	  remaining() {
     8	    return Math.max(0, this.max - this.used);
     9	  }
    10	
    11	  async fetch(url, options = {}) {
    12	    if (this.used >= this.max) {
    13	      const error = {
    14	        code: "LIMIT_SUBREQUESTS",
    15	        message: "Budget exceeded",
    16	        details: { used: this.used, max: this.max }
    17	      };
    18	      throw error;
    19	    }
    20	    this.used += 1;
    21	    const headers = {
    22	      Accept: "*/*",
    23	      ...(options.headers || {}),
    24	      ...(options.userAgent ? { "User-Agent": options.userAgent } : {})
    25	    };
    26	    const response = await fetch(url, { ...options, headers });
    27	    const text = await response.text();
    28	    return {
    29	      ok: response.ok,
    30	      status: response.status,
    31	      text,
    32	      headers: response.headers
    33	    };
    34	  }
    35	}
    36	
    37	export { RequestBudget };

## FILE: functions/api/_middleware.js
     1	import { serveStaticJson } from "./_shared/static-only.js";
     2	import { ensureEnvelopeResponse, errorEnvelope } from "./_shared/envelope.js";
     3	
     4	
     5	export async function onRequest(context) {
     6	  const { request, env } = context;
     7	  const url = new URL(request.url);
     8	  const path = url.pathname;
     9	
    10	  let res;
    11	  try {
    12	    res = await context.next();
    13	  } catch (err) {
    14	    // Return error envelope for thrown exceptions - never leak stack traces
    15	    const todayUtc = new Date().toISOString().slice(0, 10);
    16	    const envelope = errorEnvelope(
    17	      "INTERNAL",
    18	      "An unexpected error occurred",
    19	      { provider: "internal", data_date: todayUtc }
    20	    );
    21	    return new Response(JSON.stringify(envelope), {
    22	      status: 500,
    23	      headers: { "Content-Type": "application/json; charset=utf-8" }
    24	    });
    25	  }
    26	
    27	  if (res && typeof res.status === "number" && res.status === 404 && path.startsWith("/api/")) {
    28	    // Try static fallback first
    29	    const fallback = await serveStaticJson(request, env);
    30	    if (!fallback || fallback.status === 404) {
    31	      // Static fallback also 404 - return proper error envelope
    32	      const todayUtc = new Date().toISOString().slice(0, 10);
    33	      const envelope = errorEnvelope(
    34	        "NOT_FOUND",
    35	        `Resource not found: ${path}`,
    36	        { provider: "internal", data_date: todayUtc }
    37	      );
    38	      return new Response(JSON.stringify(envelope), {
    39	        status: 404,
    40	        headers: { "Content-Type": "application/json; charset=utf-8" }
    41	      });
    42	    }
    43	    res = fallback;
    44	  }
    45	  return ensureEnvelopeResponse(res);
    46	}

## FILE: functions/api/_shared/contracts.js
     1	const HEALTH_STATUSES = new Set(['OK', 'INFO', 'WARNING', 'CRITICAL']);
     2	
     3	function isObject(value) {
     4	  return value && typeof value === 'object' && !Array.isArray(value);
     5	}
     6	
     7	function isString(value) {
     8	  return typeof value === 'string' && value.length > 0;
     9	}
    10	
    11	function isNumber(value) {
    12	  return typeof value === 'number' && Number.isFinite(value);
    13	}
    14	
    15	export function validateHealthProfiles(doc) {
    16	  const errors = [];
    17	  if (!isObject(doc)) {
    18	    errors.push('profiles: not an object');
    19	    return { valid: false, errors };
    20	  }
    21	  if (!isString(doc.version)) errors.push('version missing');
    22	  if (!isString(doc.updatedAt)) errors.push('updatedAt missing');
    23	  const profiles = doc.profiles;
    24	  if (!isObject(profiles)) {
    25	    errors.push('profiles missing');
    26	    return { valid: false, errors };
    27	  }
    28	  for (const key of ['production', 'preview']) {
    29	    const profile = profiles[key];
    30	    if (!isObject(profile)) {
    31	      errors.push(`profiles.${key} missing`);
    32	      continue;
    33	    }
    34	    const expected = profile.expected;
    35	    if (!isObject(expected)) {
    36	      errors.push(`profiles.${key}.expected missing`);
    37	    } else {
    38	      for (const k of ['scheduler', 'kv', 'pipeline']) {
    39	        if (typeof expected[k] !== 'boolean') {
    40	          errors.push(`profiles.${key}.expected.${k} must be boolean`);
    41	        }
    42	      }
    43	    }
    44	    if (profile.prices_static_required !== undefined && typeof profile.prices_static_required !== 'boolean') {
    45	      errors.push(`profiles.${key}.prices_static_required must be boolean`);
    46	    }
    47	    if (profile.not_expected_status && !HEALTH_STATUSES.has(profile.not_expected_status)) {
    48	      errors.push(`profiles.${key}.not_expected_status invalid`);
    49	    }
    50	  }
    51	  return { valid: errors.length === 0, errors };
    52	}
    53	
    54	export function validateThresholds(doc) {
    55	  const errors = [];
    56	  if (!isObject(doc)) {
    57	    errors.push('thresholds: not an object');
    58	    return { valid: false, errors };
    59	  }
    60	  if (!isString(doc.version)) errors.push('version missing');
    61	  if (!isString(doc.updatedAt)) errors.push('updatedAt missing');
    62	  for (const key of ['production', 'preview']) {
    63	    const profile = doc[key];
    64	    if (!isObject(profile)) {
    65	      errors.push(`thresholds.${key} missing`);
    66	      continue;
    67	    }
    68	    if (!isNumber(profile.freshness_warn_hours)) {
    69	      errors.push(`thresholds.${key}.freshness_warn_hours missing`);
    70	    }
    71	    if (profile.freshness_crit_hours !== null && profile.freshness_crit_hours !== undefined && !isNumber(profile.freshness_crit_hours)) {
    72	      errors.push(`thresholds.${key}.freshness_crit_hours invalid`);
    73	    }
    74	  }
    75	  return { valid: errors.length === 0, errors };
    76	}
    77	
    78	export function validateSourceMap(doc) {
    79	  const errors = [];
    80	  if (!isObject(doc)) {
    81	    errors.push('source-map: not an object');
    82	    return { valid: false, errors };
    83	  }
    84	  if (!isString(doc.version)) errors.push('version missing');
    85	  if (!isString(doc.updatedAt)) errors.push('updatedAt missing');
    86	  if (!Array.isArray(doc.entries)) {
    87	    errors.push('entries missing');
    88	    return { valid: false, errors };
    89	  }
    90	  doc.entries.forEach((entry, idx) => {
    91	    if (!isObject(entry)) {
    92	      errors.push(`entries[${idx}] not an object`);
    93	      return;
    94	    }
    95	    if (!isString(entry.id)) errors.push(`entries[${idx}].id missing`);
    96	    if (!Array.isArray(entry.sources)) errors.push(`entries[${idx}].sources missing`);
    97	  });
    98	  return { valid: errors.length === 0, errors };
    99	}
   100	
   101	export function validatePipelineArtifact(doc) {
   102	  const errors = [];
   103	  if (!isObject(doc)) {
   104	    errors.push('pipeline: not an object');
   105	    return { valid: false, errors };
   106	  }
   107	  if (!('expected' in doc)) errors.push('expected missing');
   108	  if (!('count' in doc)) errors.push('count missing');
   109	  if (!Array.isArray(doc.missing)) errors.push('missing array missing');
   110	  return { valid: errors.length === 0, errors };
   111	}
   112	
   113	export function validateSnapshot(doc) {
   114	  const errors = [];
   115	  if (!isObject(doc)) {
   116	    errors.push('snapshot: not an object');
   117	    return { valid: false, errors };
   118	  }
   119	  if (!isString(doc.schema_version)) errors.push('schema_version missing');
   120	  if (!isObject(doc.metadata)) {
   121	    errors.push('metadata missing');
   122	    return { valid: false, errors };
   123	  }
   124	  const meta = doc.metadata;
   125	  if (!isString(meta.module)) errors.push('metadata.module missing');
   126	  if (!isString(meta.fetched_at)) errors.push('metadata.fetched_at missing');
   127	  if (!isString(meta.published_at)) errors.push('metadata.published_at missing');
   128	  if (typeof meta.record_count !== 'number') errors.push('metadata.record_count missing');
   129	  if (!Array.isArray(doc.data)) errors.push('data array missing');
   130	  if (!isObject(doc.meta)) {
   131	    errors.push('meta missing');
   132	  } else {
   133	    if (!(doc.meta.asOf === null || isString(doc.meta.asOf))) errors.push('meta.asOf missing');
   134	    if (!isString(doc.meta.kind)) errors.push('meta.kind missing');
   135	    if (typeof doc.meta.expectedCount !== 'number') errors.push('meta.expectedCount missing');
   136	    if (!isString(doc.meta.universe)) errors.push('meta.universe missing');
   137	  }
   138	  return { valid: errors.length === 0, errors };
   139	}
   140	
   141	export function trimErrors(errors, max = 8) {
   142	  if (!Array.isArray(errors)) return [];
   143	  return errors.slice(0, max);
   144	}

## FILE: functions/api/_shared/envelope.js
     1	const CORE_STATUS = new Set(["fresh", "stale", "closed", "pending", "error"]);
     2	const LEGACY_STATUS = new Set([
     3	  "ok",
     4	  "live",
     5	  "partial",
     6	  "empty",
     7	  "no_data",
     8	  "stub",
     9	  "unknown",
    10	  "fail",
    11	  "failed"
    12	]);
    13	
    14	const ALLOWED_STATUS = new Set([...CORE_STATUS, ...LEGACY_STATUS]);
    15	const ISO_DATE_RE = /^\d{4}-\d{2}-\d{2}$/;
    16	
    17	function nowIso() {
    18	  return new Date().toISOString();
    19	}
    20	
    21	function isObject(value) {
    22	  return value && typeof value === "object" && !Array.isArray(value);
    23	}
    24	
    25	function pickString(...values) {
    26	  for (const value of values) {
    27	    if (typeof value !== "string") continue;
    28	    const trimmed = value.trim();
    29	    if (trimmed) return trimmed;
    30	  }
    31	  return null;
    32	}
    33	
    34	function toIsoDate(value) {
    35	  if (typeof value !== "string") return "";
    36	  const trimmed = value.trim();
    37	  if (!trimmed) return "";
    38	  if (ISO_DATE_RE.test(trimmed)) return trimmed;
    39	  const parsed = Date.parse(trimmed);
    40	  if (!Number.isNaN(parsed)) {
    41	    return new Date(parsed).toISOString().slice(0, 10);
    42	  }
    43	  return "";
    44	}
    45	
    46	function extractDataDate(meta, metadata, data) {
    47	  const candidates = [
    48	    meta?.data_date,
    49	    meta?.dataDate,
    50	    meta?.asOf,
    51	    meta?.as_of,
    52	    meta?.updatedAt,
    53	    meta?.updated_at,
    54	    meta?.generatedAt,
    55	    metadata?.as_of,
    56	    metadata?.asOf,
    57	    metadata?.published_at,
    58	    metadata?.publishedAt,
    59	    metadata?.fetched_at,
    60	    metadata?.fetchedAt,
    61	    metadata?.data_date,
    62	    data?.as_of,
    63	    data?.date
    64	  ];
    65	  for (const value of candidates) {
    66	    const iso = toIsoDate(value);
    67	    if (iso) return iso;
    68	  }
    69	  // Fallback to current UTC date instead of empty string
    70	  return new Date().toISOString().slice(0, 10);
    71	}
    72	
    73	function normalizeError(error, ok, statusCode) {
    74	  if (error == null) {
    75	    if (ok) return null;
    76	    const code = statusCode ? `HTTP_${statusCode}` : "ERROR";
    77	    const message = statusCode ? `HTTP ${statusCode}` : "Unknown error";
    78	    return { code, message };
    79	  }
    80	  if (typeof error === "string") {
    81	    return { code: "ERROR", message: error };
    82	  }
    83	  if (isObject(error)) {
    84	    const code = typeof error.code === "string" ? error.code : "ERROR";
    85	    const message = typeof error.message === "string" ? error.message : "Unknown error";
    86	    const details = "details" in error ? error.details : undefined;
    87	    return details !== undefined ? { code, message, details } : { code, message };
    88	  }
    89	  return { code: "ERROR", message: "Unknown error" };
    90	}
    91	
    92	function isAllowedStatus(value) {
    93	  if (typeof value !== "string") return false;
    94	  return ALLOWED_STATUS.has(value.toLowerCase());
    95	}
    96	
    97	function deriveStatus({ ok, meta, metadata }) {
    98	  const raw = pickString(meta?.status, metadata?.status) || "";
    99	  const rawLower = raw.toLowerCase();
   100	  if (rawLower.includes("closed")) return "closed";
   101	  if (rawLower.includes("pending")) return "pending";
   102	  if (rawLower.includes("stale") || rawLower.includes("partial") || rawLower.includes("empty") || rawLower.includes("no_data") || rawLower.includes("stub")) {
   103	    return "stale";
   104	  }
   105	  if (!ok) return "error";
   106	  return "fresh";
   107	}
   108	
   109	export function ensureEnvelopePayload(payload, { statusCode } = {}) {
   110	  const obj = isObject(payload) ? payload : { data: payload ?? null };
   111	  const hasError = obj.error !== undefined && obj.error !== null;
   112	  let ok = typeof obj.ok === "boolean" ? obj.ok : !hasError;
   113	  if (hasError) ok = false;
   114	  if (typeof statusCode === "number" && statusCode >= 400) ok = false;
   115	
   116	  obj.ok = ok;
   117	  obj.error = normalizeError(obj.error, ok, statusCode);
   118	  if (!ok && obj.error == null) {
   119	    obj.error = normalizeError(null, ok, statusCode);
   120	  }
   121	  if (!("data" in obj)) obj.data = null;
   122	
   123	  const existingMeta = isObject(obj.meta) ? { ...obj.meta } : {};
   124	  const metadata = isObject(obj.metadata) ? obj.metadata : null;
   125	
   126	  const statusCandidate = pickString(existingMeta.status, metadata?.status);
   127	  const status = isAllowedStatus(statusCandidate)
   128	    ? statusCandidate
   129	    : deriveStatus({ ok, meta: existingMeta, metadata });
   130	  existingMeta.status = status;
   131	
   132	  const provider = pickString(
   133	    existingMeta.provider,
   134	    metadata?.source,
   135	    metadata?.provider,
   136	    existingMeta.source,
   137	    metadata?.module
   138	  ) || "unknown";
   139	  existingMeta.provider = provider;
   140	
   141	  const dataDate = extractDataDate(existingMeta, metadata, obj.data);
   142	  existingMeta.data_date = dataDate;
   143	  existingMeta.generated_at = nowIso();
   144	
   145	  if (!Array.isArray(existingMeta.quality_flags)) {
   146	    const flags = [];
   147	    if (metadata?.validation && metadata.validation.passed === false) {
   148	      flags.push("VALIDATION_FAILED");
   149	    }
   150	    if (flags.length) existingMeta.quality_flags = flags;
   151	  }
   152	
   153	  if (existingMeta.version == null) {
   154	    const version = pickString(
   155	      metadata?.schema_version,
   156	      metadata?.schemaVersion,
   157	      existingMeta.schema_version,
   158	      existingMeta.schemaVersion
   159	    );
   160	    if (version) existingMeta.version = version;
   161	  }
   162	
   163	  obj.meta = existingMeta;
   164	  return obj;
   165	}
   166	
   167	export function assertEnvelope(value) {
   168	  if (!isObject(value)) throw new Error("Envelope must be an object");
   169	  if (typeof value.ok !== "boolean") throw new Error("Envelope.ok must be boolean");
   170	  if (!isObject(value.meta)) throw new Error("Envelope.meta must be object");
   171	
   172	  const meta = value.meta;
   173	  if (!isAllowedStatus(meta.status)) {
   174	    throw new Error(`Envelope.meta.status invalid: ${meta.status}`);
   175	  }
   176	  if (typeof meta.generated_at !== "string" || Number.isNaN(Date.parse(meta.generated_at))) {
   177	    throw new Error("Envelope.meta.generated_at must be ISO string");
   178	  }
   179	  if (typeof meta.data_date !== "string") {
   180	    throw new Error("Envelope.meta.data_date must be string");
   181	  }
   182	  if (meta.data_date && !ISO_DATE_RE.test(meta.data_date)) {
   183	    throw new Error("Envelope.meta.data_date must be YYYY-MM-DD or empty");
   184	  }
   185	  if (typeof meta.provider !== "string" || !meta.provider.trim()) {
   186	    throw new Error("Envelope.meta.provider must be non-empty string");
   187	  }
   188	
   189	  if (!("data" in value)) throw new Error("Envelope.data missing");
   190	  if (!("error" in value)) throw new Error("Envelope.error missing");
   191	
   192	  if (value.error !== null && !isObject(value.error)) {
   193	    throw new Error("Envelope.error must be object or null");
   194	  }
   195	  if (isObject(value.error)) {
   196	    if (typeof value.error.code !== "string") throw new Error("Envelope.error.code missing");
   197	    if (typeof value.error.message !== "string") throw new Error("Envelope.error.message missing");
   198	  }
   199	}
   200	

## FILE: functions/api/_shared/eod-providers.mjs
     1	import { getTiingoKeyInfo } from './tiingo-key.mjs';
     2	import { checkCircuit, recordFailure, recordSuccess, circuitSnapshotForMeta } from './circuit.js';
     3	
     4	function toIsoDate(value) {
     5	  if (!value) return null;
     6	  try {
     7	    const date = new Date(value);
     8	    if (Number.isNaN(date.getTime())) return null;
     9	    return date.toISOString().slice(0, 10);
    10	  } catch {
    11	    return null;
    12	  }
    13	}
    14	
    15	function toNumber(value) {
    16	  const num = Number(value);
    17	  return Number.isFinite(num) ? num : null;
    18	}
    19	
    20	function normalizeAuthFailure(err) {
    21	  if (!err || typeof err !== 'object') return err;
    22	  const status = err?.details?.status;
    23	  const upstreamCode = err?.details?.code;
    24	  const statusNum = Number.isFinite(Number(status)) ? Number(status) : null;
    25	  const upstreamNum = Number.isFinite(Number(upstreamCode)) ? Number(upstreamCode) : null;
    26	  const effective = statusNum || upstreamNum;
    27	  if (effective === 401 || effective === 403) {
    28	    return {
    29	      ...err,
    30	      code: 'AUTH_FAILED',
    31	      original_code: err.code
    32	    };
    33	  }
    34	  return err;
    35	}
    36	
    37	export function getForcedProvider(env) {
    38	  const forced = String(env?.RV_FORCE_PROVIDER || '').trim().toLowerCase();
    39	  if (forced === 'tiingo') return 'tiingo';
    40	  if (forced === 'twelvedata') return 'twelvedata';
    41	  return null;
    42	}
    43	
    44	function resolveProviderMode(env) {
    45	  const mode = String(env?.PROVIDER_MODE || 'PRIMARY_ONLY').trim().toUpperCase();
    46	  return mode === 'FAILOVER_ALLOWED' ? 'FAILOVER_ALLOWED' : 'PRIMARY_ONLY';
    47	}
    48	
    49	async function guardedFetch(env, provider, fetcher) {
    50	  const circuit = await checkCircuit(env, provider);
    51	  const circuitMeta = circuitSnapshotForMeta(circuit.state, provider);
    52	  if (!circuit.allow) {
    53	    return {
    54	      ok: false,
    55	      provider,
    56	      error: { code: 'CB_OPEN', message: `Circuit open for ${provider}` },
    57	      circuit: circuitMeta
    58	    };
    59	  }
    60	
    61	  const result = await fetcher();
    62	  if (result.ok) {
    63	    await recordSuccess(env, provider);
    64	  } else {
    65	    await recordFailure(env, provider, result.error?.code || null);
    66	  }
    67	  return { ...result, circuit: circuitMeta };
    68	}
    69	
    70	export async function fetchTiingoBars(symbol, env, options = {}) {
    71	  const keyInfo = getTiingoKeyInfo(env);
    72	  const apiKey = keyInfo.key;
    73	  if (!apiKey) {
    74	    return {
    75	      ok: false,
    76	      provider: 'tiingo',
    77	      error: { code: 'MISSING_API_KEY', message: 'Missing TIINGO_API_KEY' },
    78	      key: { present: false, source: null }
    79	    };
    80	  }
    81	
    82	  const startDate = options.startDate || null;
    83	  const url = new URL(`https://api.tiingo.com/tiingo/daily/${encodeURIComponent(symbol)}/prices`);
    84	  url.searchParams.set('token', apiKey);
    85	  url.searchParams.set('resampleFreq', 'daily');
    86	  if (startDate) url.searchParams.set('startDate', startDate);
    87	
    88	  try {
    89	    const response = await fetch(url.toString(), {
    90	      headers: {
    91	        'Content-Type': 'application/json'
    92	      }
    93	    });
    94	
    95	    if (!response.ok) {
    96	      return {
    97	        ok: false,
    98	        provider: 'tiingo',
    99	        error: normalizeAuthFailure({
   100	          code: 'HTTP_ERROR',
   101	          message: `HTTP ${response.status}`,
   102	          details: { status: response.status }
   103	        })
   104	      };
   105	    }
   106	
   107	    const payload = await response.json();
   108	    if (!Array.isArray(payload)) {
   109	      return {
   110	        ok: false,
   111	        provider: 'tiingo',
   112	        error: { code: 'BAD_PAYLOAD', message: 'Tiingo payload not array' }
   113	      };
   114	    }
   115	
   116	    const bars = payload
   117	      .map((row) => {
   118	        const date = toIsoDate(row?.date);
   119	        const close = toNumber(row?.close);
   120	        const open = toNumber(row?.open);
   121	        const high = toNumber(row?.high);
   122	        const low = toNumber(row?.low);
   123	        const volume = toNumber(row?.volume);
   124	        if (!date) return null;
   125	        return { date, open, high, low, close, volume };
   126	      })
   127	      .filter(Boolean)
   128	      .sort((a, b) => (a.date < b.date ? -1 : a.date > b.date ? 1 : 0));
   129	
   130	    return { ok: true, provider: 'tiingo', bars, key: { present: true, source: keyInfo.source } };
   131	  } catch (error) {
   132	    return {
   133	      ok: false,
   134	      provider: 'tiingo',
   135	      error: { code: 'NETWORK_ERROR', message: error?.message || 'network_error' },
   136	      key: { present: true, source: keyInfo.source }
   137	    };
   138	  }
   139	}
   140	
   141	export async function fetchTwelveDataBars(symbol, env, options = {}) {
   142	  const apiKey = env?.TWELVEDATA_API_KEY;
   143	  if (!apiKey) {
   144	    return {
   145	      ok: false,
   146	      provider: 'twelvedata',
   147	      error: { code: 'MISSING_API_KEY', message: 'Missing TWELVEDATA_API_KEY' }
   148	    };
   149	  }
   150	
   151	  const outputsize = options.outputsize || '260';
   152	  const url = new URL('https://api.twelvedata.com/time_series');
   153	  url.searchParams.set('symbol', symbol);
   154	  url.searchParams.set('interval', '1day');
   155	  url.searchParams.set('outputsize', String(outputsize));
   156	  url.searchParams.set('apikey', apiKey);
   157	
   158	  try {
   159	    const response = await fetch(url.toString(), {
   160	      headers: {
   161	        'Content-Type': 'application/json'
   162	      }
   163	    });
   164	
   165	    if (!response.ok) {
   166	      return {
   167	        ok: false,
   168	        provider: 'twelvedata',
   169	        error: normalizeAuthFailure({
   170	          code: 'HTTP_ERROR',
   171	          message: `HTTP ${response.status}`,
   172	          details: { status: response.status }
   173	        })
   174	      };
   175	    }
   176	
   177	    const payload = await response.json();
   178	    if (payload?.status === 'error') {
   179	      return {
   180	        ok: false,
   181	        provider: 'twelvedata',
   182	        error: normalizeAuthFailure({
   183	          code: 'UPSTREAM_ERROR',
   184	          message: payload?.message || 'Twelve Data error',
   185	          details: payload
   186	        })
   187	      };
   188	    }
   189	
   190	    const values = Array.isArray(payload?.values) ? payload.values : [];
   191	    const bars = values
   192	      .map((row) => {
   193	        const date = toIsoDate(row?.datetime);
   194	        const close = toNumber(row?.close);
   195	        const open = toNumber(row?.open);
   196	        const high = toNumber(row?.high);
   197	        const low = toNumber(row?.low);
   198	        const volume = toNumber(row?.volume);
   199	        if (!date) return null;
   200	        return { date, open, high, low, close, volume };

## FILE: functions/api/_shared/feature-contract.js
     1	export function calculateConfidence(availableSignals, totalSignals) {
     2	  if (!totalSignals) return 0;
     3	  const raw = availableSignals / totalSignals;
     4	  if (!Number.isFinite(raw)) return 0;
     5	  return Math.max(0, Math.min(1, raw));
     6	}
     7	
     8	export function normalizeReasons(reasons) {
     9	  if (!Array.isArray(reasons)) return [];
    10	  return reasons
    11	    .map((reason) => String(reason || "").trim())
    12	    .filter(Boolean);
    13	}
    14	
    15	export function resolveDataQuality({ ok, isStale, partial, hasData }) {
    16	  if (!ok || !hasData) return "NO_DATA";
    17	  if (isStale) return "STALE";
    18	  if (partial) return "PARTIAL";
    19	  return "LIVE";
    20	}
    21	
    22	function isEmptyPayloadData(value) {
    23	  if (value === null || value === undefined) return true;
    24	  if (Array.isArray(value)) return value.length === 0;
    25	  if (typeof value === "object") return Object.keys(value).length === 0;
    26	  return false;
    27	}
    28	
    29	function normalizeDataQuality(input, { ok, isStale, error, data, partial } = {}) {
    30	  if (input && typeof input === "object" && input.status) {
    31	    return {
    32	      status: input.status,
    33	      reason: input.reason || input.status,
    34	      missingFields: input.missingFields || []
    35	    };
    36	  }
    37	
    38	  if (typeof input === "string") {
    39	    if (input === "LIVE") return { status: "LIVE", reason: "LIVE", missingFields: [] };
    40	    if (input === "STALE") return { status: "PARTIAL", reason: "STALE", missingFields: [] };
    41	    if (input === "PARTIAL") return { status: "PARTIAL", reason: "PARTIAL", missingFields: [] };
    42	    if (input === "NO_DATA") return { status: "PARTIAL", reason: "NO_DATA", missingFields: [] };
    43	    return { status: ok ? "PARTIAL" : "FAIL", reason: input, missingFields: [] };
    44	  }
    45	
    46	  if (!ok) {
    47	    return {
    48	      status: "FAIL",
    49	      reason: error?.code || "FAIL",
    50	      missingFields: []
    51	    };
    52	  }
    53	
    54	  if (isEmptyPayloadData(data)) {
    55	    return { status: "PARTIAL", reason: "NO_DATA", missingFields: [] };
    56	  }
    57	
    58	  if (isStale) return { status: "PARTIAL", reason: "STALE", missingFields: [] };
    59	  if (partial) return { status: "PARTIAL", reason: "PARTIAL", missingFields: [] };
    60	  return { status: "LIVE", reason: "LIVE", missingFields: [] };
    61	}
    62	
    63	export function normalizeResponse(raw, defaults = {}) {
    64	  const payload = raw && typeof raw === "object" ? raw : {};
    65	  const now = new Date().toISOString();
    66	  const ok = typeof payload.ok === "boolean" ? payload.ok : false;
    67	  const feature = payload.feature || defaults.feature || "unknown";
    68	  const ts = payload.ts || defaults.ts || now;
    69	  const traceId = payload.traceId || defaults.traceId || "unknown";
    70	  const schemaVersion =
    71	    typeof payload.schemaVersion === "number" ? payload.schemaVersion : 1;
    72	  const cache = {
    73	    hit: Boolean(payload.cache?.hit),
    74	    ttl: Number(payload.cache?.ttl ?? 0),
    75	    layer: payload.cache?.layer || "none"
    76	  };
    77	  const upstream = {
    78	    url: payload.upstream?.url || "",
    79	    status: payload.upstream?.status ?? null,
    80	    snippet: payload.upstream?.snippet || ""
    81	  };
    82	  const rateLimit =
    83	    payload.rateLimit || { remaining: "unknown", reset: null, estimated: true };
    84	  const data = payload.data ?? defaults.data ?? {};
    85	  const nestedData = payload.data?.data;
    86	  const error = payload.error;
    87	  const dataQualityInput = payload.dataQuality || payload.data?.dataQuality;
    88	  const dataQuality = normalizeDataQuality(dataQualityInput, {
    89	    ok,
    90	    isStale: payload.isStale,
    91	    error,
    92	    data: nestedData ?? data,
    93	    partial: payload.partial
    94	  });
    95	
    96	  return {
    97	    ok,
    98	    feature,
    99	    ts,
   100	    traceId,
   101	    schemaVersion,
   102	    cache,
   103	    upstream,
   104	    rateLimit,
   105	    dataQuality,
   106	    data,
   107	    error
   108	  };
   109	}
   110	
   111	export function buildFeaturePayload({
   112	  feature,
   113	  traceId,
   114	  source,
   115	  updatedAt,
   116	  data,
   117	  definitions,
   118	  reasons,
   119	  confidence,
   120	  dataQuality
   121	}) {
   122	  return {
   123	    feature,
   124	    traceId,
   125	    updatedAt: updatedAt || new Date().toISOString(),
   126	    source: source || "unknown",
   127	    dataQuality: dataQuality || "NO_DATA",
   128	    confidence: Number.isFinite(confidence) ? confidence : 0,
   129	    definitions: definitions || {},
   130	    reasons: normalizeReasons(reasons),
   131	    data: data || {}
   132	  };
   133	}
   134	
   135	export function withReason(list, code) {
   136	  const next = Array.isArray(list) ? list.slice() : [];
   137	  if (code) next.push(code);
   138	  return next;
   139	}

## FILE: functions/api/_shared/freshness.js
     1	export function computeCacheStatus({ hasData, ageSeconds, ttlSeconds, pending }) {
     2	  if (!hasData) {
     3	    return {
     4	      status: pending ? "pending" : "error",
     5	      stale: true
     6	    };
     7	  }
     8	  if (pending) {
     9	    return {
    10	      status: "pending",
    11	      stale: true
    12	    };
    13	  }
    14	  if (!Number.isFinite(ageSeconds)) {
    15	    return {
    16	      status: "stale",
    17	      stale: true
    18	    };
    19	  }
    20	  if (ageSeconds <= ttlSeconds) {
    21	    return {
    22	      status: "fresh",
    23	      stale: false
    24	    };
    25	  }
    26	  return {
    27	    status: "stale",
    28	    stale: true
    29	  };
    30	}

## FILE: functions/api/_shared/fundamentals-fmp.mjs
     1	/**
     2	 * FMP Fundamentals Fallback Provider
     3	 * 
     4	 * Used when Tiingo fails (e.g., rate limiting) to provide
     5	 * fundamentals data from Financial Modeling Prep.
     6	 */
     7	
     8	export async function fetchFmpFundamentals(ticker, env) {
     9	    const apiKey = String(env?.FMP_API_KEY || '').trim();
    10	    if (!apiKey) {
    11	        return {
    12	            ok: false,
    13	            provider: 'fmp',
    14	            key: { present: false, source: null },
    15	            error: { code: 'MISSING_API_KEY', message: 'Missing FMP_API_KEY' },
    16	            data: null,
    17	            httpStatus: null,
    18	            latencyMs: null
    19	        };
    20	    }
    21	
    22	    const controller = new AbortController();
    23	    const timeoutMs = 6000;
    24	    const started = Date.now();
    25	    const timer = setTimeout(() => controller.abort(), timeoutMs);
    26	
    27	    try {
    28	        const apiUrl = `https://financialmodelingprep.com/api/v3/profile/${encodeURIComponent(ticker)}?apikey=${encodeURIComponent(apiKey)}`;
    29	
    30	        const res = await fetch(apiUrl, {
    31	            method: 'GET',
    32	            headers: { Accept: 'application/json' },
    33	            signal: controller.signal
    34	        });
    35	
    36	        const latencyMs = Date.now() - started;
    37	
    38	        if (!res.ok) {
    39	            return {
    40	                ok: false,
    41	                provider: 'fmp',
    42	                key: { present: true, source: 'FMP_API_KEY' },
    43	                error: { code: res.status === 401 || res.status === 403 ? 'AUTH_FAILED' : 'HTTP_ERROR', message: `HTTP ${res.status}` },
    44	                data: null,
    45	                httpStatus: res.status,
    46	                latencyMs
    47	            };
    48	        }
    49	
    50	        const payload = await res.json();
    51	        const profile = Array.isArray(payload) && payload.length ? payload[0] : null;
    52	
    53	        if (!profile) {
    54	            return {
    55	                ok: false,
    56	                provider: 'fmp',
    57	                key: { present: true, source: 'FMP_API_KEY' },
    58	                error: { code: 'NO_DATA', message: 'No profile data returned' },
    59	                data: null,
    60	                httpStatus: res.status,
    61	                latencyMs
    62	            };
    63	        }
    64	
    65	        // Normalize FMP profile to our fundamentals schema
    66	        const data = normalizeFmpProfile(ticker, profile);
    67	
    68	        return {
    69	            ok: true,
    70	            provider: 'fmp',
    71	            key: { present: true, source: 'FMP_API_KEY' },
    72	            error: null,
    73	            data,
    74	            httpStatus: res.status,
    75	            latencyMs
    76	        };
    77	    } catch (error) {
    78	        const msg = String(error?.message || error || 'network_error');
    79	        const latencyMs = Date.now() - started;
    80	        const lower = msg.toLowerCase();
    81	        const code = lower.includes('abort') || lower.includes('timeout') ? 'TIMEOUT' : 'NETWORK_ERROR';
    82	        return {
    83	            ok: false,
    84	            provider: 'fmp',
    85	            key: { present: true, source: 'FMP_API_KEY' },
    86	            error: { code, message: msg },
    87	            data: null,
    88	            httpStatus: null,
    89	            latencyMs
    90	        };
    91	    } finally {
    92	        clearTimeout(timer);
    93	    }
    94	}
    95	
    96	function toNumber(value) {
    97	    const n = Number(value);
    98	    return Number.isFinite(n) ? n : null;
    99	}
   100	
   101	function normalizeFmpProfile(ticker, profile) {
   102	    return {
   103	        ticker,
   104	        companyName: profile.companyName || null,
   105	        marketCap: toNumber(profile.mktCap),
   106	        pe_ttm: toNumber(profile.pe) || toNumber(profile.priceEarningsRatio),
   107	        ps_ttm: toNumber(profile.priceToSalesRatio),
   108	        pb: toNumber(profile.priceToBookRatio),
   109	        ev_ebitda: null, // FMP profile doesn't include this
   110	        revenue_ttm: null, // Requires separate endpoint
   111	        grossMargin: null,
   112	        operatingMargin: null,
   113	        netMargin: null,
   114	        eps_ttm: toNumber(profile.eps),
   115	        nextEarningsDate: null, // Requires earnings calendar endpoint
   116	        updatedAt: new Date().toISOString().slice(0, 10)
   117	    };
   118	}
   119	
   120	export default { fetchFmpFundamentals };

## FILE: functions/api/_shared/kv_guard.js
     1	export function createKVGuard(env, { debugMode = false, debugKind = "", allowPrefixes = [] } = {}) {
     2	  const kv = env?.RV_KV || null;
     3	  const simulateKv429 = env?.RV_SIMULATE_KV_429 === "1";
     4	  const SIM_FLAG = "__RV_SIMULATE_KV_429_FIRED";
     5	  const isGlobalWriteDisabled = () => Boolean(env?.__RV_KV_WRITE_DISABLED__);
     6	  const flagOn = (value) => {
     7	    if (value === true) return true;
     8	    if (value === false || value === null || value === undefined) return false;
     9	    const raw = String(value).trim().toLowerCase();
    10	    if (!raw) return false;
    11	    if (raw === "0" || raw === "false" || raw === "no" || raw === "off") return false;
    12	    return true;
    13	  };
    14	  const allowWriteOnView = flagOn(env?.RV_ALLOW_WRITE_ON_VIEW);
    15	  const metrics = {
    16	    reads: 0,
    17	    writes: 0,
    18	    deletes: 0,
    19	    lists: 0,
    20	    keys: new Set(),
    21	    warnings: [],
    22	    readsBypassed: 0,
    23	    writesBypassed: 0,
    24	    writeDisabled: false,
    25	    writeDisabledReason: "",
    26	    writeDisabledStatus: null
    27	  };
    28	  const allowed = Array.isArray(allowPrefixes)
    29	    ? allowPrefixes.map((prefix) => String(prefix || "")).filter(Boolean)
    30	    : [];
    31	  const bypassReads = debugKind === "fresh";
    32	
    33	  const isRateLimitError = (error) => {
    34	    const status = error?.status ?? error?.code;
    35	    if (status === 429) return true;
    36	    const name = String(error?.name || "").toLowerCase();
    37	    const message = String(error?.message || "").toLowerCase();
    38	    if (name.includes("rate") && name.includes("limit")) return true;
    39	    return (
    40	      message.includes("429") ||
    41	      message.includes("rate limit") ||
    42	      message.includes("too many") ||
    43	      message.includes("exceeded")
    44	    );
    45	  };
    46	
    47	  const disableWrites = (error) => {
    48	    metrics.writeDisabled = true;
    49	    metrics.writeDisabledReason = String(error?.message || "rate_limited");
    50	    metrics.writeDisabledStatus = error?.status ?? error?.code ?? 429;
    51	    addWarning("KV_WRITE_DISABLED", metrics.writeDisabledReason);
    52	  };
    53	
    54	  const maybeSimulate429 = () => {
    55	    if (!simulateKv429) return;
    56	    if (globalThis[SIM_FLAG]) return;
    57	    globalThis[SIM_FLAG] = true;
    58	    const err = new Error("SIMULATED_KV_429");
    59	    err.status = 429;
    60	    throw err;
    61	  };
    62	
    63	  const recordKey = (key) => {
    64	    if (key !== undefined && key !== null) metrics.keys.add(String(key));
    65	  };
    66	
    67	  const addWarning = (code, key) => {
    68	    if (!debugMode) return;
    69	    const entry = { code: String(code || "") };
    70	    if (key !== undefined && key !== null) entry.key = String(key);
    71	    metrics.warnings.push(entry);
    72	  };
    73	
    74	  const isAllowed = (key) => {
    75	    if (!allowed.length) return false;
    76	    const value = String(key || "");
    77	    return allowed.some((prefix) => value.startsWith(prefix));
    78	  };
    79	
    80	  const warnForbidden = (op, key) => {
    81	    console.warn(`[KV-GUARD] forbidden ${op}`, key);
    82	    addWarning(`KV_${op.toUpperCase()}_BLOCKED`, key);
    83	  };
    84	
    85	  const guard = {
    86	    metrics,
    87	    get: async (key, opts) => {
    88	      metrics.reads += 1;
    89	      recordKey(key);
    90	      if (bypassReads) {
    91	        metrics.readsBypassed += 1;
    92	        addWarning("KV_READ_BYPASSED", key);
    93	        return null;
    94	      }
    95	      if (!kv || typeof kv.get !== "function") return null;
    96	      return kv.get(key, opts);
    97	    },
    98	    put: async (key) => {
    99	      metrics.writes += 1;
   100	      recordKey(key);
   101	      warnForbidden("write", key);
   102	      metrics.writesBypassed += 1;
   103	      return null;
   104	    },
   105	    delete: async (key) => {
   106	      metrics.deletes += 1;
   107	      recordKey(key);
   108	      warnForbidden("delete", key);
   109	      metrics.writesBypassed += 1;
   110	      return null;
   111	    },
   112	    list: async (opts = {}) => {
   113	      metrics.lists += 1;
   114	      const prefix = opts?.prefix || "";
   115	      recordKey(prefix);
   116	      warnForbidden("list", prefix);
   117	      return { keys: [] };
   118	    },
   119	    headerValue: () => {
   120	      const keys = Array.from(metrics.keys.values()).join(",");
   121	      return `reads=${metrics.reads};writes=${metrics.writes};deletes=${metrics.deletes};lists=${metrics.lists};writeDisabled=${metrics.writeDisabled ? 1 : 0};writesBypassed=${metrics.writesBypassed};globalWriteDisabled=${isGlobalWriteDisabled() ? 1 : 0};allowWriteOnView=${allowWriteOnView ? 1 : 0};simulateKv429=${flagOn(env?.RV_SIMULATE_KV_429) ? 1 : 0};keys=${keys}`;
   122	    },
   123	    toDebugJSON: () => ({
   124	      reads: metrics.reads,
   125	      writes: metrics.writes,
   126	      deletes: metrics.deletes,
   127	      lists: metrics.lists,
   128	      keys: Array.from(metrics.keys.values()),
   129	      warnings: metrics.warnings,
   130	      readsBypassed: metrics.readsBypassed,
   131	      writesBypassed: metrics.writesBypassed,
   132	      writeDisabled: metrics.writeDisabled,
   133	      writeDisabledReason: metrics.writeDisabledReason,
   134	      writeDisabledStatus: metrics.writeDisabledStatus,
   135	      globalWriteDisabled: isGlobalWriteDisabled(),
   136	      globalWriteDisabledReason: env?.__RV_KV_WRITE_DISABLED_REASON__ || "",
   137	      globalWriteDisabledUntil: env?.__RV_KV_WRITE_DISABLED_UNTIL__ || null,
   138	      allowWriteOnView,
   139	      simulateKv429: flagOn(env?.RV_SIMULATE_KV_429),
   140	      debugKind
   141	    })
   142	  };
   143	
   144	  return guard;
   145	}

## FILE: functions/api/_shared/parse.js
     1	function stripBom(text) {
     2	  if (!text) return "";
     3	  return text.replace(/^\uFEFF/, "");
     4	}
     5	
     6	function buildError(message, context, text) {
     7	  const error = new Error(message);
     8	  error.code = "SCHEMA_INVALID";
     9	  error.details = {
    10	    context,
    11	    head: text ? text.slice(0, 200) : ""
    12	  };
    13	  return error;
    14	}
    15	
    16	export function parseJsonLenient(text, context = "unknown") {
    17	  const raw = stripBom(String(text || "")).trim();
    18	  if (!raw) {
    19	    throw buildError("Empty response", context, raw);
    20	  }
    21	  try {
    22	    return JSON.parse(raw);
    23	  } catch (error) {
    24	    // continue to lenient path
    25	  }
    26	
    27	  const segments = [];
    28	  let depth = 0;
    29	  let start = -1;
    30	  let inString = false;
    31	  let stringChar = "";
    32	  let escaped = false;
    33	
    34	  for (let i = 0; i < raw.length; i += 1) {
    35	    const char = raw[i];
    36	    if (inString) {
    37	      if (escaped) {
    38	        escaped = false;
    39	        continue;
    40	      }
    41	      if (char === "\\") {
    42	        escaped = true;
    43	        continue;
    44	      }
    45	      if (char === stringChar) {
    46	        inString = false;
    47	        stringChar = "";
    48	      }
    49	      continue;
    50	    }
    51	
    52	    if (char === '"' || char === "'") {
    53	      inString = true;
    54	      stringChar = char;
    55	      continue;
    56	    }
    57	
    58	    if (char === "{" || char === "[") {
    59	      if (depth === 0) {
    60	        start = i;
    61	      }
    62	      depth += 1;
    63	      continue;
    64	    }
    65	
    66	    if (char === "}" || char === "]") {
    67	      if (depth > 0) {
    68	        depth -= 1;
    69	        if (depth === 0 && start >= 0) {
    70	          segments.push(raw.slice(start, i + 1));
    71	          start = -1;
    72	        }
    73	      }
    74	    }
    75	  }
    76	
    77	  const parsedSegments = [];
    78	  segments.forEach((segment) => {
    79	    try {
    80	      parsedSegments.push(JSON.parse(segment));
    81	    } catch (error) {
    82	      // ignore invalid segment
    83	    }
    84	  });
    85	
    86	  if (parsedSegments.length > 0) {
    87	    if (parsedSegments.length > 1) {
    88	      console.warn("[parseJsonLenient] multiple JSON segments detected", {
    89	        context,
    90	        segments: parsedSegments.length
    91	      });
    92	    }
    93	    return parsedSegments[0];
    94	  }
    95	
    96	  const firstIndex = Math.min(
    97	    ...["{", "["].map((token) => {
    98	      const idx = raw.indexOf(token);
    99	      return idx === -1 ? Infinity : idx;
   100	    })
   101	  );
   102	  const lastIndex = Math.max(raw.lastIndexOf("}"), raw.lastIndexOf("]"));
   103	  if (Number.isFinite(firstIndex) && lastIndex > firstIndex) {
   104	    const sliced = raw.slice(firstIndex, lastIndex + 1);
   105	    try {
   106	      return JSON.parse(sliced);
   107	    } catch (error) {
   108	      // ignore
   109	    }
   110	  }
   111	
   112	  throw buildError("Invalid JSON response", context, raw);
   113	}
   114	
   115	export async function fetchTextWithTimeout(url, options = {}, timeoutMs = 10000) {
   116	  const controller = new AbortController();
   117	  const timeout = setTimeout(() => controller.abort(), timeoutMs);
   118	  const signal = controller.signal;
   119	
   120	  if (options.signal) {
   121	    try {
   122	      options.signal.addEventListener("abort", () => controller.abort(), { once: true });
   123	    } catch (error) {
   124	      // ignore
   125	    }
   126	  }
   127	
   128	  try {
   129	    const response = await fetch(url, { ...options, signal });
   130	    const text = await response.text();
   131	    return {
   132	      ok: response.ok,
   133	      status: response.status,
   134	      text,
   135	      headers: response.headers
   136	    };
   137	  } finally {
   138	    clearTimeout(timeout);
   139	  }
   140	}
   141	
   142	export async function fetchJsonWithFallbacks(urls, options = {}, context = "unknown") {
   143	  const list = Array.isArray(urls) ? urls : [];
   144	  let lastError = null;
   145	  for (const url of list) {
   146	    try {
   147	      const { ok, status, text } = await fetchTextWithTimeout(
   148	        url,
   149	        options,
   150	        options.timeoutMs || 10000
   151	      );
   152	      const json = parseJsonLenient(text, context);
   153	      return { json, chosenUrl: url, upstreamStatus: status, upstreamOk: ok };
   154	    } catch (error) {
   155	      lastError = error;
   156	    }
   157	  }
   158	  if (lastError) {
   159	    throw lastError;
   160	  }
   161	  throw buildError("No upstream response", context, "");
   162	}

## FILE: functions/api/_shared/resilience.js
     1	import { jsonResponse, makeJson, safeSnippet, logServer } from "../_shared.js";
     2	
     3	const ALLOW_EMPTY_FEATURES = new Set();
     4	
     5	function nowIso() {
     6	  return new Date().toISOString();
     7	}
     8	
     9	function createTraceId() {
    10	  try {
    11	    if (globalThis.crypto && typeof globalThis.crypto.randomUUID === "function") {
    12	      return globalThis.crypto.randomUUID();
    13	    }
    14	  } catch (error) {
    15	    // ignore
    16	  }
    17	  return Math.random().toString(36).slice(2, 10);
    18	}
    19	
    20	function sleep(ms) {
    21	  return new Promise((resolve) => setTimeout(resolve, ms));
    22	}
    23	
    24	function isHtmlLike(text) {
    25	  const trimmed = String(text || "").trim().toLowerCase();
    26	  return trimmed.startsWith("<!doctype") || trimmed.startsWith("<html");
    27	}
    28	
    29	function defaultValidator(data) {
    30	  if (Array.isArray(data)) {
    31	    return { passed: data.length > 0 };
    32	  }
    33	  if (data && typeof data === "object") {
    34	    return { passed: Object.keys(data).length > 0 };
    35	  }
    36	  return { passed: false, failReason: "EMPTY_DATA" };
    37	}
    38	
    39	function isDataEmpty(data) {
    40	  if (!data || typeof data !== "object") return true;
    41	  if (Array.isArray(data)) return data.length === 0;
    42	  return Object.keys(data).length === 0;
    43	}
    44	
    45	function enforceEnvelope(response, { allowEmptyData = false, lastGoodData = null, hasLastGood = false } = {}) {
    46	  const next = response || {};
    47	  const meta = next.meta || {};
    48	  if (!meta.ts) meta.ts = nowIso();
    49	  if (!meta.schemaVersion) meta.schemaVersion = 1;
    50	  if (!Array.isArray(meta.warnings)) meta.warnings = [];
    51	  if (typeof meta.reason !== "string") {
    52	    meta.reason = meta.reason == null ? "" : String(meta.reason);
    53	  }
    54	  if (!meta.status) {
    55	    meta.status = "EMPTY";
    56	    meta.reason = meta.reason || "MISSING_STATUS";
    57	    next.ok = false;
    58	  }
    59	  const dataEmpty = isDataEmpty(next.data);
    60	  if (meta.status === "LIVE" && dataEmpty && !allowEmptyData) {
    61	    meta.warnings.push("EMPTY_LIVE_GUARD");
    62	    if (hasLastGood && lastGoodData) {
    63	      meta.status = "STALE";
    64	      meta.reason = meta.reason || "EMPTY_LIVE_GUARD";
    65	      next.data = lastGoodData;
    66	      next.ok = true;
    67	    } else {
    68	      meta.status = "EMPTY";
    69	      meta.reason = meta.reason || "NO_DATA_YET";
    70	      next.ok = false;
    71	      if (!next.error || !next.error.code) {
    72	        next.error = { code: "LIVE_WITHOUT_DATA", message: "Live response without data" };
    73	      }
    74	    }
    75	  }
    76	  if (meta.status === "STALE" && dataEmpty) {
    77	    meta.warnings.push("STALE_WITHOUT_DATA");
    78	    if (hasLastGood && lastGoodData) {
    79	      next.data = lastGoodData;
    80	      next.ok = true;
    81	    } else {
    82	      meta.status = "EMPTY";
    83	      meta.reason = meta.reason || "NO_LASTGOOD_AVAILABLE";
    84	      next.ok = false;
    85	      if (!next.error || !next.error.code) {
    86	        next.error = { code: "NO_LASTGOOD_AVAILABLE", message: "Stale response without data" };
    87	      }
    88	    }
    89	  }
    90	  next.meta = meta;
    91	  return next;
    92	}
    93	
    94	function parseSavedAt(value) {
    95	  if (!value) return null;
    96	  const ts = Date.parse(value);
    97	  return Number.isNaN(ts) ? null : ts;
    98	}
    99	
   100	function ageMinutes(savedAtMs) {
   101	  if (!Number.isFinite(savedAtMs)) return null;
   102	  const diffMs = Date.now() - savedAtMs;
   103	  if (!Number.isFinite(diffMs) || diffMs < 0) return 0;
   104	  return Math.round(diffMs / 60000);
   105	}
   106	
   107	function normalizeFetcherResult(result) {
   108	  if (result && typeof result === "object" && "data" in result) {
   109	    return result;
   110	  }
   111	  return { data: result, upstreamStatus: null, upstreamUrl: "", snippet: "" };
   112	}
   113	
   114	function mapRetryable(error) {
   115	  if (!error) return false;
   116	  if (error.name === "AbortError") return true;
   117	  const status = error.status ?? error.statusCode ?? null;
   118	  if (typeof status === "number" && status >= 500) return true;
   119	  if (error.code === "UPSTREAM_5XX" || error.code === "UPSTREAM_TIMEOUT") return true;
   120	  return false;
   121	}
   122	
   123	function mapCircuitStatus(error) {
   124	  const status = error?.status ?? error?.statusCode ?? null;
   125	  if (status === 403 || status === 429) return status;
   126	  if (error?.code === "UPSTREAM_403") return 403;
   127	  if (error?.code === "RATE_LIMITED" || error?.code === "UPSTREAM_429") return 429;
   128	  return null;
   129	}
   130	
   131	function computeAllowWrites(request, env) {
   132	  if (env?.RV_ALLOW_WRITE_ON_VIEW === "1") return true;
   133	  const token = env?.RV_CRON_TOKEN || "";
   134	  if (!token) return false;
   135	  const auth = request?.headers?.get("authorization") || "";
   136	  const cronHeader = request?.headers?.get("x-rv-cron") || "";
   137	  const cronTokenHeader = request?.headers?.get("x-rv-cron-token") || "";
   138	  return (
   139	    auth === `Bearer ${token}` ||
   140	    (cronHeader === "1" && cronTokenHeader === token)
   141	  );
   142	}
   143	
   144	function resolveHttpStatus(payload) {
   145	  return payload?.ok === false ? 503 : 200;
   146	}
   147	
   148	async function loadMirrorPayload(origin, featureId) {
   149	  if (!origin || !featureId) return null;
   150	  const url = `${origin}/data/snapshots/${featureId}.json`;
   151	  try {
   152	    const response = await fetch(url, { headers: { Accept: "application/json" } });
   153	    const text = await response.text();
   154	    if (!response.ok || isHtmlLike(text)) return null;
   155	    const payload = JSON.parse(text);
   156	    if (payload && typeof payload === "object") return payload;
   157	  } catch (error) {
   158	    return null;
   159	  }
   160	  return null;
   161	}
   162	
   163	function extractMirrorData(payload) {
   164	  if (!payload || typeof payload !== "object") return null;
   165	  const inner = payload.payload && typeof payload.payload === "object" ? payload.payload : payload;
   166	  if (inner && typeof inner === "object" && inner.data) return inner.data;
   167	  if (Array.isArray(inner?.items) || inner?.context) {
   168	    return { items: inner.items || [], context: inner.context || {} };
   169	  }
   170	  return inner;
   171	}
   172	
   173	export async function withResilience(context, cfg) {
   174	  const { request, env } = context;
   175	  const traceId = createTraceId();
   176	  const url = new URL(request.url);
   177	  const hostname = url.hostname || "";
   178	  const isPreview =
   179	    env?.ENV_HINT === "preview" ||
   180	    hostname.includes("pages.dev") ||
   181	    (env?.CF_PAGES_BRANCH && env.CF_PAGES_BRANCH !== "main");
   182	  const isDebug = url.searchParams.get("debug") === "1";
   183	  const allowWrites = computeAllowWrites(request, env);
   184	  const readOnly = !allowWrites;
   185	  const KV = env?.RV_KV || null;
   186	  const hasKV = KV && typeof KV.get === "function";
   187	  const featureId = cfg.featureId || "unknown";
   188	  const version = cfg.version || "v1";
   189	  const allowEmptyData =
   190	    cfg.allowEmptyData === true || ALLOW_EMPTY_FEATURES.has(featureId);
   191	  const lastGoodKey = cfg.lastGoodKey || `rv:lastgood:${featureId}:${version}`;
   192	  const circuitKey = cfg.circuitKey || `rv:circuit:${featureId}:${version}`;
   193	  const nowMs = Date.now();
   194	  const timings = { kv: 0, fetch: 0, total: 0 };
   195	
   196	  let lastGood = null;
   197	  let circuitOpen = false;
   198	  let lastGoodValid = false;
   199	  let lastGoodQuality = { passed: false, failReason: "NO_DATA_YET" };
   200	  let savedAtMs = null;

## FILE: functions/api/_shared/scheduler-law.js
     1	import { fetchBarsWithProviderChain } from "./eod-providers.mjs";
     2	import { evaluateQuality } from "./quality.js";
     3	import {
     4	  DEFAULT_TTL_SECONDS,
     5	  createCache,
     6	  getJsonKV,
     7	  nowUtcIso,
     8	  putJsonKV,
     9	  todayUtcDate
    10	} from "./cache-law.js";
    11	
    12	const DEFAULT_CHUNK_SIZE = 50;
    13	const DEFAULT_MAX_CONCURRENCY = 3;
    14	const MAX_CHUNK_SIZE = 200;
    15	const MAX_CONCURRENCY = 5;
    16	
    17	const HEARTBEAT_TTL_SECONDS = 30 * 24 * 60 * 60;
    18	const STATUS_TTL_SECONDS = 7 * 24 * 60 * 60;
    19	const CURSOR_TTL_SECONDS = 6 * 60 * 60;
    20	const ATTEMPT_TTL_SECONDS = 7 * 24 * 60 * 60;
    21	
    22	function safeArray(value) {
    23	  return Array.isArray(value) ? value : [];
    24	}
    25	
    26	function chunkList(items, size) {
    27	  const chunkSize = Math.max(1, Math.min(size, MAX_CHUNK_SIZE));
    28	  const chunks = [];
    29	  for (let i = 0; i < items.length; i += chunkSize) {
    30	    chunks.push(items.slice(i, i + chunkSize));
    31	  }
    32	  return chunks;
    33	}
    34	
    35	async function runWithConcurrency(items, worker, maxConcurrency) {
    36	  const limit = Math.max(1, Math.min(maxConcurrency, MAX_CONCURRENCY));
    37	  const results = new Array(items.length);
    38	  let cursor = 0;
    39	  const runners = new Array(limit).fill(0).map(async () => {
    40	    while (cursor < items.length) {
    41	      const index = cursor;
    42	      cursor += 1;
    43	      try {
    44	        results[index] = await worker(items[index], index);
    45	      } catch (error) {
    46	        results[index] = {
    47	          ok: false,
    48	          reason: "UNHANDLED",
    49	          details: { message: error?.message || String(error || "error") }
    50	        };
    51	      }
    52	    }
    53	  });
    54	  await Promise.all(runners);
    55	  return results;
    56	}
    57	
    58	function normalizeTicker(value) {
    59	  if (typeof value !== "string") return null;
    60	  const trimmed = value.trim().toUpperCase();
    61	  if (!trimmed) return null;
    62	  return trimmed;
    63	}
    64	
    65	let cachedSymbols = null;
    66	
    67	export async function loadSymbols() {
    68	  if (cachedSymbols) return cachedSymbols;
    69	  let payload = null;
    70	  try {
    71	    const mod = await import("../../../config/symbols.json", { assert: { type: "json" } });
    72	    payload = mod?.default ?? mod;
    73	  } catch {
    74	    payload = null;
    75	  }
    76	  if (!payload) {
    77	    try {
    78	      const { createRequire } = await import("node:module");
    79	      const require = createRequire(import.meta.url);
    80	      payload = require("../../../config/symbols.json");
    81	    } catch {
    82	      payload = null;
    83	    }
    84	  }
    85	  const raw = safeArray(payload);
    86	  cachedSymbols = raw.filter((entry) => entry && typeof entry === "object");
    87	  return cachedSymbols;
    88	}
    89	
    90	function buildSymbolIndex(symbols) {
    91	  const byAsset = new Map();
    92	  const byTicker = new Map();
    93	  for (const entry of symbols) {
    94	    const assetId = typeof entry.asset_id === "string" ? entry.asset_id : null;
    95	    const ticker = normalizeTicker(entry.ticker);
    96	    if (assetId) byAsset.set(assetId, entry);
    97	    if (ticker) byTicker.set(ticker, entry);
    98	  }
    99	  return { byAsset, byTicker };
   100	}
   101	
   102	function resolveAssets(inputAssets, symbols) {
   103	  const list = safeArray(inputAssets);
   104	  if (!list.length) return [];
   105	  const index = buildSymbolIndex(symbols);
   106	  const resolved = [];
   107	  for (const item of list) {
   108	    if (typeof item === "string") {
   109	      const ticker = normalizeTicker(item);
   110	      const entry = ticker ? index.byTicker.get(ticker) : null;
   111	      if (entry) {
   112	        resolved.push(entry);
   113	      } else if (ticker) {
   114	        resolved.push({ asset_id: null, ticker, mic: null });
   115	      }
   116	      continue;
   117	    }
   118	    if (item && typeof item === "object") {
   119	      const assetId = typeof item.asset_id === "string" ? item.asset_id : null;
   120	      const ticker = normalizeTicker(item.ticker);
   121	      const entry = assetId ? index.byAsset.get(assetId) : ticker ? index.byTicker.get(ticker) : null;
   122	      if (entry) {
   123	        resolved.push(entry);
   124	        continue;
   125	      }
   126	      if (assetId || ticker) {
   127	        resolved.push({ asset_id: assetId, ticker: ticker || null, mic: item.mic || null });
   128	      }
   129	    }
   130	  }
   131	  return resolved;
   132	}
   133	
   134	function mapUniverseKey(universe) {
   135	  if (!universe) return null;
   136	  const key = String(universe).trim().toLowerCase();
   137	  if (!key) return null;
   138	  if (key === "nasdaq100" || key === "ndx100") return "NDX100";
   139	  if (key === "sp500" || key === "spx") return "SP500";
   140	  if (key === "dow" || key === "dj30") return "DJ30";
   141	  return key.toUpperCase();
   142	}
   143	
   144	function filterByUniverse(symbols, universe) {
   145	  const indexKey = mapUniverseKey(universe);
   146	  if (!indexKey) return [];
   147	  return symbols.filter((entry) => {
   148	    const indexes = Array.isArray(entry?.indexes) ? entry.indexes : [];
   149	    return indexes.includes(indexKey);
   150	  });
   151	}
   152	
   153	async function recordHeartbeat(env, { lastRun, lastOk, status }) {
   154	  if (lastRun) {
   155	    await putJsonKV(env, "meta:scheduler:last_run", lastRun, HEARTBEAT_TTL_SECONDS);
   156	  }
   157	  if (lastOk) {
   158	    await putJsonKV(env, "meta:scheduler:last_ok", lastOk, HEARTBEAT_TTL_SECONDS);
   159	  }
   160	  if (status) {
   161	    await putJsonKV(env, "meta:scheduler:status", status, STATUS_TTL_SECONDS);
   162	  }
   163	}
   164	
   165	async function recordCursor(env, job, runId, chunkIndex, totalChunks) {
   166	  const payload = {
   167	    job,
   168	    run_id: runId,
   169	    chunk_index: chunkIndex,
   170	    total_chunks: totalChunks,
   171	    updated_at: nowUtcIso()
   172	  };
   173	  await putJsonKV(env, `sched:cursor:${job}:${runId}`, payload, CURSOR_TTL_SECONDS);
   174	}
   175	
   176	async function recordAttempt(env, job, assetId, dayKey) {
   177	  if (!assetId) return;
   178	  const key = `sched:attempt:${job}:${assetId}:${dayKey}`;
   179	  await putJsonKV(env, key, { attempted_at: nowUtcIso() }, ATTEMPT_TTL_SECONDS);
   180	}
   181	
   182	async function runEodStockAsset(env, cache, asset, options) {
   183	  const ticker = normalizeTicker(asset?.ticker);
   184	  if (!ticker) {
   185	    return { ok: false, reason: "MISSING_TICKER" };
   186	  }
   187	  await recordAttempt(env, "eod_stock", asset?.asset_id || ticker, options.dayKey);
   188	
   189	  const chainResult = await fetchBarsWithProviderChain(ticker, env, {
   190	    outputsize: "300",
   191	    startDate: options.startDate,
   192	    allowFailover: true
   193	  });
   194	  if (!chainResult.ok) {
   195	    return {
   196	      ok: false,
   197	      reason: chainResult.error?.code || "EOD_FETCH_FAILED",
   198	      details: chainResult.error || null
   199	    };
   200	  }

## FILE: functions/api/_shared/static-handler.js
     1	function nowIso() {
     2	  return new Date().toISOString();
     3	}
     4	
     5	function isHtmlLike(text) {
     6	  return /<!doctype|<html/i.test(text || "");
     7	}
     8	
     9	function json(payload, status = 200) {
    10	  return new Response(JSON.stringify(payload), {
    11	    status,
    12	    headers: {
    13	      "Content-Type": "application/json; charset=utf-8",
    14	      "Cache-Control": "no-store"
    15	    }
    16	  });
    17	}
    18	
    19	function buildEnvelope({ ok, feature, data, error, staticPath, traceId }) {
    20	  const st = ok ? "OK" : "ERROR";
    21	  const err = ok ? null : (error || { code: "ERROR", message: "unknown error" });
    22	  const ts = nowIso();
    23	  return {
    24	    ok: Boolean(ok),
    25	    feature: String(feature || "unknown"),
    26	    data: data ?? null,
    27	    error: err,
    28	    meta: {
    29	      status: st,
    30	      reason: ok ? "" : (err?.code || "ERROR"),
    31	      ts,
    32	      schemaVersion: 1,
    33	      traceId: traceId || "static",
    34	      writeMode: "NONE",
    35	      circuitOpen: false,
    36	      warnings: [],
    37	      savedAt: null,
    38	      ageMinutes: null,
    39	      source: "static-first",
    40	      emptyReason: null,
    41	      staticPath: staticPath || null
    42	    }
    43	  };
    44	}
    45	
    46	const STATIC_MAP = {
    47	  "bundle": "/data/bundle.json",
    48	  "render-plan": "/data/render-plan.json",
    49	  "system-health": "/data/system-health.json",
    50	  "provider-state": "/data/provider-state.json",
    51	  "usage-report": "/data/usage-report.json",
    52	  "error-summary": "/data/error-summary.json",
    53	  "seed-manifest": "/data/seed-manifest.json",
    54	  "health": "/data/system-health.json",
    55	  "health-report": "/data/system-health.json"
    56	};
    57	
    58	function resolveStaticPath(apiName) {
    59	  if (!apiName) return null;
    60	  if (apiName.startsWith("snapshots/")) {
    61	    const id = apiName.slice("snapshots/".length);
    62	    return id ? `/data/snapshots/${id}.json` : null;
    63	  }
    64	  if (STATIC_MAP[apiName]) return STATIC_MAP[apiName];
    65	  return `/data/snapshots/${apiName}.json`;
    66	}
    67	
    68	async function fetchStaticJson(request, apiName, staticPath) {
    69	  const traceId =
    70	    request.headers.get("x-rv-trace-id") || request.headers.get("x-rv-trace") || "static";
    71	  if (!staticPath) {
    72	    return json(
    73	      buildEnvelope({
    74	        ok: false,
    75	        feature: apiName,
    76	        data: null,
    77	        error: { code: "STATIC_MISSING", message: "No static mapping" },
    78	        staticPath: null,
    79	        traceId
    80	      })
    81	    );
    82	  }
    83	
    84	  const target = new URL(staticPath, new URL(request.url).origin);
    85	  try {
    86	    const res = await fetch(target.toString(), { headers: { Accept: "application/json" } });
    87	    const text = await res.text();
    88	
    89	    if (!res.ok) {
    90	      return json(
    91	        buildEnvelope({
    92	          ok: false,
    93	          feature: apiName,
    94	          data: null,
    95	          error: { code: "STATIC_MISSING", message: `${staticPath} unavailable (HTTP ${res.status})` },
    96	          staticPath,
    97	          traceId
    98	        })
    99	      );
   100	    }
   101	
   102	    if (!text || isHtmlLike(text)) {
   103	      return json(
   104	        buildEnvelope({
   105	          ok: false,
   106	          feature: apiName,
   107	          data: null,
   108	          error: { code: "STATIC_NOT_JSON", message: `${staticPath} did not return JSON` },
   109	          staticPath,
   110	          traceId
   111	        })
   112	      );
   113	    }
   114	
   115	    let parsed;
   116	    try {
   117	      parsed = JSON.parse(text);
   118	    } catch {
   119	      return json(
   120	        buildEnvelope({
   121	          ok: false,
   122	          feature: apiName,
   123	          data: null,
   124	          error: { code: "STATIC_INVALID_JSON", message: `${staticPath} returned invalid JSON` },
   125	          staticPath,
   126	          traceId
   127	        })
   128	      );
   129	    }
   130	
   131	    return json(
   132	      buildEnvelope({
   133	        ok: true,
   134	        feature: apiName,
   135	        data: parsed,
   136	        error: null,
   137	        staticPath,
   138	        traceId
   139	      })
   140	    );
   141	  } catch (error) {
   142	    return json(
   143	      buildEnvelope({
   144	        ok: false,
   145	        feature: apiName,
   146	        data: null,
   147	        error: { code: "STATIC_FETCH_FAILED", message: String(error?.message || error || "") },
   148	        staticPath,
   149	        traceId
   150	      })
   151	    );
   152	  }
   153	}
   154	
   155	export async function onRequest(context) {
   156	  const { request } = context;
   157	  const url = new URL(request.url);
   158	  const apiName = url.pathname.replace(/^\/api\//, "").replace(/\/+$/, "");
   159	  const staticPath = resolveStaticPath(apiName);
   160	  return fetchStaticJson(request, apiName || "unknown", staticPath);
   161	}
   162	
   163	export { resolveStaticPath };

## FILE: functions/api/_shared/static-only-backup.js
     1	/**
     2	 * Static JSON server for Cloudflare Pages Functions
     3	 * CRITICAL: Uses fetch() not fs - Cloudflare Workers Runtime!
     4	 * Supports v3.0 snapshot structure with backward compatibility transformation
     5	 */
     6	
     7	/**
     8	 * Transform v3.0 snapshot to legacy format for backward compatibility
     9	 * v3.0: { schema_version, metadata, data: [dataObject], error }
    10	 * Legacy: { ok, data: dataObject, meta: { status, updatedAt, source } }
    11	 */
    12	function transformV3ToLegacy(v3Snapshot) {
    13	  const metadata = v3Snapshot.metadata || {};
    14	  const dataArray = v3Snapshot.data || [];
    15	  
    16	  // Extract first data object from array (v3.0 wraps data in array)
    17	  const dataObject = dataArray[0] || {};
    18	  
    19	  return {
    20	    ok: true,
    21	    data: dataObject,
    22	    meta: {
    23	      status: metadata.validation?.passed ? "OK" : "PARTIAL",
    24	      updatedAt: metadata.published_at || metadata.fetched_at || new Date().toISOString(),
    25	      source: metadata.source || "unknown",
    26	      fetchedAt: metadata.fetched_at,
    27	      digest: metadata.digest,
    28	      validation: metadata.validation
    29	    },
    30	    schemaVersion: "v1", // Legacy format identifier
    31	    error: v3Snapshot.error || null
    32	  };
    33	}
    34	
    35	/**
    36	 * Module-specific transformations for field name mismatches
    37	 * Some legacy frontends expect different field names than the snapshots provide
    38	 */
    39	function applyModuleTransformations(moduleName, parsed) {
    40	  // Clone to avoid mutation
    41	  const result = JSON.parse(JSON.stringify(parsed));
    42	  
    43	  // S&P 500 Sectors: Frontend expects "sectors" but snapshot has "items"
    44	  if (moduleName === "sp500-sectors" && result.data?.items && !result.data?.sectors) {
    45	    result.data.sectors = result.data.items.map(item => ({
    46	      ...item,
    47	      // Map changePercent to r1d (1 day return) - use ?? instead of || to handle 0 correctly
    48	      r1d: item.changePercent ?? item.r1d ?? null,
    49	      r1w: item.r1w ?? null,
    50	      r1m: item.r1m ?? null,
    51	      r1y: item.r1y ?? null
    52	    }));
    53	    console.log(`[Transform] sp500-sectors: Mapped items  sectors with r1d field (${result.data.sectors.length} items)`);
    54	  }
    55	
    56	  // Sector Rotation: Same issue
    57	  if (moduleName === "sector-rotation" && result.data?.items && !result.data?.sectors) {
    58	    result.data.sectors = result.data.items.map(item => ({
    59	      ...item,
    60	      // Use ?? to correctly handle 0 values
    61	      r1d: item.changePercent ?? item.r1d ?? null,
    62	      r1w: item.r1w ?? null,
    63	      r1m: item.r1m ?? null,
    64	      r1y: item.r1y ?? null
    65	    }));
    66	    console.log(`[Transform] sector-rotation: Mapped items  sectors with r1d field (${result.data.sectors.length} items)`);
    67	  }
    68	  
    69	  return result;
    70	}
    71	
    72	export async function serveStaticJson(req) {
    73	  const url = new URL(req.url);
    74	  const moduleName = url.pathname.replace(/^\/api\//, "").replace(/\/$/, "") || "bundle";
    75	  const isDebug = url.searchParams.has("debug");
    76	  
    77	  // Try MULTIPLE paths for maximum compatibility:
    78	  const pathsToTry = [
    79	    { path: `/data/snapshots/${moduleName}/latest.json`, type: "v3_directory" },
    80	    { path: `/data/snapshots/${moduleName}.json`, type: "v3_flat" },        // NEW: Flat in snapshots/
    81	    { path: `/data/${moduleName}.json`, type: "legacy" }
    82	  ];
    83	  
    84	  let lastError = null;
    85	  
    86	  // Try each path in order
    87	  for (const { path, type } of pathsToTry) {
    88	    try {
    89	      const fetchUrl = new URL(path, url.origin);
    90	      const response = await fetch(fetchUrl.toString());
    91	      
    92	      if (response.ok) {
    93	        const text = await response.text();
    94	        let parsed = JSON.parse(text);
    95	        
    96	        const isV3 = parsed.schema_version === "3.0" || parsed.schemaVersion === "v3";
    97	        let transformed = false;
    98	        
    99	        // Transform v3.0 to legacy format for backward compatibility
   100	        if (parsed.schema_version === "3.0") {
   101	          parsed = transformV3ToLegacy(parsed);
   102	          transformed = true;
   103	        }
   104	        
   105	        // Apply module-specific transformations (field name mappings, etc.)
   106	        // THIS RUNS FOR ALL FORMATS (v3.0, v3 legacy, and flat legacy)
   107	        parsed = applyModuleTransformations(moduleName, parsed);
   108	        
   109	        // Ensure 'ok' field is set for legacy frontend compatibility
   110	        if (parsed.ok === undefined || parsed.ok === null) {
   111	          parsed.ok = true; // Default to true if data was successfully loaded
   112	        }
   113	        
   114	        const headers = {
   115	          "Content-Type": "application/json",
   116	          "X-RV-Source": type,
   117	          "X-RV-Transformed": transformed ? "true" : "false",
   118	          "Cache-Control": "public, max-age=60"
   119	        };
   120	        
   121	        // Debug mode: wrap with metadata
   122	        if (isDebug) {
   123	          const debugResponse = {
   124	            debug: true,
   125	            source: type,
   126	            file_path: path,
   127	            transformed,
   128	            snapshot: parsed
   129	          };
   130	          return new Response(JSON.stringify(debugResponse, null, 2), { headers });
   131	        }
   132	        
   133	        return new Response(JSON.stringify(parsed), { headers });
   134	      }
   135	    } catch (err) {
   136	      lastError = err;
   137	      console.log(`${type} fetch failed for ${moduleName} at ${path}:`, err.message);
   138	    }
   139	  }
   140	  
   141	  // ALL PATHS FAILED - Return 404 with helpful error
   142	  const triedPaths = pathsToTry.map(p => p.path);
   143	  return new Response(
   144	    JSON.stringify({ 
   145	      ok: false, 
   146	      error: "SNAPSHOT_NOT_FOUND", 
   147	      tried_paths: triedPaths,
   148	      message: `No snapshot found for ${moduleName}. Tried ${triedPaths.length} locations.`,
   149	      last_error: lastError?.message || null
   150	    }),
   151	    { 
   152	      status: 404, 
   153	      headers: { "Content-Type": "application/json" } 
   154	    }
   155	  );
   156	}

## FILE: functions/api/_shared/static-only-v3.js
     1	/**
     2	 * Static JSON API Server v3.0 - Enhanced with Debug Mode
     3	 * 
     4	 * Features:
     5	 * - v3.0 snapshot serving
     6	 * - Backward compatibility transformation
     7	 * - ?debug=1 full diagnostic mode
     8	 * - Proof Chain evaluation
     9	 * - Failure hints integration
    10	 * - Module state inspection
    11	 */
    12	
    13	/**
    14	 * Transform v3.0 snapshot to legacy format
    15	 */
    16	function transformV3ToLegacy(v3Snapshot) {
    17	  const metadata = v3Snapshot.metadata || {};
    18	  const dataArray = v3Snapshot.data || [];
    19	  const dataObject = dataArray[0] || {};
    20	  
    21	  return {
    22	    ok: true,
    23	    data: dataObject,
    24	    meta: {
    25	      status: metadata.validation?.passed ? "OK" : "PARTIAL",
    26	      updatedAt: metadata.published_at || metadata.fetched_at || new Date().toISOString(),
    27	      source: metadata.source || "unknown",
    28	      fetchedAt: metadata.fetched_at,
    29	      digest: metadata.digest,
    30	      validation: metadata.validation
    31	    },
    32	    schemaVersion: "v1",
    33	    error: v3Snapshot.error || null
    34	  };
    35	}
    36	
    37	/**
    38	 * Module-specific transformations
    39	 */
    40	function applyModuleTransformations(moduleName, parsed) {
    41	  const result = JSON.parse(JSON.stringify(parsed));
    42	  
    43	  // S&P 500 Sectors & Sector Rotation: items  sectors
    44	  if ((moduleName === "sp500-sectors" || moduleName === "sector-rotation") && 
    45	      result.data?.items && !result.data?.sectors) {
    46	    result.data.sectors = result.data.items.map(item => ({
    47	      ...item,
    48	      r1d: item.changePercent ?? item.r1d ?? null,
    49	      r1w: item.r1w ?? null,
    50	      r1m: item.r1m ?? null,
    51	      r1y: item.r1y ?? null
    52	    }));
    53	  }
    54	  
    55	  return result;
    56	}
    57	
    58	/**
    59	 * Evaluate Proof Chain for a snapshot
    60	 */
    61	function evaluateProofChain(snapshot, moduleConfig) {
    62	  const proofChain = {
    63	    FILE: 'UNKNOWN',
    64	    SCHEMA: 'UNKNOWN',
    65	    PLAUS: 'UNKNOWN',
    66	    UI: 'UNKNOWN',
    67	    FRESH: 'UNKNOWN',
    68	    DELIVERY: 'PASS' // Assumed PASS if we got here
    69	  };
    70	  
    71	  if (!snapshot) {
    72	    proofChain.FILE = 'FAIL';
    73	    return proofChain;
    74	  }
    75	  
    76	  proofChain.FILE = 'PASS';
    77	  
    78	  // SCHEMA Check
    79	  if (snapshot.schema_version === '3.0' && snapshot.metadata && Array.isArray(snapshot.data)) {
    80	    proofChain.SCHEMA = 'PASS';
    81	  } else {
    82	    proofChain.SCHEMA = 'FAIL';
    83	  }
    84	  
    85	  // PLAUS Check
    86	  if (snapshot.metadata?.validation?.passed) {
    87	    proofChain.PLAUS = 'PASS';
    88	  } else {
    89	    proofChain.PLAUS = 'FAIL';
    90	  }
    91	  
    92	  // UI Check
    93	  const uiRequired = moduleConfig?.ui_contract?.policy === 'always' ||
    94	                     (moduleConfig?.ui_contract?.policy === 'always_for_critical' && moduleConfig?.tier === 'critical');
    95	  
    96	  if (uiRequired) {
    97	    if (snapshot.metadata?.validation?.passed) {
    98	      proofChain.UI = 'PASS';
    99	    } else {
   100	      proofChain.UI = 'FAIL';
   101	    }
   102	  } else {
   103	    proofChain.UI = 'SKIP';
   104	  }
   105	  
   106	  // FRESH Check
   107	  if (snapshot.metadata?.freshness) {
   108	    const ageMinutes = snapshot.metadata.freshness.age_minutes;
   109	    const expected = snapshot.metadata.freshness.expected_interval_minutes;
   110	    const grace = snapshot.metadata.freshness.grace_minutes;
   111	    
   112	    if (ageMinutes <= expected) {
   113	      proofChain.FRESH = 'PASS';
   114	    } else if (ageMinutes <= expected + grace) {
   115	      proofChain.FRESH = 'WARN';
   116	    } else {
   117	      proofChain.FRESH = 'FAIL';
   118	    }
   119	  }
   120	  
   121	  return proofChain;
   122	}
   123	
   124	/**
   125	 * Determine failure class and hint
   126	 */
   127	function getFailureInfo(snapshot, proofChain) {
   128	  if (proofChain.FILE === 'FAIL') {
   129	    return {
   130	      class: 'ASSET_FETCH_FAILED',
   131	      hint: 'Check Cloudflare Pages deployment'
   132	    };
   133	  }
   134	  
   135	  if (proofChain.SCHEMA === 'FAIL') {
   136	    return {
   137	      class: 'VALIDATION_FAILED_SCHEMA',
   138	      hint: 'Update provider to v3.0 schema'
   139	    };
   140	  }
   141	  
   142	  if (proofChain.PLAUS === 'FAIL') {
   143	    return {
   144	      class: 'PLAUSIBILITY_FAILED',
   145	      hint: 'Check data source or adjust plausibility rules'
   146	    };
   147	  }
   148	  
   149	  if (proofChain.UI === 'FAIL') {
   150	    return {
   151	      class: 'UI_CONTRACT_FAILED',
   152	      hint: 'Fix provider to include required UI fields'
   153	    };
   154	  }
   155	  
   156	  if (proofChain.FRESH === 'FAIL') {
   157	    return {
   158	      class: 'STALE_DATA',
   159	      hint: 'Check scraper schedule and provider availability'
   160	    };
   161	  }
   162	  
   163	  return {
   164	    class: null,
   165	    hint: null
   166	  };
   167	}
   168	
   169	/**
   170	 * Build debug response
   171	 */
   172	async function buildDebugResponse(moduleName, snapshot, moduleConfig, sourceInfo, url) {
   173	  const proofChain = evaluateProofChain(snapshot, moduleConfig);
   174	  const failureInfo = getFailureInfo(snapshot, proofChain);
   175	  
   176	  // Try to load module state
   177	  let moduleState = null;
   178	  try {
   179	    const stateUrl = new URL(`/data/state/modules/${moduleName}.json`, url.origin);
   180	    const stateResponse = await fetch(stateUrl.toString());
   181	    if (stateResponse.ok) {
   182	      moduleState = await stateResponse.json();
   183	    }
   184	  } catch (e) {
   185	    // Module state optional for debug
   186	  }
   187	  
   188	  // Try to load manifest
   189	  let manifestEntry = null;
   190	  try {
   191	    const manifestUrl = new URL('/data/manifest.json', url.origin);
   192	    const manifestResponse = await fetch(manifestUrl.toString());
   193	    if (manifestResponse.ok) {
   194	      const manifest = await manifestResponse.json();
   195	      manifestEntry = manifest.modules?.[moduleName] || null;
   196	    }
   197	  } catch (e) {
   198	    // Manifest optional for debug
   199	  }
   200	  

## FILE: functions/api/_shared/static-only.js
     1	import { isPrivilegedDebug, redact } from "./observability.js";
     2	
     3	/**
     4	 * Static JSON API Server v3.0 - Enhanced with Debug Mode
     5	 * 
     6	 * Features:
     7	 * - v3.0 snapshot serving
     8	 * - Backward compatibility transformation
     9	 * - ?debug=1 full diagnostic mode
    10	 * - Proof Chain evaluation
    11	 * - Failure hints integration
    12	 * - Module state inspection
    13	 */
    14	
    15	/**
    16	 * Transform v3.0 snapshot to legacy format
    17	 */
    18	function transformV3ToLegacy(v3Snapshot) {
    19	  const metadata = v3Snapshot.metadata || {};
    20	  const dataArray = v3Snapshot.data || [];
    21	  const dataObject = dataArray[0] || {};
    22	
    23	  return {
    24	    ok: true,
    25	    data: dataObject,
    26	    meta: {
    27	      status: metadata.validation?.passed ? "OK" : "PARTIAL",
    28	      updatedAt: metadata.published_at || metadata.fetched_at || new Date().toISOString(),
    29	      source: metadata.source || "unknown",
    30	      fetchedAt: metadata.fetched_at,
    31	      digest: metadata.digest,
    32	      validation: metadata.validation
    33	    },
    34	    schemaVersion: "v1",
    35	    error: v3Snapshot.error || null
    36	  };
    37	}
    38	
    39	/**
    40	 * Module-specific transformations
    41	 */
    42	function applyModuleTransformations(moduleName, parsed) {
    43	  const result = JSON.parse(JSON.stringify(parsed));
    44	
    45	  // S&P 500 Sectors & Sector Rotation: items  sectors
    46	  if ((moduleName === "sp500-sectors" || moduleName === "sector-rotation") &&
    47	    result.data?.items && !result.data?.sectors) {
    48	    result.data.sectors = result.data.items.map(item => ({
    49	      ...item,
    50	      r1d: item.changePercent ?? item.r1d ?? null,
    51	      r1w: item.r1w ?? null,
    52	      r1m: item.r1m ?? null,
    53	      r1y: item.r1y ?? null
    54	    }));
    55	  }
    56	
    57	  return result;
    58	}
    59	
    60	/**
    61	 * Evaluate Proof Chain for a snapshot
    62	 */
    63	function evaluateProofChain(snapshot, moduleConfig) {
    64	  const proofChain = {
    65	    FILE: 'UNKNOWN',
    66	    SCHEMA: 'UNKNOWN',
    67	    PLAUS: 'UNKNOWN',
    68	    UI: 'UNKNOWN',
    69	    FRESH: 'UNKNOWN',
    70	    DELIVERY: 'PASS' // Assumed PASS if we got here
    71	  };
    72	
    73	  if (!snapshot) {
    74	    proofChain.FILE = 'FAIL';
    75	    return proofChain;
    76	  }
    77	
    78	  proofChain.FILE = 'PASS';
    79	
    80	  // SCHEMA Check
    81	  if (snapshot.schema_version === '3.0' && snapshot.metadata && Array.isArray(snapshot.data)) {
    82	    proofChain.SCHEMA = 'PASS';
    83	  } else {
    84	    proofChain.SCHEMA = 'FAIL';
    85	  }
    86	
    87	  // PLAUS Check
    88	  if (snapshot.metadata?.validation?.passed) {
    89	    proofChain.PLAUS = 'PASS';
    90	  } else {
    91	    proofChain.PLAUS = 'FAIL';
    92	  }
    93	
    94	  // UI Check
    95	  const uiRequired = moduleConfig?.ui_contract?.policy === 'always' ||
    96	    (moduleConfig?.ui_contract?.policy === 'always_for_critical' && moduleConfig?.tier === 'critical');
    97	
    98	  if (uiRequired) {
    99	    if (snapshot.metadata?.validation?.passed) {
   100	      proofChain.UI = 'PASS';
   101	    } else {
   102	      proofChain.UI = 'FAIL';
   103	    }
   104	  } else {
   105	    proofChain.UI = 'SKIP';
   106	  }
   107	
   108	  // FRESH Check
   109	  if (snapshot.metadata?.freshness) {
   110	    const ageMinutes = snapshot.metadata.freshness.age_minutes;
   111	    const expected = snapshot.metadata.freshness.expected_interval_minutes;
   112	    const grace = snapshot.metadata.freshness.grace_minutes;
   113	
   114	    if (ageMinutes <= expected) {
   115	      proofChain.FRESH = 'PASS';
   116	    } else if (ageMinutes <= expected + grace) {
   117	      proofChain.FRESH = 'WARN';
   118	    } else {
   119	      proofChain.FRESH = 'FAIL';
   120	    }
   121	  }
   122	
   123	  return proofChain;
   124	}
   125	
   126	/**
   127	 * Determine failure class and hint
   128	 */
   129	function getFailureInfo(snapshot, proofChain) {
   130	  if (proofChain.FILE === 'FAIL') {
   131	    return {
   132	      class: 'ASSET_FETCH_FAILED',
   133	      hint: 'Check Cloudflare Pages deployment'
   134	    };
   135	  }
   136	
   137	  if (proofChain.SCHEMA === 'FAIL') {
   138	    return {
   139	      class: 'VALIDATION_FAILED_SCHEMA',
   140	      hint: 'Update provider to v3.0 schema'
   141	    };
   142	  }
   143	
   144	  if (proofChain.PLAUS === 'FAIL') {
   145	    return {
   146	      class: 'PLAUSIBILITY_FAILED',
   147	      hint: 'Check data source or adjust plausibility rules'
   148	    };
   149	  }
   150	
   151	  if (proofChain.UI === 'FAIL') {
   152	    return {
   153	      class: 'UI_CONTRACT_FAILED',
   154	      hint: 'Fix provider to include required UI fields'
   155	    };
   156	  }
   157	
   158	  if (proofChain.FRESH === 'FAIL') {
   159	    return {
   160	      class: 'STALE_DATA',
   161	      hint: 'Check scraper schedule and provider availability'
   162	    };
   163	  }
   164	
   165	  return {
   166	    class: null,
   167	    hint: null
   168	  };
   169	}
   170	
   171	/**
   172	 * Build debug response
   173	 */
   174	async function buildDebugResponse(moduleName, snapshot, moduleConfig, sourceInfo, url) {
   175	  const proofChain = evaluateProofChain(snapshot, moduleConfig);
   176	  const failureInfo = getFailureInfo(snapshot, proofChain);
   177	  const isSuccess = Object.values(proofChain).every(v => v === 'PASS' || v === 'SKIP');
   178	  const todayUtc = new Date().toISOString().slice(0, 10);
   179	
   180	  const kvBackend = sourceInfo?.kv_backend || null;
   181	  let suggestedAction = failureInfo.hint || 'Data is healthy';
   182	  if (kvBackend === 'MISSING') {
   183	    suggestedAction = 'KV backend is unavailable. Ensure Cloudflare Pages KV binding RV_KV is configured and enabled for this environment.';
   184	  }
   185	
   186	  // Try to load module state
   187	  let moduleState = null;
   188	  try {
   189	    const stateUrl = new URL(`/data/state/modules/${moduleName}.json`, url.origin);
   190	    const stateResponse = await fetch(stateUrl.toString());
   191	    if (stateResponse.ok) {
   192	      moduleState = await stateResponse.json();
   193	    }
   194	  } catch (e) {
   195	    // Module state optional for debug
   196	  }
   197	
   198	  // Try to load manifest
   199	  let manifestEntry = null;
   200	  try {

## FILE: functions/api/_shared/symbol-resolver.mjs
     1	const TICKER_MAX_LENGTH = 15;
     2	const VALID_TICKER_REGEX = /^[A-Z0-9.\-]+$/;
     3	
     4	function normalizeQuery(raw) {
     5	  if (typeof raw !== 'string') return null;
     6	  const trimmed = raw.trim();
     7	  if (!trimmed) return null;
     8	  return trimmed;
     9	}
    10	
    11	export function normalizeTicker(raw) {
    12	  if (typeof raw !== 'string') return null;
    13	  const trimmed = raw.trim();
    14	  if (!trimmed) return null;
    15	  if (trimmed.length > TICKER_MAX_LENGTH) return null;
    16	  if (/\s/.test(trimmed)) return null;
    17	  const normalized = trimmed.toUpperCase();
    18	  if (!VALID_TICKER_REGEX.test(normalized)) return null;
    19	  return normalized;
    20	}
    21	
    22	function normalizeNameKey(input) {
    23	  return String(input || '')
    24	    .trim()
    25	    .toLowerCase()
    26	    .replace(/\s+/g, ' ');
    27	}
    28	
    29	async function fetchResolveIndex(request) {
    30	  const baseUrl = new URL(request.url);
    31	  const url = new URL('/data/symbol-resolve.v1.json', baseUrl);
    32	  const response = await fetch(url.toString());
    33	  if (!response.ok) {
    34	    const error = new Error(`HTTP ${response.status}`);
    35	    error.code = 'RESOLVE_INDEX_UNAVAILABLE';
    36	    throw error;
    37	  }
    38	  const payload = await response.json();
    39	  return payload;
    40	}
    41	
    42	function buildNameMap(indexPayload) {
    43	  const entries = Array.isArray(indexPayload?.entries) ? indexPayload.entries : [];
    44	  const map = new Map();
    45	  for (const entry of entries) {
    46	    if (!entry || typeof entry !== 'object') continue;
    47	    const ticker = normalizeTicker(entry.ticker);
    48	    if (!ticker) continue;
    49	    const name = typeof entry.name === 'string' && entry.name.trim() ? entry.name.trim() : null;
    50	    const aliases = Array.isArray(entry.aliases) ? entry.aliases : [];
    51	    const keys = new Set();
    52	    if (name) keys.add(normalizeNameKey(name));
    53	    for (const alias of aliases) {
    54	      const key = normalizeNameKey(alias);
    55	      if (key) keys.add(key);
    56	    }
    57	    for (const key of keys) {
    58	      if (!key) continue;
    59	      if (!map.has(key)) {
    60	        map.set(key, { ticker, name });
    61	      }
    62	    }
    63	  }
    64	  return map;
    65	}
    66	
    67	export async function resolveSymbol(query, request) {
    68	  const normalized = normalizeQuery(query);
    69	  if (!normalized) {
    70	    return {
    71	      ok: false,
    72	      error: {
    73	        code: 'BAD_REQUEST',
    74	        message: 'Missing query parameter',
    75	        details: { query }
    76	      }
    77	    };
    78	  }
    79	
    80	  const asTicker = normalizeTicker(normalized);
    81	  const treatAsTicker = asTicker && normalized === normalized.toUpperCase();
    82	  if (treatAsTicker) {
    83	    let name = null;
    84	    try {
    85	      const indexPayload = await fetchResolveIndex(request);
    86	      const map = buildNameMap(indexPayload);
    87	      for (const item of map.values()) {
    88	        if (item.ticker === asTicker) {
    89	          name = item.name;
    90	          break;
    91	        }
    92	      }
    93	    } catch {
    94	      // ignore
    95	    }
    96	
    97	    return {
    98	      ok: true,
    99	      data: {
   100	        ticker: asTicker,
   101	        name,
   102	        confidence: 1,
   103	        method: 'ticker'
   104	      }
   105	    };
   106	  }
   107	
   108	  let indexPayload;
   109	  try {
   110	    indexPayload = await fetchResolveIndex(request);
   111	  } catch (error) {
   112	    return {
   113	      ok: false,
   114	      error: {
   115	        code: error.code || 'RESOLVE_INDEX_UNAVAILABLE',
   116	        message: 'Resolve index is not available',
   117	        details: { message: error.message }
   118	      }
   119	    };
   120	  }
   121	
   122	  const key = normalizeNameKey(normalized);
   123	  const map = buildNameMap(indexPayload);
   124	  const hit = map.get(key) || null;
   125	  if (!hit) {
   126	    return {
   127	      ok: false,
   128	      error: {
   129	        code: 'SYMBOL_NOT_FOUND',
   130	        message: 'Unable to resolve symbol',
   131	        details: { query: normalized }
   132	      }
   133	    };
   134	  }
   135	
   136	  return {
   137	    ok: true,
   138	    data: {
   139	      ticker: hit.ticker,
   140	      name: hit.name,
   141	      confidence: 0.95,
   142	      method: 'name_exact'
   143	    }
   144	  };
   145	}

## FILE: functions/api/debug-bundle.js
     1	import { serveStaticJson } from "./_shared/static-only.js";
     2	
     3	export async function onRequestGet(context) {
     4	  try {
     5	    const res = await serveStaticJson(context.request, "debug-bundle", null, context);
     6	    if (res && typeof res.status === "number" && res.status === 503) {
     7	      throw new Error("DEBUG_BUNDLE_UPSTREAM_503");
     8	    }
     9	    return res;
    10	  } catch (error) {
    11	    const now = new Date().toISOString();
    12	    const payload = {
    13	      ok: true,
    14	      data: {
    15	        items: [],
    16	        summary: {
    17	          status: "STUB",
    18	          message: "Debug bundle not available yet"
    19	        }
    20	      },
    21	      meta: {
    22	        status: "STUB",
    23	        reason: "ASSET_MISSING",
    24	        updatedAt: now,
    25	        source: "stub",
    26	        fetchedAt: now,
    27	        digest: null,
    28	        validation: {
    29	          passed: true
    30	        }
    31	      },
    32	      schemaVersion: "v1",
    33	      error: null
    34	    };
    35	    return new Response(JSON.stringify(payload), {
    36	      status: 200,
    37	      headers: {
    38	        "Content-Type": "application/json",
    39	        "Cache-Control": "no-store",
    40	        "X-RV-Source": "DEBUG_BUNDLE_FALLBACK"
    41	      }
    42	    });
    43	  }
    44	}

## FILE: functions/api/debug-matrix.js
     1	import { serveStaticJson } from "./_shared/static-only.js";
     2	
     3	export async function onRequestGet(context) {
     4	  try {
     5	    const res = await serveStaticJson(context.request, "debug-matrix", null, context);
     6	    if (res && typeof res.status === "number" && res.status === 503) {
     7	      throw new Error("DEBUG_MATRIX_UPSTREAM_503");
     8	    }
     9	    return res;
    10	  } catch (error) {
    11	    const now = new Date().toISOString();
    12	    const payload = {
    13	      ok: true,
    14	      data: {
    15	        blocks: [],
    16	        summary: {
    17	          status: "STUB",
    18	          message: "Debug matrix not available yet"
    19	        }
    20	      },
    21	      meta: {
    22	        status: "STUB",
    23	        reason: "ASSET_MISSING",
    24	        updatedAt: now,
    25	        source: "stub",
    26	        fetchedAt: now,
    27	        digest: null,
    28	        validation: {
    29	          passed: true
    30	        }
    31	      },
    32	      schemaVersion: "v1",
    33	      error: null
    34	    };
    35	    return new Response(JSON.stringify(payload), {
    36	      status: 200,
    37	      headers: {
    38	        "Content-Type": "application/json",
    39	        "Cache-Control": "no-store",
    40	        "X-RV-Source": "DEBUG_MATRIX_FALLBACK"
    41	      }
    42	    });
    43	  }
    44	}

## FILE: functions/api/diag.js
     1	import { serveStaticJson } from "./_shared/static-only.js";
     2	
     3	export async function onRequestGet(context) {
     4	  try {
     5	    const res = await serveStaticJson(context.request, "diag", null, context);
     6	    if (res && typeof res.status === "number" && res.status === 503) {
     7	      throw new Error("DIAG_UPSTREAM_503");
     8	    }
     9	    return res;
    10	  } catch (error) {
    11	    const now = new Date().toISOString();
    12	    const payload = {
    13	      ok: true,
    14	      data: {
    15	        summary: {
    16	          status: "STUB",
    17	          reason: "DIAG_ASSET_MISSING",
    18	          message: "Diagnostic snapshot is not available yet"
    19	        },
    20	        snapshots: []
    21	      },
    22	      meta: {
    23	        status: "STUB",
    24	        reason: "DIAG_ASSET_MISSING",
    25	        updatedAt: now,
    26	        source: "stub",
    27	        fetchedAt: now,
    28	        digest: null,
    29	        validation: {
    30	          passed: true
    31	        }
    32	      },
    33	      schemaVersion: "v1",
    34	      error: null
    35	    };
    36	    return new Response(JSON.stringify(payload), {
    37	      status: 200,
    38	      headers: {
    39	        "Content-Type": "application/json",
    40	        "Cache-Control": "no-store",
    41	        "X-RV-Source": "DIAG_FALLBACK"
    42	      }
    43	    });
    44	  }
    45	}

## FILE: functions/api/diagnostics/tiingo.js
     1	import { sha256Hex } from '../_shared/digest.mjs';
     2	import { getTiingoKeyInfo } from '../_shared/tiingo-key.mjs';
     3	
     4	const MODULE_NAME = 'diagnostics-tiingo';
     5	
     6	async function computeDigest(input) {
     7	  const canonical = JSON.stringify(input);
     8	  const hex = await sha256Hex(canonical);
     9	  return `sha256:${hex}`;
    10	}
    11	
    12	function buildErrorPayload(code, message, details = {}) {
    13	  return {
    14	    code,
    15	    message,
    16	    details
    17	  };
    18	}
    19	
    20	function mapErrorCode({ httpStatus, error }) {
    21	  if (!httpStatus) {
    22	    const name = String(error?.name || '').toLowerCase();
    23	    const msg = String(error?.message || '').toLowerCase();
    24	    if (name.includes('abort') || msg.includes('timeout')) return 'TIMEOUT';
    25	    return 'NETWORK_ERROR';
    26	  }
    27	  if (httpStatus === 401 || httpStatus === 403) return 'AUTH_FAILED';
    28	  return 'HTTP_ERROR';
    29	}
    30	
    31	export async function onRequestGet(context) {
    32	  const { request, env } = context;
    33	  const url = new URL(request.url);
    34	  const isDebug = url.searchParams.get('debug') === '1';
    35	  const startedAtIso = new Date().toISOString();
    36	
    37	  const keyInfo = getTiingoKeyInfo(env);
    38	  const keyPresent = Boolean(keyInfo.key);
    39	
    40	  let canReachTiingo = false;
    41	  let httpStatus = null;
    42	  let errorCode = null;
    43	  let latencyMs = null;
    44	
    45	  if (keyPresent) {
    46	    const controller = new AbortController();
    47	    const timeoutMs = 6000;
    48	    const started = Date.now();
    49	    const timer = setTimeout(() => controller.abort(), timeoutMs);
    50	    try {
    51	      const startDate = new Date(Date.now() - 2 * 24 * 60 * 60 * 1000).toISOString().slice(0, 10);
    52	      const tiingoUrl = new URL('https://api.tiingo.com/tiingo/daily/AAPL/prices');
    53	      tiingoUrl.searchParams.set('token', keyInfo.key);
    54	      tiingoUrl.searchParams.set('resampleFreq', 'daily');
    55	      tiingoUrl.searchParams.set('startDate', startDate);
    56	
    57	      const res = await fetch(tiingoUrl.toString(), {
    58	        method: 'GET',
    59	        headers: { Accept: 'application/json' },
    60	        signal: controller.signal
    61	      });
    62	      httpStatus = res.status;
    63	      canReachTiingo = res.ok;
    64	      latencyMs = Date.now() - started;
    65	      if (!res.ok) {
    66	        errorCode = mapErrorCode({ httpStatus: res.status, error: null });
    67	      }
    68	    } catch (error) {
    69	      latencyMs = Date.now() - started;
    70	      canReachTiingo = false;
    71	      errorCode = mapErrorCode({ httpStatus: null, error });
    72	    } finally {
    73	      clearTimeout(timer);
    74	    }
    75	  } else {
    76	    canReachTiingo = false;
    77	    errorCode = 'MISSING_API_KEY';
    78	  }
    79	
    80	  const payload = {
    81	    schema_version: '3.0',
    82	    metadata: {
    83	      module: MODULE_NAME,
    84	      schema_version: '3.0',
    85	      tier: 'standard',
    86	      domain: 'system',
    87	      source: 'diagnostics',
    88	      fetched_at: startedAtIso,
    89	      published_at: startedAtIso,
    90	      digest: null,
    91	      served_from: 'RUNTIME',
    92	      request: {
    93	        debug: isDebug
    94	      },
    95	      status: canReachTiingo ? 'OK' : 'ERROR',
    96	      telemetry: {
    97	        provider: {
    98	          primary: 'tiingo',
    99	          selected: 'tiingo',
   100	          forced: false,
   101	          fallbackUsed: false,
   102	          primaryFailure: canReachTiingo ? null : errorCode
   103	        },
   104	        latencyMs,
   105	        ok: canReachTiingo,
   106	        httpStatus
   107	      }
   108	    },
   109	    data: {
   110	      keyPresent,
   111	      keySource: keyInfo.source,
   112	      canReachTiingo,
   113	      httpStatus,
   114	      errorCode,
   115	      latencyMs
   116	    },
   117	    error: null
   118	  };
   119	
   120	  if (!canReachTiingo) {
   121	    payload.error = buildErrorPayload(errorCode || 'TIINGO_UNAVAILABLE', 'Tiingo diagnostics failed', {
   122	      httpStatus
   123	    });
   124	    if (!isDebug) {
   125	      payload.error.details = { httpStatus };
   126	    }
   127	  }
   128	
   129	  payload.metadata.digest = await computeDigest(payload);
   130	
   131	  return new Response(JSON.stringify(payload, null, 2) + '\n', {
   132	    headers: { 'Content-Type': 'application/json' }
   133	  });
   134	}

## FILE: functions/api/elliott-scanner.js
     1	/**
     2	 * Elliott Waves Scanner API
     3	 * 
     4	 * DFMSIF v1.0  Deterministic Fractal Market Structure Inference
     5	 * 
     6	 * Scans NASDAQ-100 for Elliott Wave setups using:
     7	 * - Pre-computed marketphase data (AAPL, MSFT)
     8	 * - Heuristic estimation from EOD stats (remaining symbols)
     9	 * 
    10	 * This is NOT prediction  it is rule-based historical structure detection.
    11	 */
    12	
    13	export async function onRequest(context) {
    14	    const startMs = Date.now();
    15	    const baseUrl = new URL(context.request.url).origin;
    16	
    17	    try {
    18	        // Load universe
    19	        const universeRes = await fetch(`${baseUrl}/data/universe/nasdaq100.json`);
    20	        if (!universeRes.ok) {
    21	            return jsonResponse({
    22	                ok: false,
    23	                error: { code: 'UNIVERSE_UNAVAILABLE', message: 'Unable to load universe' },
    24	                setups: []
    25	            }, 503);
    26	        }
    27	
    28	        const universe = await universeRes.json();
    29	        const symbols = Array.isArray(universe)
    30	            ? universe.map(e => ({ ticker: e.ticker?.toUpperCase(), name: e.name })).filter(e => e.ticker)
    31	            : [];
    32	
    33	        // Load EOD batch for basic stats
    34	        const eodRes = await fetch(`${baseUrl}/data/eod/batches/eod.latest.000.json`);
    35	        const eodData = eodRes.ok ? await eodRes.json() : null;
    36	        const eodBySymbol = eodData?.data || {};
    37	
    38	        // Load marketphase index
    39	        const mpIndexRes = await fetch(`${baseUrl}/data/marketphase/index.json`);
    40	        const mpIndex = mpIndexRes.ok ? await mpIndexRes.json() : { symbols: [] };
    41	        const mpSymbols = new Set(mpIndex.symbols || []);
    42	
    43	        // Analyze each symbol
    44	        const setups = [];
    45	
    46	        for (const { ticker, name } of symbols) {
    47	            const eod = eodBySymbol[ticker];
    48	
    49	            // Check if we have pre-computed marketphase data
    50	            if (mpSymbols.has(ticker)) {
    51	                try {
    52	                    const mpRes = await fetch(`${baseUrl}/data/marketphase/${ticker}.json`);
    53	                    if (mpRes.ok) {
    54	                        const mp = await mpRes.json();
    55	                        const elliott = mp?.data?.elliott;
    56	
    57	                        if (elliott) {
    58	                            const setup = extractSetupFromMarketphase(ticker, name, elliott, eod);
    59	                            setups.push(setup);
    60	                            continue;
    61	                        }
    62	                    }
    63	                } catch {
    64	                    // Fall through to heuristic
    65	                }
    66	            }
    67	
    68	            // Heuristic estimation from EOD data
    69	            const setup = estimateWaveFromEOD(ticker, name, eod);
    70	            setups.push(setup);
    71	        }
    72	
    73	        // Sort by confidence descending
    74	        setups.sort((a, b) => (b.confidence || 0) - (a.confidence || 0));
    75	
    76	        return jsonResponse({
    77	            ok: true,
    78	            meta: {
    79	                asOf: new Date().toISOString(),
    80	                durationMs: Date.now() - startMs,
    81	                count: setups.length,
    82	                analyzedFull: mpSymbols.size,
    83	                version: 'DFMSIF_v1.0'
    84	            },
    85	            setups
    86	        });
    87	
    88	    } catch (err) {
    89	        return jsonResponse({
    90	            ok: false,
    91	            error: { code: 'SCANNER_ERROR', message: err.message || String(err) },
    92	            setups: []
    93	        }, 500);
    94	    }
    95	}
    96	
    97	function jsonResponse(data, status = 200) {
    98	    return new Response(JSON.stringify(data), {
    99	        status,
   100	        headers: {
   101	            'Content-Type': 'application/json',
   102	            'Cache-Control': 'public, max-age=300'
   103	        }
   104	    });
   105	}
   106	
   107	function extractSetupFromMarketphase(ticker, name, elliott, eod) {
   108	    const completed = elliott?.completedPattern || {};
   109	    const developing = elliott?.developingPattern || {};
   110	    const fib = elliott?.fib || {};
   111	    const uncertainty = elliott?.uncertainty || {};
   112	
   113	    // Determine wave position from developing pattern
   114	    let wavePosition = 'unknown';
   115	    const possibleWave = developing.possibleWave || '';
   116	
   117	    if (possibleWave.includes('4') || possibleWave.includes('ABC')) {
   118	        wavePosition = completed.valid ? 'pre-wave-5' : 'in-correction';
   119	    } else if (completed.valid && fib.conformanceScore > 50) {
   120	        wavePosition = 'wave-1-start';
   121	    } else {
   122	        wavePosition = 'pre-wave-3';
   123	    }
   124	
   125	    // Override based on rule analysis
   126	    if (!completed.rules?.r2) {
   127	        wavePosition = 'pre-wave-3';
   128	    }
   129	
   130	    const confidence = uncertainty?.confidenceDecay?.adjusted ?? completed.confidence0_100 ?? 0;
   131	
   132	    return {
   133	        ticker,
   134	        name,
   135	        wavePosition,
   136	        confidence,
   137	        direction: completed.direction || 'neutral',
   138	        fibConformance: fib.conformanceScore ?? null,
   139	        validPattern: completed.valid ?? false,
   140	        source: 'marketphase'
   141	    };
   142	}
   143	
   144	function estimateWaveFromEOD(ticker, name, eod) {
   145	    if (!eod) {
   146	        return {
   147	            ticker,
   148	            name,
   149	            wavePosition: 'unknown',
   150	            confidence: 0,
   151	            direction: 'neutral',
   152	            fibConformance: null,
   153	            validPattern: false,
   154	            source: 'unavailable'
   155	        };
   156	    }
   157	
   158	    const close = eod.close;
   159	    const high = eod.high;
   160	    const low = eod.low;
   161	    const open = eod.open;
   162	
   163	    if (!Number.isFinite(close)) {
   164	        return {
   165	            ticker,
   166	            name,
   167	            wavePosition: 'unknown',
   168	            confidence: 0,
   169	            direction: 'neutral',
   170	            fibConformance: null,
   171	            validPattern: false,
   172	            source: 'heuristic'
   173	        };
   174	    }
   175	
   176	    // Estimate direction from today's bar
   177	    const dayChange = (close - open) / open;
   178	    const direction = dayChange >= 0 ? 'bullish' : 'bearish';
   179	
   180	    // Position in day's range
   181	    const range = high - low;
   182	    const positionInRange = range > 0 ? (close - low) / range : 0.5;
   183	
   184	    // Calculate Fibonacci conformance based on close position relative to key Fib levels
   185	    // Key Fib retracement levels: 0%, 23.6%, 38.2%, 50%, 61.8%, 78.6%, 100%
   186	    const fibLevels = [0, 0.236, 0.382, 0.5, 0.618, 0.786, 1.0];
   187	
   188	    // Find nearest Fib level
   189	    let minDistance = 1;
   190	    for (const fibLevel of fibLevels) {
   191	        const distance = Math.abs(positionInRange - fibLevel);
   192	        if (distance < minDistance) {
   193	            minDistance = distance;
   194	        }
   195	    }
   196	
   197	    // Convert distance to conformance score (0-100%)
   198	    // Distance 0 = 100% conformance, Distance 0.5 = 0% conformance
   199	    const fibConformance = Math.max(0, Math.min(100, (1 - minDistance * 2) * 100));
   200	

## FILE: functions/api/fundamentals.js
     1	import { sha256Hex } from './_shared/digest.mjs';
     2	import { getTiingoKeyInfo } from './_shared/tiingo-key.mjs';
     3	import { fetchFmpFundamentals } from './_shared/fundamentals-fmp.mjs';
     4	import { kvGetJson } from '../_lib/kv-safe.js';
     5	
     6	const MODULE_NAME = 'fundamentals';
     7	const TTL_SECONDS = 24 * 60 * 60;
     8	
     9	async function computeDigest(input) {
    10	  const canonical = JSON.stringify(input);
    11	  const hex = await sha256Hex(canonical);
    12	  return `sha256:${hex}`;
    13	}
    14	
    15	function buildErrorPayload(code, message, details = {}) {
    16	  return {
    17	    code,
    18	    message,
    19	    details
    20	  };
    21	}
    22	
    23	function normalizeTicker(raw) {
    24	  const trimmed = String(raw || '').trim();
    25	  if (!trimmed) return null;
    26	  if (trimmed.length > 15) return null;
    27	  if (!/^[A-Z0-9.\-]+$/i.test(trimmed)) return null;
    28	  return trimmed.toUpperCase();
    29	}
    30	
    31	function toNumber(value) {
    32	  const n = Number(value);
    33	  return Number.isFinite(n) ? n : null;
    34	}
    35	
    36	function pick(obj, keys) {
    37	  for (const k of keys) {
    38	    if (obj && Object.prototype.hasOwnProperty.call(obj, k) && obj[k] !== undefined) return obj[k];
    39	  }
    40	  return undefined;
    41	}
    42	
    43	function normalizeFundamentalsFromTiingoRow(ticker, row) {
    44	  const r = row && typeof row === 'object' ? row : {};
    45	
    46	  const companyName = pick(r, ['companyName', 'name', 'tickerName', 'company_name', 'CompanyName']);
    47	
    48	  const marketCap = toNumber(pick(r, ['marketCap', 'marketCapUSD', 'marketCapTtm', 'market_cap']));
    49	  const pe_ttm = toNumber(pick(r, ['peTTM', 'peTtm', 'pe_ttm', 'peRatioTTM', 'peRatio']));
    50	  const ps_ttm = toNumber(pick(r, ['psTTM', 'psTtm', 'ps_ttm', 'priceToSalesTTM']));
    51	  const pb = toNumber(pick(r, ['pb', 'pbRatio', 'priceToBook']));
    52	  const ev_ebitda = toNumber(pick(r, ['evToEbitda', 'evEbitda', 'ev_ebitda']));
    53	
    54	  const revenue_ttm = toNumber(pick(r, ['revenueTTM', 'revenueTtm', 'revenue_ttm']));
    55	  const eps_ttm = toNumber(pick(r, ['epsTTM', 'epsTtm', 'eps_ttm']));
    56	
    57	  const grossMargin = toNumber(pick(r, ['grossMargin', 'grossMarginTTM', 'grossMarginTtm']));
    58	  const operatingMargin = toNumber(pick(r, ['operatingMargin', 'operatingMarginTTM', 'operatingMarginTtm']));
    59	  const netMargin = toNumber(pick(r, ['netMargin', 'netMarginTTM', 'netMarginTtm']));
    60	
    61	  const nextEarningsDate = pick(r, ['nextEarningsDate', 'nextEarnings', 'earningsDate', 'next_earnings_date']);
    62	  const sourceTimestamp = pick(r, ['date', 'asOfDate', 'asOf', 'sourceTimestamp', 'updatedAt']);
    63	
    64	  return {
    65	    ticker,
    66	    companyName: companyName ? String(companyName) : null,
    67	    marketCap,
    68	    pe_ttm,
    69	    ps_ttm,
    70	    pb,
    71	    ev_ebitda,
    72	    revenue_ttm,
    73	    grossMargin,
    74	    operatingMargin,
    75	    netMargin,
    76	    eps_ttm,
    77	    nextEarningsDate: nextEarningsDate ? String(nextEarningsDate) : null,
    78	    updatedAt: sourceTimestamp ? String(sourceTimestamp) : null
    79	  };
    80	}
    81	
    82	function buildWatermark({ servedFrom, status, data }) {
    83	  const dataSource = servedFrom ? 'real_provider' : 'unknown';
    84	  const mode = status === 'ERROR' ? 'DEGRADED' : 'LIVE';
    85	  const asOf = data?.updatedAt ? String(data.updatedAt) : null;
    86	  return {
    87	    data_source: dataSource,
    88	    mode,
    89	    asOf,
    90	    freshness: 'unknown'
    91	  };
    92	}
    93	
    94	function dataDateFrom(asOf, fallbackIso) {
    95	  if (typeof asOf === 'string' && asOf.length >= 10) return asOf.slice(0, 10);
    96	  return fallbackIso.slice(0, 10);
    97	}
    98	
    99	async function fetchTiingoFundamentalsDaily(ticker, env) {
   100	  const keyInfo = getTiingoKeyInfo(env);
   101	  if (!keyInfo.key) {
   102	    return {
   103	      ok: false,
   104	      provider: 'tiingo',
   105	      key: { present: false, source: null },
   106	      error: { code: 'MISSING_API_KEY', message: 'Missing TIINGO_API_KEY' },
   107	      data: null,
   108	      httpStatus: null,
   109	      latencyMs: null
   110	    };
   111	  }
   112	
   113	  const controller = new AbortController();
   114	  const timeoutMs = 6000;
   115	  const started = Date.now();
   116	  const timer = setTimeout(() => controller.abort(), timeoutMs);
   117	
   118	  try {
   119	    const startDate = new Date(Date.now() - 365 * 24 * 60 * 60 * 1000).toISOString().slice(0, 10);
   120	    const endDate = new Date().toISOString().slice(0, 10);
   121	    const apiUrl = new URL(`https://api.tiingo.com/tiingo/fundamentals/${encodeURIComponent(ticker)}/daily`);
   122	    apiUrl.searchParams.set('token', keyInfo.key);
   123	    apiUrl.searchParams.set('startDate', startDate);
   124	    apiUrl.searchParams.set('endDate', endDate);
   125	    apiUrl.searchParams.set('format', 'json');
   126	
   127	    const res = await fetch(apiUrl.toString(), {
   128	      method: 'GET',
   129	      headers: { Accept: 'application/json' },
   130	      signal: controller.signal
   131	    });
   132	
   133	    const latencyMs = Date.now() - started;
   134	    if (!res.ok) {
   135	      return {
   136	        ok: false,
   137	        provider: 'tiingo',
   138	        key: { present: true, source: keyInfo.source },
   139	        error: { code: res.status === 401 || res.status === 403 ? 'AUTH_FAILED' : 'HTTP_ERROR', message: `HTTP ${res.status}` },
   140	        data: null,
   141	        httpStatus: res.status,
   142	        latencyMs
   143	      };
   144	    }
   145	
   146	    const payload = await res.json();
   147	    const rows = Array.isArray(payload) ? payload : [];
   148	    const last = rows.length ? rows[rows.length - 1] : null;
   149	    if (!last) {
   150	      return {
   151	        ok: false,
   152	        provider: 'tiingo',
   153	        key: { present: true, source: keyInfo.source },
   154	        error: { code: 'NO_DATA', message: 'No fundamentals rows returned' },
   155	        data: null,
   156	        httpStatus: res.status,
   157	        latencyMs
   158	      };
   159	    }
   160	
   161	    return {
   162	      ok: true,
   163	      provider: 'tiingo',
   164	      key: { present: true, source: keyInfo.source },
   165	      error: null,
   166	      data: normalizeFundamentalsFromTiingoRow(ticker, last),
   167	      httpStatus: res.status,
   168	      latencyMs
   169	    };
   170	  } catch (error) {
   171	    const msg = String(error?.message || error || 'network_error');
   172	    const latencyMs = Date.now() - started;
   173	    const lower = msg.toLowerCase();
   174	    const code = lower.includes('abort') || lower.includes('timeout') ? 'TIMEOUT' : 'NETWORK_ERROR';
   175	    return {
   176	      ok: false,
   177	      provider: 'tiingo',
   178	      key: { present: true, source: getTiingoKeyInfo(env).source },
   179	      error: { code, message: msg },
   180	      data: null,
   181	      httpStatus: null,
   182	      latencyMs
   183	    };
   184	  } finally {
   185	    clearTimeout(timer);
   186	  }
   187	}
   188	
   189	export async function onRequestGet(context) {
   190	  const { request, env } = context;
   191	  const url = new URL(request.url);
   192	  const isDebug = url.searchParams.get('debug') === '1';
   193	  const tickerParam = url.searchParams.get('ticker') || '';
   194	  const ticker = normalizeTicker(tickerParam);
   195	  const startedAtIso = new Date().toISOString();
   196	
   197	  const key = `fund:${ticker || 'invalid'}`;
   198	  const lastGoodKey = `${key}:last_good`;
   199	
   200	  if (!ticker) {

## FILE: functions/api/health-report.js
     1	import { serveStaticJson } from "./_shared/static-only.js";
     2	
     3	export async function onRequestGet(context) {
     4	  return serveStaticJson(context.request, "health-report", null, context);
     5	}

## FILE: functions/api/health.js
     1	import { serveStaticJson } from "./_shared/static-only.js";
     2	
     3	export async function onRequestGet(context) {
     4	  return serveStaticJson(context.request, "health", null, context);
     5	}

## FILE: functions/api/metrics.js
     1	import { serveStaticJson } from "./_shared/static-only.js";
     2	
     3	export async function onRequestGet(context) {
     4	  const url = new URL(context.request.url);
     5	  const v = url.searchParams.get("v");
     6	  if (v !== "5") {
     7	    return serveStaticJson(context.request, "metrics", null, context);
     8	  }
     9	
    10	  const now = new Date();
    11	  const nowIso = now.toISOString();
    12	  const omit = (url.searchParams.get("omit") || "")
    13	    .split(",")
    14	    .map((s) => s.trim())
    15	    .filter(Boolean);
    16	  const omitSet = new Set(omit);
    17	
    18	  const TOTAL_METRICS = 43;
    19	  const baseMetricId = omitSet.has("rates.us10y") ? "risk.vix" : "rates.us10y";
    20	  const metricsById = {};
    21	
    22	  if (!omitSet.has(baseMetricId)) {
    23	    metricsById[baseMetricId] = {
    24	      id: baseMetricId,
    25	      groupId: "stub",
    26	      label: baseMetricId,
    27	      value: 0,
    28	      valueType: "number",
    29	      unit: "index",
    30	      asOf: nowIso,
    31	      cadence: "daily",
    32	      change: { d1: null, w1: null, m1: null },
    33	      spark: [],
    34	      quality: {
    35	        isFresh: false,
    36	        isStale: true,
    37	        marketClosed: false,
    38	        consecutiveFails: 0,
    39	        validation: "OK"
    40	      },
    41	      display: {
    42	        trend: "flat",
    43	        severity: "neutral",
    44	        badgeText: "STUB",
    45	        tooltip: "Stub metric (metrics snapshot missing)"
    46	      },
    47	      source: { primary: "stub", fallbackUsed: false }
    48	    };
    49	  }
    50	
    51	  const metricsCount = Object.keys(metricsById).length;
    52	  const requiredMissing = Math.max(0, TOTAL_METRICS - metricsCount);
    53	  const missingMetricIds = omitSet.size > 0
    54	    ? Array.from(omitSet).slice(0, requiredMissing)
    55	    : [];
    56	  while (missingMetricIds.length < requiredMissing) {
    57	    missingMetricIds.push(`stub.missing.${missingMetricIds.length + 1}`);
    58	  }
    59	
    60	  const payload = {
    61	    meta: {
    62	      status: "PARTIAL",
    63	      requestId: `rv-${now.getTime()}-${Math.random().toString(16).slice(2)}`,
    64	      asOf: nowIso,
    65	      generatedAt: nowIso,
    66	      ageSeconds: 0,
    67	      version: "5.0",
    68	      source: { primary: "stub", fallbackUsed: false },
    69	      cache: { hit: false, ttlSeconds: 0, kvAvailable: false },
    70	      circuitOpen: false,
    71	      missingMetricIds,
    72	      metricsCount,
    73	      groupsCount: 9
    74	    },
    75	    data: {
    76	      groups: [],
    77	      metricsById,
    78	      signals: [],
    79	      uiDefaults: { defaultUi: "stub", availableUis: ["stub"] }
    80	    },
    81	    error: null
    82	  };
    83	
    84	  return new Response(JSON.stringify(payload), {
    85	    status: 200,
    86	    headers: {
    87	      "Content-Type": "application/json",
    88	      "Cache-Control": "no-store",
    89	      "X-RV-Source": "METRICS_V5_FALLBACK"
    90	    }
    91	  });
    92	}

## FILE: functions/api/mission-control.js
     1	const MODULES_TO_TRACK = ['universe', 'market-prices', 'market-stats', 'market-score', 'stock'];
     2	const SNAPSHOT_PATHS = [
     3	  (moduleName) => `/data/snapshots/${moduleName}/latest.json`,
     4	  (moduleName) => `/data/snapshots/${moduleName}.json`
     5	];
     6	
     7	async function fetchSnapshotInfo(requestUrl, moduleName) {
     8	  for (const builder of SNAPSHOT_PATHS) {
     9	    const path = builder(moduleName);
    10	    const url = new URL(path, requestUrl);
    11	    try {
    12	      const response = await fetch(url.toString());
    13	      if (!response.ok) continue;
    14	      const payload = await response.json();
    15	      const metadata = payload?.metadata || {};
    16	      const asOf = metadata?.as_of || metadata?.published_at || metadata?.fetched_at || null;
    17	      return {
    18	        ok: true,
    19	        path,
    20	        served_from: metadata.served_from || 'ASSET',
    21	        schema_version: payload?.schema_version || null,
    22	        module: payload?.module || metadata.module || moduleName,
    23	        as_of: asOf,
    24	        record_count: metadata?.record_count ?? null,
    25	        raw: {
    26	          module: payload?.module || metadata.module || moduleName,
    27	          schema_version: payload?.schema_version || null,
    28	          served_from: metadata.served_from || 'ASSET',
    29	          record_count: metadata?.record_count ?? null
    30	        }
    31	      };
    32	    } catch (error) {
    33	      continue;
    34	    }
    35	  }
    36	  return { ok: false, paths_checked: SNAPSHOT_PATHS.map((builder) => builder(moduleName)) };
    37	}
    38	
    39	async function loadRegistry() {
    40	  try {
    41	    const response = await fetch(new URL('/data/registry/modules.json', 'https://example.com').toString());
    42	    if (!response.ok) throw new Error('registry missing');
    43	    const payload = await response.json();
    44	    return payload?.modules || {};
    45	  } catch (error) {
    46	    return {};
    47	  }
    48	}
    49	
    50	function buildModuleStatus(moduleName, snapshotInfo) {
    51	  const entry = {
    52	    module: moduleName,
    53	    status: snapshotInfo.ok ? 'ok' : 'missing',
    54	    reason_codes: snapshotInfo.ok ? [] : ['MISSING_SNAPSHOT'],
    55	    as_of: snapshotInfo.ok ? snapshotInfo.as_of : null,
    56	    path: snapshotInfo.ok ? snapshotInfo.path : snapshotInfo.paths_checked,
    57	    snapshot: snapshotInfo.ok ? snapshotInfo.raw : null
    58	  };
    59	  return entry;
    60	}
    61	
    62	export async function onRequestGet(context) {
    63	  const requestUrl = context.request.url;
    64	  const debug = new URL(requestUrl).searchParams.get('debug') === '1';
    65	  const modules = [];
    66	  let reasonCounts = {};
    67	  for (const moduleName of MODULES_TO_TRACK) {
    68	    const info = await fetchSnapshotInfo(requestUrl, moduleName);
    69	    const entry = buildModuleStatus(moduleName, info);
    70	    modules.push(entry);
    71	    entry.reason_codes.forEach((code) => {
    72	      reasonCounts[code] = (reasonCounts[code] || 0) + 1;
    73	    });
    74	  }
    75	  const payload = {
    76	    schema_version: '1.0',
    77	    module: 'mission-control',
    78	    served_from: 'ASSET',
    79	    request: {
    80	      ts_utc: new Date().toISOString(),
    81	      debug
    82	    },
    83	    modules,
    84	    reason_counts: reasonCounts,
    85	    links: {
    86	      trace: '/api/trace?ticker=SPY'
    87	    }
    88	  };
    89	  return new Response(JSON.stringify(payload, null, 2), {
    90	    headers: { 'Content-Type': 'application/json' }
    91	  });
    92	}

## FILE: functions/api/mission-control/summary.js
     1	import { sha256Hex } from '../_shared/digest.mjs';
     2	import { buildDashKeys, kvGetJsonKVSafe, computeBudgets, summarizeProviderStats } from '../_shared/telemetry.mjs';
     3	import {
     4	  validateHealthProfiles,
     5	  validateThresholds,
     6	  validateSourceMap,
     7	  validatePipelineArtifact,
     8	  validateSnapshot,
     9	  trimErrors
    10	} from '../_shared/contracts.js';
    11	import { getBarNode } from '../../_ops/shape.js';
    12	
    13	const MODULE_NAME = 'mission-control-summary';
    14	const SNAPSHOT_MODULES_HINT = ['universe', 'market-prices', 'market-stats', 'market-score'];
    15	const SNAPSHOT_PATHS = [
    16	  (moduleName) => `/data/snapshots/${moduleName}/latest.json`,
    17	  (moduleName) => `/data/snapshots/${moduleName}.json`
    18	];
    19	const PRICE_TRACE_TICKERS = ['UBER', 'TEAM', 'WBD'];
    20	const PRICE_TRACE_PATH = (ticker) => `/debug/truth-chain/${ticker}.trace.json`;
    21	const PRICE_UI_TRACE_PATH = (ticker) => `/debug/ui-path/${ticker}.ui-path.trace.json`;
    22	const PRICE_CHAIN_VERSION = 'v2';
    23	
    24	let LAST_CACHE = null;
    25	let LAST_CACHE_AT_MS = 0;
    26	const CACHE_TTL_MS = 10_000;
    27	
    28	async function computeDigest(input) {
    29	  const canonical = JSON.stringify(input);
    30	  const hex = await sha256Hex(canonical);
    31	  return `sha256:${hex}`;
    32	}
    33	
    34	function buildErrorPayload(code, message, details = {}) {
    35	  return {
    36	    code,
    37	    message,
    38	    details
    39	  };
    40	}
    41	
    42	function isoDay(date = new Date()) {
    43	  return date.toISOString().slice(0, 10);
    44	}
    45	
    46	function isoMonth(date = new Date()) {
    47	  return date.toISOString().slice(0, 7);
    48	}
    49	
    50	function isoWeek(date = new Date()) {
    51	  const d = new Date(Date.UTC(date.getUTCFullYear(), date.getUTCMonth(), date.getUTCDate()));
    52	  const dayNum = d.getUTCDay() || 7;
    53	  d.setUTCDate(d.getUTCDate() + 4 - dayNum);
    54	  const yearStart = new Date(Date.UTC(d.getUTCFullYear(), 0, 1));
    55	  const weekNo = Math.ceil((((d - yearStart) / 86400000) + 1) / 7);
    56	  return `${d.getUTCFullYear()}-${String(weekNo).padStart(2, '0')}`;
    57	}
    58	
    59	function toInt(value) {
    60	  const n = Number.parseInt(String(value ?? ''), 10);
    61	  return Number.isFinite(n) ? n : 0;
    62	}
    63	
    64	function toNumber(value) {
    65	  const n = Number(value);
    66	  return Number.isFinite(n) ? n : null;
    67	}
    68	
    69	function authFail() {
    70	  const payload = {
    71	    schema_version: '3.0',
    72	    meta: {
    73	      asOf: new Date().toISOString(),
    74	      reason: 'OPS_KEY_MISSING_OR_WRONG'
    75	    },
    76	    metadata: {
    77	      module: MODULE_NAME,
    78	      schema_version: '3.0',
    79	      tier: 'standard',
    80	      domain: 'system',
    81	      source: 'mission-control',
    82	      fetched_at: new Date().toISOString(),
    83	      published_at: new Date().toISOString(),
    84	      digest: null,
    85	      served_from: 'RUNTIME',
    86	      request: { debug: false },
    87	      status: 'ERROR',
    88	      warnings: []
    89	    },
    90	    data: null,
    91	    error: buildErrorPayload('FORBIDDEN', 'Live check requires valid OPS_KEY')
    92	  };
    93	
    94	  return new Response(JSON.stringify(payload, null, 2) + '\n', {
    95	    status: 403,
    96	    headers: {
    97	      'Content-Type': 'application/json',
    98	      'Cache-Control': 'no-store'
    99	    }
   100	  });
   101	}
   102	
   103	async function fetchAssetJson(requestUrl, path, fallback = null) {
   104	  try {
   105	    const url = new URL(path, requestUrl);
   106	    const res = await fetch(url.toString(), { cf: { cacheTtl: 30 } });
   107	    if (!res.ok) return fallback;
   108	    return await res.json();
   109	  } catch {
   110	    return fallback;
   111	  }
   112	}
   113	
   114	async function fetchAssetText(requestUrl, path, fallback = null) {
   115	  try {
   116	    const url = new URL(path, requestUrl);
   117	    const res = await fetch(url.toString(), { cf: { cacheTtl: 30 } });
   118	    if (!res.ok) return { ok: false, status: res.status, text: null, json: fallback };
   119	    const text = await res.text();
   120	    let json = fallback;
   121	    try {
   122	      json = text ? JSON.parse(text) : fallback;
   123	    } catch {
   124	      json = fallback;
   125	    }
   126	    return { ok: true, status: res.status, text, json };
   127	  } catch {
   128	    return { ok: false, status: null, text: null, json: fallback };
   129	  }
   130	}
   131	
   132	async function fetchApiStock(requestUrl, ticker) {
   133	  try {
   134	    const url = new URL('/api/stock', requestUrl);
   135	    url.searchParams.set('ticker', ticker);
   136	    const res = await fetch(url.toString(), { cache: 'no-store' });
   137	    const status = res.status;
   138	    let json = null;
   139	    try {
   140	      json = await res.json();
   141	    } catch {
   142	      json = null;
   143	    }
   144	    const bar = getBarNode(json);
   145	    return {
   146	      ok: res.ok,
   147	      status,
   148	      url: `${url.pathname}?${url.searchParams.toString()}`,
   149	      response: json,
   150	      bar,
   151	      meta: json?.meta || null
   152	    };
   153	  } catch (err) {
   154	    return {
   155	      ok: false,
   156	      status: null,
   157	      url: `/api/stock?ticker=${encodeURIComponent(ticker)}`,
   158	      response: null,
   159	      bar: null,
   160	      meta: null,
   161	      error: String(err?.message || err)
   162	    };
   163	  }
   164	}
   165	
   166	function isPipelineTruthDoc(doc) {
   167	  return doc && typeof doc === 'object' && typeof doc.universe === 'string' && 'expected' in doc && 'count' in doc && 'missing' in doc;
   168	}
   169	
   170	function toIntOrNull(v) {
   171	  const n = Number(v);
   172	  return Number.isFinite(n) ? Math.trunc(n) : null;
   173	}
   174	
   175	function normalizePipelineTruth(doc) {
   176	  if (!isPipelineTruthDoc(doc)) return null;
   177	  const expected = toIntOrNull(doc.expected);
   178	  let count = toIntOrNull(doc.count);
   179	  const missing = Array.isArray(doc.missing) ? doc.missing : [];
   180	  if (count == null && Number.isFinite(expected) && expected >= 0 && Array.isArray(missing)) {
   181	    count = Math.max(0, expected - missing.length);
   182	  }
   183	  return {
   184	    universe: typeof doc.universe === 'string' ? doc.universe : null,
   185	    expected,
   186	    count,
   187	    reason: doc.reason ? String(doc.reason) : null,
   188	    missing
   189	  };
   190	}
   191	
   192	function normalizePipelineLatest(doc) {
   193	  if (!doc || typeof doc !== 'object') return null;
   194	  const counts = doc.counts && typeof doc.counts === 'object' ? doc.counts : {};
   195	  return {
   196	    universe: typeof doc.universe === 'string' ? doc.universe : null,
   197	    generated_at: typeof doc.generated_at === 'string' ? doc.generated_at : null,
   198	    type: typeof doc.type === 'string' ? doc.type : null,
   199	    counts: {
   200	      expected: toIntOrNull(counts.expected),

## FILE: functions/api/probe/[module].js
     1	/**
     2	 * Probe Endpoint - On-Demand Delivery Verification
     3	 * 
     4	 * URL: /api/probe/{module}
     5	 * 
     6	 * Purpose:
     7	 * - Verify that module data is accessible
     8	 * - Test delivery chain (ASSET  KV  Maintenance)
     9	 * - Validate UI contract fields
    10	 * - Return proof that value is visible
    11	 * 
    12	 * Usage:
    13	 * - Mission Control UI triggers probe
    14	 * - Returns: latency, status, proof chain, UI field check
    15	 * - Does NOT write anything (0 compliant)
    16	 */
    17	
    18	import { serveStaticJson } from '../_shared/static-only.js';
    19	
    20	/**
    21	 * Extract critical UI fields from data
    22	 * Handles both v3.0 and legacy-transformed formats
    23	 */
    24	function extractUIFields(data, requiredPaths) {
    25	  if (!requiredPaths || requiredPaths.length === 0) {
    26	    return { available: true, fields: {} };
    27	  }
    28	  
    29	  const fields = {};
    30	  let allPresent = true;
    31	  
    32	  // Check if data is legacy-transformed (has .data and .meta)
    33	  const isLegacyFormat = data && typeof data === 'object' && 'data' in data && 'meta' in data;
    34	  
    35	  for (const path of requiredPaths) {
    36	    try {
    37	      let value = null;
    38	      
    39	      // Try v3.0 path first ($.data[0].items[0].symbol)
    40	      const parts = path.replace(/^\$\./, '').split(/[\.\[\]]+/).filter(Boolean);
    41	      let current = data;
    42	      
    43	      for (const part of parts) {
    44	        if (current === null || current === undefined) {
    45	          current = null;
    46	          break;
    47	        }
    48	        
    49	        if (part === '*') {
    50	          if (Array.isArray(current)) {
    51	            current = current[0];
    52	          }
    53	        } else if (!isNaN(part)) {
    54	          current = current[parseInt(part, 10)];
    55	        } else {
    56	          current = current[part];
    57	        }
    58	      }
    59	      
    60	      value = current;
    61	      
    62	      // If not found and legacy format, try alternative paths
    63	      if ((value === null || value === undefined) && isLegacyFormat) {
    64	        // Try multiple legacy path transformations
    65	        const legacyPathVariants = [
    66	          // $.data[0].items[0].symbol  $.data.items[0].symbol
    67	          path.replace(/\$\.data\[0\]\./, '$.data.'),
    68	          // $.metadata.fetched_at  $.meta.fetchedAt (camelCase)
    69	          path.replace(/\$\.metadata\.fetched_at/, '$.meta.fetchedAt'),
    70	          // $.metadata.  $.meta.
    71	          path.replace(/\$\.metadata\./, '$.meta.')
    72	        ];
    73	        
    74	        for (const legacyPath of legacyPathVariants) {
    75	          const legacyParts = legacyPath.replace(/^\$\./, '').split(/[\.\[\]]+/).filter(Boolean);
    76	          let legacyCurrent = data;
    77	          
    78	          for (const part of legacyParts) {
    79	            if (legacyCurrent === null || legacyCurrent === undefined) {
    80	              legacyCurrent = null;
    81	              break;
    82	            }
    83	            
    84	            if (part === '*') {
    85	              if (Array.isArray(legacyCurrent)) {
    86	                legacyCurrent = legacyCurrent[0];
    87	              }
    88	            } else if (!isNaN(part)) {
    89	              legacyCurrent = legacyCurrent[parseInt(part, 10)];
    90	            } else {
    91	              legacyCurrent = legacyCurrent[part];
    92	            }
    93	          }
    94	          
    95	          // If we found a value, use it
    96	          if (legacyCurrent !== null && legacyCurrent !== undefined) {
    97	            value = legacyCurrent;
    98	            break;
    99	          }
   100	        }
   101	      }
   102	      
   103	      fields[path] = value;
   104	      
   105	      if (value === null || value === undefined || 
   106	          (typeof value === 'number' && isNaN(value)) ||
   107	          (typeof value === 'string' && value.trim() === '')) {
   108	        allPresent = false;
   109	      }
   110	    } catch (e) {
   111	      fields[path] = null;
   112	      allPresent = false;
   113	    }
   114	  }
   115	  
   116	  return {
   117	    available: allPresent,
   118	    fields
   119	  };
   120	}
   121	
   122	/**
   123	 * Main probe handler
   124	 */
   125	export async function onRequestGet(context) {
   126	  const { request, params, env } = context;
   127	  const module = params.module;
   128	  const startTime = Date.now();
   129	  
   130	  // Load module config
   131	  let moduleConfig = null;
   132	  try {
   133	    const registryUrl = new URL('/data/registry/modules.json', request.url);
   134	    const registryResponse = await fetch(registryUrl.toString());
   135	    if (registryResponse.ok) {
   136	      const registry = await registryResponse.json();
   137	      moduleConfig = registry.modules?.[module] || null;
   138	    }
   139	  } catch (e) {
   140	    // Continue without config
   141	  }
   142	  
   143	  // Fetch the actual API endpoint
   144	  let apiResponse = null;
   145	  let apiStatus = 'UNKNOWN';
   146	  let apiData = null;
   147	  let apiError = null;
   148	  
   149	  try {
   150	    const apiUrl = new URL(`/api/${module}`, request.url);
   151	    apiResponse = await fetch(apiUrl.toString());
   152	    apiStatus = apiResponse.ok ? 'SUCCESS' : 'ERROR';
   153	    
   154	    if (apiResponse.ok) {
   155	      const text = await apiResponse.text();
   156	      apiData = JSON.parse(text);
   157	    } else {
   158	      apiError = `HTTP ${apiResponse.status}`;
   159	    }
   160	  } catch (e) {
   161	    apiStatus = 'FETCH_FAILED';
   162	    apiError = e.message;
   163	  }
   164	  
   165	  const latencyMs = Date.now() - startTime;
   166	  
   167	  // Extract UI fields
   168	  let uiCheck = { available: false, fields: {} };
   169	  if (apiData && moduleConfig) {
   170	    const requiredPaths = moduleConfig.ui_contract?.required_paths || [];
   171	    uiCheck = extractUIFields(apiData, requiredPaths);
   172	  }
   173	  
   174	  // Determine overall status
   175	  let overallStatus = 'UNKNOWN';
   176	  let proofStatus = 'UNKNOWN';
   177	  
   178	  if (apiStatus === 'SUCCESS') {
   179	    if (apiData?.ok === true && uiCheck.available) {
   180	      overallStatus = 'PASS';
   181	      proofStatus = 'VALUE_VISIBLE';
   182	    } else if (apiData?.ok === true && !uiCheck.available) {
   183	      overallStatus = 'PARTIAL';
   184	      proofStatus = 'DATA_PRESENT_BUT_UI_INCOMPLETE';
   185	    } else {
   186	      overallStatus = 'FAIL';
   187	      proofStatus = 'DATA_INVALID';
   188	    }
   189	  } else {
   190	    overallStatus = 'FAIL';
   191	    proofStatus = 'DELIVERY_FAILED';
   192	  }
   193	  
   194	  // Build probe result
   195	  const probeResult = {
   196	    schema_version: '3.0',
   197	    probe: {
   198	      module,
   199	      timestamp: new Date().toISOString(),
   200	      latency_ms: latencyMs

## FILE: functions/api/resolve.js
     1	import { sha256Hex } from './_shared/digest.mjs';
     2	import { resolveSymbol } from './_shared/symbol-resolver.mjs';
     3	import {
     4	  DEFAULT_TTL_SECONDS,
     5	  SWR_MARK_TTL_SECONDS,
     6	  DEGRADE_AFTER_SECONDS,
     7	  buildCacheMeta,
     8	  computeAgeSeconds,
     9	  createCache,
    10	  getJsonKV,
    11	  makeCacheKey,
    12	  nowUtcIso,
    13	  parseIsoDateToMs,
    14	  todayUtcDate,
    15	  tryMarkSWR
    16	} from './_shared/cache-law.js';
    17	import { isPrivilegedDebug, redact } from './_shared/observability.js';
    18	import { computeCacheStatus } from './_shared/freshness.js';
    19	
    20	const MODULE_NAME = 'resolve';
    21	const DEFAULT_RESOLVE_CACHE_TTL_SECONDS = DEFAULT_TTL_SECONDS;
    22	const DEFAULT_RESOLVE_LOCK_TTL_SECONDS = 30;
    23	
    24	async function computeDigest(input) {
    25	  const canonical = JSON.stringify(input);
    26	  const hex = await sha256Hex(canonical);
    27	  return `sha256:${hex}`;
    28	}
    29	
    30	function buildErrorPayload(code, message, details = {}) {
    31	  return {
    32	    code,
    33	    message,
    34	    details
    35	  };
    36	}
    37	
    38	function coerceTimestampMs(value) {
    39	  if (typeof value === 'number' && Number.isFinite(value)) {
    40	    return value > 1e12 ? value : value * 1000;
    41	  }
    42	  if (typeof value === 'string') {
    43	    return parseIsoDateToMs(value);
    44	  }
    45	  return 0;
    46	}
    47	
    48	function parseSchedulerLastOk(value) {
    49	  if (value == null) return 0;
    50	  if (typeof value === 'string' || typeof value === 'number') {
    51	    return coerceTimestampMs(value);
    52	  }
    53	  if (typeof value === 'object') {
    54	    const candidate =
    55	      value.generated_at ||
    56	      value.last_ok ||
    57	      value.lastOk ||
    58	      value.ts ||
    59	      value.timestamp ||
    60	      value.time;
    61	    return coerceTimestampMs(candidate);
    62	  }
    63	  return 0;
    64	}
    65	
    66	async function loadSchedulerState(env, isPrivileged) {
    67	  const keys = ['meta:scheduler:last_ok', 'rv:scheduler:last_ok'];
    68	  for (const key of keys) {
    69	    const result = await getJsonKV(env, key);
    70	    if (!result?.meta?.hit) continue;
    71	    const ms = parseSchedulerLastOk(result.value);
    72	    const ageSeconds = ms ? Math.floor((Date.now() - ms) / 1000) : null;
    73	    const degraded = typeof ageSeconds === 'number' && ageSeconds > DEGRADE_AFTER_SECONDS;
    74	    return {
    75	      degraded,
    76	      reason: degraded ? 'scheduler_stale' : null
    77	    };
    78	  }
    79	  return {
    80	    degraded: false,
    81	    reason: isPrivileged ? 'unknown' : null
    82	  };
    83	}
    84	
    85	async function getSWRPending(env, swrKey, pendingWindowSeconds) {
    86	  if (!swrKey) return false;
    87	  const result = await getJsonKV(env, swrKey);
    88	  if (!result?.meta?.hit) return false;
    89	  const marker = result.value || {};
    90	  const markedAt = marker.marked_at || marker.ts || marker.time || '';
    91	  const ageSeconds = computeAgeSeconds(markedAt);
    92	  if (ageSeconds == null) return false;
    93	  return ageSeconds <= pendingWindowSeconds;
    94	}
    95	
    96	export async function onRequestGet(context) {
    97	  const { request } = context;
    98	  const env = context?.env || {};
    99	  const url = new URL(request.url);
   100	  const query = url.searchParams.get('q') || '';
   101	
   102	  const isPrivileged = isPrivilegedDebug(request, env);
   103	  const timings = { t_total_ms: 0, t_kv_ms: null, t_origin_ms: null, t_build_ms: null };
   104	  const requestStart = Date.now();
   105	  const startedAt = nowUtcIso();
   106	  const cache = createCache(env);
   107	  const normalizedQuery = query ? query.trim().toLowerCase() : '';
   108	  const cacheId = normalizedQuery ? `resolve:${normalizedQuery}` : null;
   109	  const cacheTtlSeconds = Number(env?.RESOLVE_CACHE_TTL_SECONDS) || DEFAULT_RESOLVE_CACHE_TTL_SECONDS;
   110	  const lockTtlSeconds = Number(env?.RESOLVE_LOCK_TTL_SECONDS) || DEFAULT_RESOLVE_LOCK_TTL_SECONDS;
   111	  const pendingWindowSeconds = Number(env?.SWR_PENDING_WINDOW_SECONDS) || 120;
   112	  const qualityFlags = [];
   113	  let result;
   114	  let envelopeStatus = 'fresh';
   115	
   116	  const primaryKey = cacheId ? cache.dataKey(cacheId) : null;
   117	  const primaryMetaKey = cacheId ? cache.metaKey(cacheId) : null;
   118	  const aliasKey = normalizedQuery ? makeCacheKey('resolve', normalizedQuery) : null;
   119	  const aliasMetaKey = normalizedQuery ? makeCacheKey('meta', `resolve:${normalizedQuery}`) : null;
   120	  const swrKey = normalizedQuery ? makeCacheKey('swr', `resolve:${normalizedQuery}`) : null;
   121	
   122	  let cachedData = null;
   123	  let cachedMeta = null;
   124	  let cachedAgeSeconds = null;
   125	  let cachedStale = false;
   126	  let cacheHit = false;
   127	  let swrMarked = undefined;
   128	  let swrPending = false;
   129	  let cacheKeyUsed = null;
   130	  let cacheMetaKeyUsed = null;
   131	
   132	  if (cacheId) {
   133	    const kvStart = Date.now();
   134	    const cached = await cache.readCached(cacheId);
   135	    cachedData = cached?.data ?? null;
   136	    cachedMeta = cached?.metaLike ?? null;
   137	    cacheKeyUsed = primaryKey;
   138	    cacheMetaKeyUsed = primaryMetaKey;
   139	
   140	    if (cachedData == null && aliasKey && aliasKey !== primaryKey) {
   141	      const aliasData = await getJsonKV(env, aliasKey);
   142	      if (aliasData?.meta?.hit) {
   143	        cachedData = aliasData.value;
   144	        cacheKeyUsed = aliasKey;
   145	      }
   146	      if (cachedData && aliasMetaKey) {
   147	        const aliasMeta = await getJsonKV(env, aliasMetaKey);
   148	        if (aliasMeta?.meta?.hit) {
   149	          cachedMeta = aliasMeta.value;
   150	          cacheMetaKeyUsed = aliasMetaKey;
   151	        }
   152	      }
   153	    }
   154	    timings.t_kv_ms = Date.now() - kvStart;
   155	  }
   156	
   157	  cachedAgeSeconds = computeAgeSeconds(cachedMeta?.generated_at);
   158	  swrPending = cacheId ? await getSWRPending(env, swrKey, pendingWindowSeconds) : false;
   159	  const cacheStatus = computeCacheStatus({
   160	    hasData: Boolean(cachedData),
   161	    ageSeconds: cachedAgeSeconds,
   162	    ttlSeconds: cacheTtlSeconds,
   163	    pending: swrPending
   164	  });
   165	  const cacheFresh = cacheStatus.status === 'fresh';
   166	  cachedStale = cacheStatus.stale;
   167	
   168	  async function refreshCacheInBackground() {
   169	    if (!cacheId) return;
   170	    try {
   171	      const refreshed = await resolveSymbol(query, request);
   172	      if (refreshed?.ok && refreshed?.data) {
   173	        await cache.writeCached(cacheId, refreshed.data, cacheTtlSeconds, {
   174	          provider: 'asset',
   175	          data_date: todayUtcDate()
   176	        });
   177	      }
   178	      console.log(
   179	        JSON.stringify({
   180	          event: 'swr_refresh',
   181	          module: MODULE_NAME,
   182	          query: normalizedQuery,
   183	          ok: Boolean(refreshed?.ok),
   184	          cache_key: cacheKeyUsed || primaryKey || null
   185	        })
   186	      );
   187	    } catch {
   188	      console.log(
   189	        JSON.stringify({
   190	          event: 'swr_refresh',
   191	          module: MODULE_NAME,
   192	          query: normalizedQuery,
   193	          ok: false,
   194	          cache_key: cacheKeyUsed || primaryKey || null
   195	        })
   196	      );
   197	    }
   198	  }
   199	
   200	  if (cacheFresh) {

## FILE: functions/api/scheduler/health.js
     1	import { getJsonKV, nowUtcIso, parseIsoDateToMs, todayUtcDate } from "../_shared/cache-law.js";
     2	import { readSchedulerStatus } from "../_shared/scheduler-law.js";
     3	
     4	const DEFAULT_MAX_AGE_SECONDS = 24 * 60 * 60;
     5	const SCHEDULER_OK_STATUS = "ok";
     6	const SCHEDULER_STALE_STATUS = "stale";
     7	const SCHEDULER_NEVER_STATUS = "never_ran";
     8	
     9	function parseTimestamp(value) {
    10	  if (typeof value === "string") return parseIsoDateToMs(value);
    11	  if (typeof value === "number" && Number.isFinite(value)) {
    12	    return value > 1e12 ? value : value * 1000;
    13	  }
    14	  if (value && typeof value === "object") {
    15	    return parseIsoDateToMs(
    16	      value.last_ok || value.lastOk || value.generated_at || value.ts || value.time || ""
    17	    );
    18	  }
    19	  return 0;
    20	}
    21	
    22	async function readFirstKV(env, keys) {
    23	  const list = Array.isArray(keys) ? keys : [];
    24	  for (const key of list) {
    25	    const result = await getJsonKV(env, key);
    26	    if (result?.meta?.hit) {
    27	      return { value: result.value ?? null, key };
    28	    }
    29	  }
    30	  return { value: null, key: list[0] || null };
    31	}
    32	
    33	export async function onRequestGet(context) {
    34	  const env = context?.env || {};
    35	  const maxAgeSeconds = Number(env?.SCHEDULER_HEALTH_MAX_SECONDS) || DEFAULT_MAX_AGE_SECONDS;
    36	
    37	  const lastOk = await readFirstKV(env, ["meta:scheduler:last_ok", "rv:scheduler:last_ok"]);
    38	  const lastRun = await readFirstKV(env, ["meta:scheduler:last_run", "rv:scheduler:last_run"]);
    39	  const status = await readSchedulerStatus(env);
    40	
    41	  const lastOkValue = lastOk?.value ?? null;
    42	  const lastRunValue = lastRun?.value ?? null;
    43	  const lastOkMs = parseTimestamp(lastOkValue);
    44	  const ageSeconds = lastOkMs ? Math.floor((Date.now() - lastOkMs) / 1000) : null;
    45	  const hasLastOk = lastOkValue !== null && lastOkValue !== undefined;
    46	  const healthy = typeof ageSeconds === "number" ? ageSeconds <= maxAgeSeconds : false;
    47	  const healthStatus = hasLastOk
    48	    ? healthy
    49	      ? SCHEDULER_OK_STATUS
    50	      : SCHEDULER_STALE_STATUS
    51	    : SCHEDULER_NEVER_STATUS;
    52	
    53	  const data = {
    54	    last_ok: lastOkValue,
    55	    last_run: lastRunValue,
    56	    age_s: ageSeconds,
    57	    max_age_s: maxAgeSeconds,
    58	    status: healthStatus,
    59	    now: nowUtcIso(),
    60	    key: lastOk?.key || "meta:scheduler:last_ok",
    61	    note: hasLastOk ? null : "no_heartbeat_recorded",
    62	    scheduler: status
    63	  };
    64	
    65	  const headers = {
    66	    "Content-Type": "application/json; charset=utf-8",
    67	    "cache-control": "no-store, max-age=0"
    68	  };
    69	
    70	  if (!healthy) {
    71	    const payload = {
    72	      ok: false,
    73	      data,
    74	      error: {
    75	        code: "SCHEDULER_STALE",
    76	        message: hasLastOk ? "Scheduler heartbeat is stale" : "Scheduler heartbeat not recorded",
    77	        details: { age_s: ageSeconds, max_age_s: maxAgeSeconds }
    78	      },
    79	      meta: {
    80	        status: "error",
    81	        provider: "scheduler",
    82	        data_date: todayUtcDate()
    83	      }
    84	    };
    85	    return new Response(JSON.stringify(payload), { status: 503, headers });
    86	  }
    87	
    88	  const payload = {
    89	    ok: true,
    90	    data,
    91	    error: null,
    92	    meta: {
    93	      status: "live",
    94	      provider: "scheduler",
    95	      data_date: todayUtcDate()
    96	    }
    97	  };
    98	  return new Response(JSON.stringify(payload), { status: 200, headers });
    99	}

## FILE: functions/api/scheduler/run.js
     1	import { jsonEnvelopeResponse } from "../_shared/envelope.js";
     2	import { nowUtcIso, todayUtcDate } from "../_shared/cache-law.js";
     3	import { runSchedulerJob } from "../_shared/scheduler-law.js";
     4	import { isPrivilegedDebug, redact } from "../_shared/observability.js";
     5	
     6	const DEFAULT_CHUNK_SIZE = 50;
     7	const DEFAULT_MAX_CONCURRENCY = 3;
     8	
     9	function clampNumber(value, fallback, min, max) {
    10	  const num = Number(value);
    11	  if (!Number.isFinite(num)) return fallback;
    12	  return Math.min(max, Math.max(min, num));
    13	}
    14	
    15	export async function onRequestPost(context) {
    16	  const { request } = context;
    17	  const env = context?.env || {};
    18	
    19	  if (!isPrivilegedDebug(request, env)) {
    20	    return jsonEnvelopeResponse({
    21	      ok: false,
    22	      error: { code: "UNAUTHORIZED", message: "Admin token required" },
    23	      meta: {
    24	        status: "error",
    25	        provider: "scheduler",
    26	        data_date: todayUtcDate()
    27	      },
    28	      status: 403
    29	    });
    30	  }
    31	
    32	  let payload = null;
    33	  try {
    34	    payload = await request.json();
    35	  } catch {
    36	    return jsonEnvelopeResponse({
    37	      ok: false,
    38	      error: { code: "BAD_REQUEST", message: "Invalid JSON payload" },
    39	      meta: {
    40	        status: "error",
    41	        provider: "scheduler",
    42	        data_date: todayUtcDate()
    43	      },
    44	      status: 400
    45	    });
    46	  }
    47	
    48	  const job = typeof payload?.job === "string" ? payload.job : "eod_stock";
    49	  const mode = payload?.mode === "s2" ? "s2" : "s3";
    50	  const assets = Array.isArray(payload?.assets) ? payload.assets : null;
    51	  const universe = payload?.universe || null;
    52	  const chunkSize = clampNumber(payload?.chunk_size || payload?.chunkSize, DEFAULT_CHUNK_SIZE, 1, 200);
    53	  const maxConcurrency = clampNumber(
    54	    payload?.max_concurrency || payload?.maxConcurrency,
    55	    DEFAULT_MAX_CONCURRENCY,
    56	    1,
    57	    5
    58	  );
    59	
    60	  const prevAllowWrite = env.__RV_ALLOW_WRITE__;
    61	  env.__RV_ALLOW_WRITE__ = true;
    62	
    63	  const result = await runSchedulerJob({
    64	    env,
    65	    job,
    66	    assets,
    67	    universe,
    68	    mode,
    69	    chunkSize,
    70	    maxConcurrency
    71	  });
    72	  env.__RV_ALLOW_WRITE__ = prevAllowWrite;
    73	
    74	  const responsePayload = {
    75	    job,
    76	    mode,
    77	    run_id: result.status?.run_id || null,
    78	    started_at: result.status?.started_at || nowUtcIso(),
    79	    finished_at: result.status?.finished_at || nowUtcIso(),
    80	    summary: result.summary,
    81	    timing_ms: result.timing_ms,
    82	    status: result.status
    83	  };
    84	
    85	  const safePayload = redact(responsePayload);
    86	
    87	  const metaStatus = result.ok ? (result.partial ? "partial" : "fresh") : "error";
    88	  return jsonEnvelopeResponse({
    89	    ok: result.ok,
    90	    data: safePayload,
    91	    error: result.ok ? null : result.error || { code: "SCHEDULER_FAILED", message: "Scheduler failed" },
    92	    meta: {
    93	      status: metaStatus,
    94	      provider: "scheduler",
    95	      data_date: todayUtcDate()
    96	    },
    97	    status: result.ok ? 200 : 500
    98	  });
    99	}

## FILE: functions/api/stock.js
     1	import { sha256Hex } from './_shared/digest.mjs';
     2	import { resolveSymbol, normalizeTicker as normalizeTickerStrict } from './_shared/symbol-resolver.mjs';
     3	import { fetchBarsWithProviderChain } from './_shared/eod-providers.mjs';
     4	import { recordFailure } from './_shared/circuit.js';
     5	import { computeIndicators } from './_shared/eod-indicators.mjs';
     6	import { getTiingoKeyInfo } from './_shared/tiingo-key.mjs';
     7	import {
     8	  DEFAULT_TTL_SECONDS,
     9	  SWR_MARK_TTL_SECONDS,
    10	  DEGRADE_AFTER_SECONDS,
    11	  buildCacheMeta,
    12	  computeAgeSeconds,
    13	  createCache,
    14	  getJsonKV,
    15	  makeCacheKey,
    16	  nowUtcIso,
    17	  parseIsoDateToMs,
    18	  todayUtcDate,
    19	  tryMarkSWR
    20	} from './_shared/cache-law.js';
    21	import { evaluateQuality } from './_shared/quality.js';
    22	import { isPrivilegedDebug, redact } from './_shared/observability.js';
    23	import { computeCacheStatus } from './_shared/freshness.js';
    24	
    25	const MODULE_NAME = 'stock';
    26	const TICKER_MAX_LENGTH = 12;
    27	const VALID_TICKER_REGEX = /^[A-Z0-9.\-]+$/;
    28	const SNAPSHOT_PATH_TEMPLATES = [
    29	  '/data/snapshots/{module}/latest.json',
    30	  '/data/snapshots/{module}.json',
    31	  '/data/{module}.json'
    32	];
    33	const MODULE_PATHS = ['universe', 'market-prices', 'market-stats', 'market-score'];
    34	const DEFAULT_EOD_CACHE_TTL_SECONDS = DEFAULT_TTL_SECONDS;
    35	const DEFAULT_EOD_LOCK_TTL_SECONDS = 60;
    36	const DEFAULT_MAX_STALE_DAYS = 14;
    37	const DEFAULT_PENDING_WINDOW_MINUTES = 120;
    38	
    39	function normalizeTicker(raw) {
    40	  if (typeof raw !== 'string') return null;
    41	  const trimmed = raw.trim();
    42	  if (!trimmed) return null;
    43	  if (trimmed.length > TICKER_MAX_LENGTH) return null;
    44	  if (/\s/.test(trimmed)) return null;
    45	  const normalized = trimmed.toUpperCase();
    46	  if (!VALID_TICKER_REGEX.test(normalized)) return null;
    47	  return normalized;
    48	}
    49	
    50	function buildSourceChainMetadata(chain) {
    51	  if (!chain || typeof chain !== 'object') {
    52	    return {
    53	      primary: 'tiingo',
    54	      secondary: 'twelvedata',
    55	      forced: null,
    56	      selected: null,
    57	      fallbackUsed: false,
    58	      failureReason: null,
    59	      primaryFailure: null,
    60	      circuit: null
    61	    };
    62	  }
    63	  return {
    64	    primary: chain.primary || 'tiingo',
    65	    secondary: chain.secondary || 'twelvedata',
    66	    forced: chain.forced || null,
    67	    selected: chain.selected || null,
    68	    fallbackUsed: Boolean(chain.fallbackUsed),
    69	    failureReason: chain.failureReason || null,
    70	    primaryFailure: chain.primaryFailure || null,
    71	    circuit: chain.circuit || null
    72	  };
    73	}
    74	
    75	function pickLatestBar(bars) {
    76	  if (!Array.isArray(bars) || bars.length === 0) return null;
    77	  return bars[bars.length - 1] || null;
    78	}
    79	
    80	function computeDayChange(bars) {
    81	  if (!Array.isArray(bars) || bars.length < 2) {
    82	    return { abs: null, pct: null };
    83	  }
    84	  const latest = bars[bars.length - 1];
    85	  const prev = bars[bars.length - 2];
    86	  if (!Number.isFinite(latest?.close) || !Number.isFinite(prev?.close) || prev.close === 0) {
    87	    return { abs: null, pct: null };
    88	  }
    89	  const abs = latest.close - prev.close;
    90	  return { abs, pct: abs / prev.close };
    91	}
    92	
    93	function computeStartDateISO(daysBack) {
    94	  const days = Number.isFinite(Number(daysBack)) ? Number(daysBack) : 0;
    95	  if (days <= 0) return null;
    96	  const ms = Date.now() - days * 24 * 60 * 60 * 1000;
    97	  const d = new Date(ms);
    98	  if (Number.isNaN(d.getTime())) return null;
    99	  return d.toISOString().slice(0, 10);
   100	}
   101	
   102	function isoDay(date = new Date()) {
   103	  return date.toISOString().slice(0, 10);
   104	}
   105	
   106	function parseIsoDay(value) {
   107	  if (typeof value !== 'string') return null;
   108	  const trimmed = value.trim();
   109	  if (!trimmed) return null;
   110	  if (/^\d{4}-\d{2}-\d{2}$/.test(trimmed)) return trimmed;
   111	  const parsed = Date.parse(trimmed);
   112	  if (Number.isNaN(parsed)) return null;
   113	  return new Date(parsed).toISOString().slice(0, 10);
   114	}
   115	
   116	function diffDays(fromDay, toDay) {
   117	  const from = Date.UTC(
   118	    Number(fromDay.slice(0, 4)),
   119	    Number(fromDay.slice(5, 7)) - 1,
   120	    Number(fromDay.slice(8, 10))
   121	  );
   122	  const to = Date.UTC(
   123	    Number(toDay.slice(0, 4)),
   124	    Number(toDay.slice(5, 7)) - 1,
   125	    Number(toDay.slice(8, 10))
   126	  );
   127	  return Math.floor((to - from) / 86400000);
   128	}
   129	
   130	function minutesSinceUtcMidnight(date) {
   131	  return date.getUTCHours() * 60 + date.getUTCMinutes();
   132	}
   133	
   134	function computeStatusFromDataDate(dataDate, now, maxStaleDays, pendingWindowMinutes) {
   135	  const today = isoDay(now);
   136	  const normalized = parseIsoDay(dataDate);
   137	  if (!normalized) {
   138	    return minutesSinceUtcMidnight(now) <= pendingWindowMinutes ? 'pending' : 'error';
   139	  }
   140	  if (normalized === today) return 'fresh';
   141	  const ageDays = diffDays(normalized, today);
   142	  if (ageDays === 1 && minutesSinceUtcMidnight(now) <= pendingWindowMinutes) return 'pending';
   143	  if (ageDays <= maxStaleDays) return 'stale';
   144	  return 'error';
   145	}
   146	
   147	function coerceTimestampMs(value) {
   148	  if (typeof value === 'number' && Number.isFinite(value)) {
   149	    return value > 1e12 ? value : value * 1000;
   150	  }
   151	  if (typeof value === 'string') {
   152	    return parseIsoDateToMs(value);
   153	  }
   154	  return 0;
   155	}
   156	
   157	function parseSchedulerLastOk(value) {
   158	  if (value == null) return 0;
   159	  if (typeof value === 'string' || typeof value === 'number') {
   160	    return coerceTimestampMs(value);
   161	  }
   162	  if (typeof value === 'object') {
   163	    const candidate =
   164	      value.generated_at ||
   165	      value.last_ok ||
   166	      value.lastOk ||
   167	      value.ts ||
   168	      value.timestamp ||
   169	      value.time;
   170	    return coerceTimestampMs(candidate);
   171	  }
   172	  return 0;
   173	}
   174	
   175	async function loadSchedulerState(env, isPrivileged) {
   176	  const keys = ['meta:scheduler:last_ok', 'rv:scheduler:last_ok'];
   177	  for (const key of keys) {
   178	    const result = await getJsonKV(env, key);
   179	    if (!result?.meta?.hit) continue;
   180	    const ms = parseSchedulerLastOk(result.value);
   181	    const ageSeconds = ms ? Math.floor((Date.now() - ms) / 1000) : null;
   182	    const degraded = typeof ageSeconds === 'number' && ageSeconds > DEGRADE_AFTER_SECONDS;
   183	    return {
   184	      degraded,
   185	      reason: degraded ? 'scheduler_stale' : null
   186	    };
   187	  }
   188	  return {
   189	    degraded: false,
   190	    reason: isPrivileged ? 'unknown' : null
   191	  };
   192	}
   193	
   194	async function getSWRPending(env, swrKey, pendingWindowSeconds) {
   195	  if (!swrKey) return false;
   196	  const result = await getJsonKV(env, swrKey);
   197	  if (!result?.meta?.hit) return false;
   198	  const marker = result.value || {};
   199	  const markedAt = marker.marked_at || marker.ts || marker.time || '';
   200	  const ageSeconds = computeAgeSeconds(markedAt);

## FILE: functions/api/system-health.js
     1	import { serveStaticJson } from "./_shared/static-only.js";
     2	
     3	export async function onRequestGet(context) {
     4	  return serveStaticJson(context.request, "system-health", null, context);
     5	}

## FILE: functions/internal-health.js
     1	/**
     2	 * Embedded Mission Control Dashboard HTML
     3	 * 
     4	 * This file contains the complete HTML for /internal/health
     5	 * to avoid file system access issues in Cloudflare Pages Functions
     6	 */
     7	
     8	// HTML content embedded as string constant
     9	const MISSION_CONTROL_HTML = `<!DOCTYPE html>
    10	<html lang="en">
    11	<head>
    12	  <meta charset="UTF-8">
    13	  <meta name="viewport" content="width=device-width, initial-scale=1.0">
    14	  <title>Mission Control v3.0 - RubikVault</title>
    15	  <style>
    16	    * { box-sizing: border-box; margin: 0; padding: 0; }
    17	    body {
    18	      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, sans-serif;
    19	      background: #0a0e27;
    20	      color: #e0e0e0;
    21	      padding: 20px;
    22	      line-height: 1.6;
    23	    }
    24	    .container { max-width: 1400px; margin: 0 auto; }
    25	    h1 { color: #4a9eff; margin-bottom: 10px; }
    26	    .subtitle { color: #888; margin-bottom: 30px; }
    27	    .header {
    28	      background: #1a1e37;
    29	      padding: 20px;
    30	      border-radius: 8px;
    31	      margin-bottom: 20px;
    32	      display: grid;
    33	      grid-template-columns: 1fr 1fr 1fr;
    34	      gap: 20px;
    35	    }
    36	    .header-item {
    37	      background: #0f1320;
    38	      padding: 15px;
    39	      border-radius: 6px;
    40	    }
    41	    .header-label { font-size: 12px; color: #888; text-transform: uppercase; margin-bottom: 5px; }
    42	    .header-value { font-size: 24px; font-weight: bold; }
    43	    .status-ok { color: #4caf50; }
    44	    .status-warn { color: #ff9800; }
    45	    .status-crit { color: #f44336; }
    46	    .controls {
    47	      background: #1a1e37;
    48	      padding: 15px;
    49	      border-radius: 8px;
    50	      margin-bottom: 20px;
    51	      display: flex;
    52	      gap: 10px;
    53	      flex-wrap: wrap;
    54	    }
    55	    .controls input, .controls select {
    56	      background: #0f1320;
    57	      border: 1px solid #333;
    58	      color: #e0e0e0;
    59	      padding: 8px 12px;
    60	      border-radius: 4px;
    61	      font-size: 14px;
    62	    }
    63	    .controls input:focus, .controls select:focus {
    64	      outline: none;
    65	      border-color: #4a9eff;
    66	    }
    67	    .modules-table {
    68	      background: #1a1e37;
    69	      border-radius: 8px;
    70	      overflow: hidden;
    71	    }
    72	    table {
    73	      width: 100%;
    74	      border-collapse: collapse;
    75	    }
    76	    th {
    77	      background: #0f1320;
    78	      padding: 12px;
    79	      text-align: left;
    80	      font-size: 12px;
    81	      text-transform: uppercase;
    82	      color: #888;
    83	      font-weight: 600;
    84	      position: sticky;
    85	      top: 0;
    86	    }
    87	    td {
    88	      padding: 12px;
    89	      border-top: 1px solid #252940;
    90	    }
    91	    tr:hover { background: #252940; }
    92	    .badge {
    93	      display: inline-block;
    94	      padding: 4px 8px;
    95	      border-radius: 4px;
    96	      font-size: 11px;
    97	      font-weight: 600;
    98	      text-transform: uppercase;
    99	    }
   100	    .badge-ok { background: #1b5e20; color: #4caf50; }
   101	    .badge-warn { background: #e65100; color: #ff9800; }
   102	    .badge-error { background: #b71c1c; color: #f44336; }
   103	    .badge-stale { background: #424242; color: #9e9e9e; }
   104	    .proof-chain {
   105	      display: flex;
   106	      gap: 4px;
   107	    }
   108	    .proof-item {
   109	      width: 20px;
   110	      height: 20px;
   111	      border-radius: 3px;
   112	      display: inline-flex;
   113	      align-items: center;
   114	      justify-content: center;
   115	      font-size: 10px;
   116	      font-weight: bold;
   117	    }
   118	    .proof-pass { background: #1b5e20; color: #4caf50; }
   119	    .proof-fail { background: #b71c1c; color: #f44336; }
   120	    .proof-warn { background: #e65100; color: #ff9800; }
   121	    .proof-unknown { background: #424242; color: #9e9e9e; }
   122	    .links {
   123	      display: flex;
   124	      gap: 8px;
   125	    }
   126	    .link {
   127	      color: #4a9eff;
   128	      text-decoration: none;
   129	      font-size: 12px;
   130	      padding: 4px 8px;
   131	      border: 1px solid #4a9eff;
   132	      border-radius: 4px;
   133	    }
   134	    .link:hover { background: #4a9eff; color: #0a0e27; }
   135	    .top-issues {
   136	      background: #1a1e37;
   137	      padding: 20px;
   138	      border-radius: 8px;
   139	      margin-bottom: 20px;
   140	    }
   141	    .issue {
   142	      padding: 10px;
   143	      margin-bottom: 10px;
   144	      background: #0f1320;
   145	      border-left: 4px solid;
   146	      border-radius: 4px;
   147	    }
   148	    .issue-crit { border-color: #f44336; }
   149	    .issue-warn { border-color: #ff9800; }
   150	    .loading {
   151	      text-align: center;
   152	      padding: 40px;
   153	      color: #888;
   154	    }
   155	    .error {
   156	      background: #b71c1c;
   157	      color: #fff;
   158	      padding: 15px;
   159	      border-radius: 8px;
   160	      margin-bottom: 20px;
   161	    }
   162	    @media (max-width: 768px) {
   163	      .header { grid-template-columns: 1fr; }
   164	      table { font-size: 12px; }
   165	      th, td { padding: 8px; }
   166	    }
   167	  </style>
   168	</head>
   169	<body>
   170	  <div class="container">
   171	    <h1>Mission Control v3.0</h1>
   172	    <div class="subtitle">RubikVault System Health Dashboard</div>
   173	    <div id="loading" class="loading">Loading provider state...</div>
   174	    <div id="error" class="error" style="display: none;"></div>
   175	    <div id="content" style="display: none;">
   176	      <div class="header" id="header"></div>
   177	      <div class="top-issues" id="top-issues" style="display: none;">
   178	        <h3 style="margin-bottom: 15px; color: #4a9eff;">Top Issues</h3>
   179	        <div id="issues-list"></div>
   180	      </div>
   181	      <div class="controls">
   182	        <input type="text" id="search" placeholder="Search modules..." style="flex: 1; min-width: 200px;">
   183	        <select id="filter-tier">
   184	          <option value="">All Tiers</option>
   185	          <option value="critical">Critical</option>
   186	          <option value="standard">Standard</option>
   187	          <option value="experimental">Experimental</option>
   188	        </select>
   189	        <select id="filter-status">
   190	          <option value="">All Status</option>
   191	          <option value="ok">OK</option>
   192	          <option value="warn">Warn</option>
   193	          <option value="error">Error</option>
   194	          <option value="stale">Stale</option>
   195	        </select>
   196	        <select id="filter-domain">
   197	          <option value="">All Domains</option>
   198	        </select>
   199	      </div>
   200	      <div class="modules-table">

## FILE: functions/internal.js
     1	export async function onRequestGet(context) {
     2	  const { request, env } = context;
     3	  const url = new URL(request.url);
     4	
     5	  // IMPORTANT: Don't handle /internal/health - let it be handled by functions/internal-health-html.js
     6	  // That function will match /internal-health/* and serve embedded HTML
     7	  // We skip it here so the more specific route can handle it
     8	  if (url.pathname.startsWith('/internal/health')) {
     9	    // Let the request pass through - another function or static file should handle it
    10	    // Return 404 here so the request can be handled by _redirects or other functions
    11	    return new Response('Not found', { status: 404 });
    12	  }
    13	
    14	  const required = env?.RV_INTERNAL_TOKEN;
    15	  if (required) {
    16	    const provided =
    17	      request.headers.get("x-rv-internal-token") ||
    18	      url.searchParams.get("token") ||
    19	      "";
    20	
    21	    if (!provided || provided !== required) {
    22	      return new Response("Not found", {
    23	        status: 404,
    24	        headers: { "content-type": "text/plain; charset=utf-8" }
    25	      });
    26	    }
    27	  }
    28	
    29	  const redirectTo = new URL("/internal-dashboard", request.url);
    30	  const token = url.searchParams.get("token") || "";
    31	  if (token) redirectTo.searchParams.set("token", token);
    32	  return Response.redirect(redirectTo.toString(), 302);
    33	}

## FILE: functions/proxy.js
     1	const CORS_HEADERS = {
     2	  "Access-Control-Allow-Origin": "*",
     3	  "Access-Control-Allow-Methods": "GET, POST, OPTIONS",
     4	  "Access-Control-Allow-Headers": "Content-Type"
     5	};
     6	
     7	const ALLOWED_HOSTS = new Set([
     8	  "api.coingecko.com",
     9	  "api.alternative.me"
    10	]);
    11	
    12	export async function onRequest(context) {
    13	  const { request } = context;
    14	
    15	  if (request.method === "OPTIONS") {
    16	    return new Response(null, {
    17	      status: 204,
    18	      headers: CORS_HEADERS
    19	    });
    20	  }
    21	
    22	  const url = new URL(request.url);
    23	  const targetUrl = url.searchParams.get("url");
    24	  const requestId = request.headers.get("x-rv-request-id") || "unknown";
    25	
    26	  if (!targetUrl) {
    27	    return new Response('Missing "url" parameter', { status: 400, headers: CORS_HEADERS });
    28	  }
    29	
    30	  if (!/^https?:\/\//i.test(targetUrl)) {
    31	    return new Response('Invalid "url" parameter', { status: 400, headers: CORS_HEADERS });
    32	  }
    33	
    34	  if (!["GET", "HEAD"].includes(request.method)) {
    35	    return new Response("Method not allowed", { status: 405, headers: CORS_HEADERS });
    36	  }
    37	
    38	  const target = new URL(targetUrl);
    39	  if (!ALLOWED_HOSTS.has(target.hostname)) {
    40	    return new Response("Host not allowed", { status: 403, headers: CORS_HEADERS });
    41	  }
    42	
    43	  try {
    44	    const response = await fetch(targetUrl, {
    45	      method: request.method,
    46	      headers: {
    47	        "User-Agent": "RubikVault/1.0 (Cloudflare Proxy)"
    48	      },
    49	      body: request.method === "GET" || request.method === "HEAD" ? undefined : request.body
    50	    });
    51	
    52	    const newResponse = new Response(response.body, response);
    53	    newResponse.headers.set("Access-Control-Allow-Origin", "*");
    54	    newResponse.headers.set("Access-Control-Allow-Methods", "GET, POST, OPTIONS");
    55	    newResponse.headers.set("Access-Control-Allow-Headers", "Content-Type");
    56	    newResponse.headers.set("x-rv-request-id", requestId);
    57	    newResponse.headers.set("Cache-Control", "public, max-age=60");
    58	
    59	    return newResponse;
    60	  } catch (error) {
    61	    return new Response(
    62	      JSON.stringify({
    63	        ok: false,
    64	        error: {
    65	          code: "proxy_error",
    66	          message: error?.message || "Unknown error"
    67	        },
    68	        requestId
    69	      }),
    70	      {
    71	        status: 500,
    72	        headers: {
    73	          ...CORS_HEADERS,
    74	          "Content-Type": "application/json; charset=utf-8",
    75	          "x-rv-request-id": requestId
    76	        }
    77	      }
    78	    );
    79	  }
    80	}

## FILE: scripts/_lib/contracts/envelope.js
     1	import { STATUS_LIST } from "./status-enum.js";
     2	
     3	function normalizeMeta(meta) {
     4	  const base = meta && typeof meta === "object" ? { ...meta } : {};
     5	  const status = STATUS_LIST.includes(String(base.status)) ? base.status : "ERROR";
     6	  return {
     7	    ...base,
     8	    status,
     9	    reason: base.reason ?? ""
    10	  };
    11	}
    12	
    13	export function buildEnvelope({ ok, feature, data, error, meta }) {
    14	  const safeOk = Boolean(ok);
    15	  const safeFeature = String(feature || "");
    16	  const safeMeta = normalizeMeta(meta);
    17	  const safeData = data && typeof data === "object" ? data : {};
    18	  let safeError = null;
    19	
    20	  if (!safeOk) {
    21	    if (error && typeof error === "object") {
    22	      safeError = {
    23	        code: error.code || "ERROR",
    24	        message: error.message || "",
    25	        details: error.details || {}
    26	      };
    27	    } else {
    28	      safeError = { code: "ERROR", message: "", details: {} };
    29	    }
    30	  }
    31	
    32	  return {
    33	    ok: safeOk,
    34	    feature: safeFeature,
    35	    meta: safeMeta,
    36	    data: safeData,
    37	    error: safeError
    38	  };
    39	}

## FILE: scripts/_lib/with-meta.mjs
     1	export function withMeta(data, opts = {}) {
     2	  const now = new Date().toISOString();
     3	  return {
     4	    meta: {
     5	      generatedAt: now,
     6	      asOf: now,
     7	      source: "build",
     8	      ttlSeconds: 3600,
     9	      freshness: { status: "fresh", ageMinutes: 0 },
    10	      validation: {
    11	        schema: { ok: true, errors: [] },
    12	        ranges: { ok: true, errors: [] },
    13	        integrity: { ok: true, errors: [] }
    14	      },
    15	      schedule: opts.schedule ?? null,
    16	      runId: opts.runId ?? now
    17	    },
    18	    data
    19	  };
    20	}

## FILE: scripts/aggregator/finalize.mjs
     1	#!/usr/bin/env node
     2	/**
     3	 * Finalizer - Atomic Publish Logic
     4	 * 
     5	 * Mission Control v3.0 Finalizer:
     6	 * - Downloads artifacts from GitHub Actions
     7	 * - Builds candidate manifest
     8	 * - Validates integrity
     9	 * - Performs atomic promote (tmp -> public)
    10	 * - Updates provider-state.json
    11	 * 
    12	 * This is the single-flight gatekeeper that prevents partial publishes.
    13	 */
    14	
    15	import { readFile, writeFile, readdir, stat, mkdir, rename } from 'node:fs/promises';
    16	import { promises as fs } from 'node:fs';
    17	import { join, dirname } from 'node:path';
    18	import { fileURLToPath } from 'node:url';
    19	import { computeSnapshotDigest, computeDigest } from '../lib/digest.js';
    20	import { validateEnvelopeSchema } from '../lib/envelope.js';
    21	import { generateProviderState, writeProviderState } from '../lib/provider-state.js';
    22	import { getCurrentBuildId } from '../lib/build-id.js';
    23	import { appendAuditEvent, createPublishEvent, createBlockEvent, createStateChangeEvent, EventType } from '../lib/audit-log.js';
    24	import {
    25	  createOptionalCloudflareRestKVFromEnv,
    26	  kvPutSnapshotIfChanged,
    27	  shouldSkipKvWrite
    28	} from '../lib/kv-write.js';
    29	
    30	const __filename = fileURLToPath(import.meta.url);
    31	const __dirname = dirname(__filename);
    32	
    33	const BASE_DIR = process.cwd();
    34	const ARTIFACTS_DIR = process.env.ARTIFACTS_DIR || join(BASE_DIR, 'artifacts');
    35	const TMP_DIR = join(BASE_DIR, 'public/data/.tmp');
    36	const PUBLIC_DIR = join(BASE_DIR, 'public/data');
    37	const REGISTRY_PATH = join(PUBLIC_DIR, 'registry/modules.json');
    38	const CORE_MODULES = ['universe', 'market-prices', 'market-stats', 'market-score'];
    39	
    40	async function hasNonZeroFile(filePath) {
    41	  try {
    42	    const stats = await stat(filePath);
    43	    return stats.isFile() && stats.size > 0;
    44	  } catch (err) {
    45	    if (err.code === 'ENOENT') return false;
    46	    throw err;
    47	  }
    48	}
    49	
    50	function buildPlaceholderEnvelope(moduleName, reason) {
    51	  const now = new Date().toISOString();
    52	  const placeholder = {
    53	    schema_version: '3.0',
    54	    module: moduleName,
    55	    metadata: {
    56	      module: moduleName,
    57	      schema_version: '3.0',
    58	      source: 'finalizer-placeholder',
    59	      provider: 'finalizer',
    60	      fetched_at: now,
    61	      published_at: now,
    62	      record_count: 0,
    63	      validation: {
    64	        passed: false,
    65	        checks: {
    66	          placeholder: {
    67	            passed: false,
    68	            reason: reason.message,
    69	            details: reason.details
    70	          }
    71	        }
    72	      },
    73	      warnings: ['SNAPSHOT_PLACEHOLDER']
    74	    },
    75	    error: {
    76	      code: reason.code,
    77	      message: reason.message,
    78	      details: reason.details
    79	    },
    80	    data: null
    81	  };
    82	  placeholder.metadata.digest = computeSnapshotDigest(placeholder);
    83	  return placeholder;
    84	}
    85	
    86	async function ensureCoreSnapshots(artifacts) {
    87	  const artifactsMap = artifacts || new Map();
    88	
    89	  for (const moduleName of CORE_MODULES) {
    90	    const snapshotDir = join(PUBLIC_DIR, 'snapshots', moduleName);
    91	    const snapshotPath = join(snapshotDir, 'latest.json');
    92	    await mkdir(snapshotDir, { recursive: true });
    93	    const exists = await hasNonZeroFile(snapshotPath);
    94	    if (exists) continue;
    95	
    96	    const artifactPresent = artifactsMap.has(moduleName);
    97	    const reason = {
    98	      code: artifactPresent ? 'ARTIFACT_PROMOTION_FAILED' : 'SNAPSHOT_MISSING',
    99	      message: artifactPresent
   100	        ? 'Snapshot artifact produced but could not be promoted; placeholder inserted.'
   101	        : 'No artifact available for this module; placeholder inserted to avoid 404.',
   102	      details: {
   103	        module: moduleName,
   104	        artifact_present: artifactPresent,
   105	        timestamp: new Date().toISOString()
   106	      }
   107	    };
   108	
   109	    const placeholder = buildPlaceholderEnvelope(moduleName, reason);
   110	    await writeFile(snapshotPath, JSON.stringify(placeholder, null, 2) + '\n', 'utf-8');
   111	  }
   112	}
   113	
   114	/**
   115	 * Load module registry
   116	 */
   117	async function loadRegistry() {
   118	  try {
   119	    const content = await readFile(REGISTRY_PATH, 'utf-8');
   120	    return JSON.parse(content);
   121	  } catch (err) {
   122	    console.error(`ERROR: Failed to load registry: ${err.message}`);
   123	    process.exit(1);
   124	  }
   125	}
   126	
   127	/**
   128	 * Load artifacts (simulated for now - will be real artifact downloads in GitHub Actions)
   129	 */
   130	async function loadArtifacts() {
   131	  const artifacts = new Map();
   132	  
   133	  try {
   134	    const entries = await readdir(ARTIFACTS_DIR, { withFileTypes: true });
   135	    
   136	    for (const entry of entries) {
   137	      if (!entry.isDirectory()) continue;
   138	      
   139	      const moduleName = entry.name;
   140	      const moduleDir = join(ARTIFACTS_DIR, moduleName);
   141	      
   142	      try {
   143	        const snapshotPath = join(moduleDir, 'snapshot.json');
   144	        const statePath = join(moduleDir, 'module-state.json');
   145	        
   146	        const snapshotContent = await readFile(snapshotPath, 'utf-8');
   147	        const stateContent = await readFile(statePath, 'utf-8');
   148	        
   149	        artifacts.set(moduleName, {
   150	          snapshot: JSON.parse(snapshotContent),
   151	          state: JSON.parse(stateContent)
   152	        });
   153	        
   154	        console.log(` Loaded artifact: ${moduleName}`);
   155	      } catch (err) {
   156	        console.warn(` Skipping ${moduleName}: ${err.message}`);
   157	      }
   158	    }
   159	  } catch (err) {
   160	    if (err.code === 'ENOENT') {
   161	      console.warn(` Artifacts directory not found: ${ARTIFACTS_DIR}`);
   162	      console.warn(`  (This is expected if running locally without artifacts)`);
   163	    } else {
   164	      throw err;
   165	    }
   166	  }
   167	  
   168	  return artifacts;
   169	}
   170	
   171	/**
   172	 * Validate snapshot envelope
   173	 */
   174	function validateSnapshot(snapshot, moduleConfig) {
   175	  const errors = [];
   176	  
   177	  // Schema validation
   178	  const schemaCheck = validateEnvelopeSchema(snapshot);
   179	  if (!schemaCheck.valid) {
   180	    errors.push(...schemaCheck.errors.map(e => `SCHEMA: ${e}`));
   181	  }
   182	  
   183	  // Digest verification
   184	  const computedDigest = computeSnapshotDigest(snapshot);
   185	  if (snapshot.metadata.digest !== computedDigest) {
   186	    const module = snapshot.metadata?.module || 'unknown';
   187	    errors.push(`DIGEST_MISMATCH: computed=${computedDigest}, provided=${snapshot.metadata.digest}`);
   188	    
   189	    // DEBUG: Show what data is being hashed
   190	    console.log(`\n DIGEST MISMATCH DEBUG for ${module}:`);
   191	    console.log(`  Provider digest:  ${snapshot.metadata.digest}`);
   192	    console.log(`  Computed digest:  ${computedDigest}`);
   193	    console.log(`\n  Snapshot structure:`);
   194	    console.log(`    schema_version: ${snapshot.schema_version}`);
   195	    console.log(`    module: ${snapshot.metadata.module}`);
   196	    console.log(`    source: ${snapshot.metadata.source}`);
   197	    console.log(`    record_count: ${snapshot.metadata.record_count}`);
   198	    console.log(`    data array length: ${snapshot.data?.length}`);
   199	    if (snapshot.data && snapshot.data[0]) {
   200	      console.log(`    data[0] keys: ${Object.keys(snapshot.data[0]).join(', ')}`);

## FILE: scripts/audit-site.mjs
     1	#!/usr/bin/env node
     2	import fs from "node:fs";
     3	import path from "node:path";
     4	import crypto from "node:crypto";
     5	import { execSync } from "node:child_process";
     6	import { fileURLToPath, pathToFileURL } from "node:url";
     7	
     8	const TOOL_VERSION = "audit-site/v1";
     9	const DEFAULTS = {
    10	  mode: "local",
    11	  base: "public",
    12	  format: "json",
    13	  failOn: "none",
    14	  timeoutMs: 10000,
    15	  maxDepth: 6,
    16	  maxItems: 50,
    17	  maxFieldsPerBlock: 500,
    18	  maxBlocks: 200,
    19	  maxAuditTimeMs: 60000,
    20	  maxBlocksLive: 20,
    21	  debug: false
    22	};
    23	let LAST_ARGS = { failOn: DEFAULTS.failOn };
    24	
    25	function getByPath(obj, pathExpr) {
    26	  if (!obj || typeof obj !== "object") return undefined;
    27	  const parts = String(pathExpr).split(".").filter(Boolean);
    28	  let current = obj;
    29	  for (const part of parts) {
    30	    if (current && typeof current === "object" && part in current) {
    31	      current = current[part];
    32	    } else {
    33	      return undefined;
    34	    }
    35	  }
    36	  return current;
    37	}
    38	
    39	function auditLocal({ args, auditTrace, uiMappings, schemaRegistry, featureRegistry }) {
    40	  const basePath = args.base;
    41	  const base = path.isAbsolute(basePath) ? basePath : path.join(process.cwd(), basePath);
    42	  const blocks = featureRegistry ? discoverBlocksFromRegistry(featureRegistry, base) : discoverLocalBlocks(base, auditTrace);
    43	  const freshnessPolicy = readFreshnessPolicy();
    44	  const results = [];
    45	  for (const entry of blocks) {
    46	    if (results.length >= args.maxBlocks) break;
    47	    const schemaRules =
    48	      schemaRegistry?.blockSchemas?.[entry.id] ||
    49	      schemaRegistry?.blockSchemas?.[String(entry.id).toLowerCase()] ||
    50	      schemaRegistry?.blockSchemas?.["*"] ||
    51	      null;
    52	    results.push(
    53	      auditBlockLocal({
    54	        filePath: entry.file,
    55	        blockId: entry.id,
    56	        optional: Boolean(entry.optional),
    57	        limits: { maxDepth: args.maxDepth, maxItems: args.maxItems, maxFieldsPerBlock: args.maxFieldsPerBlock },
    58	        auditTrace,
    59	        uiMappings,
    60	        schemaRules,
    61	        requiredFields: entry.requiredFields,
    62	        freshnessPolicy
    63	      })
    64	    );
    65	  }
    66	  return results;
    67	}
    68	
    69	const REASON_CODES = [
    70	  "FILE_MISSING",
    71	  "JSON_PARSE_ERROR",
    72	  "FIELD_MISSING",
    73	  "FIELD_NULLISH",
    74	  "TYPE_MISMATCH",
    75	  "FORMAT_INVALID",
    76	  "RANGE_INVALID",
    77	  "DATA_EMPTY",
    78	  "STALE_DATA",
    79	  "UPSTREAM_ERROR",
    80	  "NETWORK_TIMEOUT",
    81	  "RATE_LIMIT_EXCEEDED",
    82	  "CIRCUIT_OPEN",
    83	  "UI_MAPPING_MISMATCH",
    84	  "BASE_URL_MISCONFIG",
    85	  "DEPENDENCY_MISSING",
    86	  "LIMIT_EXCEEDED",
    87	  "UNKNOWN",
    88	  "OK"
    89	];
    90	
    91	const SEVERITY_BY_REASON = {
    92	  FILE_MISSING: "CRITICAL",
    93	  JSON_PARSE_ERROR: "CRITICAL",
    94	  BASE_URL_MISCONFIG: "CRITICAL",
    95	  UI_MAPPING_MISMATCH: "CRITICAL",
    96	  UPSTREAM_ERROR: "ERROR",
    97	  FIELD_MISSING: "ERROR",
    98	  TYPE_MISMATCH: "ERROR",
    99	  FORMAT_INVALID: "ERROR",
   100	  RANGE_INVALID: "ERROR",
   101	  STALE_DATA: "WARN",
   102	  DATA_EMPTY: "WARN",
   103	  LIMIT_EXCEEDED: "WARN",
   104	  UNKNOWN: "WARN",
   105	  OK: "INFO",
   106	  DEPENDENCY_MISSING: "WARN",
   107	  RATE_LIMIT_EXCEEDED: "WARN",
   108	  NETWORK_TIMEOUT: "WARN",
   109	  CIRCUIT_OPEN: "WARN",
   110	  FIELD_NULLISH: "ERROR"
   111	};
   112	
   113	function readFreshnessPolicy() {
   114	  const filePath = path.join(process.cwd(), "config", "freshness-policy.v6.json");
   115	  if (!fs.existsSync(filePath)) return null;
   116	  try {
   117	    const parsed = JSON.parse(fs.readFileSync(filePath, "utf8"));
   118	    if (!parsed || typeof parsed !== "object") return null;
   119	    return parsed;
   120	  } catch {
   121	    return null;
   122	  }
   123	}
   124	
   125	function resolveFreshnessPolicy(policy, blockId) {
   126	  if (!policy || typeof policy !== "object") return null;
   127	  const defaults = policy.defaults && typeof policy.defaults === "object" ? policy.defaults : {};
   128	  const blocks = policy.blocks && typeof policy.blocks === "object" ? policy.blocks : {};
   129	  const byBlock = blocks && blockId && blocks[blockId] && typeof blocks[blockId] === "object" ? blocks[blockId] : {};
   130	  const warnAfterHours =
   131	    Number.isFinite(byBlock.warn_after_hours)
   132	      ? byBlock.warn_after_hours
   133	      : Number.isFinite(defaults.warn_after_hours)
   134	        ? defaults.warn_after_hours
   135	        : 24;
   136	  const errorAfterHours =
   137	    Number.isFinite(byBlock.error_after_hours)
   138	      ? byBlock.error_after_hours
   139	      : Number.isFinite(defaults.error_after_hours)
   140	        ? defaults.error_after_hours
   141	        : null;
   142	  return {
   143	    warnAfterMs: Number.isFinite(warnAfterHours) ? warnAfterHours * 3600 * 1000 : null,
   144	    errorAfterMs: Number.isFinite(errorAfterHours) ? errorAfterHours * 3600 * 1000 : null
   145	  };
   146	}
   147	
   148	function redact(str) {
   149	  if (typeof str !== "string") return str;
   150	  return str
   151	    .replace(/api[_-]?key=([^&\s]+)/gi, "api_key=***")
   152	    .replace(/token=([^&\s]+)/gi, "token=***")
   153	    .replace(/authorization:\s*bearer\s+([^\s]+)/gi, "authorization: bearer ***")
   154	    .replace(/[a-f0-9]{32,64}/gi, "***")
   155	    .replace(/(ghp|gho|ghu|ghs|ghr)_[A-Za-z0-9_]+/gi, "$1_***")
   156	    .replace(/AKIA[0-9A-Z]{16}/gi, "AKIA***")
   157	    .replace(/eyJ[A-Za-z0-9_-]{10,}\.[A-Za-z0-9_-]{10,}\.[A-Za-z0-9_-]{10,}/gi, "eyJ***")
   158	    .replace(/[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}/g, "***@***.***")
   159	    .replace(/\+?\d{1,3}[-.\s]?\d{1,4}[-.\s]?\d{1,4}[-.\s]?\d{1,9}/g, "+***");
   160	}
   161	
   162	function valuePreview(value) {
   163	  if (value === null) return "null";
   164	  if (value === undefined) return "undefined";
   165	  if (typeof value === "number") return value;
   166	  if (typeof value === "string") {
   167	    const cleaned = redact(value);
   168	    return cleaned.length > 80 ? `${cleaned.slice(0, 80)}` : cleaned;
   169	  }
   170	  if (Array.isArray(value)) return `[Array(${value.length})]`;
   171	  if (typeof value === "object") return `{Object(${Object.keys(value).length} keys)}`;
   172	  return redact(String(value));
   173	}
   174	
   175	function nowIso() {
   176	  return new Date().toISOString();
   177	}
   178	
   179	function stableHash(input) {
   180	  return crypto.createHash("sha256").update(input).digest("hex").slice(0, 12);
   181	}
   182	
   183	function parseArgs(argv) {
   184	  const args = { ...DEFAULTS };
   185	  for (let i = 0; i < argv.length; i += 1) {
   186	    const key = argv[i];
   187	    if (!key.startsWith("--")) continue;
   188	    const name = key.slice(2);
   189	    const next = argv[i + 1];
   190	    if (next && !next.startsWith("--")) {
   191	      args[name] = next;
   192	      i += 1;
   193	    } else {
   194	      args[name] = true;
   195	    }
   196	  }
   197	  args.timeoutMs = Number(args.timeoutMs) || DEFAULTS.timeoutMs;
   198	  args.maxDepth = Number(args.maxDepth) || DEFAULTS.maxDepth;
   199	  args.maxItems = Number(args.maxItems) || DEFAULTS.maxItems;
   200	  args.maxFieldsPerBlock = Number(args.maxFieldsPerBlock) || DEFAULTS.maxFieldsPerBlock;

## FILE: scripts/audit/REALITY.md
     1	Audit Reality Snapshot
     2	
     3	REPO_ROOT: (captured at runtime; do not hardcode absolute paths)
     4	TOPLEVEL: (captured at runtime; do not hardcode absolute paths)
     5	BRANCH: main
     6	GIT_SHA: 0164b992abbbdcdd82df089945d50f360beb7c93
     7	GIT_STATUS_PORCELAIN:
     8	M public/data/feature-registry.v1.json
     9	 M public/mirrors/_health.json
    10	 M public/mirrors/manifest.json
    11	 M scripts/audit/REALITY.md
    12	
    13	NODE_VERSION: v25.2.1
    14	NPM_VERSION: 11.6.2
    15	
    16	MIRRORS_DIR_EXISTS: yes
    17	MIRRORS_DIR: (repo_root)/public/mirrors
    18	
    19	MIRROR_FILES:
    20	public/mirrors/_health.json
    21	public/mirrors/alpha-performance.json
    22	public/mirrors/alpha-radar.json
    23	public/mirrors/analyst-stampede.json
    24	public/mirrors/arb-breadth-lite.json
    25	public/mirrors/arb-liquidity-pulse.json
    26	public/mirrors/arb-risk-regime.json
    27	public/mirrors/breakout-energy.json
    28	public/mirrors/central-bank-watch.json
    29	public/mirrors/congress-trading.json
    30	
    31	FEATURES_DIR_EXISTS: yes
    32	SCRIPTS_DIR_EXISTS: yes
    33	FUNCTIONS_DIR_EXISTS: yes
    34	
    35	HTML_FEATURE_COUNT: 32
    36	HTML_FEATURE_SAMPLE:
    37	rv-market-cockpit
    38	rv-yield-curve
    39	rv-sector-rotation
    40	rv-central-bank-watch
    41	rv-market-health
    42	rv-price-snapshot
    43	rv-top-movers
    44	rv-earnings-calendar
    45	rv-news-headlines
    46	rv-news-intelligence
    47	rv-watchlist-local
    48	rv-export-csv
    49	rv-macro-rates
    50	rv-sp500-sectors
    51	rv-market-regime
    52	rv-arb-risk-regime
    53	rv-arb-liquidity-pulse
    54	rv-arb-breadth-lite
    55	rv-why-moved
    56	rv-volume-anomaly
    57	
    58	MIRROR_FEATURE_COUNT: 38
    59	MIRROR_FEATURE_SAMPLE:
    60	alpha-performance
    61	alpha-radar
    62	analyst-stampede
    63	arb-breadth-lite
    64	arb-liquidity-pulse
    65	arb-risk-regime
    66	breakout-energy
    67	central-bank-watch
    68	congress-trading
    69	crypto-snapshot
    70	daily-digest
    71	earnings-calendar
    72	earnings-reality
    73	earnings
    74	export-csv
    75	hype-divergence
    76	insider-cluster
    77	macro-rates
    78	market-cockpit
    79	market-health
    80	
    81	DRIFT_HTML_NOT_IN_MIRRORS:
    82	rv-market-cockpit
    83	rv-yield-curve
    84	rv-sector-rotation
    85	rv-central-bank-watch
    86	rv-market-health
    87	rv-price-snapshot
    88	rv-top-movers
    89	rv-earnings-calendar
    90	rv-news-headlines
    91	rv-news-intelligence
    92	rv-watchlist-local
    93	rv-export-csv
    94	rv-macro-rates
    95	rv-sp500-sectors
    96	rv-market-regime
    97	rv-arb-risk-regime
    98	rv-arb-liquidity-pulse
    99	rv-arb-breadth-lite
   100	rv-why-moved
   101	rv-volume-anomaly
   102	
   103	DRIFT_MIRRORS_NOT_IN_HTML:
   104	alpha-performance
   105	alpha-radar
   106	analyst-stampede
   107	arb-breadth-lite
   108	arb-liquidity-pulse
   109	arb-risk-regime
   110	breakout-energy
   111	central-bank-watch
   112	congress-trading
   113	crypto-snapshot
   114	daily-digest
   115	earnings-calendar
   116	earnings-reality
   117	earnings
   118	export-csv
   119	hype-divergence
   120	insider-cluster
   121	macro-rates
   122	market-cockpit
   123	market-health
   124	
   125	TREE_PUBLIC_MAXDEPTH3_FILES:
   126	public/build-info.json
   127	public/index.html
   128	public/posts/.gitkeep
   129	public/.DS_Store
   130	public/_redirects
   131	public/_headers
   132	public/mirrors/smart-money.json
   133	public/mirrors/alpha-performance.json
   134	public/mirrors/sector-rotation.json
   135	public/mirrors/export-csv.json
   136	public/mirrors/sentiment.json
   137	public/mirrors/breakout-energy.json
   138	public/mirrors/news-headlines.json
   139	public/mirrors/arb-risk-regime.json
   140	public/mirrors/macro-rates.json
   141	public/mirrors/market-health.json
   142	public/mirrors/analyst-stampede.json
   143	public/mirrors/volume-anomaly.json
   144	public/mirrors/daily-digest.json
   145	public/mirrors/market-cockpit.json
   146	public/mirrors/price-snapshot.json
   147	public/mirrors/earnings.json
   148	public/mirrors/quotes.json
   149	public/mirrors/arb-liquidity-pulse.json
   150	public/mirrors/_health.json
   151	public/mirrors/why-moved.json
   152	public/mirrors/news.json
   153	public/mirrors/tech-signals.json
   154	public/mirrors/yield-curve.json
   155	public/mirrors/hype-divergence.json
   156	public/mirrors/news-intelligence.json
   157	public/mirrors/top-movers.json
   158	public/mirrors/sentiment-barometer.json
   159	public/mirrors/manifest.json
   160	public/mirrors/insider-cluster.json
   161	public/mirrors/sp500-sectors.json
   162	public/mirrors/market-regime.json
   163	public/mirrors/earnings-reality.json
   164	public/mirrors/earnings-calendar.json
   165	public/mirrors/alpha-radar.json
   166	public/mirrors/crypto-snapshot.json
   167	public/mirrors/watchlist-local.json
   168	public/mirrors/arb-breadth-lite.json
   169	public/mirrors/system-health.json
   170	public/mirrors/central-bank-watch.json
   171	public/mirrors/congress-trading.json
   172	public/diagnose.js
   173	
   174	TREE_SCRIPTS_MAXDEPTH4_FILES:
   175	scripts/audit-site.mjs
   176	scripts/seed-mirrors.mjs
   177	scripts/validate-mirrors.mjs
   178	scripts/smoke-debug.mjs
   179	scripts/generate-crypto-snapshot.mjs
   180	scripts/generate-eod-market.mjs
   181	scripts/dev-local.sh
   182	scripts/generate-event-mirrors.mjs
   183	scripts/generate-eod-mirrors.mjs
   184	scripts/utils/stooq-fetch.mjs
   185	scripts/utils/market-rsi.mjs
   186	scripts/utils/eod-market-symbols.mjs
   187	scripts/utils/market-indicators.mjs
   188	scripts/utils/mirror-builders.mjs
   189	scripts/utils/eod-market-mirrors.mjs
   190	scripts/utils/universe.mjs
   191	scripts/utils/mirror-io.mjs
   192	scripts/move-repo-out-of-cloud.sh
   193	scripts/audit/generate-stub-mirrors.mjs
   194	scripts/audit/REALITY.md
   195	scripts/audit/generate-reality.mjs
   196	scripts/audit/build-artifacts.mjs
   197	scripts/audit/build-feature-registry.mjs
   198	scripts/mirror-breakout-energy.mjs
   199	scripts/alpha-radar-debug.js
   200	scripts/build-mirrors-manifest.mjs

## FILE: scripts/audit/build-artifacts.mjs
     1	#!/usr/bin/env node
     2	import fs from "node:fs";
     3	import path from "node:path";
     4	import { execSync } from "node:child_process";
     5	
     6	const ROOT = process.cwd();
     7	const REGISTRY_PATH = path.join(ROOT, "public", "data", "feature-registry.v1.json");
     8	const OUTPUT_DIR = path.join(ROOT, "internal", "mirror-artifacts");
     9	const MANIFEST_PATH = path.join(OUTPUT_DIR, "manifest.json");
    10	const HEALTH_PATH = path.join(OUTPUT_DIR, "_health.json");
    11	
    12	function nowIso() {
    13	  return new Date().toISOString();
    14	}
    15	
    16	function readJson(filePath) {
    17	  try {
    18	    return JSON.parse(fs.readFileSync(filePath, "utf8"));
    19	  } catch {
    20	    return null;
    21	  }
    22	}
    23	
    24	function safeCommit() {
    25	  try {
    26	    return execSync("git rev-parse HEAD", { encoding: "utf8" }).trim();
    27	  } catch {
    28	    return null;
    29	  }
    30	}
    31	
    32	function atomicWrite(filePath, content) {
    33	  const tmpPath = `${filePath}.tmp`;
    34	  fs.mkdirSync(path.dirname(filePath), { recursive: true });
    35	  fs.writeFileSync(tmpPath, content);
    36	  fs.renameSync(tmpPath, filePath);
    37	}
    38	
    39	function shouldWrite(filePath, next) {
    40	  if (!fs.existsSync(filePath)) return true;
    41	  const current = fs.readFileSync(filePath, "utf8");
    42	  return current.trim() !== next.trim();
    43	}
    44	
    45	const registry = readJson(REGISTRY_PATH);
    46	if (!registry || !Array.isArray(registry.features)) {
    47	  process.stderr.write("Missing or invalid registry. Run build-feature-registry first.\n");
    48	  process.exit(1);
    49	}
    50	
    51	const commit = safeCommit();
    52	const generatedAt = nowIso();
    53	const manifestBlocks = [];
    54	const healthFeatures = {};
    55	
    56	registry.features.forEach((feature) => {
    57	  const mirrorPath = feature.mirrorPath || `mirrors/${feature.id}.json`;
    58	  const fullPath = path.isAbsolute(mirrorPath) ? mirrorPath : path.join(ROOT, mirrorPath);
    59	  let json = null;
    60	  let parseError = null;
    61	  try {
    62	    json = JSON.parse(fs.readFileSync(fullPath, "utf8"));
    63	  } catch (error) {
    64	    parseError = error;
    65	  }
    66	  const raw = json && json.meta && json.raw ? json.raw : json;
    67	
    68	  const fileRel = mirrorPath.replace(/^public\//, "");
    69	  const schemaVersion = raw?.meta?.schemaVersion || raw?.schemaVersion || "v1";
    70	  const updatedAt =
    71	    raw?.meta?.asOf || raw?.meta?.generatedAt || raw?.meta?.updatedAt || raw?.meta?.savedAt || raw?.updatedAt || null;
    72	  const staleAfter = Number(feature.staleAfterMinutes || 1440);
    73	  let status = "OK";
    74	  let reasonCode = "OK";
    75	  let ageMinutes = null;
    76	
    77	  if (parseError) {
    78	    status = "ERROR";
    79	    reasonCode = "JSON_PARSE_ERROR";
    80	  } else if (!raw) {
    81	    status = "ERROR";
    82	    reasonCode = "MIRROR_MISSING";
    83	  } else if (raw?.meta?.status === "STUB") {
    84	    status = "STUB";
    85	    reasonCode = "MIRROR_MISSING";
    86	  } else if (updatedAt) {
    87	    const ageMs = Date.now() - Date.parse(updatedAt);
    88	    ageMinutes = Math.max(0, Math.round(ageMs / 60000));
    89	    if (Number.isFinite(ageMinutes) && ageMinutes > staleAfter) {
    90	      status = "STALE";
    91	      reasonCode = "STALE_DATA";
    92	    }
    93	  }
    94	
    95	  healthFeatures[feature.id] = {
    96	    status,
    97	    updatedAt: updatedAt || null,
    98	    ageMinutes,
    99	    reasonCode,
   100	    evidence: {
   101	      file: fileRel,
   102	      updatedAt: updatedAt || null,
   103	      staleAfterMinutes: staleAfter,
   104	      errorMessage: parseError ? parseError.message : null
   105	    }
   106	  };
   107	
   108	  manifestBlocks.push({
   109	    id: feature.id,
   110	    file: fileRel.replace(/^mirrors\//, "mirrors/"),
   111	    schemaVersion,
   112	    optional: Boolean(feature.optional),
   113	    generatedAt: updatedAt
   114	  });
   115	});
   116	
   117	const manifest = {
   118	  version: "1.0",
   119	  generated_at: generatedAt,
   120	  commit,
   121	  blocks: manifestBlocks.sort((a, b) => String(a.id).localeCompare(String(b.id)))
   122	};
   123	
   124	const health = {
   125	  meta: {
   126	    status: "OK",
   127	    updatedAt: generatedAt,
   128	    reason: null
   129	  },
   130	  generatedAt,
   131	  features: Object.fromEntries(
   132	    Object.entries(healthFeatures).sort(([a], [b]) => String(a).localeCompare(String(b)))
   133	  )
   134	};
   135	
   136	const manifestText = JSON.stringify(manifest, null, 2);
   137	const healthText = JSON.stringify(health, null, 2);
   138	
   139	if (shouldWrite(MANIFEST_PATH, manifestText) || shouldWrite(HEALTH_PATH, healthText)) {
   140	  const tmpManifest = `${MANIFEST_PATH}.tmp`;
   141	  const tmpHealth = `${HEALTH_PATH}.tmp`;
   142	  fs.mkdirSync(path.dirname(MANIFEST_PATH), { recursive: true });
   143	  fs.writeFileSync(tmpManifest, manifestText);
   144	  fs.writeFileSync(tmpHealth, healthText);
   145	  fs.renameSync(tmpManifest, MANIFEST_PATH);
   146	  fs.renameSync(tmpHealth, HEALTH_PATH);
   147	  process.stdout.write("Artifacts written.\n");
   148	} else {
   149	  process.stdout.write("Artifacts unchanged.\n");
   150	}

## FILE: scripts/audit/build-feature-registry.mjs
     1	#!/usr/bin/env node
     2	import fs from "node:fs";
     3	import path from "node:path";
     4	
     5	const ROOT = process.cwd();
     6	const REGISTRY_PATH = path.join(ROOT, "public", "data", "feature-registry.v1.json");
     7	const MIRRORS_DIR = path.join(ROOT, "mirrors");
     8	
     9	function nowIso() {
    10	  return new Date().toISOString();
    11	}
    12	
    13	function readJson(filePath) {
    14	  try {
    15	    return JSON.parse(fs.readFileSync(filePath, "utf8"));
    16	  } catch {
    17	    return null;
    18	  }
    19	}
    20	
    21	function normalizeId(raw) {
    22	  if (!raw) return "";
    23	  const trimmed = String(raw).trim();
    24	  const noPrefix = trimmed.startsWith("rv-") ? trimmed.slice(3) : trimmed;
    25	  return noPrefix.toLowerCase();
    26	}
    27	
    28	function titleCase(id) {
    29	  return id
    30	    .split("-")
    31	    .filter(Boolean)
    32	    .map((part) => part.charAt(0).toUpperCase() + part.slice(1))
    33	    .join(" ");
    34	}
    35	
    36	function sortObject(value) {
    37	  if (Array.isArray(value)) return value.map(sortObject);
    38	  if (value && typeof value === "object") {
    39	    const out = {};
    40	    Object.keys(value)
    41	      .sort()
    42	      .forEach((key) => {
    43	        out[key] = sortObject(value[key]);
    44	      });
    45	    return out;
    46	  }
    47	  return value;
    48	}
    49	
    50	function stableStringify(value) {
    51	  return JSON.stringify(sortObject(value), null, 2);
    52	}
    53	
    54	function extractHtmlFeatures() {
    55	  const htmlPaths = [
    56	    path.join(ROOT, "public", "index.html"),
    57	    path.join(ROOT, "index.html")
    58	  ];
    59	  const htmlPath = htmlPaths.find((p) => fs.existsSync(p));
    60	  if (!htmlPath) return [];
    61	  const html = fs.readFileSync(htmlPath, "utf8");
    62	  const regex = /data-rv-feature="([^"]+)"/g;
    63	  const found = new Set();
    64	  let match;
    65	  while ((match = regex.exec(html))) {
    66	    const normalized = normalizeId(match[1]);
    67	    if (normalized) found.add(normalized);
    68	  }
    69	  return [...found];
    70	}
    71	
    72	function extractMirrorFeatures() {
    73	  if (!fs.existsSync(MIRRORS_DIR)) return [];
    74	  return fs
    75	    .readdirSync(MIRRORS_DIR)
    76	    .filter((file) => file.endsWith(".json"))
    77	    .filter((file) => !["manifest.json", "_health.json"].includes(file))
    78	    .map((file) => file.replace(/\.json$/, ""))
    79	    .map(normalizeId)
    80	    .filter(Boolean);
    81	}
    82	
    83	function defaultEntry(id) {
    84	  return {
    85	    id,
    86	    name: titleCase(id),
    87	    mirrorPath: `mirrors/${id}.json`,
    88	    schemaVersion: "v1",
    89	    staleAfterMinutes: 1440,
    90	    critical: false,
    91	    requiredFields: ["meta.status", "meta.updatedAt"],
    92	    providers: [],
    93	    _deprecated: false
    94	  };
    95	}
    96	
    97	function mergeFeature(existing, discovered, now) {
    98	  const merged = { ...discovered, ...(existing || {}) };
    99	  merged._lastSeen = now;
   100	  merged._deprecated = false;
   101	  if (merged._deprecatedReason) delete merged._deprecatedReason;
   102	  if (merged._deprecatedAt) delete merged._deprecatedAt;
   103	  return merged;
   104	}
   105	
   106	function buildRegistry() {
   107	  const now = nowIso();
   108	  const htmlFeatures = extractHtmlFeatures();
   109	  const mirrorFeatures = extractMirrorFeatures();
   110	  const discoveredIds = Array.from(new Set([...htmlFeatures, ...mirrorFeatures])).sort();
   111	
   112	  const existing = readJson(REGISTRY_PATH);
   113	  const existingFeatures = Array.isArray(existing?.features) ? existing.features : [];
   114	  const existingById = new Map(existingFeatures.map((entry) => [String(entry.id).toLowerCase(), entry]));
   115	
   116	  const features = [];
   117	  discoveredIds.forEach((id) => {
   118	    const discovered = defaultEntry(id);
   119	    const existingEntry = existingById.get(id);
   120	    features.push(mergeFeature(existingEntry, discovered, now));
   121	  });
   122	
   123	  existingFeatures.forEach((entry) => {
   124	    const id = normalizeId(entry.id);
   125	    if (!id) return;
   126	    if (!discoveredIds.includes(id)) {
   127	      const deprecated = { ...entry };
   128	      deprecated._deprecated = true;
   129	      deprecated._deprecatedAt = now;
   130	      deprecated._deprecatedReason = "Removed from discovery (HTML/mirrors)";
   131	      deprecated._lastSeen = deprecated._lastSeen || now;
   132	      features.push(deprecated);
   133	    }
   134	  });
   135	
   136	  const sorted = features.sort((a, b) => String(a.id).localeCompare(String(b.id)));
   137	  return {
   138	    registryVersion: "1.0",
   139	    generatedAt: now,
   140	    features: sorted
   141	  };
   142	}
   143	
   144	function writeRegistry(registry) {
   145	  const next = stableStringify(registry);
   146	  if (fs.existsSync(REGISTRY_PATH)) {
   147	    const current = fs.readFileSync(REGISTRY_PATH, "utf8");
   148	    if (current.trim() === next.trim()) {
   149	      process.stdout.write("Registry unchanged.\n");
   150	      return;
   151	    }
   152	  }
   153	  fs.mkdirSync(path.dirname(REGISTRY_PATH), { recursive: true });
   154	  const tmpPath = `${REGISTRY_PATH}.tmp`;
   155	  fs.writeFileSync(tmpPath, next);
   156	  fs.renameSync(tmpPath, REGISTRY_PATH);
   157	  process.stdout.write(`Registry written: ${REGISTRY_PATH}\n`);
   158	}
   159	
   160	const registry = buildRegistry();
   161	writeRegistry(registry);
   162	
   163	const stats = {
   164	  total: registry.features.length,
   165	  deprecated: registry.features.filter((f) => f._deprecated).length
   166	};
   167	process.stdout.write(`Summary: total=${stats.total} deprecated=${stats.deprecated}\n`);

## FILE: scripts/audit/generate-reality.mjs
     1	import fs from "node:fs";
     2	import path from "node:path";
     3	import { execSync } from "node:child_process";
     4	
     5	const TEMPLATE = `Audit Reality Snapshot
     6	
     7	REPO_ROOT: {{pwd}}
     8	TOPLEVEL: {{git_toplevel}}
     9	BRANCH: {{git_branch}}
    10	GIT_SHA: {{git_sha}}
    11	GIT_STATUS_PORCELAIN:
    12	{{git_status}}
    13	
    14	NODE_VERSION: {{node_version}}
    15	NPM_VERSION: {{npm_version}}
    16	
    17	MIRRORS_DIR_EXISTS: {{mirrors_exists}}
    18	MIRRORS_DIR: {{mirrors_dir}}
    19	
    20	MIRROR_FILES:
    21	{{mirror_files}}
    22	
    23	FEATURES_DIR_EXISTS: {{features_exists}}
    24	SCRIPTS_DIR_EXISTS: {{scripts_exists}}
    25	FUNCTIONS_DIR_EXISTS: {{functions_exists}}
    26	
    27	HTML_FEATURE_COUNT: {{html_feature_count}}
    28	HTML_FEATURE_SAMPLE:
    29	{{html_feature_sample}}
    30	
    31	MIRROR_FEATURE_COUNT: {{mirror_feature_count}}
    32	MIRROR_FEATURE_SAMPLE:
    33	{{mirror_feature_sample}}
    34	
    35	DRIFT_HTML_NOT_IN_MIRRORS:
    36	{{drift_html_missing}}
    37	
    38	DRIFT_MIRRORS_NOT_IN_HTML:
    39	{{drift_mirror_missing}}
    40	
    41	TREE_PUBLIC_MAXDEPTH3_FILES:
    42	{{tree_public_files}}
    43	
    44	TREE_SCRIPTS_MAXDEPTH4_FILES:
    45	{{tree_scripts_files}}
    46	
    47	PACKAGE_JSON_PRESENT: {{package_json_present}}
    48	
    49	ISSUES DETECTED:
    50	{{issues_detected}}
    51	`;
    52	
    53	function run(cmd, { allowFail = false } = {}) {
    54	  try {
    55	    return execSync(cmd, { encoding: "utf8", stdio: ["ignore", "pipe", "pipe"] }).trim();
    56	  } catch (error) {
    57	    if (allowFail) {
    58	      const msg = String(error?.stdout || error?.stderr || error?.message || "").trim();
    59	      return msg || "ERROR";
    60	    }
    61	    throw error;
    62	  }
    63	}
    64	
    65	function yesNo(value) {
    66	  return value ? "yes" : "no";
    67	}
    68	
    69	function ensureRepo(root) {
    70	  if (!root) {
    71	    console.error("STOP: not a git repo");
    72	    process.exit(1);
    73	  }
    74	}
    75	
    76	function ensureNodeVersion() {
    77	  const major = Number((process.versions.node || "0").split(".")[0]);
    78	  if (Number.isNaN(major) || major < 20) {
    79	    console.error("STOP: Node < 20");
    80	    process.exit(1);
    81	  }
    82	}
    83	
    84	function ensureExists(filePath, message) {
    85	  if (!fs.existsSync(filePath)) {
    86	    console.error(message);
    87	    process.exit(1);
    88	  }
    89	}
    90	
    91	function extractHtmlFeatures(rootDir) {
    92	  const htmlPaths = [
    93	    path.join(rootDir, "public", "index.html"),
    94	    path.join(rootDir, "index.html")
    95	  ];
    96	  const htmlPath = htmlPaths.find((candidate) => fs.existsSync(candidate));
    97	  if (!htmlPath) return [];
    98	  const html = fs.readFileSync(htmlPath, "utf8");
    99	  const regex = /data-rv-feature="([^"]+)"/g;
   100	  const found = new Set();
   101	  let match;
   102	  while ((match = regex.exec(html))) {
   103	    const raw = match[1];
   104	    if (raw) found.add(raw.trim());
   105	  }
   106	  return [...found];
   107	}
   108	
   109	function extractMirrorFeatures(mirrorsDir) {
   110	  if (!fs.existsSync(mirrorsDir)) return [];
   111	  return fs
   112	    .readdirSync(mirrorsDir)
   113	    .filter((f) => f.endsWith(".json"))
   114	    .filter((f) => !["manifest.json", "_health.json"].includes(f))
   115	    .map((f) => f.replace(/\.json$/, ""));
   116	}
   117	
   118	function formatIssue(severity, message) {
   119	  return `- [${severity}] ${message}`;
   120	}
   121	
   122	const pwd = process.cwd();
   123	const gitTop = run("git rev-parse --show-toplevel", { allowFail: true });
   124	ensureRepo(gitTop);
   125	ensureNodeVersion();
   126	
   127	const root = gitTop || pwd;
   128	const mirrorsDir = path.join(root, "public", "data", "snapshots");
   129	ensureExists(mirrorsDir, "Repo has no public/data/snapshots; audit can't run");
   130	ensureExists(path.join(root, "package.json"), "STOP: package.json missing");
   131	
   132	const mirrorFilesAll = fs
   133	  .readdirSync(mirrorsDir)
   134	  .filter((f) => f.endsWith(".json"))
   135	  .map((f) => `public/data/snapshots/${f}`);
   136	const mirrorFiles = mirrorFilesAll.slice(0, 10);
   137	const htmlFeatures = extractHtmlFeatures(root);
   138	const mirrorFeatures = extractMirrorFeatures(mirrorsDir);
   139	const htmlMissing = htmlFeatures.filter((id) => !mirrorFeatures.includes(id));
   140	const mirrorMissing = mirrorFeatures.filter((id) => !htmlFeatures.includes(id));
   141	const issues = [];
   142	
   143	if (!fs.existsSync(path.join(root, "public", "data", "feature-registry.v1.json"))) {
   144	  issues.push(formatIssue("WARN", "feature-registry.v1.json missing (registry-first audit will fall back to discovery)"));
   145	}
   146	if (htmlMissing.length) {
   147	  issues.push(
   148	    formatIssue(
   149	      "WARN",
   150	      `HTML features missing snapshots: count=${htmlMissing.length} sample=${htmlMissing.slice(0, 10).join(", ")}`
   151	    )
   152	  );
   153	}
   154	if (mirrorMissing.length) {
   155	  issues.push(
   156	    formatIssue(
   157	      "WARN",
   158	      `Snapshots not in HTML: count=${mirrorMissing.length} sample=${mirrorMissing.slice(0, 10).join(", ")}`
   159	    )
   160	  );
   161	}
   162	if (!issues.length) {
   163	  issues.push(formatIssue("INFO", "none"));
   164	}
   165	
   166	const data = {
   167	  pwd: run("pwd", { allowFail: true }),
   168	  git_toplevel: gitTop,
   169	  git_branch: run("git branch --show-current", { allowFail: true }),
   170	  git_sha: run("git log -1 --format=%H", { allowFail: true }),
   171	  git_status: run("git status --porcelain", { allowFail: true }),
   172	  node_version: run("node --version", { allowFail: true }),
   173	  npm_version: run("npm --version", { allowFail: true }) || "missing",
   174	  mirrors_exists: yesNo(fs.existsSync(mirrorsDir)),
   175	  mirrors_dir: fs.existsSync(mirrorsDir) ? mirrorsDir : "n/a",
   176	  mirror_files: mirrorFiles.length ? mirrorFiles.join("\n") : "none",
   177	  features_exists: yesNo(fs.existsSync(path.join(root, "features"))),
   178	  scripts_exists: yesNo(fs.existsSync(path.join(root, "scripts"))),
   179	  functions_exists: yesNo(fs.existsSync(path.join(root, "functions"))),
   180	  html_feature_count: htmlFeatures.length,
   181	  html_feature_sample: htmlFeatures.length ? htmlFeatures.slice(0, 20).join("\n") : "none",
   182	  mirror_feature_count: mirrorFeatures.length,
   183	  mirror_feature_sample: mirrorFeatures.length ? mirrorFeatures.slice(0, 20).join("\n") : "none",
   184	  drift_html_missing: htmlMissing.length ? htmlMissing.slice(0, 20).join("\n") : "none",
   185	  drift_mirror_missing: mirrorMissing.length ? mirrorMissing.slice(0, 20).join("\n") : "none",
   186	  tree_public_files: run("find public -maxdepth 3 -type f -print || true", { allowFail: true }) || "n/a",
   187	  tree_scripts_files: run("find scripts -maxdepth 4 -type f -print || true", { allowFail: true }) || "n/a",
   188	  package_json_present: yesNo(fs.existsSync(path.join(root, "package.json"))),
   189	  issues_detected: issues.join("\n")
   190	};
   191	
   192	let output = TEMPLATE;
   193	Object.entries(data).forEach(([key, value]) => {
   194	  const safe = value === "" ? "" : String(value);
   195	  output = output.replace(new RegExp(`{{${key}}}`, "g"), safe);
   196	});
   197	
   198	const outDir = path.join(root, "scripts", "audit");
   199	fs.mkdirSync(outDir, { recursive: true });
   200	fs.writeFileSync(path.join(outDir, "REALITY.md"), output);

## FILE: scripts/audit/generate-stub-mirrors.mjs
     1	#!/usr/bin/env node
     2	import fs from "node:fs";
     3	import path from "node:path";
     4	import { saveMirror } from "../utils/mirror-io.mjs";
     5	
     6	const ROOT = process.cwd();
     7	const REGISTRY_PATH = path.join(ROOT, "public", "data", "feature-registry.v1.json");
     8	
     9	function nowIso() {
    10	  return new Date().toISOString();
    11	}
    12	
    13	function readJson(filePath) {
    14	  try {
    15	    return JSON.parse(fs.readFileSync(filePath, "utf8"));
    16	  } catch {
    17	    return null;
    18	  }
    19	}
    20	
    21	const registry = readJson(REGISTRY_PATH);
    22	if (!registry || !Array.isArray(registry.features)) {
    23	  process.stderr.write("Missing or invalid registry. Run build-feature-registry first.\n");
    24	  process.exit(1);
    25	}
    26	
    27	let created = 0;
    28	registry.features.forEach((feature) => {
    29	  const mirrorPath = feature.mirrorPath || `mirrors/${feature.id}.json`;
    30	  const fullPath = path.isAbsolute(mirrorPath) ? mirrorPath : path.join(ROOT, mirrorPath);
    31	  if (fs.existsSync(fullPath)) return;
    32	  const stub = {
    33	    meta: {
    34	      feature: feature.id,
    35	      status: "STUB",
    36	      reason: "MIRROR_MISSING",
    37	      updatedAt: nowIso(),
    38	      schemaVersion: feature.schemaVersion || "v1"
    39	    },
    40	    data: {}
    41	  };
    42	  saveMirror(fullPath, stub);
    43	  created += 1;
    44	});
    45	
    46	process.stdout.write(`Stub mirrors created: ${created}\n`);

## FILE: scripts/contract-smoke.js
     1	import fs from "node:fs";
     2	import { readFile } from "node:fs/promises";
     3	import path from "node:path";
     4	
     5	function resolveFirstExisting(root, relPaths) {
     6	  const tried = [];
     7	  for (const rel of relPaths) {
     8	    const abs = path.join(root, rel);
     9	    tried.push(abs);
    10	    if (fs.existsSync(abs)) return { ok: true, path: abs, tried };
    11	  }
    12	  return { ok: false, path: null, tried };
    13	}
    14	
    15	function walkFiles(dir, out, opts) {
    16	  if (!fs.existsSync(dir)) return;
    17	  const entries = fs.readdirSync(dir, { withFileTypes: true });
    18	  for (const entry of entries) {
    19	    const full = path.join(dir, entry.name);
    20	    if (entry.isDirectory()) {
    21	      if (opts.skipDirs.has(entry.name)) continue;
    22	      walkFiles(full, out, opts);
    23	      continue;
    24	    }
    25	    if (!entry.isFile()) continue;
    26	    const lower = entry.name.toLowerCase();
    27	    if (opts.skipExts.has(path.extname(lower))) continue;
    28	    if (lower.includes(".bak")) continue;
    29	    if (lower.endsWith(".map")) continue;
    30	    out.push(full);
    31	  }
    32	}
    33	
    34	function guardNoMetaNull(root) {
    35	  const files = [];
    36	  const opts = {
    37	    skipDirs: new Set(["node_modules", ".git", ".wrangler", "dist", "build"]),
    38	    skipExts: new Set([".png", ".jpg", ".jpeg", ".gif", ".webp", ".ico", ".svg"]) 
    39	  };
    40	  ["scripts", "public"].forEach((rel) => walkFiles(path.join(root, rel), files, opts));
    41	  walkFiles(path.join(root, "functions", "api"), files, opts);
    42	  const offenders = [];
    43	  const re = /\bmeta\s*:\s*null\b|\bmeta\s*=\s*null\b|return\s*\{\s*meta\s*:\s*null\b/;
    44	  for (const filePath of files) {
    45	    if (!/\.(js|mjs|ts|json|md)$/i.test(filePath)) continue;
    46	    let raw;
    47	    try {
    48	      raw = fs.readFileSync(filePath, "utf8");
    49	    } catch {
    50	      continue;
    51	    }
    52	    if (re.test(raw)) offenders.push(filePath);
    53	    if (offenders.length >= 10) break;
    54	  }
    55	  if (offenders.length) {
    56	    throw new Error(`Forbidden meta null pattern found in:\n${offenders.map((p) => `- ${p}`).join("\n")}`);
    57	  }
    58	}
    59	
    60	function validateEnvelope(obj) {
    61	  if (!obj || typeof obj !== "object") return false;
    62	  if (typeof obj.ok !== "boolean") return false;
    63	  if (typeof obj.feature !== "string") return false;
    64	  if (!obj.meta || typeof obj.meta !== "object") return false;
    65	  if (typeof obj.meta.status !== "string") return false;
    66	  if (!obj.data || typeof obj.data !== "object") return false;
    67	  if (!(obj.error === null || typeof obj.error === "object")) return false;
    68	  return true;
    69	}
    70	
    71	function hasArray(value) {
    72	  return Array.isArray(value);
    73	}
    74	
    75	function fail(message) {
    76	  throw new Error(message);
    77	}
    78	
    79	async function validateTechSignalsPayloads(root) {
    80	  const mirrorPath = path.join(root, "public", "mirrors", "tech-signals.json");
    81	  const snapshotPath = path.join(root, "public", "data", "snapshots", "tech-signals.json");
    82	  const mirrorRaw = JSON.parse(await readFile(mirrorPath, "utf8"));
    83	  const snapshotRaw = JSON.parse(await readFile(snapshotPath, "utf8"));
    84	  const mirrorData = mirrorRaw?.data || {};
    85	  const snapshotData = snapshotRaw?.data || {};
    86	  if (!hasArray(mirrorData.signals) && !hasArray(mirrorData.rows)) {
    87	    throw new Error("Tech Signals mirror missing data.signals/data.rows arrays");
    88	  }
    89	  if (!hasArray(snapshotData.signals) && !hasArray(snapshotData.items) && !hasArray(snapshotData.rows)) {
    90	    throw new Error("Tech Signals snapshot missing signals/items/rows arrays");
    91	  }
    92	}
    93	
    94	function validateHealthLatestSnapshot(root) {
    95	  const healthLatestPath = path.join(root, "public", "data", "snapshots", "health", "latest.json");
    96	  if (!fs.existsSync(healthLatestPath)) {
    97	    throw new Error("Health latest snapshot missing at public/data/snapshots/health/latest.json");
    98	  }
    99	  const payload = JSON.parse(fs.readFileSync(healthLatestPath, "utf8"));
   100	  if (payload?.schema_version !== "3.0") {
   101	    throw new Error(`Health latest snapshot schema_version must be 3.0, got: ${payload?.schema_version}`);
   102	  }
   103	  if (!payload.metadata || typeof payload.metadata !== "object") {
   104	    throw new Error("Health latest snapshot missing metadata object");
   105	  }
   106	}
   107	
   108	async function main() {
   109	  const root = process.cwd();
   110	  const schemaPath = path.join(root, "schemas", "api-envelope.schema.json");
   111	  await readFile(schemaPath, "utf8");
   112	
   113	  guardNoMetaNull(root);
   114	
   115	  const sample = {
   116	    ok: true,
   117	    feature: "rv-sample",
   118	    meta: { status: "LIVE", reason: "", schemaVersion: "v1" },
   119	    data: { items: [] },
   120	    error: null
   121	  };
   122	
   123	  if (!validateEnvelope(sample)) {
   124	    throw new Error("Sample envelope does not match required shape");
   125	  }
   126	  validateHealthLatestSnapshot(root);
   127	  await validateTechSignalsPayloads(root);
   128	
   129	  // --- SNAPSHOT>=MIRROR guard (tech-signals + alpha-radar) ---
   130	  // If mirror has structural arrays, snapshot must also have them (prevents legacy UI regressions).
   131	  const mirrorPath = path.join(root, "public", "mirrors", "tech-signals.json");
   132	  const snapshotPath = path.join(root, "public", "data", "snapshots", "tech-signals.json");
   133	  const alphaMirrorPath = path.join(root, "public", "mirrors", "alpha-radar.json");
   134	  const alphaSnapPath = path.join(root, "public", "data", "snapshots", "alpha-radar.json");
   135	
   136	  const techMirror = JSON.parse(fs.readFileSync(mirrorPath, "utf8"));
   137	  const techSnap = JSON.parse(fs.readFileSync(snapshotPath, "utf8"));
   138	
   139	  const alphaMirror = fs.existsSync(alphaMirrorPath) ? JSON.parse(fs.readFileSync(alphaMirrorPath, "utf8")) : null;
   140	  const alphaSnap = fs.existsSync(alphaSnapPath) ? JSON.parse(fs.readFileSync(alphaSnapPath, "utf8")) : null;
   141	
   142	  const tech_m_rows = Array.isArray(techMirror?.data?.rows) ? techMirror.data.rows.length : 0;
   143	  const tech_s_rows = Array.isArray(techSnap?.data?.rows) ? techSnap.data.rows.length : 0;
   144	  const tech_m_sig = Array.isArray(techMirror?.data?.signals) ? techMirror.data.signals.length : 0;
   145	  const tech_s_sig = Array.isArray(techSnap?.data?.signals) ? techSnap.data.signals.length : 0;
   146	  const tech_s_items = Array.isArray(techSnap?.data?.items) ? techSnap.data.items.length : 0;
   147	  if (tech_m_rows > 0 && tech_s_rows === 0 && tech_s_items === 0) {
   148	    fail("SNAPSHOT>=MIRROR guard: tech-signals snapshot missing rows/items while mirror has rows[]");
   149	  }
   150	  if (tech_m_sig > 0 && tech_s_sig === 0 && tech_s_items === 0) {
   151	    fail("SNAPSHOT>=MIRROR guard: tech-signals snapshot missing signals/items while mirror has signals[]");
   152	  }
   153	
   154	  if (alphaMirror) {
   155	    const picks = [];
   156	    const alphaPicks = alphaMirror?.data?.picks || {};
   157	    const buckets = [
   158	      alphaPicks.top,
   159	      alphaPicks.shortterm,
   160	      alphaPicks.shortTerm,
   161	      alphaPicks.swing,
   162	      alphaPicks.medium,
   163	      alphaPicks.longterm,
   164	      alphaPicks.longTerm,
   165	      alphaPicks.long
   166	    ].filter(Array.isArray);
   167	    buckets.forEach((bucket) => picks.push(...bucket));
   168	    if (!picks.length) {
   169	      fail("alpha-radar mirror missing picks buckets (top/short/long)");
   170	    }
   171	    const hasReasons = picks.some((pick) => Array.isArray(pick?.reasons) && pick.reasons.length > 0);
   172	    const hasIndicators = picks.some((pick) => Array.isArray(pick?.indicators) && pick.indicators.length > 0);
   173	    const hasChecklist =
   174	      picks.some((pick) => pick?.setup && Object.keys(pick.setup).length > 0) ||
   175	      picks.some((pick) => pick?.trigger && Object.keys(pick.trigger).length > 0);
   176	    const isPartial =
   177	      alphaMirror?.dataQuality === "PARTIAL" || alphaMirror?.meta?.status === "PARTIAL";
   178	    const hasNotes = Array.isArray(alphaMirror?.notes) && alphaMirror.notes.length > 0;
   179	    if (!hasReasons && !hasIndicators && !hasChecklist) {
   180	      if (!(isPartial && hasNotes)) {
   181	        fail("alpha-radar mirror missing indicators/reasons; no partial note present");
   182	      }
   183	    }
   184	  }
   185	
   186	  if (alphaSnap) {
   187	    const alpha_m_top = Array.isArray(alphaMirror?.data?.picks?.top) ? alphaMirror.data.picks.top.length : 0;
   188	    const alpha_s_top = Array.isArray(alphaSnap?.data?.picks?.top) ? alphaSnap.data.picks.top.length : 0;
   189	    if (alpha_m_top > 0 && alpha_s_top === 0) {
   190	      fail("SNAPSHOT>=MIRROR guard: alpha-radar snapshot missing picks.top[] while mirror has picks.top[]");
   191	    }
   192	  }
   193	  // --- end SNAPSHOT>=MIRROR guard ---
   194	
   195	  console.log("Contract smoke OK");
   196	}
   197	
   198	main().catch((error) => {
   199	  console.error(error.message || error);
   200	  process.exit(1);

## FILE: scripts/contract-smoke.mjs
     1	import { promises as fs } from "node:fs";
     2	import path from "node:path";
     3	import { fileURLToPath } from "node:url";
     4	
     5	const ROOT = path.resolve(path.dirname(fileURLToPath(import.meta.url)), "..");
     6	
     7	async function resolveLoaderPath() {
     8	  const candidates = [
     9	    path.join(ROOT, "public", "rv-loader.js"),
    10	    path.join(ROOT, "rv-loader.js"),
    11	    path.join(ROOT, "public", "features", "rv-loader.js"),
    12	    path.join(ROOT, "public", "features", "blocks-registry.js"),
    13	    path.join(ROOT, "features", "blocks-registry.js")
    14	  ];
    15	  for (const candidate of candidates) {
    16	    try {
    17	      await fs.access(candidate);
    18	      return candidate;
    19	    } catch {
    20	      // continue
    21	    }
    22	  }
    23	  fail(`Loader file not found. Tried:\n${candidates.map((p) => `- ${p}`).join("\n")}`);
    24	  return null;
    25	}
    26	
    27	function fail(message) {
    28	  console.error(`[contract-smoke] ${message}`);
    29	  process.exit(1);
    30	}
    31	
    32	function selectTechSignalsRows(data) {
    33	  const signals = Array.isArray(data?.signals) ? data.signals : [];
    34	  const items = Array.isArray(data?.items) ? data.items : [];
    35	  return signals.length ? signals : items.length ? items : [];
    36	}
    37	
    38	function selectAlphaRadarRows(data) {
    39	  const picks = Array.isArray(data?.picks) ? data.picks : [];
    40	  const items = Array.isArray(data?.items) ? data.items : [];
    41	  return picks.length ? picks : items.length ? items : [];
    42	}
    43	
    44	function isEmptyValid(meta, rows) {
    45	  if (!rows.length && (meta?.status === "LIVE" || meta?.status === "STALE")) return true;
    46	  return false;
    47	}
    48	
    49	async function checkMirrorPriority() {
    50	  const loaderPath = await resolveLoaderPath();
    51	  const loader = await fs.readFile(loaderPath, "utf8");
    52	  const required = ["rv-tech-signals", "rv-alpha-radar"];
    53	  const missing = required.filter((token) => !loader.includes(token));
    54	  if (missing.length) {
    55	    fail(`Required feature ids not referenced in loader (${path.basename(loaderPath)}): ${missing.join(", ")}`);
    56	  }
    57	}
    58	
    59	async function checkAlphaRadarTitle() {
    60	  const configPath = path.join(ROOT, "rv-config.js");
    61	  const config = await fs.readFile(configPath, "utf8");
    62	  const match = config.match(/id:\s*"rv-alpha-radar"[\s\S]*?title:\s*"([^"]+)"/);
    63	  if (!match) fail("rv-alpha-radar title not found in rv-config.js");
    64	  const title = match[1];
    65	  if (/lite/i.test(title)) fail("rv-alpha-radar title includes Lite");
    66	}
    67	
    68	async function main() {
    69	  await checkMirrorPriority();
    70	  await checkAlphaRadarTitle();
    71	
    72	  const techSignals = selectTechSignalsRows({ signals: [1], items: [] });
    73	  if (techSignals.length !== 1) fail("tech-signals does not prefer signals array");
    74	
    75	  const techFallback = selectTechSignalsRows({ signals: [], items: [1] });
    76	  if (techFallback.length !== 1) fail("tech-signals does not fallback to items array");
    77	
    78	  const alphaPicks = selectAlphaRadarRows({ picks: [1], items: [] });
    79	  if (alphaPicks.length !== 1) fail("alpha-radar does not prefer picks array");
    80	
    81	  const alphaFallback = selectAlphaRadarRows({ picks: [], items: [1] });
    82	  if (alphaFallback.length !== 1) fail("alpha-radar does not fallback to items array");
    83	
    84	  const emptyValidTech = isEmptyValid({ status: "LIVE" }, []);
    85	  if (!emptyValidTech) fail("empty-valid rule failed for tech-signals");
    86	
    87	  const emptyValidAlpha = isEmptyValid({ status: "STALE" }, []);
    88	  if (!emptyValidAlpha) fail("empty-valid rule failed for alpha-radar");
    89	
    90	  console.log("[contract-smoke] ok");
    91	}
    92	
    93	main().catch((error) => fail(error?.message || "Unknown error"));

## FILE: scripts/create-initial-provider-state.mjs
     1	#!/usr/bin/env node
     2	/**
     3	 * Create initial provider-state.json for Mission Control Dashboard
     4	 * 
     5	 * Generates a minimal valid provider-state.json if it doesn't exist
     6	 * or is not in v3.0 format.
     7	 */
     8	
     9	import { readFile, writeFile } from 'node:fs/promises';
    10	import { join } from 'node:path';
    11	import { generateProviderState } from './lib/provider-state.js';
    12	
    13	const BASE_DIR = process.cwd();
    14	const PROVIDER_STATE_PATH = join(BASE_DIR, 'public/data/provider-state.json');
    15	
    16	async function main() {
    17	  try {
    18	    // Check if file exists and is v3.0
    19	    let existing = null;
    20	    try {
    21	      const content = await readFile(PROVIDER_STATE_PATH, 'utf-8');
    22	      existing = JSON.parse(content);
    23	      if (existing.schema_version === '3.0') {
    24	        console.log(' provider-state.json already exists in v3.0 format');
    25	        return;
    26	      }
    27	    } catch (err) {
    28	      if (err.code !== 'ENOENT') throw err;
    29	    }
    30	
    31	    // Load registry
    32	    const registryPath = join(BASE_DIR, 'public/data/registry/modules.json');
    33	    let registry;
    34	    try {
    35	      const registryContent = await readFile(registryPath, 'utf-8');
    36	      registry = JSON.parse(registryContent);
    37	    } catch (err) {
    38	      console.error(`ERROR: Failed to load registry: ${err.message}`);
    39	      process.exit(1);
    40	    }
    41	
    42	    // Create minimal manifest
    43	    const now = new Date().toISOString();
    44	    const manifest = {
    45	      schema_version: "3.0",
    46	      published_at: now,
    47	      publish_policy: "critical_core_hybrid_v3",
    48	      modules: {},
    49	      summary: {
    50	        modules_total: 0,
    51	        ok: 0,
    52	        warn: 0,
    53	        error: 0,
    54	        stale_ratio: 0,
    55	        critical_ok: true
    56	      }
    57	    };
    58	
    59	    // Generate provider state
    60	    const providerState = generateProviderState(manifest, new Map());
    61	
    62	    // Write provider state
    63	    const { writeProviderState } = await import('./lib/provider-state.js');
    64	    await writeProviderState(providerState, BASE_DIR);
    65	
    66	    console.log(' Created initial provider-state.json');
    67	    console.log(`  Location: ${PROVIDER_STATE_PATH}`);
    68	    console.log(`  Modules: ${providerState.modules.length}`);
    69	    
    70	  } catch (err) {
    71	    console.error(` Failed to create provider-state.json: ${err.message}`);
    72	    console.error(err.stack);
    73	    process.exit(1);
    74	  }
    75	}
    76	
    77	main();

## FILE: scripts/dev-local.sh
     1	#!/usr/bin/env bash
     2	set -euo pipefail
     3	
     4	# Reality check outputs (2026-01-01)
     5	# pwd: (captured at runtime; do not hardcode absolute paths)
     6	# show-toplevel: (captured at runtime; do not hardcode absolute paths)
     7	# git status --porcelain: M .gitignore | M functions/api/health.js | M scripts/test-api.sh | ?? .wranglerignore | ?? scripts/dev-local.sh | ?? scripts/move-repo-out-of-cloud.sh
     8	# node -v: v25.2.1
     9	# wrangler --version: 4.54.0
    10	# wrangler pages dev --help (watch flags): --live-reload (default false), --persist-to, --inspector-port, --no-bundle
    11	# wrangler dev --help (watch flags): --live-reload, --persist-to, --no-bundle
    12	
    13	ROOT=$(git rev-parse --show-toplevel)
    14	
    15	# If repo is under cloud-synced location (sync risk), use /tmp for slim workspace
    16	if [[ "$ROOT" == *"/cloud/"* ]] || [[ -n "${CLOUD_SYNCED:-}" ]]; then
    17	  SLIM_DIR="/tmp/rv-dev-slim"
    18	else
    19	  SLIM_DIR="$ROOT/.tmp/dev-slim"
    20	fi
    21	
    22	rm -rf "$SLIM_DIR"
    23	mkdir -p "$SLIM_DIR"
    24	
    25	export HOME="/tmp/rv_home"
    26	mkdir -p "$HOME"
    27	export NODE_OPTIONS=""
    28	export CHOKIDAR_USEPOLLING=1
    29	export CHOKIDAR_INTERVAL=500
    30	
    31	ulimit -n 65536 >/dev/null 2>&1 || true
    32	
    33	if [[ -f "$ROOT/.dev.vars" ]]; then
    34	  set -a
    35	  # shellcheck disable=SC1090
    36	  source "$ROOT/.dev.vars"
    37	  set +a
    38	fi
    39	
    40	# Copy only what Pages dev needs to minimize file watching
    41	if command -v rsync >/dev/null 2>&1; then
    42	  rsync -a --delete --prune-empty-dirs \
    43	    --include "/functions/***" \
    44	    --include "/public/***" \
    45	    --include "/features/***" \
    46	    --include "/assets/***" \
    47	    --include "/mirrors/***" \
    48	    --include "/*.html" \
    49	    --include "/*.css" \
    50	    --include "/*.js" \
    51	    --include "/_redirects" \
    52	    --include "/_headers" \
    53	    --include "/wrangler.toml" \
    54	    --include "/package.json" \
    55	    --include "/package-lock.json" \
    56	    --exclude "node_modules" \
    57	    --exclude ".git" \
    58	    --exclude ".wrangler" \
    59	    --exclude ".tmp" \
    60	    --exclude "logs" \
    61	    --exclude "coverage" \
    62	    --exclude ".cache" \
    63	    --exclude "dist" \
    64	    --exclude "build" \
    65	    --exclude ".next" \
    66	    --exclude ".DS_Store" \
    67	    --exclude "*" \
    68	    "$ROOT/" "$SLIM_DIR/"
    69	else
    70	  mkdir -p "$SLIM_DIR/functions" "$SLIM_DIR/public" "$SLIM_DIR/features" "$SLIM_DIR/assets" "$SLIM_DIR/mirrors"
    71	  cp -R "$ROOT/functions/." "$SLIM_DIR/functions/" 2>/dev/null || true
    72	  cp -R "$ROOT/public/." "$SLIM_DIR/public/" 2>/dev/null || true
    73	  cp -R "$ROOT/features/." "$SLIM_DIR/features/" 2>/dev/null || true
    74	  cp -R "$ROOT/assets/." "$SLIM_DIR/assets/" 2>/dev/null || true
    75	  cp -R "$ROOT/mirrors/." "$SLIM_DIR/mirrors/" 2>/dev/null || true
    76	  cp "$ROOT/"*.html "$SLIM_DIR/" 2>/dev/null || true
    77	  cp "$ROOT/"*.css "$SLIM_DIR/" 2>/dev/null || true
    78	  cp "$ROOT/"*.js "$SLIM_DIR/" 2>/dev/null || true
    79	  cp "$ROOT/wrangler.toml" "$SLIM_DIR/" 2>/dev/null || true
    80	  cp "$ROOT/package.json" "$SLIM_DIR/" 2>/dev/null || true
    81	  cp "$ROOT/package-lock.json" "$SLIM_DIR/" 2>/dev/null || true
    82	fi
    83	
    84	# Copy only required runtime dependency to reduce watch load
    85	mkdir -p "$SLIM_DIR/node_modules"
    86	if [[ -d "$ROOT/node_modules/fast-xml-parser" ]]; then
    87	  rsync -a "$ROOT/node_modules/fast-xml-parser" "$SLIM_DIR/node_modules/"
    88	fi
    89	if [[ -d "$ROOT/node_modules/strnum" ]]; then
    90	  rsync -a "$ROOT/node_modules/strnum" "$SLIM_DIR/node_modules/"
    91	fi
    92	
    93	cd "$SLIM_DIR"
    94	
    95	PORT="${PORT:-8799}"
    96	IP="${IP:-127.0.0.1}"
    97	
    98	NODE_MAJOR=$(node -v | sed 's/^v//; s/\..*$//')
    99	if [[ "$NODE_MAJOR" -ge 25 ]]; then
   100	  echo "Warning: Node ${NODE_MAJOR} detected. Wrangler is most stable on Node 20/22 LTS."
   101	fi
   102	
   103	WRANGLER_BIN="$ROOT/node_modules/.bin/wrangler"
   104	if [[ ! -x "$WRANGLER_BIN" ]]; then
   105	  echo "Error: wrangler not found at $WRANGLER_BIN. Run: npm install"
   106	  exit 1
   107	fi
   108	
   109	echo "Ready on http://${IP}:${PORT}"
   110	
   111	exec "$WRANGLER_BIN" pages dev . \
   112	  --ip "$IP" \
   113	  --port "$PORT" \
   114	  --kv RV_KV \
   115	  --persist-to "$ROOT/.wrangler/state" \
   116	  --compatibility-date=2025-12-29 \
   117	  --inspector-port 0

## FILE: scripts/eod/build-eod-latest.mjs
     1	import fs from 'node:fs/promises';
     2	import path from 'node:path';
     3	
     4	import { writeJsonAtomic } from '../lib/fs-atomic.mjs';
     5	import { classifyError } from '../lib/error-classify.mjs';
     6	import { validateEodRecord } from '../lib/validate-eod.mjs';
     7	
     8	const REPO_ROOT = process.cwd();
     9	const DEFAULT_CHUNK_SIZE = 500;
    10	const CONCURRENCY = 5;
    11	const MAX_RETRIES = 2;
    12	const TIMEOUT_MS = 8000;
    13	
    14	function isoNow() {
    15	  return new Date().toISOString();
    16	}
    17	
    18	function normalizeSymbol(value) {
    19	  return String(value || '').trim().toUpperCase();
    20	}
    21	
    22	function parseArgs(argv) {
    23	  const out = {
    24	    universe: null,
    25	    chunkSize: DEFAULT_CHUNK_SIZE,
    26	    outDir: 'public/data'
    27	  };
    28	
    29	  for (let i = 0; i < argv.length; i += 1) {
    30	    const arg = argv[i];
    31	    if (arg === '--universe') {
    32	      out.universe = argv[i + 1] || null;
    33	      i += 1;
    34	    } else if (arg === '--chunk-size') {
    35	      out.chunkSize = Number(argv[i + 1]) || DEFAULT_CHUNK_SIZE;
    36	      i += 1;
    37	    } else if (arg === '--out') {
    38	      out.outDir = argv[i + 1] || out.outDir;
    39	      i += 1;
    40	    }
    41	  }
    42	
    43	  return out;
    44	}
    45	
    46	async function readJson(filePath) {
    47	  const raw = await fs.readFile(filePath, 'utf-8');
    48	  return JSON.parse(raw);
    49	}
    50	
    51	async function readStaticReadyCount(outRoot, universe) {
    52	  const filePath = path.join(outRoot, 'pipeline', `${universe}.static-ready.json`);
    53	  try {
    54	    const doc = await readJson(filePath);
    55	    const count = Number(doc?.count);
    56	    return Number.isInteger(count) ? count : null;
    57	  } catch {
    58	    return null;
    59	  }
    60	}
    61	
    62	async function readComputedCount(outRoot, universe) {
    63	  const filePath = path.join(outRoot, 'pipeline', `${universe}.computed.json`);
    64	  try {
    65	    const doc = await readJson(filePath);
    66	    const count = Number(doc?.count);
    67	    return Number.isInteger(count) ? count : null;
    68	  } catch {
    69	    return null;
    70	  }
    71	}
    72	function extractUniverseSymbols(payload) {
    73	  if (!Array.isArray(payload)) return [];
    74	  const symbols = new Set();
    75	  for (const row of payload) {
    76	    if (typeof row === 'string') {
    77	      const sym = normalizeSymbol(row);
    78	      if (sym) symbols.add(sym);
    79	      continue;
    80	    }
    81	    const sym = normalizeSymbol(row?.ticker ?? row?.symbol ?? row?.code ?? null);
    82	    if (sym) symbols.add(sym);
    83	  }
    84	  return Array.from(symbols).sort();
    85	}
    86	
    87	function toIsoDate(value) {
    88	  if (!value) return null;
    89	  try {
    90	    const d = new Date(value);
    91	    if (Number.isNaN(d.getTime())) return null;
    92	    return d.toISOString().slice(0, 10);
    93	  } catch {
    94	    return null;
    95	  }
    96	}
    97	
    98	function toNumber(value) {
    99	  const n = Number(value);
   100	  return Number.isFinite(n) ? n : null;
   101	}
   102	
   103	function normalizeTiingoRow(symbol, row) {
   104	  if (!row || typeof row !== 'object') return null;
   105	  return {
   106	    symbol,
   107	    date: toIsoDate(row?.date),
   108	    open: toNumber(row?.open),
   109	    high: toNumber(row?.high),
   110	    low: toNumber(row?.low),
   111	    close: toNumber(row?.close),
   112	    volume: toNumber(row?.volume)
   113	  };
   114	}
   115	
   116	function pickLatestRow(rows) {
   117	  if (!Array.isArray(rows) || rows.length === 0) return null;
   118	  const sorted = rows
   119	    .filter((row) => row && row.date)
   120	    .sort((a, b) => (a.date < b.date ? -1 : a.date > b.date ? 1 : 0));
   121	  return sorted.length ? sorted[sorted.length - 1] : null;
   122	}
   123	
   124	function sleep(ms) {
   125	  return new Promise((resolve) => setTimeout(resolve, ms));
   126	}
   127	
   128	async function fetchLatestEodOnce(symbol, token) {
   129	  const controller = new AbortController();
   130	  const timer = setTimeout(() => controller.abort(), TIMEOUT_MS);
   131	  const startDate = new Date(Date.now() - 14 * 24 * 60 * 60 * 1000).toISOString().slice(0, 10);
   132	  const url = new URL(`https://api.tiingo.com/tiingo/daily/${encodeURIComponent(symbol)}/prices`);
   133	  url.searchParams.set('token', token);
   134	  url.searchParams.set('resampleFreq', 'daily');
   135	  url.searchParams.set('startDate', startDate);
   136	
   137	  try {
   138	    const res = await fetch(url.toString(), {
   139	      method: 'GET',
   140	      headers: { Accept: 'application/json' },
   141	      signal: controller.signal
   142	    });
   143	
   144	    if (!res.ok) {
   145	      const error = new Error(`HTTP ${res.status}`);
   146	      error.status = res.status;
   147	      return { ok: false, error, httpStatus: res.status };
   148	    }
   149	
   150	    const payload = await res.json();
   151	    if (!Array.isArray(payload) || payload.length === 0) {
   152	      const error = new Error('empty_payload');
   153	      error.status = res.status;
   154	      return { ok: false, error, httpStatus: res.status };
   155	    }
   156	
   157	    const latest = pickLatestRow(payload);
   158	    if (!latest) {
   159	      const error = new Error('no_latest_row');
   160	      error.status = res.status;
   161	      return { ok: false, error, httpStatus: res.status };
   162	    }
   163	
   164	    const record = normalizeTiingoRow(symbol, latest);
   165	    if (!record) {
   166	      const error = new Error('normalize_failed');
   167	      error.status = res.status;
   168	      return { ok: false, error, httpStatus: res.status };
   169	    }
   170	
   171	    return { ok: true, record, httpStatus: res.status };
   172	  } finally {
   173	    clearTimeout(timer);
   174	  }
   175	}
   176	
   177	function isTransientClass(cls) {
   178	  return cls === 'UPSTREAM_TIMEOUT' || cls === 'UPSTREAM_5XX' || cls === 'RATE_LIMIT';
   179	}
   180	
   181	async function fetchLatestEodWithRetry(symbol, token) {
   182	  let lastError = null;
   183	  let lastStatus = null;
   184	
   185	  for (let attempt = 0; attempt <= MAX_RETRIES; attempt += 1) {
   186	    try {
   187	      const result = await fetchLatestEodOnce(symbol, token);
   188	      if (result.ok) return result;
   189	      lastError = result.error;
   190	      lastStatus = result.httpStatus;
   191	      const classification = classifyError(result.error, { httpStatus: result.httpStatus });
   192	      if (!isTransientClass(classification.class) || attempt >= MAX_RETRIES) {
   193	        return { ok: false, error: result.error, httpStatus: result.httpStatus, classification };
   194	      }
   195	    } catch (error) {
   196	      lastError = error;
   197	      lastStatus = null;
   198	      const classification = classifyError(error, {});
   199	      if (!isTransientClass(classification.class) || attempt >= MAX_RETRIES) {
   200	        return { ok: false, error, httpStatus: null, classification };

## FILE: scripts/eod/check-eod-artifacts.mjs
     1	import fs from 'node:fs/promises';
     2	import path from 'node:path';
     3	
     4	const REPO_ROOT = process.cwd();
     5	
     6	function parseArgs(argv) {
     7	  const out = { universe: 'nasdaq100', outDir: 'public/data' };
     8	  for (let i = 0; i < argv.length; i += 1) {
     9	    const arg = argv[i];
    10	    if (arg === '--universe') {
    11	      out.universe = argv[i + 1] || out.universe;
    12	      i += 1;
    13	    } else if (arg === '--out') {
    14	      out.outDir = argv[i + 1] || out.outDir;
    15	      i += 1;
    16	    }
    17	  }
    18	  return out;
    19	}
    20	
    21	async function readJson(filePath) {
    22	  const raw = await fs.readFile(filePath, 'utf-8');
    23	  return JSON.parse(raw);
    24	}
    25	
    26	function fail(message) {
    27	  throw new Error(message);
    28	}
    29	
    30	function assertManifest(doc) {
    31	  if (!doc || typeof doc !== 'object') fail('manifest: not an object');
    32	  if (doc.schema_version !== '1.0') fail('manifest: schema_version must be 1.0');
    33	  if (doc.type !== 'eod.latest.manifest') fail('manifest: type must be eod.latest.manifest');
    34	  if (typeof doc.generated_at !== 'string') fail('manifest: generated_at missing');
    35	  if (typeof doc.universe !== 'string') fail('manifest: universe missing');
    36	  if (!Number.isInteger(doc.total_symbols)) fail('manifest: total_symbols must be int');
    37	  if (!Number.isInteger(doc.chunk_size)) fail('manifest: chunk_size must be int');
    38	  if (!Array.isArray(doc.chunks)) fail('manifest: chunks must be array');
    39	  if (!doc.errors_by_class || typeof doc.errors_by_class !== 'object') fail('manifest: errors_by_class must be object');
    40	}
    41	
    42	function assertPipeline(doc) {
    43	  if (!doc || typeof doc !== 'object') fail('pipeline: not an object');
    44	  if (doc.schema_version !== '1.0') fail('pipeline: schema_version must be 1.0');
    45	  if (doc.type !== 'pipeline.truth') fail('pipeline: type must be pipeline.truth');
    46	  if (typeof doc.generated_at !== 'string') fail('pipeline: generated_at missing');
    47	  if (typeof doc.universe !== 'string') fail('pipeline: universe missing');
    48	  if (!doc.refs || typeof doc.refs !== 'object') fail('pipeline: refs missing');
    49	  if (!doc.counts || typeof doc.counts !== 'object') fail('pipeline: counts missing');
    50	  if (!Number.isInteger(doc.counts.expected)) fail('pipeline: counts.expected must be int');
    51	  if (!Number.isInteger(doc.counts.fetched)) fail('pipeline: counts.fetched must be int');
    52	  if (!Number.isInteger(doc.counts.validated)) fail('pipeline: counts.validated must be int');
    53	  if (!Number.isInteger(doc.counts.computed)) fail('pipeline: counts.computed must be int');
    54	  if (!Number.isInteger(doc.counts.static_ready)) fail('pipeline: counts.static_ready must be int');
    55	  if (!doc.degraded_summary || typeof doc.degraded_summary !== 'object') fail('pipeline: degraded_summary missing');
    56	  if (!Number.isInteger(doc.degraded_summary.count)) fail('pipeline: degraded_summary.count must be int');
    57	  if (!doc.degraded_summary.classes || typeof doc.degraded_summary.classes !== 'object') fail('pipeline: degraded_summary.classes must be object');
    58	  if (!Array.isArray(doc.degraded_summary.sample)) fail('pipeline: degraded_summary.sample must be array');
    59	  if (doc.degraded_summary.sample.length > 25) fail('pipeline: degraded_summary.sample max 25');
    60	}
    61	
    62	async function main() {
    63	  const args = parseArgs(process.argv.slice(2));
    64	  const dataRoot = path.resolve(REPO_ROOT, args.outDir);
    65	
    66	  const universePath = path.join(dataRoot, 'universe', `${args.universe}.json`);
    67	  const manifestPath = path.join(dataRoot, 'eod', 'manifest.latest.json');
    68	  const pipelinePath = path.join(dataRoot, 'pipeline', `${args.universe}.latest.json`);
    69	
    70	  const universe = await readJson(universePath);
    71	  const expected = Array.isArray(universe) ? universe.length : 0;
    72	
    73	  const manifest = await readJson(manifestPath);
    74	  assertManifest(manifest);
    75	
    76	  const pipeline = await readJson(pipelinePath);
    77	  assertPipeline(pipeline);
    78	
    79	  if (manifest.total_symbols !== expected) {
    80	    fail(`manifest: total_symbols ${manifest.total_symbols} != universe length ${expected}`);
    81	  }
    82	
    83	  if (pipeline.counts.expected !== expected) {
    84	    fail(`pipeline: counts.expected ${pipeline.counts.expected} != universe length ${expected}`);
    85	  }
    86	
    87	  process.stdout.write('OK: eod manifest + pipeline latest present and consistent\n');
    88	}
    89	
    90	main().catch((err) => {
    91	  process.stderr.write(`FAIL: ${err.stack || err.message || String(err)}\n`);
    92	  process.exit(1);
    93	});

## FILE: scripts/fix-api-exports.mjs
     1	#!/usr/bin/env node
     2	/**
     3	 * Bulk-fix API endpoints: Workers format  Pages Functions format
     4	 * 
     5	 * Changes:
     6	 * FROM: export default { fetch: serveStaticJson };
     7	 * TO:   export async function onRequestGet(context) { return serveStaticJson(context.request, ...); }
     8	 */
     9	
    10	import { readdir, readFile, writeFile } from 'node:fs/promises';
    11	import { join } from 'node:path';
    12	
    13	const API_DIR = 'functions/api';
    14	const DRY_RUN = process.env.DRY_RUN === '1';
    15	
    16	// Files to skip (not API endpoints or special cases)
    17	const SKIP_FILES = new Set([
    18	  '_middleware.js',
    19	  '_shared.js',
    20	  '_env.js',
    21	  '_circuit.js',
    22	  '_debug-trace.js',
    23	  '_diag.js'
    24	]);
    25	
    26	async function fixFile(filePath, fileName) {
    27	  const content = await readFile(filePath, 'utf-8');
    28	  
    29	  // Check if it needs fixing
    30	  if (!content.includes('export default { fetch:')) {
    31	    return { status: 'skip', reason: 'already_fixed' };
    32	  }
    33	  
    34	  // Pattern 1: export default { fetch: serveStaticJson };
    35	  if (content.match(/export\s+default\s+{\s*fetch:\s*serveStaticJson\s*};?/)) {
    36	    const fixed = content.replace(
    37	      /import\s+{\s*serveStaticJson\s*}\s+from\s+["']\.\/(_shared\/static-only\.js|_shared\.js)["'];?\s*\n\s*export\s+default\s+{\s*fetch:\s*serveStaticJson\s*};?/,
    38	      `import { serveStaticJson } from "./_shared/static-only.js";\n\nexport async function onRequestGet(context) {\n  return serveStaticJson(context.request, "${fileName.replace('.js', '')}", null, context);\n}`
    39	    );
    40	    
    41	    if (fixed !== content) {
    42	      if (!DRY_RUN) {
    43	        await writeFile(filePath, fixed, 'utf-8');
    44	      }
    45	      return { status: 'fixed', type: 'serveStaticJson' };
    46	    }
    47	  }
    48	  
    49	  // Pattern 2: Other export default { fetch: ... }
    50	  if (content.match(/export\s+default\s+{\s*fetch:\s*\w+\s*};?/)) {
    51	    return { status: 'skip', reason: 'custom_handler_needs_manual_fix' };
    52	  }
    53	  
    54	  return { status: 'skip', reason: 'no_pattern_match' };
    55	}
    56	
    57	async function main() {
    58	  console.log(' Fixing API endpoint exports...\n');
    59	  console.log(`Mode: ${DRY_RUN ? 'DRY RUN (no changes)' : 'LIVE (will modify files)'}\n`);
    60	  
    61	  const files = await readdir(API_DIR);
    62	  const jsFiles = files.filter(f => f.endsWith('.js') && !SKIP_FILES.has(f));
    63	  
    64	  const results = {
    65	    fixed: [],
    66	    skipped: [],
    67	    errors: []
    68	  };
    69	  
    70	  for (const file of jsFiles) {
    71	    const filePath = join(API_DIR, file);
    72	    try {
    73	      const result = await fixFile(filePath, file);
    74	      
    75	      if (result.status === 'fixed') {
    76	        results.fixed.push(file);
    77	        console.log(` ${file} - Fixed (${result.type})`);
    78	      } else {
    79	        results.skipped.push({ file, reason: result.reason });
    80	        console.log(`  ${file} - ${result.reason}`);
    81	      }
    82	    } catch (err) {
    83	      results.errors.push({ file, error: err.message });
    84	      console.error(` ${file} - ERROR: ${err.message}`);
    85	    }
    86	  }
    87	  
    88	  console.log('\n');
    89	  console.log(' SUMMARY');
    90	  console.log('');
    91	  console.log(`Fixed:   ${results.fixed.length}`);
    92	  console.log(`Skipped: ${results.skipped.length}`);
    93	  console.log(`Errors:  ${results.errors.length}`);
    94	  console.log(`\nTotal files processed: ${jsFiles.length}`);
    95	  
    96	  if (DRY_RUN) {
    97	    console.log('\n  DRY RUN - No files were modified');
    98	    console.log('   Run without DRY_RUN=1 to apply changes');
    99	  }
   100	}
   101	
   102	main().catch(err => {
   103	  console.error('Fatal error:', err);
   104	  process.exit(1);
   105	});

## FILE: scripts/generate-crypto-snapshot.mjs
     1	import path from "node:path";
     2	import { fileURLToPath } from "node:url";
     3	import { saveMirror, loadMirror } from "./utils/mirror-io.mjs";
     4	import { buildBaseMirror, buildSystemHealth } from "./utils/mirror-builders.mjs";
     5	import { createBudgetState, createUsageCollector, loadBudgetsConfig } from "./_lib/usage.js";
     6	import { fetchCoinGeckoSimple } from "./providers/coingecko.js";
     7	import { acquireLock, releaseLock } from "./_lib/lock.js";
     8	
     9	const __dirname = path.dirname(fileURLToPath(import.meta.url));
    10	const MIRROR_DIRS = [path.resolve(__dirname, "../mirrors")];
    11	const SYSTEM_HEALTH_PATH = path.resolve(__dirname, "../mirrors/system-health.json");
    12	
    13	const COINS = ["bitcoin", "ethereum", "solana"];
    14	const COIN_MAP = { bitcoin: "BTC", ethereum: "ETH", solana: "SOL" };
    15	async function fetchCrypto() {
    16	  const limits = loadBudgetsConfig(path.resolve(__dirname, ".."));
    17	  const usage = createUsageCollector(limits);
    18	  const budget = createBudgetState(limits, usage);
    19	  const ctx = { providerId: "coingecko", endpoint: "simple", usage, budget };
    20	  const result = await fetchCoinGeckoSimple(ctx, {
    21	    ids: COINS,
    22	    vsCurrency: "usd",
    23	    includeMarketCap: true,
    24	    include24hChange: true
    25	  });
    26	  return result.data || {};
    27	}
    28	
    29	const lock = acquireLock({ providerId: "coingecko", datasetId: "crypto-snapshot", ttlSeconds: 900 });
    30	if (!lock.ok) {
    31	  console.log("LOCK_HELD", lock.details?.expiresAt || "active");
    32	  process.exit(0);
    33	}
    34	
    35	try {
    36	  const previous = loadMirror(path.resolve(__dirname, "../mirrors/crypto-snapshot.json"));
    37	  let items = [];
    38	  const errors = [];
    39	  const noteFlags = [];
    40	
    41	  try {
    42	    const data = await fetchCrypto();
    43	    items = COINS.map((coin) => {
    44	      const payload = data[coin] || {};
    45	      return {
    46	        symbol: COIN_MAP[coin],
    47	        price: Number.isFinite(payload.usd) ? payload.usd : null,
    48	        change24h: Number.isFinite(payload.usd_24h_change) ? payload.usd_24h_change : null,
    49	        marketCap: Number.isFinite(payload.usd_market_cap) ? payload.usd_market_cap : null
    50	      };
    51	    }).filter((item) => item.price !== null);
    52	  } catch (err) {
    53	    errors.push(String(err.message || err));
    54	  }
    55	
    56	  if (!items.length && previous) {
    57	    items = previous.items || [];
    58	    if (items.length) {
    59	      noteFlags.push("STALE_LAST_GOOD");
    60	    }
    61	  }
    62	
    63	  const mode = items.length ? "LIVE" : "EMPTY";
    64	  const dataQuality = items.length ? (noteFlags.includes("STALE_LAST_GOOD") ? "STALE" : "OK") : "EMPTY";
    65	
    66	  const mirror = buildBaseMirror({
    67	    mirrorId: "crypto-snapshot",
    68	    mode,
    69	    cadence: "hourly",
    70	    trust: "raw",
    71	    sourceUpstream: "coingecko",
    72	    whyUnique: "Live crypto snapshot from CoinGecko.",
    73	    items,
    74	    context: { coins: COINS },
    75	    missingSymbols: [],
    76	    errors,
    77	    notes: noteFlags,
    78	    dataQuality,
    79	    asOf: new Date().toISOString()
    80	  });
    81	
    82	  for (const dir of MIRROR_DIRS) {
    83	    saveMirror(path.join(dir, "crypto-snapshot.json"), mirror);
    84	  }
    85	
    86	  const systemHealth = loadMirror(SYSTEM_HEALTH_PATH) || buildSystemHealth({
    87	    jobs: [],
    88	    mirrors: [],
    89	    selectedSymbols: [],
    90	    skippedSymbols: [],
    91	    overallStatus: "OK"
    92	  });
    93	
    94	  const jobEntry = {
    95	    id: "crypto-snapshot",
    96	    lastRunAt: new Date().toISOString(),
    97	    lastSuccessAt: new Date().toISOString(),
    98	    status: errors.length ? "FAILED" : "OK",
    99	    durationMs: 0,
   100	    errors,
   101	    notes: []
   102	  };
   103	
   104	  systemHealth.jobs = systemHealth.jobs.filter((job) => job.id !== "crypto-snapshot");
   105	  systemHealth.jobs.push(jobEntry);
   106	
   107	  systemHealth.mirrors = systemHealth.mirrors.filter((m) => m.id !== "crypto-snapshot");
   108	  systemHealth.mirrors.push({
   109	    id: "crypto-snapshot",
   110	    updatedAt: mirror.updatedAt,
   111	    dataQuality: mirror.dataQuality,
   112	    itemCount: mirror.items.length,
   113	    sizeKB: 0
   114	  });
   115	
   116	  saveMirror(SYSTEM_HEALTH_PATH, systemHealth);
   117	
   118	  console.log("CRYPTO_SNAPSHOT_DONE", items.length);
   119	} finally {
   120	  releaseLock(lock.path);
   121	}

## FILE: scripts/generate-eod-market.mjs
     1	import path from "node:path";
     2	import fs from "node:fs";
     3	import { execSync } from "node:child_process";
     4	import { fileURLToPath } from "node:url";
     5	import { saveMirror, validateBasicMirrorShape, loadMirror, atomicWriteJson } from "./utils/mirror-io.mjs";
     6	import { selectUniverse } from "./utils/universe.mjs";
     7	import { processSymbols } from "./utils/eod-market-symbols.mjs";
     8	import { buildEodMirrors } from "./utils/eod-market-mirrors.mjs";
     9	import { buildDigest, buildSystemHealth } from "./utils/mirror-builders.mjs";
    10	
    11	const __dirname = path.dirname(fileURLToPath(import.meta.url));
    12	const MIRROR_DIRS = [
    13	  path.resolve(__dirname, "../mirrors")
    14	];
    15	const SYSTEM_HEALTH_PATH = path.resolve(__dirname, "../mirrors/system-health.json");
    16	const DAILY_DIGEST_PATH = path.resolve(__dirname, "../mirrors/daily-digest.json");
    17	const PREV_REGIME_PATH = path.resolve(__dirname, "../mirrors/market-regime.json");
    18	const BUILD_INFO_PATH = path.resolve(__dirname, "../public/build-info.json");
    19	
    20	const CONTINUOUS_MIN_ITEMS = {
    21	  quotes: 3,
    22	  "market-cockpit": 1,
    23	  "market-health": 1,
    24	  "price-snapshot": 3,
    25	  "top-movers": 1,
    26	  "tech-signals": 3,
    27	  "alpha-radar": 3,
    28	  "market-regime": 1,
    29	  "volume-anomaly": 1,
    30	  "breakout-energy": 1
    31	};
    32	
    33	function fallbackToLastGood(mirrorId, mirror) {
    34	  const expected = CONTINUOUS_MIN_ITEMS[mirrorId] || 0;
    35	  if (mirror.items.length >= expected) return mirror;
    36	  const prevPath = path.resolve(__dirname, `../mirrors/${mirrorId}.json`);
    37	  const prev = loadMirror(prevPath);
    38	  if (prev && Array.isArray(prev.items) && prev.items.length >= expected) {
    39	    return {
    40	      ...prev,
    41	      dataQuality: "STALE",
    42	      notes: [...(prev.notes || []), "STALE_LAST_GOOD"],
    43	      updatedAt: mirror.updatedAt
    44	    };
    45	  }
    46	  return mirror;
    47	}
    48	
    49	const { selected: universe, skipped } = selectUniverse();
    50	const data = await processSymbols(universe);
    51	const asOfIso = data.latestAsOf ? new Date(`${data.latestAsOf}T21:00:00Z`).toISOString() : new Date().toISOString();
    52	
    53	const { mirrors } = buildEodMirrors({
    54	  universe,
    55	  skipped,
    56	  data,
    57	  asOfIso,
    58	  prevRegimePath: PREV_REGIME_PATH
    59	});
    60	
    61	const mirrorSummary = [];
    62	for (const [mirrorId, mirrorDataRaw] of Object.entries(mirrors)) {
    63	  const mirrorData = fallbackToLastGood(mirrorId, mirrorDataRaw);
    64	  const validation = validateBasicMirrorShape(mirrorData);
    65	  if (!validation.ok) {
    66	    throw new Error(`mirror_invalid:${mirrorId}`);
    67	  }
    68	  for (const dir of MIRROR_DIRS) {
    69	    saveMirror(path.join(dir, `${mirrorId}.json`), mirrorData);
    70	  }
    71	  mirrorSummary.push({
    72	    id: mirrorId,
    73	    updatedAt: mirrorData.updatedAt,
    74	    dataQuality: mirrorData.dataQuality,
    75	    itemCount: mirrorData.items.length,
    76	    sizeKB: 0
    77	  });
    78	}
    79	
    80	const systemHealth = buildSystemHealth({
    81	  jobs: [
    82	    {
    83	      id: "eod-market",
    84	      lastRunAt: new Date().toISOString(),
    85	      lastSuccessAt: new Date().toISOString(),
    86	      status: data.errors.length ? "FAILED" : "OK",
    87	      durationMs: 0,
    88	      errors: data.errors,
    89	      notes: []
    90	    }
    91	  ],
    92	  mirrors: mirrorSummary,
    93	  selectedSymbols: universe,
    94	  skippedSymbols: skipped,
    95	  overallStatus: data.errors.length ? "DEGRADED" : "OK"
    96	});
    97	
    98	saveMirror(SYSTEM_HEALTH_PATH, systemHealth);
    99	
   100	saveMirror(DAILY_DIGEST_PATH, buildDigest({
   101	  highlights: ["EOD mirrors updated"],
   102	  signals: mirrors["breakout-energy"].items.slice(0, 3).map((item) => `${item.symbol} breakout energy`),
   103	  changes: [],
   104	  sources: Object.keys(mirrors)
   105	}));
   106	
   107	let commitSha = process.env.GITHUB_SHA || process.env.COMMIT_SHA || process.env.BUILD_SHA || "";
   108	if (!commitSha) {
   109	  try {
   110	    commitSha = execSync("git rev-parse HEAD", { encoding: "utf8" }).trim();
   111	  } catch (err) {
   112	    commitSha = "unknown";
   113	  }
   114	}
   115	atomicWriteJson(BUILD_INFO_PATH, {
   116	  commitSha,
   117	  generatedAt: new Date().toISOString()
   118	});
   119	
   120	console.log("EOD_MARKET_MIRRORS_DONE", universe.length, "symbols");

## FILE: scripts/generate-eod-mirrors.mjs
     1	import fs from "node:fs";
     2	import path from "node:path";
     3	import { FEATURES } from "../rv-config.js";
     4	
     5	const OUT_DIRS = ["mirrors"];
     6	const NOW = new Date().toISOString();
     7	const EXTRA_ENDPOINTS = ["quotes", "tech-signals"];
     8	
     9	function getApiNames() {
    10	  const names = new Set();
    11	  FEATURES.forEach((feature) => {
    12	    if (feature?.api) names.add(feature.api);
    13	  });
    14	  EXTRA_ENDPOINTS.forEach((name) => names.add(name));
    15	  return Array.from(names);
    16	}
    17	
    18	function readExistingDefinitions(filePath) {
    19	  try {
    20	    const raw = fs.readFileSync(filePath, "utf8");
    21	    const parsed = JSON.parse(raw);
    22	    const payload = parsed?.payload || {};
    23	    return payload?.data?.definitions || payload?.definitions || {};
    24	  } catch (error) {
    25	    return {};
    26	  }
    27	}
    28	
    29	function buildPayload(apiName, definitions) {
    30	  const dataQuality = { status: "LIVE", reason: "EMPTY", missingFields: [] };
    31	  return {
    32	    ok: true,
    33	    feature: apiName,
    34	    ts: NOW,
    35	    traceId: "mirror",
    36	    schemaVersion: 1,
    37	    cache: { hit: true, ttl: 0, layer: "mirror" },
    38	    upstream: { url: "mirror", status: null, snippet: "" },
    39	    rateLimit: { remaining: "unknown", reset: null, estimated: true },
    40	    dataQuality,
    41	    data: {
    42	      updatedAt: NOW,
    43	      source: "mirror",
    44	      dataQuality,
    45	      confidence: 0,
    46	      definitions: definitions || {},
    47	      reasons: ["MIRROR", "EMPTY"],
    48	      data: {
    49	        items: [],
    50	        signals: [],
    51	        trades: [],
    52	        quotes: [],
    53	        metrics: [],
    54	        stocks: { volumeLeaders: [], gainers: [] }
    55	      }
    56	    }
    57	  };
    58	}
    59	
    60	function writeMirrorFile(apiName) {
    61	  const fileName = `${apiName}.json`;
    62	  OUT_DIRS.forEach((dir) => {
    63	    fs.mkdirSync(dir, { recursive: true });
    64	    const filePath = path.join(dir, fileName);
    65	    const existingDefinitions = readExistingDefinitions(filePath);
    66	    const wrapper = {
    67	      ts: NOW,
    68	      source: "mirror",
    69	      payload: buildPayload(apiName, existingDefinitions)
    70	    };
    71	    fs.writeFileSync(filePath, JSON.stringify(wrapper, null, 2));
    72	  });
    73	}
    74	
    75	const apiNames = getApiNames();
    76	apiNames.forEach((apiName) => writeMirrorFile(apiName));
    77	console.log(`MIRRORS_WRITTEN=${apiNames.length}`);

## FILE: scripts/generate-event-mirrors.mjs
     1	import path from "node:path";
     2	import { fileURLToPath } from "node:url";
     3	import { XMLParser } from "fast-xml-parser";
     4	import { loadMirror, saveMirror, withRetries } from "./utils/mirror-io.mjs";
     5	import { buildBaseMirror, buildSystemHealth } from "./utils/mirror-builders.mjs";
     6	import { createBudgetState, createUsageCollector, loadBudgetsConfig } from "./_lib/usage.js";
     7	import { fetchRssFeed } from "./providers/rss.js";
     8	import { acquireLock, releaseLock } from "./_lib/lock.js";
     9	
    10	const __dirname = path.dirname(fileURLToPath(import.meta.url));
    11	const MIRROR_DIRS = [
    12	  path.resolve(__dirname, "../mirrors")
    13	];
    14	const SYSTEM_HEALTH_PATH = path.resolve(__dirname, "../mirrors/system-health.json");
    15	
    16	const FEEDS = [
    17	  { url: "https://feeds.a.dj.com/rss/RSSMarketsMain.xml", source: "WSJ" },
    18	  { url: "https://www.cnbc.com/id/100003114/device/rss/rss.html", source: "CNBC" },
    19	  { url: "https://finance.yahoo.com/rss/", source: "YH" }
    20	];
    21	
    22	const parser = new XMLParser({ ignoreAttributes: false, attributeNamePrefix: "" });
    23	const limits = loadBudgetsConfig(path.resolve(__dirname, ".."));
    24	const usage = createUsageCollector(limits);
    25	const budget = createBudgetState(limits, usage);
    26	const ctx = { providerId: "rss", endpoint: "rss", usage, budget };
    27	
    28	async function fetchFeed(feed, ctx) {
    29	  return withRetries(async () => {
    30	    const result = await fetchRssFeed(ctx, feed.url);
    31	    return result.data || "";
    32	  }, { retries: 2, baseDelayMs: 600 });
    33	}
    34	
    35	function parseItems(xmlText, source) {
    36	  const parsed = parser.parse(xmlText);
    37	  const items = [];
    38	  const channelItems = parsed?.rss?.channel?.item || [];
    39	  const entries = parsed?.feed?.entry || [];
    40	  const list = Array.isArray(channelItems) ? channelItems : [channelItems];
    41	  const entriesList = Array.isArray(entries) ? entries : [entries];
    42	
    43	  list.forEach((item) => {
    44	    if (!item || !item.title || !item.link) return;
    45	    items.push({
    46	      title: String(item.title).trim(),
    47	      url: String(item.link).trim(),
    48	      source,
    49	      publishedAt: item.pubDate || item.published || null
    50	    });
    51	  });
    52	
    53	  entriesList.forEach((entry) => {
    54	    const link = entry.link?.href || entry.link?.[0]?.href;
    55	    if (!entry || !entry.title || !link) return;
    56	    items.push({
    57	      title: String(entry.title).trim(),
    58	      url: String(link).trim(),
    59	      source,
    60	      publishedAt: entry.published || entry.updated || null
    61	    });
    62	  });
    63	
    64	  return items;
    65	}
    66	
    67	function eventContext(prev, lookbackDays, explain) {
    68	  return {
    69	    lookbackWindowDays: lookbackDays,
    70	    explain,
    71	    lastEventAt: prev?.context?.lastEventAt || null,
    72	    lastEventSummary: prev?.context?.lastEventSummary || null
    73	  };
    74	}
    75	
    76	async function buildNews() {
    77	  let items = [];
    78	  const errors = [];
    79	  for (const feed of FEEDS) {
    80	    try {
    81	      const xml = await fetchFeed(feed, ctx);
    82	      items = items.concat(parseItems(xml, feed.source));
    83	    } catch (err) {
    84	      errors.push(`${feed.source}:${err.message || err}`);
    85	    }
    86	  }
    87	  const unique = new Map();
    88	  items.forEach((item) => {
    89	    const key = `${item.title}|${item.source}`;
    90	    if (!unique.has(key)) unique.set(key, item);
    91	  });
    92	  items = Array.from(unique.values()).slice(0, 50);
    93	
    94	  const prev = loadMirror(path.resolve(__dirname, "../mirrors/news.json"));
    95	  let dataQuality = items.length ? "OK" : "EMPTY";
    96	  let mode = items.length ? "LIVE" : "EMPTY";
    97	  let notes = [];
    98	  if (!items.length && prev && Array.isArray(prev.items) && prev.items.length) {
    99	    items = prev.items;
   100	    dataQuality = "STALE";
   101	    mode = prev.mode || "STALE";
   102	    notes = ["STALE_LAST_GOOD"];
   103	  }
   104	
   105	  return buildBaseMirror({
   106	    mirrorId: "news",
   107	    mode,
   108	    cadence: "best_effort",
   109	    trust: "raw",
   110	    sourceUpstream: "rss",
   111	    whyUnique: "RSS-only headlines for key market sources.",
   112	    items,
   113	    context: { feeds: FEEDS.map((f) => f.source) },
   114	    missingSymbols: [],
   115	    errors,
   116	    notes,
   117	    dataQuality,
   118	    asOf: new Date().toISOString()
   119	  });
   120	}
   121	
   122	function buildEmptyEvent(id, explain) {
   123	  const prev = loadMirror(path.resolve(__dirname, `../mirrors/${id}.json`));
   124	  return buildBaseMirror({
   125	    mirrorId: id,
   126	    mode: "EMPTY",
   127	    cadence: "daily",
   128	    trust: "heuristic",
   129	    sourceUpstream: "unknown",
   130	    whyUnique: explain,
   131	    items: [],
   132	    context: eventContext(prev, 30, explain),
   133	    missingSymbols: [],
   134	    errors: [],
   135	    notes: ["COVERAGE_LIMIT"],
   136	    dataQuality: "COVERAGE_LIMIT",
   137	    asOf: new Date().toISOString()
   138	  });
   139	}
   140	
   141	const lock = acquireLock({ providerId: "rss", datasetId: "event-mirrors", ttlSeconds: 900 });
   142	if (!lock.ok) {
   143	  console.log("LOCK_HELD", lock.details?.expiresAt || "active");
   144	  process.exit(0);
   145	}
   146	
   147	try {
   148	  const newsMirror = await buildNews();
   149	  const whyMovedMirror = buildEmptyEvent("why-moved", "Derived event context from news and anomalies.");
   150	  const hypeMirror = buildEmptyEvent("hype-divergence", "Mentions vs price divergence is limited in free mode.");
   151	  const earningsMirror = buildEmptyEvent("earnings", "Earnings coverage is limited in free mode.");
   152	  const congressMirror = buildEmptyEvent("congress-trading", "Congress trading coverage limited in free mode.");
   153	  const insiderMirror = buildEmptyEvent("insider-cluster", "Insider cluster coverage limited in free mode.");
   154	  const analystMirror = buildEmptyEvent("analyst-stampede", "Analyst coverage limited in free mode.");
   155	  const smartMoneyMirror = buildEmptyEvent("smart-money", "Composite scoring limited in free mode.");
   156	  const alphaPerfMirror = buildEmptyEvent("alpha-performance", "Alpha performance tracking not yet available.");
   157	  const earningsRealityMirror = buildEmptyEvent("earnings-reality", "Earnings reality checks limited in free mode.");
   158	
   159	  const mirrors = [
   160	    newsMirror,
   161	    whyMovedMirror,
   162	    hypeMirror,
   163	    earningsMirror,
   164	    congressMirror,
   165	    insiderMirror,
   166	    analystMirror,
   167	    smartMoneyMirror,
   168	    alphaPerfMirror,
   169	    earningsRealityMirror
   170	  ];
   171	
   172	  for (const mirror of mirrors) {
   173	    for (const dir of MIRROR_DIRS) {
   174	      saveMirror(path.join(dir, `${mirror.mirrorId}.json`), mirror);
   175	    }
   176	  }
   177	
   178	  const systemHealth = loadMirror(SYSTEM_HEALTH_PATH) || buildSystemHealth({
   179	    jobs: [],
   180	    mirrors: [],
   181	    selectedSymbols: [],
   182	    skippedSymbols: [],
   183	    overallStatus: "OK"
   184	  });
   185	
   186	  const jobEntry = {
   187	    id: "event-mirrors",
   188	    lastRunAt: new Date().toISOString(),
   189	    lastSuccessAt: new Date().toISOString(),
   190	    status: "OK",
   191	    durationMs: 0,
   192	    errors: [],
   193	    notes: []
   194	  };
   195	
   196	  systemHealth.jobs = systemHealth.jobs.filter((job) => job.id !== "event-mirrors");
   197	  systemHealth.jobs.push(jobEntry);
   198	
   199	  const mirrorUpdates = mirrors.map((mirror) => ({
   200	    id: mirror.mirrorId,

## FILE: scripts/generate-health-snapshot.mjs
     1	import fs from "node:fs";
     2	import path from "node:path";
     3	import { loadSnapshotEnvelopeSchema, createValidator, buildEnvelope } from "./lib/envelope-builder.mjs";
     4	
     5	const OUT = "public/data/snapshots/health/latest.json";
     6	const SCHEMA_PATH = "schemas/snapshot-envelope.schema.json";
     7	
     8	function readJsonIfExists(p) {
     9	  try { return JSON.parse(fs.readFileSync(p, "utf-8")); } catch { return null; }
    10	}
    11	
    12	function ensureDir(p) {
    13	  fs.mkdirSync(path.dirname(p), { recursive: true });
    14	}
    15	
    16	function main() {
    17	  const schema = loadSnapshotEnvelopeSchema(SCHEMA_PATH);
    18	  const { validate } = createValidator(schema);
    19	
    20	  const existing = readJsonIfExists(OUT);
    21	
    22	  // Preserve any existing meaningful content as data payload, but normalize envelope strictly.
    23	  // Priority:
    24	  // 1) existing.data if present
    25	  // 2) existing.data.data if envelope-like legacy
    26	  // 3) whole existing object as data
    27	  let payload = null;
    28	  if (existing && existing.data !== undefined) payload = existing.data;
    29	  else if (existing && existing.data && existing.data.data !== undefined) payload = existing.data.data;
    30	  else payload = existing;
    31	
    32	  const env = buildEnvelope(schema, {
    33	    module: "health",
    34	    tier: "critical",
    35	    domain: "system",
    36	    source: "generator",
    37	    data: payload ?? { note: "health snapshot regenerated (empty legacy payload)" },
    38	    // validation/upstream/freshness will be schema-driven; passed defaults to true
    39	  });
    40	
    41	  const ok = validate(env);
    42	  if (!ok) {
    43	    console.error("FAIL: generated health snapshot does not validate against schema");
    44	    console.error(validate.errors);
    45	    process.exit(1);
    46	  }
    47	
    48	  ensureDir(OUT);
    49	  fs.writeFileSync(OUT, JSON.stringify(env, null, 2) + "\n", "utf-8");
    50	  console.log(`OK: wrote ${OUT}`);
    51	}
    52	
    53	main();

## FILE: scripts/generate-health.mjs
     1	import { promises as fs } from "node:fs";
     2	import path from "node:path";
     3	import { fileURLToPath } from "node:url";
     4	import { loadMirror, saveMirror } from "./utils/mirror-io.mjs";
     5	
     6	const ROOT = path.resolve(path.dirname(fileURLToPath(import.meta.url)), "..");
     7	const DATA_DIR = path.join(ROOT, "mirrors");
     8	const SEED_MANIFEST_PATH = path.join(DATA_DIR, "seed-manifest.json");
     9	const USAGE_REPORT_PATH = path.join(DATA_DIR, "usage-report.json");
    10	const HEALTH_PATH = path.join(DATA_DIR, "health.json");
    11	const HEALTH_HISTORY_PATH = path.join(DATA_DIR, "health_history.json");
    12	
    13	function todayUtc() {
    14	  return new Date().toISOString().slice(0, 10);
    15	}
    16	
    17	async function readJsonIfExists(filePath) {
    18	  const payload = loadMirror(filePath);
    19	  return payload || null;
    20	}
    21	
    22	function summarizeBlocks(seedManifest) {
    23	  const blocks = Array.isArray(seedManifest?.blocks) ? seedManifest.blocks : [];
    24	  const counts = { LIVE: 0, PARTIAL: 0, ERROR: 0 };
    25	  const byReason = {};
    26	
    27	  for (const b of blocks) {
    28	    const status = String(b?.status || "ERROR").toUpperCase();
    29	    const reason = String(b?.reason || "UNKNOWN");
    30	    if (status === "LIVE") counts.LIVE += 1;
    31	    else if (status === "PARTIAL") counts.PARTIAL += 1;
    32	    else counts.ERROR += 1;
    33	    byReason[reason] = (byReason[reason] || 0) + 1;
    34	  }
    35	
    36	  const total = blocks.length;
    37	  const okPct = total ? (counts.LIVE + counts.PARTIAL) / total : 0;
    38	
    39	  return { blocks, counts: { ...counts, total }, okPct, byReason };
    40	}
    41	
    42	function summarizeUsage(usageReport) {
    43	  const providers = usageReport?.providers && typeof usageReport.providers === "object" ? usageReport.providers : {};
    44	  const totals = usageReport?.totals && typeof usageReport.totals === "object" ? usageReport.totals : {};
    45	  return { providers, totals };
    46	}
    47	
    48	function buildHealth(seedManifest, usageReport) {
    49	  const marketDate = todayUtc();
    50	  const generatedAt = new Date().toISOString();
    51	
    52	  const blocksSummary = summarizeBlocks(seedManifest);
    53	  const usageSummary = summarizeUsage(usageReport);
    54	
    55	  const inputs = [];
    56	  if (Array.isArray(seedManifest?.blocks)) inputs.push("mirrors/seed-manifest.json");
    57	  if (usageReport) inputs.push("mirrors/usage-report.json");
    58	
    59	  let status = "LIVE";
    60	  let reason = null;
    61	  if (!blocksSummary.counts.total) {
    62	    status = "ERROR";
    63	    reason = "NO_BLOCKS";
    64	  } else if (blocksSummary.counts.ERROR > 0) {
    65	    status = "PARTIAL";
    66	    reason = "BLOCK_ERRORS";
    67	  }
    68	
    69	  return {
    70	    schemaVersion: "1.0.0",
    71	    meta: {
    72	      blockId: "health",
    73	      generatedAt,
    74	      marketDate,
    75	      dataAsOf: seedManifest?.generatedAt || generatedAt,
    76	      status,
    77	      coveragePct: blocksSummary.counts.total ? blocksSummary.okPct : 0,
    78	      reason,
    79	      inputs
    80	    },
    81	    data: {
    82	      blocks: blocksSummary.blocks,
    83	      summary: {
    84	        ...blocksSummary.counts,
    85	        okPct: blocksSummary.okPct,
    86	        reasons: blocksSummary.byReason
    87	      },
    88	      usage: usageSummary
    89	    }
    90	  };
    91	}
    92	
    93	function normalizeHistory(history) {
    94	  if (!history || typeof history !== "object") return { schemaVersion: "1.0.0", items: [] };
    95	  if (!Array.isArray(history.items)) return { schemaVersion: "1.0.0", items: [] };
    96	  return { schemaVersion: "1.0.0", items: history.items };
    97	}
    98	
    99	function upsertHistory(history, health) {
   100	  const marketDate = health?.meta?.marketDate;
   101	  const items = Array.isArray(history.items) ? history.items.slice() : [];
   102	  const filtered = items.filter((item) => item?.meta?.marketDate && item.meta.marketDate !== marketDate);
   103	  filtered.push(health);
   104	  filtered.sort((a, b) => String(a?.meta?.marketDate || "").localeCompare(String(b?.meta?.marketDate || "")));
   105	  const last30 = filtered.slice(-30);
   106	  return { schemaVersion: "1.0.0", items: last30 };
   107	}
   108	
   109	async function main() {
   110	  const seedManifest = await readJsonIfExists(SEED_MANIFEST_PATH);
   111	  if (!seedManifest) {
   112	    console.warn("seed-manifest.json missing or invalid, creating minimal health");
   113	    // Create minimal health if manifest is missing
   114	    const minimalHealth = {
   115	      schemaVersion: "1.0.0",
   116	      meta: {
   117	        blockId: "health",
   118	        generatedAt: new Date().toISOString(),
   119	        marketDate: todayUtc(),
   120	        dataAsOf: new Date().toISOString(),
   121	        status: "PARTIAL",
   122	        coveragePct: 0,
   123	        reason: "SEED_MANIFEST_MISSING",
   124	        inputs: []
   125	      },
   126	      data: {
   127	        blocks: [],
   128	        summary: { total: 0, LIVE: 0, PARTIAL: 0, ERROR: 0, okPct: 0, reasons: {} },
   129	        usage: { providers: {}, totals: {} }
   130	      }
   131	    };
   132	    saveMirror(HEALTH_PATH, minimalHealth);
   133	    console.log(`[health] wrote minimal health.json for ${minimalHealth.meta.marketDate}`);
   134	    return;
   135	  }
   136	  const usageReport = await readJsonIfExists(USAGE_REPORT_PATH);
   137	
   138	  const health = buildHealth(seedManifest, usageReport);
   139	  saveMirror(HEALTH_PATH, health);
   140	
   141	  const historyRaw = await readJsonIfExists(HEALTH_HISTORY_PATH);
   142	  const history = normalizeHistory(historyRaw);
   143	  const updated = upsertHistory(history, health);
   144	  saveMirror(HEALTH_HISTORY_PATH, updated);
   145	
   146	  console.log(`[health] wrote health.json + health_history.json for ${health.meta.marketDate}`);
   147	}
   148	
   149	main().catch((error) => {
   150	  console.error(error?.message || error);
   151	  process.exit(1);
   152	});

## FILE: scripts/generate-posts.js
     1	#!/usr/bin/env node
     2	const fs = require("node:fs");
     3	const path = require("node:path");
     4	
     5	const baseUrl = process.argv[2] || process.env.RV_BASE_URL || "http://localhost:8788";
     6	const outDir = path.join(process.cwd(), "public", "posts");
     7	const dateTag = new Date().toISOString().slice(0, 10);
     8	
     9	const FEATURES = [
    10	  { id: "market-cockpit", label: "Market Cockpit", endpoint: "/api/market-cockpit" },
    11	  { id: "market-health", label: "Market Health", endpoint: "/api/market-health" },
    12	  { id: "yield-curve", label: "Yield Curve", endpoint: "/api/yield-curve" },
    13	  { id: "sector-rotation", label: "Sector Rotation", endpoint: "/api/sector-rotation" },
    14	  { id: "central-bank-watch", label: "Central Bank Watch", endpoint: "/api/central-bank-watch" },
    15	  { id: "sp500-sectors", label: "S&P 500 Sectors", endpoint: "/api/sp500-sectors" },
    16	  { id: "news", label: "News Headlines", endpoint: "/api/news" },
    17	  { id: "news-intelligence", label: "News Intelligence", endpoint: "/api/news-intelligence" },
    18	  { id: "macro-rates", label: "Macro & Rates", endpoint: "/api/macro-rates" },
    19	  { id: "crypto-snapshot", label: "Crypto Snapshot", endpoint: "/api/crypto-snapshot" },
    20	  { id: "sentiment", label: "Sentiment Barometer", endpoint: "/api/sentiment" },
    21	  { id: "tech-signals", label: "Tech Signals", endpoint: "/api/tech-signals" },
    22	  { id: "alpha-radar", label: "Alpha Radar", endpoint: "/api/alpha-radar" },
    23	  { id: "market-regime", label: "Market Regime Radar", endpoint: "/api/market-regime" },
    24	  { id: "why-moved", label: "Why This Stock Moved", endpoint: "/api/why-moved" },
    25	  { id: "volume-anomaly", label: "Volume Anomaly", endpoint: "/api/volume-anomaly" },
    26	  { id: "hype-divergence", label: "Inverse Hype Detector", endpoint: "/api/hype-divergence" },
    27	  { id: "congress-trading", label: "Congress Trading Tracker", endpoint: "/api/congress-trading" },
    28	  { id: "insider-cluster", label: "Insider Cluster", endpoint: "/api/insider-cluster" },
    29	  { id: "analyst-stampede", label: "Analyst Stampede", endpoint: "/api/analyst-stampede" },
    30	  { id: "smart-money", label: "Smart Money Score", endpoint: "/api/smart-money" },
    31	  { id: "alpha-performance", label: "Alpha Consistency", endpoint: "/api/alpha-performance" },
    32	  { id: "earnings-reality", label: "Earnings Reality Check", endpoint: "/api/earnings-reality" }
    33	];
    34	
    35	function ensureDir() {
    36	  fs.mkdirSync(outDir, { recursive: true });
    37	}
    38	
    39	function safeNumber(value, digits = 2) {
    40	  if (value === null || value === undefined || Number.isNaN(value)) return "N/A";
    41	  return Number(value).toFixed(digits);
    42	}
    43	
    44	function resolveDataQuality(payload) {
    45	  return payload?.data?.dataQuality || payload?.dataQuality || (payload?.ok ? "LIVE" : "NO_DATA");
    46	}
    47	
    48	function summarize(featureId, payload) {
    49	  const data = payload?.data?.data || payload?.data || {};
    50	  switch (featureId) {
    51	    case "market-regime":
    52	      return `${data.label || "Regime"} (${safeNumber(data.riskOnScore, 0)})`;
    53	    case "why-moved":
    54	      return data.movers?.[0]
    55	        ? `${data.movers[0].symbol}: ${data.movers[0].reasonLabel || "Move"}`
    56	        : "No movers";
    57	    case "volume-anomaly":
    58	      return data.signals?.[0]
    59	        ? `${data.signals[0].symbol}: ${data.signals[0].signal}`
    60	        : "No signals";
    61	    case "hype-divergence":
    62	      return data.signals?.[0]
    63	        ? `${data.signals[0].symbol}: ${data.signals[0].signal}`
    64	        : "No signals";
    65	    case "congress-trading":
    66	      return data.trades?.[0]
    67	        ? `${data.trades[0].symbol} ${data.trades[0].action}`
    68	        : "No trades";
    69	    case "insider-cluster":
    70	      return data.items?.[0]
    71	        ? `${data.items[0].symbol}: ${data.items[0].insiderCount} insiders`
    72	        : "No clusters";
    73	    case "analyst-stampede":
    74	      return data.items?.[0]
    75	        ? `${data.items[0].symbol}: ${data.items[0].delta} changes`
    76	        : "No analyst moves";
    77	    case "smart-money":
    78	      return `Score ${safeNumber(data.score, 0)}`;
    79	    case "alpha-radar":
    80	      return data.picks?.top?.[0]
    81	        ? `Top: ${data.picks.top[0].symbol} (${safeNumber(data.picks.top[0].totalScore, 0)})`
    82	        : "No picks";
    83	    case "alpha-performance":
    84	      return `Hit rate ${safeNumber(data.hitRate * 100, 1)}%`;
    85	    case "earnings-reality":
    86	      return data.items?.[0]
    87	        ? `${data.items[0].symbol}: ${data.items[0].flag || "Check"}`
    88	        : "No earnings";
    89	    default:
    90	      return `${payload?.feature || featureId}`;
    91	  }
    92	}
    93	
    94	async function fetchPayload(endpoint) {
    95	  const url = `${baseUrl}${endpoint}`;
    96	  try {
    97	    const res = await fetch(url, { headers: { "Accept": "application/json" } });
    98	    const text = await res.text();
    99	    const json = text ? JSON.parse(text) : null;
   100	    return { ok: res.ok, json, url };
   101	  } catch (error) {
   102	    return { ok: false, json: null, url: endpoint, error: error?.message || "fetch_failed" };
   103	  }
   104	}
   105	
   106	async function writeSummary(feature) {
   107	  const payload = await fetchPayload(feature.endpoint);
   108	  const data = payload.json || { ok: false, feature: feature.id };
   109	  const dataQuality = resolveDataQuality(data);
   110	  const headline = summarize(feature.id, data);
   111	  const baseLine = `${feature.label}: ${headline}`;
   112	  const summary = {
   113	    feature: feature.id,
   114	    label: feature.label,
   115	    date: dateTag,
   116	    generatedAt: new Date().toISOString(),
   117	    endpoint: feature.endpoint,
   118	    dataQuality,
   119	    traceId: data?.traceId || "",
   120	    updatedAt: data?.data?.updatedAt || data?.ts || null,
   121	    summary: {
   122	      text_short: `${baseLine}  ${dataQuality}`,
   123	      text_medium: `${baseLine}. Quality: ${dataQuality}. Updated: ${data?.data?.updatedAt || data?.ts || ""}`,
   124	      text_linkedin: `${baseLine}\nQuality: ${dataQuality}\nUpdated: ${data?.data?.updatedAt || data?.ts || ""}`,
   125	      text_instagram: `${baseLine}\n#RubikVault #Markets`
   126	    }
   127	  };
   128	
   129	  const filename = `${feature.id}_${dateTag}.json`;
   130	  fs.writeFileSync(path.join(outDir, filename), JSON.stringify(summary, null, 2));
   131	  return filename;
   132	}
   133	
   134	async function main() {
   135	  ensureDir();
   136	  const written = [];
   137	  for (const feature of FEATURES) {
   138	    const file = await writeSummary(feature);
   139	    written.push(file);
   140	  }
   141	  console.log(`Generated ${written.length} posts in ${outDir}`);
   142	}
   143	
   144	main();

## FILE: scripts/generate-snapshots.mjs.bak
     1	import { promises as fs } from "node:fs";
     2	import path from "node:path";
     3	import { fileURLToPath } from "node:url";
     4	
     5	const ROOT = path.resolve(path.dirname(fileURLToPath(import.meta.url)), "..");
     6	const SNAPSHOT_DIR = path.join(ROOT, "public", "data", "snapshots");
     7	const TMP_DIR = path.join(SNAPSHOT_DIR, ".tmp");
     8	const MIRROR_DIRS = [
     9	  path.join(ROOT, "public", "mirrors"),
    10	  path.join(ROOT, "public", "mirror")
    11	];
    12	
    13	const SNAPSHOTS = [
    14	  { id: "top-movers", mirrorId: "top-movers", mapData: mapItemsOnly },
    15	  { id: "yield-curve", mirrorId: "yield-curve", mapData: mapItemsOnly },
    16	  { id: "why-moved", mirrorId: "why-moved", mapData: mapItemsOnly },
    17	  { id: "sp500-sectors", mirrorId: "sp500-sectors", mapData: mapSectors },
    18	  { id: "tech-signals", mirrorId: "tech-signals", mapData: mapSignals },
    19	  { id: "volume-anomaly", mirrorId: "volume-anomaly", mapData: mapItemsOnly }
    20	];
    21	
    22	function normalizeId(rawId) {
    23	  const raw = String(rawId || "");
    24	  const match = raw.match(/^(\d+):(.*)$/);
    25	  if (!match) return raw;
    26	  return match[2] || "";
    27	}
    28	
    29	function ensureUniqueIds(entries) {
    30	  const seen = new Map();
    31	  entries.forEach((entry) => {
    32	    const normalized = normalizeId(entry.id);
    33	    if (seen.has(normalized)) {
    34	      throw new Error(
    35	        `Duplicate snapshot id after normalization: ${entry.id} conflicts with ${seen.get(normalized)}`
    36	      );
    37	    }
    38	    seen.set(normalized, entry.id);
    39	  });
    40	}
    41	
    42	async function findMirrorPath(mirrorId) {
    43	  const candidates = MIRROR_DIRS.map((dir) => path.join(dir, `${mirrorId}.json`));
    44	  for (const candidate of candidates) {
    45	    try {
    46	      await fs.access(candidate);
    47	      return candidate;
    48	    } catch {
    49	      continue;
    50	    }
    51	  }
    52	  return null;
    53	}
    54	
    55	async function readMirrorJson(mirrorId) {
    56	  const mirrorPath = await findMirrorPath(mirrorId);
    57	  if (!mirrorPath) {
    58	    const error = new Error(`Mirror not found for ${mirrorId}`);
    59	    error.code = "MIRROR_MISSING";
    60	    throw error;
    61	  }
    62	  const raw = await fs.readFile(mirrorPath, "utf8");
    63	  try {
    64	    return JSON.parse(raw);
    65	  } catch (error) {
    66	    const parseError = new Error(`Mirror JSON parse failed for ${mirrorId}`);
    67	    parseError.code = "MIRROR_PARSE_ERROR";
    68	    parseError.cause = error;
    69	    throw parseError;
    70	  }
    71	}
    72	
    73	function extractItems(payload) {
    74	  if (Array.isArray(payload?.items)) return payload.items;
    75	  if (Array.isArray(payload?.payload?.data?.data?.items)) return payload.payload.data.data.items;
    76	  if (Array.isArray(payload?.payload?.data?.items)) return payload.payload.data.items;
    77	  return [];
    78	}
    79	
    80	function mapItemsOnly(raw) {
    81	  const items = extractItems(raw);
    82	  return { data: { items }, itemsCount: items.length };
    83	}
    84	
    85	function mapSectors(raw) {
    86	  const items = extractItems(raw);
    87	  return { data: { items, sectors: items }, itemsCount: items.length };
    88	}
    89	
    90	function mapSignals(raw) {
    91	  const items = extractItems(raw);
    92	  return { data: { items, signals: items }, itemsCount: items.length };
    93	}
    94	
    95	function pickUpdatedAt(raw) {
    96	  const candidates = [
    97	    raw?.updatedAt,
    98	    raw?.asOf,
    99	    raw?.ts,
   100	    raw?.meta?.updatedAt,
   101	    raw?.payload?.data?.updatedAt,
   102	    raw?.payload?.data?.data?.updatedAt
   103	  ];
   104	  return candidates.find((value) => value && typeof value === "string") || null;
   105	}
   106	
   107	function computeStalenessSec(updatedAt, generatedAt) {
   108	  if (!updatedAt) return 0;
   109	  const updatedMs = Date.parse(updatedAt);
   110	  const generatedMs = Date.parse(generatedAt);
   111	  if (!Number.isFinite(updatedMs) || !Number.isFinite(generatedMs)) return 0;
   112	  return Math.max(0, Math.floor((generatedMs - updatedMs) / 1000));
   113	}
   114	
   115	async function atomicWriteJson(targetPath, payload) {
   116	  await fs.mkdir(TMP_DIR, { recursive: true });
   117	  const tmpPath = path.join(TMP_DIR, `${path.basename(targetPath)}.tmp`);
   118	  let serialized = JSON.stringify(payload, null, 2);
   119	  payload.meta.bytes = Buffer.byteLength(serialized);
   120	  serialized = JSON.stringify(payload, null, 2);
   121	  await fs.writeFile(tmpPath, serialized);
   122	  await fs.rename(tmpPath, targetPath);
   123	  return Buffer.byteLength(serialized);
   124	}
   125	
   126	async function generateSnapshot(entry) {
   127	  const started = Date.now();
   128	  const generatedAt = new Date().toISOString();
   129	  let mirrorPayload = null;
   130	  let metaStatus = "ERROR";
   131	  let metaReason = "MIRROR_ERROR";
   132	  let data = { items: [] };
   133	  let ok = false;
   134	  let itemsCount = 0;
   135	
   136	  try {
   137	    mirrorPayload = await readMirrorJson(entry.mirrorId);
   138	    const mapped = entry.mapData(mirrorPayload);
   139	    data = mapped.data;
   140	    itemsCount = mapped.itemsCount;
   141	    if (itemsCount > 0) {
   142	      metaStatus = "LIVE";
   143	      metaReason = "OK";
   144	      ok = true;
   145	    } else {
   146	      metaStatus = "NO_DATA";
   147	      metaReason = "EMPTY_ITEMS";
   148	      ok = false;
   149	    }
   150	  } catch (error) {
   151	    metaStatus = "ERROR";
   152	    metaReason = error?.code || "MIRROR_ERROR";
   153	    ok = false;
   154	  }
   155	
   156	  const updatedAt = pickUpdatedAt(mirrorPayload);
   157	  const durationMs = Date.now() - started;
   158	  const stalenessSec = computeStalenessSec(updatedAt, generatedAt);
   159	
   160	  const envelope = {
   161	    ok,
   162	    feature: entry.id,
   163	    meta: {
   164	      status: metaStatus,
   165	      reason: metaReason,
   166	      generatedAt,
   167	      stalenessSec,
   168	      durationMs,
   169	      bytes: 0
   170	    },
   171	    data
   172	  };
   173	
   174	  const targetPath = path.join(SNAPSHOT_DIR, `${entry.id}.json`);
   175	  const bytes = await atomicWriteJson(targetPath, envelope);
   176	  return {
   177	    id: entry.id,
   178	    status: metaStatus,
   179	    reason: metaReason,
   180	    generatedAt,
   181	    durationMs,
   182	    bytes,
   183	    itemsCount,
   184	    updatedAt: updatedAt || null
   185	  };
   186	}
   187	
   188	async function main() {
   189	  ensureUniqueIds(SNAPSHOTS);
   190	  await fs.mkdir(SNAPSHOT_DIR, { recursive: true });
   191	  const manifest = {
   192	    generatedAt: new Date().toISOString(),
   193	    snapshots: {}
   194	  };
   195	
   196	  for (const entry of SNAPSHOTS) {
   197	    const summary = await generateSnapshot(entry);
   198	    manifest.snapshots[entry.id] = summary;
   199	    console.log(
   200	      `[snapshot] ${entry.id} status=${summary.status} reason=${summary.reason} items=${summary.itemsCount} durationMs=${summary.durationMs}`

## FILE: scripts/generate-snapshots.mjs.bak.1768075080
     1	import { promises as fs } from "node:fs";
     2	import path from "node:path";
     3	import { fileURLToPath } from "node:url";
     4	
     5	const ROOT = path.resolve(path.dirname(fileURLToPath(import.meta.url)), "..");
     6	const SNAPSHOT_DIR = path.join(ROOT, "public", "data", "snapshots");
     7	const TMP_DIR = path.join(SNAPSHOT_DIR, ".tmp");
     8	const MIRROR_DIRS = [
     9	  path.join(ROOT, "public", "mirrors"),
    10	  path.join(ROOT, "public", "mirror")
    11	];
    12	
    13	const SNAPSHOTS = [
    14	  { id: "top-movers", mirrorId: "top-movers", mapData: mapItemsOnly },
    15	  { id: "yield-curve", mirrorId: "yield-curve", mapData: mapItemsOnly },
    16	  { id: "why-moved", mirrorId: "why-moved", mapData: mapItemsOnly },
    17	  { id: "sp500-sectors", mirrorId: "sp500-sectors", mapData: mapSectors },
    18	  { id: "tech-signals", mirrorId: "tech-signals", mapData: mapSignals },
    19	  { id: "volume-anomaly", mirrorId: "volume-anomaly", mapData: mapItemsOnly }
    20	];
    21	
    22	function normalizeId(rawId) {
    23	  const raw = String(rawId || "");
    24	  const match = raw.match(/^(\d+):(.*)$/);
    25	  if (!match) return raw;
    26	  return match[2] || "";
    27	}
    28	
    29	function ensureUniqueIds(entries) {
    30	  const seen = new Map();
    31	  entries.forEach((entry) => {
    32	    const normalized = normalizeId(entry.id);
    33	    if (seen.has(normalized)) {
    34	      throw new Error(
    35	        `Duplicate snapshot id after normalization: ${entry.id} conflicts with ${seen.get(normalized)}`
    36	      );
    37	    }
    38	    seen.set(normalized, entry.id);
    39	  });
    40	}
    41	
    42	async function findMirrorPath(mirrorId) {
    43	  const candidates = MIRROR_DIRS.map((dir) => path.join(dir, `${mirrorId}.json`));
    44	  for (const candidate of candidates) {
    45	    try {
    46	      await fs.access(candidate);
    47	      return candidate;
    48	    } catch {
    49	      continue;
    50	    }
    51	  }
    52	  return null;
    53	}
    54	
    55	async function readMirrorJson(mirrorId) {
    56	  const mirrorPath = await findMirrorPath(mirrorId);
    57	  if (!mirrorPath) {
    58	    const error = new Error(`Mirror not found for ${mirrorId}`);
    59	    error.code = "MIRROR_MISSING";
    60	    throw error;
    61	  }
    62	  const raw = await fs.readFile(mirrorPath, "utf8");
    63	  try {
    64	    return JSON.parse(raw);
    65	  } catch (error) {
    66	    const parseError = new Error(`Mirror JSON parse failed for ${mirrorId}`);
    67	    parseError.code = "MIRROR_PARSE_ERROR";
    68	    parseError.cause = error;
    69	    throw parseError;
    70	  }
    71	}
    72	
    73	function extractItems(payload) {
    74	  if (Array.isArray(payload?.items)) return payload.items;
    75	  if (Array.isArray(payload?.payload?.data?.data?.items)) return payload.payload.data.data.items;
    76	  if (Array.isArray(payload?.payload?.data?.items)) return payload.payload.data.items;
    77	  return [];
    78	}
    79	
    80	function extractSectors(payload) {
    81	  if (Array.isArray(payload?.sectors)) return payload.sectors;
    82	  if (Array.isArray(payload?.payload?.data?.data?.sectors)) return payload.payload.data.data.sectors;
    83	  if (Array.isArray(payload?.payload?.data?.sectors)) return payload.payload.data.sectors;
    84	  if (Array.isArray(payload?.items) && payload.items.length && payload.items[0]?.sector) return payload.items;
    85	  return [];
    86	}
    87	
    88	function mapItemsOnly(raw) {
    89	  const items = extractItems(raw);
    90	  return { data: { items }, itemsCount: items.length };
    91	}
    92	
    93	function mapSectors(raw) {
    94	  const sectors = extractSectors(raw);
    95	  const items = extractItems(raw);
    96	  const itemsCount = sectors.length || items.length;
    97	  return { data: { items, sectors }, itemsCount };
    98	}
    99	
   100	function mapSignals(raw) {
   101	  const items = extractItems(raw);
   102	  return { data: { items, signals: items }, itemsCount: items.length };
   103	}
   104	
   105	function pickUpdatedAt(raw) {
   106	  const candidates = [
   107	    raw?.updatedAt,
   108	    raw?.asOf,
   109	    raw?.ts,
   110	    raw?.meta?.updatedAt,
   111	    raw?.payload?.data?.updatedAt,
   112	    raw?.payload?.data?.data?.updatedAt
   113	  ];
   114	  return candidates.find((value) => value && typeof value === "string") || null;
   115	}
   116	
   117	function computeStalenessSec(updatedAt, generatedAt) {
   118	  if (!updatedAt) return 0;
   119	  const updatedMs = Date.parse(updatedAt);
   120	  const generatedMs = Date.parse(generatedAt);
   121	  if (!Number.isFinite(updatedMs) || !Number.isFinite(generatedMs)) return 0;
   122	  return Math.max(0, Math.floor((generatedMs - updatedMs) / 1000));
   123	}
   124	
   125	async function atomicWriteJson(targetPath, payload) {
   126	  await fs.mkdir(TMP_DIR, { recursive: true });
   127	  const tmpPath = path.join(TMP_DIR, `${path.basename(targetPath)}.tmp`);
   128	  let serialized = JSON.stringify(payload, null, 2);
   129	  payload.meta.bytes = Buffer.byteLength(serialized);
   130	  serialized = JSON.stringify(payload, null, 2);
   131	  await fs.writeFile(tmpPath, serialized);
   132	  await fs.rename(tmpPath, targetPath);
   133	  return Buffer.byteLength(serialized);
   134	}
   135	
   136	async function generateSnapshot(entry) {
   137	  const started = Date.now();
   138	  const generatedAt = new Date().toISOString();
   139	  let mirrorPayload = null;
   140	  let metaStatus = "ERROR";
   141	  let metaReason = "MIRROR_ERROR";
   142	  let data = { items: [] };
   143	  let ok = false;
   144	  let itemsCount = 0;
   145	
   146	  try {
   147	    mirrorPayload = await readMirrorJson(entry.mirrorId);
   148	    if (!mirrorPayload || (typeof mirrorPayload !== "object")) {
   149	      const schemaErr = new Error(`Mirror schema invalid for ${entry.mirrorId}`);
   150	      schemaErr.code = "MIRROR_SCHEMA_EMPTY";
   151	      throw schemaErr;
   152	    }
   153	
   154	    const mapped = entry.mapData(mirrorPayload);
   155	    data = mapped.data;
   156	    itemsCount = mapped.itemsCount;
   157	    if (itemsCount > 0) {
   158	      metaStatus = "LIVE";
   159	      metaReason = "OK";
   160	      ok = true;
   161	    } else {
   162	      metaStatus = "NO_DATA";
   163	      metaReason = "EMPTY_ITEMS";
   164	      ok = false;
   165	    }
   166	  } catch (error) {
   167	    metaStatus = "ERROR";
   168	    metaReason = error?.code || "MIRROR_ERROR";
   169	    ok = false;
   170	  }
   171	
   172	  const updatedAt = pickUpdatedAt(mirrorPayload);
   173	  const durationMs = Date.now() - started;
   174	  const stalenessSec = computeStalenessSec(updatedAt, generatedAt);
   175	
   176	  const envelope = {
   177	    ok,
   178	    feature: entry.id,
   179	    meta: {
   180	      status: metaStatus,
   181	      reason: metaReason,
   182	      generatedAt,
   183	      stalenessSec,
   184	      durationMs,
   185	      bytes: 0
   186	    },
   187	    data
   188	  };
   189	
   190	  const targetPath = path.join(SNAPSHOT_DIR, `${entry.id}.json`);
   191	  const bytes = await atomicWriteJson(targetPath, envelope);
   192	  return {
   193	    id: entry.id,
   194	    status: metaStatus,
   195	    reason: metaReason,
   196	    generatedAt,
   197	    durationMs,
   198	    bytes,
   199	    itemsCount,
   200	    updatedAt: updatedAt || null

## FILE: scripts/generate-snapshots.mjs.bak.1768075659
     1	import { promises as fs } from "node:fs";
     2	import path from "node:path";
     3	import { fileURLToPath } from "node:url";
     4	
     5	const ROOT = path.resolve(path.dirname(fileURLToPath(import.meta.url)), "..");
     6	const SNAPSHOT_DIR = path.join(ROOT, "public", "data", "snapshots");
     7	const TMP_DIR = path.join(SNAPSHOT_DIR, ".tmp");
     8	const MIRROR_DIRS = [
     9	  path.join(ROOT, "public", "mirrors"),
    10	  path.join(ROOT, "public", "mirror")
    11	];
    12	
    13	const SNAPSHOTS = [
    14	  { id: "top-movers", mirrorId: "top-movers", mapData: mapItemsOnly },
    15	  { id: "yield-curve", mirrorId: "yield-curve", mapData: mapItemsOnly },
    16	  { id: "why-moved", mirrorId: "why-moved", mapData: mapItemsOnly },
    17	  { id: "sp500-sectors", mirrorId: "sp500-sectors", mapData: mapSectors },
    18	  { id: "tech-signals", mirrorId: "tech-signals", mapData: mapSignals },
    19	  { id: "volume-anomaly", mirrorId: "volume-anomaly", mapData: mapItemsOnly }
    20	];
    21	
    22	function normalizeId(rawId) {
    23	  const raw = String(rawId || "");
    24	  const match = raw.match(/^(\d+):(.*)$/);
    25	  if (!match) return raw;
    26	  return match[2] || "";
    27	}
    28	
    29	function ensureUniqueIds(entries) {
    30	  const seen = new Map();
    31	  entries.forEach((entry) => {
    32	    const normalized = normalizeId(entry.id);
    33	    if (seen.has(normalized)) {
    34	      throw new Error(
    35	        `Duplicate snapshot id after normalization: ${entry.id} conflicts with ${seen.get(normalized)}`
    36	      );
    37	    }
    38	    seen.set(normalized, entry.id);
    39	  });
    40	}
    41	
    42	async function findMirrorPath(mirrorId) {
    43	  const candidates = MIRROR_DIRS.map((dir) => path.join(dir, `${mirrorId}.json`));
    44	  for (const candidate of candidates) {
    45	    try {
    46	      await fs.access(candidate);
    47	      return candidate;
    48	    } catch {
    49	      continue;
    50	    }
    51	  }
    52	  return null;
    53	}
    54	
    55	async function readMirrorJson(mirrorId) {
    56	  const mirrorPath = await findMirrorPath(mirrorId);
    57	  if (!mirrorPath) {
    58	    const error = new Error(`Mirror not found for ${mirrorId}`);
    59	    error.code = "MIRROR_MISSING";
    60	    throw error;
    61	  }
    62	  const raw = await fs.readFile(mirrorPath, "utf8");
    63	  try {
    64	    return JSON.parse(raw);
    65	  } catch (error) {
    66	    const parseError = new Error(`Mirror JSON parse failed for ${mirrorId}`);
    67	    parseError.code = "MIRROR_PARSE_ERROR";
    68	    parseError.cause = error;
    69	    throw parseError;
    70	  }
    71	}
    72	
    73	function extractItems(payload) {
    74	  // mirror shapes vary across generators; accept multiple common paths
    75	  if (Array.isArray(payload?.items)) return payload.items;
    76	
    77	  // "wrapped mirror" shapes
    78	  if (Array.isArray(payload?.payload?.items)) return payload.payload.items;
    79	
    80	  // common nested shapes
    81	  if (Array.isArray(payload?.payload?.data?.items)) return payload.payload.data.items;
    82	  if (Array.isArray(payload?.payload?.data?.data?.items)) return payload.payload.data.data.items;
    83	
    84	  // IMPORTANT: some mirrors include an extra 'data' layer (payload.data.data.items)
    85	  if (Array.isArray(payload?.payload?.data?.data?.data?.items)) return payload.payload.data.data.data.items;
    86	
    87	  return [];
    88	}
    89	
    90	function extractSectors(payload) {
    91	  if (Array.isArray(payload?.sectors)) return payload.sectors;
    92	  if (Array.isArray(payload?.payload?.data?.data?.sectors)) return payload.payload.data.data.sectors;
    93	  if (Array.isArray(payload?.payload?.data?.sectors)) return payload.payload.data.sectors;
    94	  if (Array.isArray(payload?.items) && payload.items.length && payload.items[0]?.sector) return payload.items;
    95	  return [];
    96	}
    97	
    98	function mapItemsOnly(raw) {
    99	  const items = extractItems(raw);
   100	  return { data: { items }, itemsCount: items.length };
   101	}
   102	
   103	function mapSectors(raw) {
   104	  const sectors = extractSectors(raw);
   105	  const items = extractItems(raw);
   106	  const itemsCount = sectors.length || items.length;
   107	  return { data: { items, sectors }, itemsCount };
   108	}
   109	
   110	function mapSignals(raw) {
   111	  const items = extractItems(raw);
   112	  return { data: { items, signals: items }, itemsCount: items.length };
   113	}
   114	
   115	function pickUpdatedAt(raw) {
   116	  const candidates = [
   117	    raw?.updatedAt,
   118	    raw?.asOf,
   119	    raw?.ts,
   120	    raw?.meta?.updatedAt,
   121	    raw?.payload?.data?.updatedAt,
   122	    raw?.payload?.data?.data?.updatedAt
   123	  ];
   124	  return candidates.find((value) => value && typeof value === "string") || null;
   125	}
   126	
   127	function computeStalenessSec(updatedAt, generatedAt) {
   128	  if (!updatedAt) return 0;
   129	  const updatedMs = Date.parse(updatedAt);
   130	  const generatedMs = Date.parse(generatedAt);
   131	  if (!Number.isFinite(updatedMs) || !Number.isFinite(generatedMs)) return 0;
   132	  return Math.max(0, Math.floor((generatedMs - updatedMs) / 1000));
   133	}
   134	
   135	async function atomicWriteJson(targetPath, payload) {
   136	  await fs.mkdir(TMP_DIR, { recursive: true });
   137	  const tmpPath = path.join(TMP_DIR, `${path.basename(targetPath)}.tmp`);
   138	  let serialized = JSON.stringify(payload, null, 2);
   139	  payload.meta.bytes = Buffer.byteLength(serialized);
   140	  serialized = JSON.stringify(payload, null, 2);
   141	  await fs.writeFile(tmpPath, serialized);
   142	  await fs.rename(tmpPath, targetPath);
   143	  return Buffer.byteLength(serialized);
   144	}
   145	
   146	async function generateSnapshot(entry) {
   147	  const started = Date.now();
   148	  const generatedAt = new Date().toISOString();
   149	  let mirrorPayload = null;
   150	  let metaStatus = "ERROR";
   151	  let metaReason = "MIRROR_ERROR";
   152	  let data = { items: [] };
   153	  let ok = false;
   154	  let itemsCount = 0;
   155	
   156	  try {
   157	    mirrorPayload = await readMirrorJson(entry.mirrorId);
   158	    if (!mirrorPayload || (typeof mirrorPayload !== "object")) {
   159	      const schemaErr = new Error(`Mirror schema invalid for ${entry.mirrorId}`);
   160	      schemaErr.code = "MIRROR_SCHEMA_EMPTY";
   161	      throw schemaErr;
   162	    }
   163	
   164	    const mapped = entry.mapData(mirrorPayload);
   165	    data = mapped.data;
   166	    itemsCount = mapped.itemsCount;
   167	    if (itemsCount > 0) {
   168	      metaStatus = "LIVE";
   169	      metaReason = "OK";
   170	      ok = true;
   171	    } else {
   172	      metaStatus = "NO_DATA";
   173	      metaReason = "EMPTY_ITEMS";
   174	      ok = false;
   175	    }
   176	  } catch (error) {
   177	    metaStatus = "ERROR";
   178	    metaReason = error?.code || "MIRROR_ERROR";
   179	    ok = false;
   180	  }
   181	
   182	  const updatedAt = pickUpdatedAt(mirrorPayload);
   183	  const durationMs = Date.now() - started;
   184	  const stalenessSec = computeStalenessSec(updatedAt, generatedAt);
   185	
   186	  const envelope = {
   187	    ok,
   188	    feature: entry.id,
   189	    meta: {
   190	      status: metaStatus,
   191	      reason: metaReason,
   192	      generatedAt,
   193	      stalenessSec,
   194	      durationMs,
   195	      bytes: 0
   196	    },
   197	    data
   198	  };
   199	
   200	  const targetPath = path.join(SNAPSHOT_DIR, `${entry.id}.json`);

## FILE: scripts/generate-snapshots.mjs.bak.1768075753
     1	import { promises as fs } from "node:fs";
     2	import path from "node:path";
     3	import { fileURLToPath } from "node:url";
     4	
     5	const ROOT = path.resolve(path.dirname(fileURLToPath(import.meta.url)), "..");
     6	const SNAPSHOT_DIR = path.join(ROOT, "public", "data", "snapshots");
     7	const TMP_DIR = path.join(SNAPSHOT_DIR, ".tmp");
     8	const MIRROR_DIRS = [
     9	  path.join(ROOT, "public", "mirrors"),
    10	  path.join(ROOT, "public", "mirror")
    11	];
    12	
    13	const SNAPSHOTS = [
    14	  { id: "top-movers", mirrorId: "top-movers", mapData: mapItemsOnly },
    15	  { id: "yield-curve", mirrorId: "yield-curve", mapData: mapItemsOnly },
    16	  { id: "why-moved", mirrorId: "why-moved", mapData: mapItemsOnly },
    17	  { id: "sp500-sectors", mirrorId: "sp500-sectors", mapData: mapSectors },
    18	  { id: "tech-signals", mirrorId: "tech-signals", mapData: mapSignals },
    19	  { id: "volume-anomaly", mirrorId: "volume-anomaly", mapData: mapItemsOnly }
    20	];
    21	
    22	function normalizeId(rawId) {
    23	  const raw = String(rawId || "");
    24	  const match = raw.match(/^(\d+):(.*)$/);
    25	  if (!match) return raw;
    26	  return match[2] || "";
    27	}
    28	
    29	function ensureUniqueIds(entries) {
    30	  const seen = new Map();
    31	  entries.forEach((entry) => {
    32	    const normalized = normalizeId(entry.id);
    33	    if (seen.has(normalized)) {
    34	      throw new Error(
    35	        `Duplicate snapshot id after normalization: ${entry.id} conflicts with ${seen.get(normalized)}`
    36	      );
    37	    }
    38	    seen.set(normalized, entry.id);
    39	  });
    40	}
    41	
    42	async function findMirrorPath(mirrorId) {
    43	  const candidates = MIRROR_DIRS.map((dir) => path.join(dir, `${mirrorId}.json`));
    44	  for (const candidate of candidates) {
    45	    try {
    46	      await fs.access(candidate);
    47	      return candidate;
    48	    } catch {
    49	      continue;
    50	    }
    51	  }
    52	  return null;
    53	}
    54	
    55	async function readMirrorJson(mirrorId) {
    56	  const mirrorPath = await findMirrorPath(mirrorId);
    57	  if (!mirrorPath) {
    58	    const error = new Error(`Mirror not found for ${mirrorId}`);
    59	    error.code = "MIRROR_MISSING";
    60	    throw error;
    61	  }
    62	  const raw = await fs.readFile(mirrorPath, "utf8");
    63	  try {
    64	    return JSON.parse(raw);
    65	  } catch (error) {
    66	    const parseError = new Error(`Mirror JSON parse failed for ${mirrorId}`);
    67	    parseError.code = "MIRROR_PARSE_ERROR";
    68	    parseError.cause = error;
    69	    throw parseError;
    70	  }
    71	}
    72	
    73	function extractItems(payload) {
    74	  // mirror shapes vary across generators; accept multiple common paths
    75	  if (Array.isArray(payload?.items)) return payload.items;
    76	
    77	  // "wrapped mirror" shapes
    78	  if (Array.isArray(payload?.payload?.items)) return payload.payload.items;
    79	
    80	  // common nested shapes
    81	  if (Array.isArray(payload?.payload?.data?.items)) return payload.payload.data.items;
    82	  if (Array.isArray(payload?.payload?.data?.data?.items)) return payload.payload.data.data.items;
    83	
    84	  // IMPORTANT: some mirrors include an extra 'data' layer (payload.data.data.items)
    85	  if (Array.isArray(payload?.payload?.data?.data?.data?.items)) return payload.payload.data.data.data.items;
    86	
    87	  return [];
    88	}
    89	
    90	function extractSectors(payload) {
    91	  if (Array.isArray(payload?.sectors)) return payload.sectors;
    92	  if (Array.isArray(payload?.payload?.data?.data?.sectors)) return payload.payload.data.data.sectors;
    93	  if (Array.isArray(payload?.payload?.data?.sectors)) return payload.payload.data.sectors;
    94	  if (Array.isArray(payload?.items) && payload.items.length && payload.items[0]?.sector) return payload.items;
    95	  return [];
    96	}
    97	
    98	function mapItemsOnly(raw) {
    99	  const items = extractItems(raw);
   100	  return { data: { items }, itemsCount: items.length };
   101	}
   102	
   103	function mapSectors(raw) {
   104	  const sectors = extractSectors(raw);
   105	  const items = extractItems(raw);
   106	  const itemsCount = sectors.length || items.length;
   107	  return { data: { items, sectors }, itemsCount };
   108	}
   109	
   110	function mapSignals(raw) {
   111	  const items = extractItems(raw);
   112	  return { data: { items, signals: items }, itemsCount: items.length };
   113	}
   114	
   115	function pickUpdatedAt(raw) {
   116	  const candidates = [
   117	    raw?.updatedAt,
   118	    raw?.asOf,
   119	    raw?.ts,
   120	    raw?.meta?.updatedAt,
   121	    raw?.payload?.data?.updatedAt,
   122	    raw?.payload?.data?.data?.updatedAt
   123	  ];
   124	  return candidates.find((value) => value && typeof value === "string") || null;
   125	}
   126	
   127	function computeStalenessSec(updatedAt, generatedAt) {
   128	  if (!updatedAt) return 0;
   129	  const updatedMs = Date.parse(updatedAt);
   130	  const generatedMs = Date.parse(generatedAt);
   131	  if (!Number.isFinite(updatedMs) || !Number.isFinite(generatedMs)) return 0;
   132	  return Math.max(0, Math.floor((generatedMs - updatedMs) / 1000));
   133	}
   134	
   135	async function atomicWriteJson(targetPath, payload) {
   136	  await fs.mkdir(TMP_DIR, { recursive: true });
   137	  const tmpPath = path.join(TMP_DIR, `${path.basename(targetPath)}.tmp`);
   138	  let serialized = JSON.stringify(payload, null, 2);
   139	  payload.meta.bytes = Buffer.byteLength(serialized);
   140	  serialized = JSON.stringify(payload, null, 2);
   141	  await fs.writeFile(tmpPath, serialized);
   142	  await fs.rename(tmpPath, targetPath);
   143	  return Buffer.byteLength(serialized);
   144	}
   145	
   146	async function generateSnapshot(entry) {
   147	  const started = Date.now();
   148	  const generatedAt = new Date().toISOString();
   149	  let mirrorPayload = null;
   150	  let metaStatus = "ERROR";
   151	  let metaReason = "MIRROR_ERROR";
   152	  let data = { items: [] };
   153	  let ok = false;
   154	  let itemsCount = 0;
   155	
   156	  try {
   157	    mirrorPayload = await readMirrorJson(entry.mirrorId);
   158	    if (!mirrorPayload || (typeof mirrorPayload !== "object")) {
   159	      const schemaErr = new Error(`Mirror schema invalid for ${entry.mirrorId}`);
   160	      schemaErr.code = "MIRROR_SCHEMA_EMPTY";
   161	      throw schemaErr;
   162	    }
   163	
   164	    const mapped = entry.mapData(mirrorPayload);
   165	    data = mapped.data;
   166	    itemsCount = mapped.itemsCount;
   167	    if (itemsCount > 0) {
   168	      metaStatus = "LIVE";
   169	      metaReason = "OK";
   170	      ok = true;
   171	    } else {
   172	      metaStatus = "NO_DATA";
   173	      metaReason = "EMPTY_ITEMS";
   174	      ok = false;
   175	    }
   176	  } catch (error) {
   177	    metaStatus = "ERROR";
   178	    metaReason = error?.code || "MIRROR_ERROR";
   179	    ok = false;
   180	  }
   181	
   182	  const updatedAt = pickUpdatedAt(mirrorPayload);
   183	  const durationMs = Date.now() - started;
   184	  const stalenessSec = computeStalenessSec(updatedAt, generatedAt);
   185	
   186	  const envelope = {
   187	    ok,
   188	    feature: entry.id,
   189	    meta: {
   190	      status: metaStatus,
   191	      reason: metaReason,
   192	      generatedAt,
   193	      stalenessSec,
   194	      durationMs,
   195	      bytes: 0
   196	    },
   197	    data
   198	  };
   199	
   200	  const targetPath = path.join(SNAPSHOT_DIR, `${entry.id}.json`);

## FILE: scripts/healthcheck.sh
     1	#!/usr/bin/env bash
     2	set -euo pipefail
     3	
     4	BASE_URL="${1:-${BASE_URL:-http://localhost:8788}}"
     5	
     6	ENDPOINTS=(
     7	  "/api/market-health"
     8	  "/api/price-snapshot"
     9	  "/api/top-movers"
    10	  "/api/earnings-calendar"
    11	  "/api/news"
    12	  "/api/tech-signals"
    13	  "/api/macro-rates"
    14	  "/api/snapshots/market_health"
    15	  "/api/snapshots/macro_rates"
    16	)
    17	
    18	ok_count=0
    19	partial_count=0
    20	fail_count=0
    21	
    22	echo "Running healthcheck against: ${BASE_URL}"
    23	
    24	for endpoint in "${ENDPOINTS[@]}"; do
    25	  url="${BASE_URL}${endpoint}"
    26	  tmp_body="$(mktemp)"
    27	  tmp_headers="$(mktemp)"
    28	
    29	  http_code="$(curl -sS -m 10 -D "${tmp_headers}" -o "${tmp_body}" -w "%{http_code}" "${url}" || true)"
    30	  content_type="$(grep -i '^content-type:' "${tmp_headers}" | head -n1 | cut -d: -f2- | tr -d '\r' | xargs || true)"
    31	
    32	  status="FAIL"
    33	  message="HTTP ${http_code}"
    34	  exit_code=1
    35	
    36	  if [[ "${http_code}" == "200" ]]; then
    37	    set +e
    38	    result="$(python - "${tmp_body}" <<'PY'
    39	import json, sys
    40	path = sys.argv[1]
    41	with open(path, "r", encoding="utf-8") as f:
    42	    data = json.load(f)
    43	ok = data.get("ok")
    44	print("OK" if ok is True else "PARTIAL" if ok is False else "FAIL")
    45	PY
    46	)"
    47	    py_status=$?
    48	    set -e
    49	
    50	    if [[ ${py_status} -eq 0 ]]; then
    51	      if [[ "${result}" == "OK" ]]; then
    52	        status="OK"
    53	        message="ok"
    54	        exit_code=0
    55	      elif [[ "${result}" == "PARTIAL" ]]; then
    56	        status="PARTIAL"
    57	        message="ok:false"
    58	        exit_code=2
    59	      else
    60	        status="FAIL"
    61	        message="invalid schema"
    62	        exit_code=1
    63	      fi
    64	    else
    65	      status="FAIL"
    66	      message="invalid json"
    67	      exit_code=1
    68	    fi
    69	  fi
    70	
    71	  rm -f "${tmp_body}" "${tmp_headers}"
    72	
    73	  if [[ "${status}" == "OK" ]]; then
    74	    ok_count=$((ok_count + 1))
    75	  elif [[ "${status}" == "PARTIAL" ]]; then
    76	    partial_count=$((partial_count + 1))
    77	  else
    78	    fail_count=$((fail_count + 1))
    79	  fi
    80	
    81	  printf "%-32s %-8s %s (content-type: %s)\n" "${endpoint}" "${status}" "${message}" "${content_type:-unknown}"
    82	done
    83	
    84	echo "Summary: OK=${ok_count} PARTIAL=${partial_count} FAIL=${fail_count}"
    85	
    86	if [[ ${fail_count} -gt 0 ]]; then
    87	  exit 1
    88	fi
    89	if [[ ${partial_count} -gt 0 ]]; then
    90	  exit 2
    91	fi
    92	exit 0

## FILE: scripts/lib/atomic-publish.js
     1	/**
     2	 * Atomic Publishing Logic
     3	 * 
     4	 * Ensures data consistency by:
     5	 * 1. Writing to temp directory first
     6	 * 2. Validating all files
     7	 * 3. Atomically promoting temp -> public
     8	 * 
     9	 * If any step fails, the old data remains intact.
    10	 */
    11	
    12	import { readFile, writeFile, mkdir, rename, rm, readdir } from 'node:fs/promises';
    13	import { join, dirname } from 'node:path';
    14	import { existsSync } from 'node:fs';
    15	
    16	/**
    17	 * Write snapshot to temp directory
    18	 * 
    19	 * @param {string} moduleName - Module name
    20	 * @param {object} snapshot - Snapshot data
    21	 * @param {string} tmpDir - Temp directory path
    22	 */
    23	export async function writeSnapshotToTemp(moduleName, snapshot, tmpDir) {
    24	  const moduleTmpDir = join(tmpDir, 'snapshots', moduleName);
    25	  await mkdir(moduleTmpDir, { recursive: true });
    26	  
    27	  const snapshotPath = join(moduleTmpDir, 'latest.json');
    28	  await writeFile(snapshotPath, JSON.stringify(snapshot, null, 2), 'utf-8');
    29	  
    30	  return snapshotPath;
    31	}
    32	
    33	/**
    34	 * Write module state to temp directory
    35	 * 
    36	 * @param {string} moduleName - Module name
    37	 * @param {object} state - Module state data
    38	 * @param {string} tmpDir - Temp directory path
    39	 */
    40	export async function writeModuleStateToTemp(moduleName, state, tmpDir) {
    41	  const stateTmpDir = join(tmpDir, 'state', 'modules');
    42	  await mkdir(stateTmpDir, { recursive: true });
    43	  
    44	  const statePath = join(stateTmpDir, `${moduleName}.json`);
    45	  await writeFile(statePath, JSON.stringify(state, null, 2), 'utf-8');
    46	  
    47	  return statePath;
    48	}
    49	
    50	/**
    51	 * Write manifest to temp directory
    52	 * 
    53	 * @param {object} manifest - Manifest data
    54	 * @param {string} tmpDir - Temp directory path
    55	 */
    56	export async function writeManifestToTemp(manifest, tmpDir) {
    57	  await mkdir(tmpDir, { recursive: true });
    58	  
    59	  const manifestPath = join(tmpDir, 'manifest.json');
    60	  await writeFile(manifestPath, JSON.stringify(manifest, null, 2), 'utf-8');
    61	  
    62	  return manifestPath;
    63	}
    64	
    65	/**
    66	 * Write provider-state to temp directory
    67	 * 
    68	 * @param {object} providerState - Provider state data
    69	 * @param {string} tmpDir - Temp directory path
    70	 */
    71	export async function writeProviderStateToTemp(providerState, tmpDir) {
    72	  await mkdir(tmpDir, { recursive: true });
    73	  
    74	  const statePath = join(tmpDir, 'provider-state.json');
    75	  await writeFile(statePath, JSON.stringify(providerState, null, 2), 'utf-8');
    76	  
    77	  return statePath;
    78	}
    79	
    80	/**
    81	 * Validate all files in temp directory
    82	 * 
    83	 * @param {string} tmpDir - Temp directory path
    84	 * @param {Map} expectedModules - Expected modules (name -> artifact)
    85	 * @returns {{ valid: boolean, errors: string[] }}
    86	 */
    87	export async function validateTempFiles(tmpDir, expectedModules) {
    88	  const errors = [];
    89	  
    90	  try {
    91	    // Check manifest exists and is valid JSON
    92	    const manifestPath = join(tmpDir, 'manifest.json');
    93	    if (!existsSync(manifestPath)) {
    94	      errors.push('manifest.json missing');
    95	    } else {
    96	      try {
    97	        const content = await readFile(manifestPath, 'utf-8');
    98	        JSON.parse(content); // Validate JSON
    99	      } catch (err) {
   100	        errors.push(`manifest.json invalid: ${err.message}`);
   101	      }
   102	    }
   103	    
   104	    // Check provider-state exists and is valid JSON
   105	    const statePath = join(tmpDir, 'provider-state.json');
   106	    if (!existsSync(statePath)) {
   107	      errors.push('provider-state.json missing');
   108	    } else {
   109	      try {
   110	        const content = await readFile(statePath, 'utf-8');
   111	        JSON.parse(content); // Validate JSON
   112	      } catch (err) {
   113	        errors.push(`provider-state.json invalid: ${err.message}`);
   114	      }
   115	    }
   116	    
   117	    // Check all module snapshots exist
   118	    for (const [moduleName, artifact] of expectedModules.entries()) {
   119	      const snapshotPath = join(tmpDir, 'snapshots', moduleName, 'latest.json');
   120	      if (!existsSync(snapshotPath)) {
   121	        errors.push(`${moduleName}: snapshot missing`);
   122	      } else {
   123	        try {
   124	          const content = await readFile(snapshotPath, 'utf-8');
   125	          const snapshot = JSON.parse(content);
   126	          
   127	          // Verify digest matches
   128	          if (snapshot.metadata?.digest !== artifact.snapshot.metadata?.digest) {
   129	            errors.push(`${moduleName}: digest mismatch`);
   130	          }
   131	        } catch (err) {
   132	          errors.push(`${moduleName}: snapshot invalid - ${err.message}`);
   133	        }
   134	      }
   135	      
   136	      // Check module state exists
   137	      const moduleStatePath = join(tmpDir, 'state', 'modules', `${moduleName}.json`);
   138	      if (!existsSync(moduleStatePath)) {
   139	        errors.push(`${moduleName}: module-state missing`);
   140	      }
   141	    }
   142	    
   143	  } catch (err) {
   144	    errors.push(`Validation error: ${err.message}`);
   145	  }
   146	  
   147	  return {
   148	    valid: errors.length === 0,
   149	    errors
   150	  };
   151	}
   152	
   153	/**
   154	 * Atomically promote temp files to public directory
   155	 * 
   156	 * This uses atomic rename operations where possible.
   157	 * For directories, it does a swap to ensure atomicity.
   158	 * 
   159	 * @param {string} tmpDir - Temp directory path
   160	 * @param {string} publicDir - Public directory path
   161	 */
   162	export async function atomicPromote(tmpDir, publicDir) {
   163	  const operations = [];
   164	  
   165	  try {
   166	    // Ensure public directories exist
   167	    await mkdir(join(publicDir, 'snapshots'), { recursive: true });
   168	    await mkdir(join(publicDir, 'state', 'modules'), { recursive: true });
   169	    
   170	    // 1. Promote manifest.json
   171	    const manifestTmp = join(tmpDir, 'manifest.json');
   172	    const manifestPublic = join(publicDir, 'manifest.json');
   173	    if (existsSync(manifestTmp)) {
   174	      await rename(manifestTmp, manifestPublic);
   175	      operations.push('manifest.json');
   176	    }
   177	    
   178	    // 2. Promote provider-state.json
   179	    const stateTmp = join(tmpDir, 'provider-state.json');
   180	    const statePublic = join(publicDir, 'provider-state.json');
   181	    if (existsSync(stateTmp)) {
   182	      await rename(stateTmp, statePublic);
   183	      operations.push('provider-state.json');
   184	    }
   185	    
   186	    // 3. Promote module snapshots
   187	    const snapshotsTmpDir = join(tmpDir, 'snapshots');
   188	    if (existsSync(snapshotsTmpDir)) {
   189	      const modules = await readdir(snapshotsTmpDir, { withFileTypes: true });
   190	      
   191	      for (const entry of modules) {
   192	        if (!entry.isDirectory()) continue;
   193	        
   194	        const moduleName = entry.name;
   195	        const moduleTmpDir = join(snapshotsTmpDir, moduleName);
   196	        const modulePublicDir = join(publicDir, 'snapshots', moduleName);
   197	        
   198	        // Ensure public module dir exists
   199	        await mkdir(modulePublicDir, { recursive: true });
   200	        

## FILE: scripts/lib/build-id.js
     1	/**
     2	 * Build ID Generator
     3	 * 
     4	 * Generates time-based, deterministic Build IDs for the Mission Control v3.0 system.
     5	 * Format: YYYYMMDDTHHMMSSZ_<short_sha>
     6	 * 
     7	 * Purpose:
     8	 * - Unique identifier for each build/publish
     9	 * - Sortable by time (lexicographic)
    10	 * - Traceable back to Git commit
    11	 * - Debug-friendly (human-readable timestamp)
    12	 * 
    13	 * Usage:
    14	 *   import { generateBuildId, parseBuildId } from './build-id.js';
    15	 *   const buildId = generateBuildId();
    16	 *   const info = parseBuildId(buildId);
    17	 */
    18	
    19	import { execSync } from 'node:child_process';
    20	
    21	/**
    22	 * Generate a time-based Build ID
    23	 * 
    24	 * @param {Date} [timestamp] - Optional timestamp (defaults to now)
    25	 * @param {string} [gitSha] - Optional Git SHA (auto-detected if not provided)
    26	 * @returns {string} Build ID in format: YYYYMMDDTHHMMSSZ_abcdef
    27	 */
    28	export function generateBuildId(timestamp = new Date(), gitSha = null) {
    29	  // Format timestamp as YYYYMMDDTHHMMSSZ
    30	  const year = timestamp.getUTCFullYear();
    31	  const month = String(timestamp.getUTCMonth() + 1).padStart(2, '0');
    32	  const day = String(timestamp.getUTCDate()).padStart(2, '0');
    33	  const hour = String(timestamp.getUTCHours()).padStart(2, '0');
    34	  const minute = String(timestamp.getUTCMinutes()).padStart(2, '0');
    35	  const second = String(timestamp.getUTCSeconds()).padStart(2, '0');
    36	  
    37	  const timeStr = `${year}${month}${day}T${hour}${minute}${second}Z`;
    38	  
    39	  // Get Git SHA (short)
    40	  let shortSha = gitSha;
    41	  if (!shortSha) {
    42	    try {
    43	      shortSha = execSync('git rev-parse --short=7 HEAD', { 
    44	        encoding: 'utf-8',
    45	        stdio: ['pipe', 'pipe', 'ignore'] // Suppress stderr
    46	      }).trim();
    47	    } catch (err) {
    48	      // Fallback if not in Git repo or Git not available
    49	      shortSha = 'unknown';
    50	    }
    51	  }
    52	  
    53	  return `${timeStr}_${shortSha}`;
    54	}
    55	
    56	/**
    57	 * Parse a Build ID back into its components
    58	 * 
    59	 * @param {string} buildId - Build ID to parse
    60	 * @returns {{ timestamp: Date, gitSha: string, isValid: boolean }}
    61	 */
    62	export function parseBuildId(buildId) {
    63	  const parts = buildId.split('_');
    64	  if (parts.length !== 2) {
    65	    return { timestamp: null, gitSha: null, isValid: false };
    66	  }
    67	  
    68	  const [timeStr, gitSha] = parts;
    69	  
    70	  // Parse YYYYMMDDTHHMMSSZ
    71	  const match = timeStr.match(/^(\d{4})(\d{2})(\d{2})T(\d{2})(\d{2})(\d{2})Z$/);
    72	  if (!match) {
    73	    return { timestamp: null, gitSha, isValid: false };
    74	  }
    75	  
    76	  const [, year, month, day, hour, minute, second] = match;
    77	  const timestamp = new Date(Date.UTC(
    78	    parseInt(year, 10),
    79	    parseInt(month, 10) - 1,
    80	    parseInt(day, 10),
    81	    parseInt(hour, 10),
    82	    parseInt(minute, 10),
    83	    parseInt(second, 10)
    84	  ));
    85	  
    86	  return {
    87	    timestamp,
    88	    gitSha,
    89	    isValid: !isNaN(timestamp.getTime())
    90	  };
    91	}
    92	
    93	/**
    94	 * Get current Build ID from environment or generate new
    95	 * 
    96	 * Priority:
    97	 * 1. BUILD_ID env var (set by CI)
    98	 * 2. Generate from current time + Git SHA
    99	 * 
   100	 * @returns {string} Build ID
   101	 */
   102	export function getCurrentBuildId() {
   103	  if (process.env.BUILD_ID) {
   104	    return process.env.BUILD_ID;
   105	  }
   106	  
   107	  return generateBuildId();
   108	}
   109	
   110	/**
   111	 * Validate that a Build ID is well-formed
   112	 * 
   113	 * @param {string} buildId - Build ID to validate
   114	 * @returns {boolean}
   115	 */
   116	export function isValidBuildId(buildId) {
   117	  if (typeof buildId !== 'string') return false;
   118	  const parsed = parseBuildId(buildId);
   119	  return parsed.isValid;
   120	}
   121	
   122	/**
   123	 * Compare two Build IDs (for sorting)
   124	 * 
   125	 * @param {string} a - First Build ID
   126	 * @param {string} b - Second Build ID
   127	 * @returns {number} -1 if a < b, 0 if equal, 1 if a > b
   128	 */
   129	export function compareBuildIds(a, b) {
   130	  // Lexicographic sort (time-based IDs are sortable as strings)
   131	  if (a < b) return -1;
   132	  if (a > b) return 1;
   133	  return 0;
   134	}
   135	
   136	/**
   137	 * Get age in minutes for a Build ID
   138	 * 
   139	 * @param {string} buildId - Build ID
   140	 * @param {Date} [now] - Current time (defaults to now)
   141	 * @returns {number|null} Age in minutes, or null if invalid
   142	 */
   143	export function getBuildIdAge(buildId, now = new Date()) {
   144	  const parsed = parseBuildId(buildId);
   145	  if (!parsed.isValid) return null;
   146	  
   147	  const ageMs = now.getTime() - parsed.timestamp.getTime();
   148	  return Math.floor(ageMs / (60 * 1000));
   149	}

## FILE: scripts/lib/drop-threshold.js
     1	/**
     2	 * Drop Threshold Validation
     3	 *
     4	 * Prevents silent data loss by enforcing hard drop thresholds.
     5	 * Blocks publish when thresholds are exceeded.
     6	 *
     7	 * THRESHOLDS (constants):
     8	 * - max_drop_abs = 5 (absolute max dropped records)
     9	 * - max_drop_ratio = 0.001 (0.1% max drop ratio)
    10	 *
    11	 * RULE:
    12	 * If dropped_records > min(max_drop_abs, raw_count * max_drop_ratio):
    13	 *   - validation.passed = false
    14	 *   - module publish MUST be blocked
    15	 */
    16	
    17	export const MAX_DROP_ABS = 5;
    18	export const MAX_DROP_RATIO = 0.001;
    19	
    20	/**
    21	 * Validate drop threshold
    22	 * @param {number} rawCount - Total records before filtering
    23	 * @param {number} droppedRecords - Number of records dropped during validation
    24	 * @returns {object} { passed: boolean, drop_ratio: number, threshold_abs: number, threshold_ratio: number, reason: string|null }
    25	 */
    26	export function validateDropThreshold(rawCount, droppedRecords) {
    27	  if (typeof rawCount !== 'number' || rawCount < 0) {
    28	    throw new Error(`Invalid rawCount: ${rawCount} (must be non-negative number)`);
    29	  }
    30	  
    31	  if (typeof droppedRecords !== 'number' || droppedRecords < 0) {
    32	    throw new Error(`Invalid droppedRecords: ${droppedRecords} (must be non-negative number)`);
    33	  }
    34	  
    35	  // Calculate drop ratio
    36	  const dropRatio = rawCount > 0 ? droppedRecords / rawCount : 0;
    37	  
    38	  // Calculate dynamic threshold based on raw count
    39	  const thresholdAbs = MAX_DROP_ABS;
    40	  const thresholdRatio = rawCount * MAX_DROP_RATIO;
    41	  const effectiveThreshold = Math.min(thresholdAbs, thresholdRatio);
    42	  
    43	  // Check if threshold exceeded
    44	  const passed = droppedRecords <= effectiveThreshold;
    45	  
    46	  let reason = null;
    47	  if (!passed) {
    48	    reason = `DROP_THRESHOLD_EXCEEDED: dropped ${droppedRecords} records (threshold: ${effectiveThreshold.toFixed(2)}, raw_count: ${rawCount}, drop_ratio: ${(dropRatio * 100).toFixed(3)}%)`;
    49	  }
    50	  
    51	  return {
    52	    passed,
    53	    drop_ratio: dropRatio,
    54	    threshold_abs: thresholdAbs,
    55	    threshold_ratio: thresholdRatio,
    56	    effective_threshold: effectiveThreshold,
    57	    reason
    58	  };
    59	}
    60	
    61	/**
    62	 * Compute validation metadata with drop threshold enforcement
    63	 * @param {number} rawCount - Total records before filtering
    64	 * @param {number} validCount - Records after filtering
    65	 * @param {number|boolean} droppedRecordsOrOther - Records dropped OR otherValidationPassed (optional)
    66	 * @param {boolean} otherValidationPassed - Whether other validation checks passed (optional)
    67	 * @returns {object} Validation metadata for envelope
    68	 */
    69	export function computeValidationMetadata(rawCount, validCount, droppedRecordsOrOther, otherValidationPassed) {
    70	  let droppedRecords;
    71	  let otherPassed;
    72	  
    73	  // Disambiguate arguments
    74	  if (typeof droppedRecordsOrOther === 'boolean' && otherValidationPassed === undefined) {
    75	    // Called as (rawCount, validCount, otherValidationPassed)
    76	    otherPassed = droppedRecordsOrOther;
    77	    droppedRecords = Math.max(0, rawCount - validCount);
    78	  } else {
    79	    // Called as (rawCount, validCount, droppedRecords, otherValidationPassed) or (rawCount, validCount)
    80	    droppedRecords = (typeof droppedRecordsOrOther === 'number')
    81	      ? droppedRecordsOrOther
    82	      : Math.max(0, rawCount - validCount);
    83	    otherPassed = (typeof otherValidationPassed === 'boolean')
    84	      ? otherValidationPassed
    85	      : true;
    86	  }
    87	  
    88	  const dropCheck = validateDropThreshold(rawCount, droppedRecords);
    89	  
    90	  const limit = dropCheck.effective_threshold;
    91	  const violated = !dropCheck.passed;
    92	  const dropCheckPassed = !violated;
    93	
    94	  return {
    95	    dropped_records: droppedRecords,
    96	    drop_ratio: dropCheck.drop_ratio,
    97	    drop_threshold: {
    98	      max_drop_abs: MAX_DROP_ABS,
    99	      max_drop_ratio: MAX_DROP_RATIO,
   100	      limit,
   101	      violated
   102	    },
   103	    drop_check_passed: dropCheckPassed,
   104	    checks: {
   105	      drop_threshold: {
   106	        passed: dropCheckPassed,
   107	        effective_threshold: limit,
   108	        reason: dropCheck.reason
   109	      },
   110	      provided_validation: {
   111	        passed: otherPassed,
   112	        source: "caller"
   113	      }
   114	    }
   115	  };
   116	}
   117	
   118	export default {
   119	  validateDropThreshold,
   120	  computeValidationMetadata,
   121	  MAX_DROP_ABS,
   122	  MAX_DROP_RATIO
   123	};

## FILE: scripts/lib/envelope-builder.mjs
     1	import fs from "node:fs";
     2	import path from "node:path";
     3	import crypto from "node:crypto";
     4	import Ajv from "ajv";
     5	import addFormats from "ajv-formats";
     6	
     7	function isoNow() { return new Date().toISOString(); }
     8	
     9	function sha256Hex(obj) {
    10	  const s = JSON.stringify(obj);
    11	  return crypto.createHash("sha256").update(s).digest("hex");
    12	}
    13	
    14	function pickType(node) {
    15	  if (!node) return null;
    16	  if (typeof node.type === "string") return node.type;
    17	  if (Array.isArray(node.type) && node.type.length) {
    18	    // Prefer non-null types if present
    19	    const nonNull = node.type.find(t => t !== "null");
    20	    return nonNull || node.type[0];
    21	  }
    22	  if (node.oneOf && node.oneOf.length) return pickType(node.oneOf[0]);
    23	  if (node.anyOf && node.anyOf.length) return pickType(node.anyOf[0]);
    24	  if (node.allOf && node.allOf.length) return pickType(node.allOf[0]);
    25	  return null;
    26	}
    27	
    28	function defaultFor(node) {
    29	  if (!node) return null;
    30	  if (node.default !== undefined) return node.default;
    31	  if (node.const !== undefined) return node.const;
    32	  if (Array.isArray(node.enum) && node.enum.length) return node.enum[0];
    33	
    34	  const t = pickType(node);
    35	  if (t === "string") return "";
    36	  if (t === "number") return 0;
    37	  if (t === "integer") return 0;
    38	  if (t === "boolean") return false;
    39	  if (t === "array") return [];
    40	  if (t === "object") return {};
    41	  return null;
    42	}
    43	
    44	// Build ONLY allowed keys, and ensure ALL required keys exist (schema-driven).
    45	function buildFromSchema(node, provided) {
    46	  const t = pickType(node);
    47	  if (t === "object") {
    48	    const props = node.properties || {};
    49	    const required = Array.isArray(node.required) ? node.required : [];
    50	    const additional = node.additionalProperties;
    51	
    52	    const out = {};
    53	
    54	    // Only allow schema properties when additionalProperties is false;
    55	    // otherwise still prefer properties-based output for determinism.
    56	    const allowedKeys = new Set(Object.keys(props));
    57	
    58	    // Fill required keys first
    59	    for (const k of required) {
    60	      const childSchema = props[k];
    61	      const pv = (provided && typeof provided === "object") ? provided[k] : undefined;
    62	      if (childSchema) {
    63	        out[k] = buildFromSchema(childSchema, pv);
    64	        // If child is still "empty" and we have a usable provided scalar, preserve it
    65	        const ct = pickType(childSchema);
    66	        if (pv !== undefined && pv !== null && ct && ct !== "object" && ct !== "array") {
    67	          out[k] = pv;
    68	        }
    69	      } else {
    70	        out[k] = (pv !== undefined) ? pv : null;
    71	      }
    72	    }
    73	
    74	    // Add optional keys if provided and allowed
    75	    if (provided && typeof provided === "object") {
    76	      for (const [k, v] of Object.entries(provided)) {
    77	        if (!allowedKeys.has(k)) continue;
    78	        if (out[k] !== undefined) continue;
    79	        const childSchema = props[k];
    80	        out[k] = childSchema ? buildFromSchema(childSchema, v) : v;
    81	      }
    82	    }
    83	
    84	    // If schema has additionalProperties object schema, we could allow extras.
    85	    // But CI failures indicate strict "additionalProperties:false" is used.
    86	    // So we intentionally do NOT keep unknown keys.
    87	    if (additional !== undefined && additional !== false && provided && typeof provided === "object") {
    88	      // still do nothing: keep strict determinism
    89	    }
    90	
    91	    return out;
    92	  }
    93	
    94	  if (t === "array") {
    95	    if (Array.isArray(provided)) return provided;
    96	    const dv = defaultFor(node);
    97	    return Array.isArray(dv) ? dv : [];
    98	  }
    99	
   100	  // scalar
   101	  if (provided !== undefined && provided !== null) return provided;
   102	  return defaultFor(node);
   103	}
   104	
   105	export function loadSnapshotEnvelopeSchema(schemaPath = "schemas/snapshot-envelope.schema.json") {
   106	  const p = path.resolve(schemaPath);
   107	  return JSON.parse(fs.readFileSync(p, "utf-8"));
   108	}
   109	
   110	export function createValidator(schema) {
   111	  const ajv = new Ajv({ allErrors: true, strict: false });
   112	  addFormats(ajv);
   113	  const validate = ajv.compile(schema);
   114	  return { ajv, validate };
   115	}
   116	
   117	export function buildEnvelope(schema, input = {}) {
   118	  // Provide meaningful defaults for common fields via "provided" values.
   119	  // The schema-driven builder will still enforce required structure & allowed keys.
   120	  const now = isoNow();
   121	  const data = (input.data !== undefined) ? input.data : null;
   122	  const digest = input.digest || `sha256:${sha256Hex(data)}`;
   123	
   124	  const provided = {
   125	    schema_version: input.schema_version || "3.0",
   126	    metadata: {
   127	      module: input.module || "health",
   128	      tier: input.tier || "critical",
   129	      domain: input.domain || "system",
   130	      source: input.source || "generator",
   131	      fetched_at: input.fetched_at || now,
   132	      published_at: input.published_at || now,
   133	      digest,
   134	      record_count: (typeof input.record_count === "number")
   135	        ? input.record_count
   136	        : (Array.isArray(data) ? data.length : (data && typeof data === "object" ? Object.keys(data).length : 0)),
   137	      expected_count: (typeof input.expected_count === "number")
   138	        ? input.expected_count
   139	        : (Array.isArray(data) ? data.length : (data && typeof data === "object" ? Object.keys(data).length : 0)),
   140	      validation: {
   141	        passed: (input.validation && typeof input.validation.passed === "boolean") ? input.validation.passed : true,
   142	        ...(input.validation || {})
   143	      },
   144	      freshness: { ...(input.freshness || {}) },
   145	      upstream: { ...(input.upstream || {}) }
   146	    },
   147	    data: data,
   148	    error: (input.error !== undefined) ? input.error : null
   149	  };
   150	
   151	  // Build strict object from schema (required + allowed only)
   152	  const strict = buildFromSchema(schema, provided);
   153	
   154	  // Deterministic key order at top-level
   155	  const ordered = {
   156	    schema_version: strict.schema_version,
   157	    metadata: strict.metadata,
   158	    data: strict.data,
   159	    error: strict.error
   160	  };
   161	
   162	  return ordered;
   163	}

## FILE: scripts/lib/envelope.js
     1	/**
     2	 * Envelope Library - v3.0 Snapshot Envelope
     3	 * 
     4	 * Provides:
     5	 * - Envelope builder (wrap data with metadata)
     6	 * - Envelope validator (schema validation)
     7	 * - Contract checker (UI contract, plausibility)
     8	 * 
     9	 * Usage:
    10	 *   const envelope = buildEnvelope(data, metadata);
    11	 *   const valid = validateEnvelope(envelope, registry);
    12	 */
    13	
    14	import { computeSnapshotDigest } from './digest.js';
    15	
    16	/**
    17	 * Build v3.0 snapshot envelope
    18	 * Supports two call styles for backward compatibility:
    19	 * 1. buildEnvelope(data, metadata) - New style (two params)
    20	 * 2. buildEnvelope({ module, data, ... }) - Legacy style (single object)
    21	 * 
    22	 * @param {array|object} dataOrOptions - Data array OR options object
    23	 * @param {object} metadata - Metadata fields (only for new style)
    24	 * @returns {object} Complete envelope
    25	 */
    26	export function buildEnvelope(dataOrOptions, metadata) {
    27	  const now = new Date().toISOString();
    28	  
    29	  // Detect call style
    30	  let data, meta;
    31	  if (metadata === undefined && typeof dataOrOptions === 'object' && !Array.isArray(dataOrOptions) && dataOrOptions.data) {
    32	    // Legacy style: buildEnvelope({ module, data, ... })
    33	    meta = dataOrOptions;
    34	    data = meta.data;
    35	  } else {
    36	    // New style: buildEnvelope(data, metadata)
    37	    data = dataOrOptions;
    38	    meta = metadata || {};
    39	  }
    40	  
    41	  const isObjectMap = data && typeof data === "object" && !Array.isArray(data);
    42	  const envelopeData = isObjectMap ? data : Array.isArray(data) ? data : [data];
    43	  const envelope = {
    44	    schema_version: "3.0",
    45	    metadata: {
    46	      module: meta.module || "unknown",
    47	      tier: meta.tier || "standard",
    48	      domain: meta.domain || "unknown",
    49	      source: meta.source || "unknown",
    50	      fetched_at: (meta.fetchedAt instanceof Date ? meta.fetchedAt.toISOString() : meta.fetched_at) || now,
    51	      published_at: (meta.publishedAt instanceof Date ? meta.publishedAt.toISOString() : meta.published_at) || now,
    52	      digest: null, // Will be computed below
    53	      record_count: isObjectMap ? Object.keys(data).length : Array.isArray(data) ? data.length : 0,
    54	      expected_count: meta.expected_count || null,
    55	      validation: {
    56	        passed: meta.validation?.passed ?? true,
    57	        dropped_records: meta.validation?.dropped_records ?? 0,
    58	        drop_ratio: meta.validation?.drop_ratio ?? 0,
    59	        drop_check_passed: meta.validation?.drop_check_passed ?? true,
    60	        drop_threshold: meta.validation?.drop_threshold ?? null,
    61	        checks: meta.validation?.checks ?? [],
    62	        warnings: meta.validation?.warnings ?? []
    63	      },
    64	      freshness: {
    65	        expected_interval_minutes: meta.freshness?.expected_interval_minutes || 1440,
    66	        grace_minutes: meta.freshness?.grace_minutes || 180,
    67	        policy: meta.freshness?.policy || "always",
    68	        age_minutes: meta.freshness?.age_minutes || 0,
    69	        next_expected_at: meta.freshness?.next_expected_at || null
    70	      },
    71	      upstream: {
    72	        http_status: meta.upstream?.http_status ?? null,
    73	        latency_ms: meta.upstream?.latency_ms ?? 0,
    74	        rate_limit_remaining: meta.upstream?.rate_limit_remaining ?? null,
    75	        retry_count: meta.upstream?.retry_count ?? 0,
    76	        rate_limited: meta.upstream?.rate_limited ?? false
    77	      }
    78	    },
    79	    data: envelopeData,
    80	    error: meta.error || null
    81	  };
    82	  
    83	  // Compute digest
    84	  envelope.metadata.digest = computeSnapshotDigest(envelope);
    85	  
    86	  return envelope;
    87	}
    88	
    89	/**
    90	 * Validate envelope schema (v3.0)
    91	 * @param {object} envelope - Envelope to validate
    92	 * @returns {object} { valid: boolean, errors: string[] }
    93	 */
    94	export function validateEnvelopeSchema(envelope) {
    95	  const errors = [];
    96	  
    97	  // Required top-level fields
    98	  if (!envelope.schema_version) errors.push("Missing schema_version");
    99	  if (envelope.schema_version !== "3.0") errors.push(`Invalid schema_version: ${envelope.schema_version}, expected 3.0`);
   100	  if (!envelope.metadata) errors.push("Missing metadata");
   101	  if (!Array.isArray(envelope.data) && !(envelope.data && typeof envelope.data === "object")) {
   102	    errors.push("data must be an array or object map");
   103	  }
   104	  
   105	  // Required metadata fields
   106	  if (envelope.metadata) {
   107	    const m = envelope.metadata;
   108	    if (!m.module) errors.push("Missing metadata.module");
   109	    if (!m.tier) errors.push("Missing metadata.tier");
   110	    if (!m.source) errors.push("Missing metadata.source");
   111	    if (!m.fetched_at) errors.push("Missing metadata.fetched_at");
   112	    if (!m.digest) errors.push("Missing metadata.digest");
   113	    
   114	    // Validate timestamps
   115	    if (m.fetched_at) {
   116	      try {
   117	        const fetchedDate = new Date(m.fetched_at);
   118	        if (isNaN(fetchedDate.getTime())) {
   119	          errors.push("Invalid fetched_at timestamp");
   120	        }
   121	      } catch (e) {
   122	        errors.push(`Invalid fetched_at: ${e.message}`);
   123	      }
   124	    }
   125	    
   126	    // Validation object required
   127	    if (!m.validation) {
   128	      errors.push("Missing metadata.validation");
   129	    } else {
   130	      if (typeof m.validation.passed !== 'boolean') {
   131	        errors.push("validation.passed must be boolean");
   132	      }
   133	    }
   134	  }
   135	  
   136	  return {
   137	    valid: errors.length === 0,
   138	    errors
   139	  };
   140	}
   141	
   142	/**
   143	 * Evaluate JSONPath-like path on object
   144	 * @param {object} obj - Object to evaluate
   145	 * @param {string} path - Path like "$.data[0].close"
   146	 * @returns {array} Array of values found
   147	 */
   148	function evaluatePath(obj, path) {
   149	  // Simple JSONPath evaluator
   150	  // Handles: $.data[0].field, $.data[*].field
   151	  
   152	  const parts = path.replace(/^\$\./, '').split('.');
   153	  let current = [obj];
   154	  
   155	  for (const part of parts) {
   156	    const next = [];
   157	    
   158	    for (const item of current) {
   159	      if (!item) continue;
   160	      
   161	      // Handle array indexing: field[0] or field[*]
   162	      const match = part.match(/^(\w+)(?:\[(\d+|\*)\])?$/);
   163	      if (!match) continue;
   164	      
   165	      const [, key, index] = match;
   166	      const value = item[key];
   167	      
   168	      if (index === '*' && Array.isArray(value)) {
   169	        next.push(...value);
   170	      } else if (index !== undefined && Array.isArray(value)) {
   171	        const idx = parseInt(index, 10);
   172	        if (value[idx] !== undefined) {
   173	          next.push(value[idx]);
   174	        }
   175	      } else {
   176	        next.push(value);
   177	      }
   178	    }
   179	    
   180	    current = next;
   181	  }
   182	  
   183	  return current.filter(v => v !== undefined);
   184	}
   185	
   186	/**
   187	 * Check plausibility rules
   188	 * @param {object} envelope - Envelope to check
   189	 * @param {array} rules - Plausibility rules from registry
   190	 * @returns {object} { passed: boolean, errors: string[] }
   191	 */
   192	export function checkPlausibility(envelope, rules) {
   193	  if (!rules || rules.length === 0) {
   194	    return { passed: true, errors: [] };
   195	  }
   196	  
   197	  const errors = [];
   198	  
   199	  for (const rule of rules) {
   200	    const values = evaluatePath(envelope, rule.path);

## FILE: scripts/lib/error-classify.mjs
     1	const DEFAULT_HINTS = {
     2	  NO_API_KEY: 'Missing upstream API key',
     3	  UPSTREAM_TIMEOUT: 'Upstream request timed out',
     4	  UPSTREAM_4XX: 'Upstream rejected the request',
     5	  UPSTREAM_5XX: 'Upstream server error',
     6	  RATE_LIMIT: 'Upstream rate limit hit',
     7	  VALIDATION_FAILED: 'Record failed validation checks',
     8	  WRITE_FAILED: 'Failed to write artifact'
     9	};
    10	
    11	function toLower(value) {
    12	  return String(value || '').toLowerCase();
    13	}
    14	
    15	export function classifyError(err, context = {}) {
    16	  const stage = context.stage || null;
    17	  const httpStatus = Number.isFinite(Number(context.httpStatus))
    18	    ? Number(context.httpStatus)
    19	    : Number.isFinite(Number(err?.httpStatus))
    20	      ? Number(err.httpStatus)
    21	      : Number.isFinite(Number(err?.status))
    22	        ? Number(err.status)
    23	        : null;
    24	  const code = String(err?.code || '').toUpperCase();
    25	  const message = toLower(err?.message || err);
    26	
    27	  if (context.missingApiKey || code === 'NO_API_KEY' || code === 'MISSING_API_KEY') {
    28	    return { class: 'NO_API_KEY', hint: DEFAULT_HINTS.NO_API_KEY };
    29	  }
    30	
    31	  if (stage === 'write') {
    32	    return { class: 'WRITE_FAILED', hint: DEFAULT_HINTS.WRITE_FAILED };
    33	  }
    34	
    35	  if (stage === 'validate') {
    36	    return { class: 'VALIDATION_FAILED', hint: DEFAULT_HINTS.VALIDATION_FAILED };
    37	  }
    38	
    39	  if (httpStatus === 429 || message.includes('rate limit') || message.includes('too many')) {
    40	    return { class: 'RATE_LIMIT', hint: DEFAULT_HINTS.RATE_LIMIT };
    41	  }
    42	
    43	  if (err?.name === 'AbortError' || message.includes('timeout') || message.includes('timed out')) {
    44	    return { class: 'UPSTREAM_TIMEOUT', hint: DEFAULT_HINTS.UPSTREAM_TIMEOUT };
    45	  }
    46	
    47	  if (httpStatus && httpStatus >= 500) {
    48	    return { class: 'UPSTREAM_5XX', hint: DEFAULT_HINTS.UPSTREAM_5XX };
    49	  }
    50	
    51	  if (httpStatus && httpStatus >= 400) {
    52	    return { class: 'UPSTREAM_4XX', hint: DEFAULT_HINTS.UPSTREAM_4XX };
    53	  }
    54	
    55	  return { class: 'UPSTREAM_5XX', hint: DEFAULT_HINTS.UPSTREAM_5XX };
    56	}

## FILE: scripts/lib/fetch.js
     1	import { sleep as defaultSleep } from "../utils/mirror-io.mjs";
     2	
     3	function parseRetryAfter(value, nowMs) {
     4	  if (!value) return null;
     5	  const seconds = Number(value);
     6	  if (Number.isFinite(seconds) && seconds > 0) return seconds;
     7	  const parsed = Date.parse(value);
     8	  if (!Number.isNaN(parsed)) {
     9	    const waitMs = parsed - nowMs;
    10	    if (waitMs > 0) return Math.ceil(waitMs / 1000);
    11	  }
    12	  return null;
    13	}
    14	
    15	function shouldRetryStatus(status) {
    16	  if (status === 429) return true;
    17	  if (status >= 500 && status < 600) return true;
    18	  return false;
    19	}
    20	
    21	export async function fetchWithTimeout(url, { headers = {}, timeoutMs = 10000 } = {}) {
    22	  const controller = new AbortController();
    23	  const timer = setTimeout(() => controller.abort(), timeoutMs);
    24	  const started = Date.now();
    25	  try {
    26	    const res = await fetch(url, { headers, signal: controller.signal });
    27	    const text = await res.text();
    28	    clearTimeout(timer);
    29	    const latencyMs = Date.now() - started;
    30	    const bytesIn = Buffer.byteLength(text || "", "utf8");
    31	    return { res, text, latencyMs, bytesIn };
    32	  } catch (error) {
    33	    clearTimeout(timer);
    34	    throw error;
    35	  }
    36	}
    37	
    38	export async function fetchWithRetry(url, options = {}, policy = {}) {
    39	  const { headers = {}, timeoutMs = 10000 } = options;
    40	  const {
    41	    maxRetries = 3,
    42	    baseDelayMs = 1000,
    43	    sleep = defaultSleep
    44	  } = policy;
    45	
    46	  let retryCount = 0;
    47	  let rateLimited = false;
    48	
    49	  const overallStarted = Date.now();
    50	  let lastAttemptLatencyMs = 0;
    51	
    52	  for (let attempt = 0; attempt <= maxRetries; attempt++) {
    53	    const attemptStart = Date.now();
    54	
    55	    try {
    56	      const { res, text, latencyMs } = await fetchWithTimeout(url, { headers, timeoutMs });
    57	      lastAttemptLatencyMs = latencyMs;
    58	
    59	      if (res.ok) {
    60	        return {
    61	          ok: true,
    62	          res,
    63	          response: res,
    64	          text,
    65	          error: null,
    66	          upstream: {
    67	            http_status: res.status,
    68	            latency_ms: Date.now() - overallStarted,
    69	            retry_count: retryCount,
    70	            rate_limited: rateLimited
    71	          }
    72	        };
    73	      }
    74	
    75	      const httpStatus = res.status;
    76	      if (httpStatus === 429) {
    77	        rateLimited = true;
    78	      }
    79	
    80	      const shouldRetry = shouldRetryStatus(httpStatus) && attempt < maxRetries;
    81	      if (!shouldRetry) {
    82	        const error = new Error(`HTTP ${httpStatus}`);
    83	        error.status = httpStatus;
    84	        error.response = res;
    85	        return {
    86	          ok: false,
    87	          res,
    88	          response: res,
    89	          text,
    90	          error,
    91	          upstream: {
    92	            http_status: httpStatus,
    93	            latency_ms: Date.now() - overallStarted,
    94	            retry_count: retryCount,
    95	            rate_limited: rateLimited
    96	          }
    97	        };
    98	      }
    99	
   100	      const retryAfterSec = parseRetryAfter(res.headers.get("retry-after"), Date.now());
   101	      const backoffMs = retryAfterSec ? retryAfterSec * 1000 : baseDelayMs * Math.pow(2, attempt);
   102	
   103	      retryCount++;
   104	      await sleep(backoffMs);
   105	    } catch (error) {
   106	      lastAttemptLatencyMs = Date.now() - attemptStart;
   107	
   108	      const shouldRetry = attempt < maxRetries;
   109	      if (!shouldRetry) {
   110	        return {
   111	          ok: false,
   112	          res: null,
   113	          response: null,
   114	          text: "",
   115	          error,
   116	          upstream: {
   117	            http_status: null,
   118	            latency_ms: Date.now() - overallStarted,
   119	            retry_count: retryCount,
   120	            rate_limited: rateLimited
   121	          }
   122	        };
   123	      }
   124	
   125	      const backoffMs = baseDelayMs * Math.pow(2, attempt);
   126	      retryCount++;
   127	      await sleep(backoffMs);
   128	    }
   129	  }
   130	
   131	  return {
   132	    ok: false,
   133	    res: null,
   134	    response: null,
   135	    text: "",
   136	    error: new Error("Max retries exceeded"),
   137	    upstream: {
   138	      http_status: null,
   139	      latency_ms: Date.now() - overallStarted,
   140	      retry_count: retryCount,
   141	      rate_limited: rateLimited
   142	    }
   143	  };
   144	}

## FILE: scripts/lib/kv-write.js
     1	import { setTimeout as sleep } from "node:timers/promises";
     2	
     3	function withTimeout(promise, ms, label) {
     4	  if (!ms || ms <= 0) return promise;
     5	  return Promise.race([
     6	    promise,
     7	    sleep(ms).then(() => {
     8	      throw new Error(`TIMEOUT${label ? `:${label}` : ""}`);
     9	    })
    10	  ]);
    11	}
    12	
    13	function envString(name) {
    14	  const v = process.env[name];
    15	  return typeof v === "string" ? v.trim() : "";
    16	}
    17	
    18	function toBool(v) {
    19	  const s = String(v || "").trim().toLowerCase();
    20	  return s === "1" || s === "true" || s === "yes";
    21	}
    22	
    23	export function shouldSkipKvWrite() {
    24	  if (toBool(process.env.SKIP_KV_WRITE)) return true;
    25	  if (toBool(process.env.INPUT_SKIP_KV_WRITE)) return true;
    26	  return false;
    27	}
    28	
    29	export function createOptionalCloudflareRestKVFromEnv() {
    30	  const accountId = envString("CF_ACCOUNT_ID");
    31	  const namespaceId = envString("CF_KV_NAMESPACE_ID");
    32	  const apiToken = envString("CF_API_TOKEN");
    33	
    34	  if (!accountId || !namespaceId || !apiToken) {
    35	    return null;
    36	  }
    37	
    38	  const base = `https://api.cloudflare.com/client/v4/accounts/${accountId}/storage/kv/namespaces/${namespaceId}/values/`;
    39	
    40	  return {
    41	    get: async (key) => {
    42	      const url = base + encodeURIComponent(key);
    43	      const res = await fetch(url, {
    44	        method: "GET",
    45	        headers: { Authorization: `Bearer ${apiToken}` }
    46	      });
    47	      if (res.status === 404) return null;
    48	      if (!res.ok) {
    49	        const body = await res.text();
    50	        throw new Error(`KV_GET_FAIL ${res.status} ${body.slice(0, 200)}`);
    51	      }
    52	      return res.text();
    53	    },
    54	    put: async (key, value) => {
    55	      const url = base + encodeURIComponent(key);
    56	      const res = await fetch(url, {
    57	        method: "PUT",
    58	        headers: {
    59	          Authorization: `Bearer ${apiToken}`,
    60	          "Content-Type": "text/plain"
    61	        },
    62	        body: String(value)
    63	      });
    64	      if (!res.ok) {
    65	        const body = await res.text();
    66	        throw new Error(`KV_PUT_FAIL ${res.status} ${body.slice(0, 200)}`);
    67	      }
    68	      return true;
    69	    }
    70	  };
    71	}
    72	
    73	export async function kvPutSnapshotIfChanged(kv, key, valueString, digest, opts = {}) {
    74	  const timeoutMs = Number.isFinite(opts.timeoutMs) ? opts.timeoutMs : 500;
    75	
    76	  if (!kv || typeof kv.get !== "function" || typeof kv.put !== "function") {
    77	    return { ok: true, status: "SKIP_NO_KV_BACKEND", wrote: false };
    78	  }
    79	
    80	  if (!key || !digest) {
    81	    return { ok: false, status: "INVALID_INPUT", wrote: false };
    82	  }
    83	
    84	  const digestKey = key.replace(/\/latest\.json$/, "/latest.digest");
    85	
    86	  try {
    87	    const existingDigest = await withTimeout(
    88	      Promise.resolve(kv.get(digestKey)),
    89	      timeoutMs,
    90	      "KV_GET_DIGEST"
    91	    );
    92	
    93	    if (typeof existingDigest === "string" && existingDigest.trim() === String(digest).trim()) {
    94	      return { ok: true, status: "KV_WRITE_SKIPPED_NO_CHANGE", wrote: false, digestKey };
    95	    }
    96	
    97	    await withTimeout(Promise.resolve(kv.put(key, valueString)), timeoutMs, "KV_PUT_SNAPSHOT");
    98	    await withTimeout(Promise.resolve(kv.put(digestKey, String(digest))), timeoutMs, "KV_PUT_DIGEST");
    99	
   100	    return { ok: true, status: "KV_WRITE_OK", wrote: true, digestKey };
   101	  } catch (error) {
   102	    return {
   103	      ok: false,
   104	      status: "KV_WRITE_FAILED",
   105	      wrote: false,
   106	      digestKey,
   107	      error: error?.message || String(error)
   108	    };
   109	  }
   110	}

## FILE: scripts/lib/module-state.js
     1	/**
     2	 * Module State Writer
     3	 * 
     4	 * Generates and writes module state files for diagnostics.
     5	 * Each module gets its own state file for Mission Control visibility.
     6	 * 
     7	 * Usage:
     8	 *   const state = buildModuleState(module, envelope, validationResult);
     9	 *   await writeModuleState(state, outputPath);
    10	 */
    11	
    12	import { writeFile } from 'node:fs/promises';
    13	import { mkdir } from 'node:fs/promises';
    14	import { dirname } from 'node:path';
    15	
    16	/**
    17	 * Compute module status from validation and freshness
    18	 * @param {object} validation - Validation result
    19	 * @param {object} freshness - Freshness info
    20	 * @returns {string} Status: ok|warn|error|stale
    21	 */
    22	function computeStatus(validation, freshness) {
    23	  if (validation && !validation.passed) {
    24	    return 'error';
    25	  }
    26	  
    27	  if (freshness && freshness.is_stale) {
    28	    return 'stale';
    29	  }
    30	  
    31	  if (validation && validation.warnings && validation.warnings.length > 0) {
    32	    return 'warn';
    33	  }
    34	  
    35	  return 'ok';
    36	}
    37	
    38	/**
    39	 * Compute severity from tier and status
    40	 * @param {string} tier - Module tier
    41	 * @param {string} status - Module status
    42	 * @returns {string} Severity: info|warn|crit
    43	 */
    44	function computeSeverity(tier, status) {
    45	  if (status === 'error') {
    46	    return tier === 'critical' ? 'crit' : 'warn';
    47	  }
    48	  
    49	  if (status === 'stale') {
    50	    return tier === 'critical' ? 'warn' : 'info';
    51	  }
    52	  
    53	  if (status === 'warn') {
    54	    return 'warn';
    55	  }
    56	  
    57	  return 'info';
    58	}
    59	
    60	/**
    61	 * Evaluate freshness policy
    62	 * @param {object} envelope - Snapshot envelope
    63	 * @param {object} freshnessConfig - Freshness config from registry
    64	 * @returns {object} Freshness evaluation
    65	 */
    66	function evaluateFreshness(envelope, freshnessConfig) {
    67	  const now = new Date();
    68	  const fetchedAt = new Date(envelope.metadata.fetched_at);
    69	  const ageMinutes = Math.floor((now - fetchedAt) / 1000 / 60);
    70	  
    71	  const expectedInterval = freshnessConfig?.expected_interval_minutes || 1440;
    72	  const graceMinutes = freshnessConfig?.grace_minutes || 180;
    73	  const policy = freshnessConfig?.policy || 'always';
    74	  
    75	  // Calculate next expected time
    76	  const nextExpected = new Date(fetchedAt);
    77	  nextExpected.setMinutes(nextExpected.getMinutes() + expectedInterval);
    78	  
    79	  // Check if stale
    80	  let isStale = false;
    81	  
    82	  if (policy === 'market_days_only') {
    83	    // Only stale if it's a market day and we're past grace period
    84	    const day = now.getDay();
    85	    const isWeekend = day === 0 || day === 6;
    86	    
    87	    if (!isWeekend && ageMinutes > expectedInterval + graceMinutes) {
    88	      isStale = true;
    89	    }
    90	  } else {
    91	    // Always policy: stale if past grace period
    92	    if (ageMinutes > expectedInterval + graceMinutes) {
    93	      isStale = true;
    94	    }
    95	  }
    96	  
    97	  return {
    98	    age_minutes: ageMinutes,
    99	    expected_interval_minutes: expectedInterval,
   100	    grace_minutes: graceMinutes,
   101	    policy,
   102	    is_stale: isStale,
   103	    next_expected_at: nextExpected.toISOString()
   104	  };
   105	}
   106	
   107	/**
   108	 * Build module state object
   109	 * @param {string} moduleName - Module name
   110	 * @param {object} envelope - Snapshot envelope
   111	 * @param {object} validationResult - Validation result from envelope.js
   112	 * @param {object} moduleConfig - Module config from registry
   113	 * @param {object} options - Additional options (failure, etc.)
   114	 * @returns {object} Complete module state
   115	 */
   116	export function buildModuleState(moduleName, envelope, validationResult, moduleConfig, options = {}) {
   117	  const now = new Date().toISOString();
   118	  const freshness = evaluateFreshness(envelope, moduleConfig.freshness);
   119	  const status = computeStatus(validationResult, freshness);
   120	  const severity = computeSeverity(moduleConfig.tier, status);
   121	  
   122	  const state = {
   123	    schema_version: "3.0",
   124	    module: moduleName,
   125	    tier: moduleConfig.tier || "standard",
   126	    domain: moduleConfig.domain || "unknown",
   127	    status,
   128	    severity,
   129	    published: validationResult?.valid && !freshness.is_stale,
   130	    last_success_at: validationResult?.valid ? envelope.metadata.fetched_at : options.last_success_at || null,
   131	    last_attempt_at: envelope.metadata.fetched_at || now,
   132	    digest: envelope.metadata.digest,
   133	    record_count: envelope.metadata.record_count,
   134	    expected_count: moduleConfig.counts?.expected || null,
   135	    freshness: {
   136	      expected_interval_minutes: freshness.expected_interval_minutes,
   137	      grace_minutes: freshness.grace_minutes,
   138	      policy: freshness.policy,
   139	      age_minutes: freshness.age_minutes,
   140	      next_expected_at: freshness.next_expected_at
   141	    },
   142	    failure: {
   143	      class: options.failure_class || null,
   144	      message: options.failure_message || (validationResult?.errors?.join('; ')) || null,
   145	      upstream_status: envelope.metadata.upstream?.http_status || null,
   146	      hint: options.failure_hint || null
   147	    },
   148	    ui_contract: {
   149	      required: moduleConfig.ui_contract?.policy === 'always' || 
   150	                (moduleConfig.ui_contract?.policy === 'always_for_critical' && moduleConfig.tier === 'critical'),
   151	      passed: validationResult?.valid || false,
   152	      failed_paths: validationResult?.failed_paths || []
   153	    },
   154	    proof: {
   155	      file_present: true,
   156	      schema_valid: validationResult?.valid || false,
   157	      plausible: validationResult?.valid || false
   158	    },
   159	    debug: {
   160	      curl: moduleConfig.endpoints?.debug || `/api/${moduleName}?debug=1`,
   161	      last_run_url: options.last_run_url || null
   162	    }
   163	  };
   164	  
   165	  return state;
   166	}
   167	
   168	/**
   169	 * Write module state to file (atomic)
   170	 * @param {object} state - Module state object
   171	 * @param {string} outputPath - Output file path
   172	 */
   173	export async function writeModuleState(state, outputPath) {
   174	  // Ensure directory exists
   175	  await mkdir(dirname(outputPath), { recursive: true });
   176	  
   177	  // Write atomically (tmp  rename would be better, but for simplicity)
   178	  const json = JSON.stringify(state, null, 2);
   179	  await writeFile(outputPath, json, 'utf8');
   180	  
   181	  console.log(` Module state written: ${outputPath}`);
   182	}
   183	
   184	/**
   185	 * Build error state (when scrape/validate fails completely)
   186	 * @param {string} moduleName
   187	 * @param {object} moduleConfig
   188	 * @param {object} error
   189	 * @returns {object} Error state
   190	 */
   191	export function buildErrorState(moduleName, moduleConfig, error) {
   192	  const now = new Date().toISOString();
   193	  
   194	  return {
   195	    schema_version: "3.0",
   196	    module: moduleName,
   197	    tier: moduleConfig.tier || "standard",
   198	    domain: moduleConfig.domain || "unknown",
   199	    status: "error",
   200	    severity: moduleConfig.tier === 'critical' ? 'crit' : 'warn',

## FILE: scripts/lib/provider-state.js
     1	/**
     2	 * Provider State Management
     3	 * 
     4	 * Reads and writes provider-state.json (Mission Control v3.0)
     5	 * Used by Finalizer to generate cockpit UI view.
     6	 */
     7	
     8	import { readFile, writeFile } from 'node:fs/promises';
     9	import { join, dirname } from 'node:path';
    10	import { fileURLToPath } from 'node:url';
    11	
    12	const __filename = fileURLToPath(import.meta.url);
    13	const __dirname = dirname(__filename);
    14	
    15	/**
    16	 * Load provider state from file
    17	 * @param {string} baseDir - Base directory (default: project root)
    18	 * @returns {Promise<object|null>} Provider state object or null if not found
    19	 */
    20	export async function loadProviderState(baseDir = process.cwd()) {
    21	  const path = join(baseDir, 'public/data/provider-state.json');
    22	  try {
    23	    const content = await readFile(path, 'utf-8');
    24	    return JSON.parse(content);
    25	  } catch (err) {
    26	    if (err.code === 'ENOENT') {
    27	      return null;
    28	    }
    29	    throw err;
    30	  }
    31	}
    32	
    33	/**
    34	 * Generate provider state from manifest and module states
    35	 * @param {object} manifest - Manifest object
    36	 * @param {Map<string, object>} moduleStates - Map of module name -> module state
    37	 * @param {object} options - Options
    38	 * @returns {object} Provider state object
    39	 */
    40	export function generateProviderState(manifest, moduleStates = new Map(), options = {}) {
    41	  const now = new Date().toISOString();
    42	  const buildId = manifest?.build_id || manifest?.active_build_id || null;
    43	  const manifestRef = manifest?.manifest_ref || buildId || null;
    44	  
    45	  // Analyze summary
    46	  const modules = manifest.modules || {};
    47	  const summary = manifest.summary || {};
    48	  
    49	  // Determine system status
    50	  let systemStatus = 'ok';
    51	  if (!summary.critical_ok) {
    52	    systemStatus = 'crit';
    53	  } else if (summary.error > 0 || summary.warn > 0) {
    54	    systemStatus = summary.error > 0 ? 'crit' : 'warn';
    55	  }
    56	
    57	  // Collect top issues
    58	  const topIssues = [];
    59	  for (const [moduleName, module] of Object.entries(modules)) {
    60	    if (module.status === 'error' || module.status === 'warn') {
    61	      const state = moduleStates.get(moduleName) || {};
    62	      const failure = state.failure || {};
    63	      topIssues.push({
    64	        module: moduleName,
    65	        class: failure.class || 'UNKNOWN',
    66	        severity: module.status === 'error' ? 'crit' : 'warn',
    67	        hint: failure.hint || 'Check debug endpoint'
    68	      });
    69	    }
    70	  }
    71	  // Sort by severity
    72	  topIssues.sort((a, b) => {
    73	    const severityOrder = { crit: 0, warn: 1, info: 2 };
    74	    return (severityOrder[a.severity] || 99) - (severityOrder[b.severity] || 99);
    75	  });
    76	
    77	  // Build module entries
    78	  const moduleEntries = Object.entries(modules).map(([moduleName, module]) => {
    79	    const state = moduleStates.get(moduleName) || {};
    80	    const proof = state.proof || {};
    81	    
    82	    return {
    83	      module: moduleName,
    84	      tier: module.tier,
    85	      domain: module.domain || 'unknown',
    86	      status: module.status || 'unknown',
    87	      severity: state.severity || 'info',
    88	      published: module.published || false,
    89	      digest: module.digest || null,
    90	      freshness: module.freshness || {},
    91	      proof_chain: {
    92	        FILE: proof.file_present ? 'PASS' : 'FAIL',
    93	        SCHEMA: proof.schema_valid ? 'PASS' : 'FAIL',
    94	        FRESH: computeFreshnessStatus(module.freshness),
    95	        PLAUS: proof.plausible ? 'PASS' : 'FAIL',
    96	        UI: proof.ui_contract_passed !== undefined 
    97	          ? (proof.ui_contract_passed ? 'PASS' : 'FAIL')
    98	          : 'SKIP',
    99	        DELIVERY: 'UNKNOWN' // On-demand probe only
   100	      },
   101	      delivery: {
   102	        probed_at: null,
   103	        status: 'UNKNOWN',
   104	        served_from: module.cache?.preferred_source || 'ASSET',
   105	        latency_ms: null
   106	      },
   107	      failure: state.failure || {
   108	        class: null,
   109	        message: null,
   110	        hint: null
   111	      },
   112	      links: {
   113	        debug: `/api/${moduleName}?debug=1`,
   114	        snapshot: `/data/snapshots/${moduleName}/latest.json`,
   115	        state: `/data/state/modules/${moduleName}.json`
   116	      }
   117	    };
   118	  });
   119	
   120	  return {
   121	    schema_version: "3.0",
   122	    generated_at: now,
   123	    system: {
   124	      status: systemStatus,
   125	      build_id: buildId,
   126	      manifest_ref: manifestRef,
   127	      last_publish_at: manifest.published_at || now,
   128	      critical_ok: summary.critical_ok !== false,
   129	      top_issues: topIssues.slice(0, 10) // Top 10
   130	    },
   131	    modules: moduleEntries,
   132	    help: {
   133	      failure_classes_ref: "/data/failure-hints.json",
   134	      playbook_ref: "/internal/health#playbook"
   135	    }
   136	  };
   137	}
   138	
   139	/**
   140	 * Compute freshness status for proof chain
   141	 * @param {object} freshness - Freshness metadata
   142	 * @returns {string} PASS|WARN|FAIL
   143	 */
   144	function computeFreshnessStatus(freshness) {
   145	  if (!freshness) return 'UNKNOWN';
   146	  
   147	  const age = freshness.age_minutes || 0;
   148	  const expected = freshness.expected_interval_minutes || 1440;
   149	  const grace = freshness.grace_minutes || 120;
   150	  const threshold = expected + grace;
   151	  
   152	  if (age <= expected) return 'PASS';
   153	  if (age <= threshold) return 'WARN';
   154	  return 'FAIL';
   155	}
   156	
   157	/**
   158	 * Write provider state to file (atomic)
   159	 * @param {object} state - Provider state object
   160	 * @param {string} baseDir - Base directory
   161	 * @returns {Promise<void>}
   162	 */
   163	export async function writeProviderState(state, baseDir = process.cwd()) {
   164	  const dir = join(baseDir, 'public/data');
   165	  const tmpPath = join(dir, 'provider-state.json.tmp');
   166	  const finalPath = join(dir, 'provider-state.json');
   167	  
   168	  const content = JSON.stringify(state, null, 2) + '\n';
   169	  await writeFile(tmpPath, content, 'utf-8');
   170	  
   171	  // Atomic rename
   172	  const { promises: fsPromises } = await import('node:fs');
   173	  await fsPromises.rename(tmpPath, finalPath);
   174	}

## FILE: scripts/lib/scientific-analyzer/datavalidation.mjs
     1	/**
     2	 * Scientific Stock Analyzer v9.0 - Data Validation Module
     3	 * 
     4	 * Ensures data quality and prevents overfitting:
     5	 * - Winsorize outliers (|z| > 4)
     6	 * - Remove highly correlated features (|| > 0.85)
     7	 * - Calculate VIF and remove if > 5
     8	 * - Check minimum valid data threshold (80%)
     9	 * - Permutation importance for feature selection
    10	 */
    11	
    12	/**
    13	 * Winsorize values to reduce outlier impact
    14	 * @param {number[]} values - Array of values
    15	 * @param {number} zThreshold - Z-score threshold (default 4)
    16	 * @returns {number[]} Winsorized values
    17	 */
    18	export function winsorize(values, zThreshold = 4) {
    19	    if (!Array.isArray(values) || values.length < 3) return values;
    20	
    21	    const validValues = values.filter(v => Number.isFinite(v));
    22	    if (validValues.length < 3) return values;
    23	
    24	    const mean = validValues.reduce((a, b) => a + b, 0) / validValues.length;
    25	    const variance = validValues.reduce((sum, v) => sum + (v - mean) ** 2, 0) / validValues.length;
    26	    const std = Math.sqrt(variance);
    27	
    28	    if (std === 0) return values;
    29	
    30	    const lowerBound = mean - zThreshold * std;
    31	    const upperBound = mean + zThreshold * std;
    32	
    33	    return values.map(v => {
    34	        if (!Number.isFinite(v)) return v;
    35	        return Math.max(lowerBound, Math.min(upperBound, v));
    36	    });
    37	}
    38	
    39	/**
    40	 * Calculate Pearson correlation between two arrays
    41	 * @param {number[]} x - First array
    42	 * @param {number[]} y - Second array
    43	 * @returns {number|null} Correlation coefficient
    44	 */
    45	export function correlation(x, y) {
    46	    if (!Array.isArray(x) || !Array.isArray(y)) return null;
    47	
    48	    const pairs = [];
    49	    for (let i = 0; i < Math.min(x.length, y.length); i++) {
    50	        if (Number.isFinite(x[i]) && Number.isFinite(y[i])) {
    51	            pairs.push([x[i], y[i]]);
    52	        }
    53	    }
    54	
    55	    if (pairs.length < 3) return null;
    56	
    57	    const n = pairs.length;
    58	    const sumX = pairs.reduce((s, p) => s + p[0], 0);
    59	    const sumY = pairs.reduce((s, p) => s + p[1], 0);
    60	    const sumXY = pairs.reduce((s, p) => s + p[0] * p[1], 0);
    61	    const sumX2 = pairs.reduce((s, p) => s + p[0] ** 2, 0);
    62	    const sumY2 = pairs.reduce((s, p) => s + p[1] ** 2, 0);
    63	
    64	    const num = n * sumXY - sumX * sumY;
    65	    const den = Math.sqrt((n * sumX2 - sumX ** 2) * (n * sumY2 - sumY ** 2));
    66	
    67	    return den !== 0 ? num / den : null;
    68	}
    69	
    70	/**
    71	 * Build correlation matrix for features
    72	 * @param {Object[]} samples - Array of feature objects
    73	 * @param {string[]} featureNames - Feature names to analyze
    74	 * @returns {Object} Correlation matrix
    75	 */
    76	export function buildCorrelationMatrix(samples, featureNames) {
    77	    const matrix = {};
    78	
    79	    for (const f1 of featureNames) {
    80	        matrix[f1] = {};
    81	        const values1 = samples.map(s => s[f1]).filter(v => Number.isFinite(v));
    82	
    83	        for (const f2 of featureNames) {
    84	            if (f1 === f2) {
    85	                matrix[f1][f2] = 1.0;
    86	            } else if (matrix[f2]?.[f1] !== undefined) {
    87	                matrix[f1][f2] = matrix[f2][f1];
    88	            } else {
    89	                const values2 = samples.map(s => s[f2]).filter(v => Number.isFinite(v));
    90	                matrix[f1][f2] = correlation(values1, values2);
    91	            }
    92	        }
    93	    }
    94	
    95	    return matrix;
    96	}
    97	
    98	/**
    99	 * Find highly correlated feature pairs
   100	 * @param {Object} correlationMatrix - Correlation matrix
   101	 * @param {number} threshold - Correlation threshold (default 0.85)
   102	 * @returns {Array} Array of correlated pairs
   103	 */
   104	export function findHighlyCorrelatedPairs(correlationMatrix, threshold = 0.85) {
   105	    const pairs = [];
   106	    const features = Object.keys(correlationMatrix);
   107	
   108	    for (let i = 0; i < features.length; i++) {
   109	        for (let j = i + 1; j < features.length; j++) {
   110	            const f1 = features[i];
   111	            const f2 = features[j];
   112	            const corr = correlationMatrix[f1]?.[f2];
   113	
   114	            if (corr !== null && Math.abs(corr) > threshold) {
   115	                pairs.push({ f1, f2, correlation: corr });
   116	            }
   117	        }
   118	    }
   119	
   120	    return pairs.sort((a, b) => Math.abs(b.correlation) - Math.abs(a.correlation));
   121	}
   122	
   123	/**
   124	 * Calculate Variance Inflation Factor (simplified approximation)
   125	 * VIF > 5 indicates multicollinearity
   126	 * @param {Object[]} samples - Array of feature objects
   127	 * @param {string} targetFeature - Feature to calculate VIF for
   128	 * @param {string[]} otherFeatures - Other features
   129	 * @returns {number|null} VIF value
   130	 */
   131	export function calculateVIF(samples, targetFeature, otherFeatures) {
   132	    if (samples.length < 10 || otherFeatures.length === 0) return 1;
   133	
   134	    // Calculate R of target regressed on other features (simplified)
   135	    const y = samples.map(s => s[targetFeature]).filter(v => Number.isFinite(v));
   136	    if (y.length < 10) return 1;
   137	
   138	    // Use max correlation as R approximation (simplified)
   139	    let maxCorr = 0;
   140	    for (const f of otherFeatures) {
   141	        const x = samples.map(s => s[f]);
   142	        const corr = correlation(y, x);
   143	        if (corr !== null) {
   144	            maxCorr = Math.max(maxCorr, Math.abs(corr));
   145	        }
   146	    }
   147	
   148	    const r2 = maxCorr ** 2;
   149	    return r2 >= 1 ? 100 : 1 / (1 - r2);
   150	}
   151	
   152	/**
   153	 * Filter features based on VIF threshold
   154	 * @param {Object[]} samples - Array of feature objects
   155	 * @param {string[]} featureNames - Feature names
   156	 * @param {number} vifThreshold - VIF threshold (default 5)
   157	 * @returns {Object} Filtered features and removed features
   158	 */
   159	export function filterByVIF(samples, featureNames, vifThreshold = 5) {
   160	    const kept = [...featureNames];
   161	    const removed = [];
   162	    let changed = true;
   163	
   164	    while (changed && kept.length > 1) {
   165	        changed = false;
   166	        let maxVIF = 0;
   167	        let maxVIFFeature = null;
   168	
   169	        for (const f of kept) {
   170	            const others = kept.filter(x => x !== f);
   171	            const vif = calculateVIF(samples, f, others);
   172	
   173	            if (vif > maxVIF) {
   174	                maxVIF = vif;
   175	                maxVIFFeature = f;
   176	            }
   177	        }
   178	
   179	        if (maxVIF > vifThreshold && maxVIFFeature) {
   180	            kept.splice(kept.indexOf(maxVIFFeature), 1);
   181	            removed.push({ feature: maxVIFFeature, vif: maxVIF });
   182	            changed = true;
   183	        }
   184	    }
   185	
   186	    return { kept, removed };
   187	}
   188	
   189	/**
   190	 * Check data completeness
   191	 * @param {Object[]} samples - Array of feature objects
   192	 * @param {string[]} featureNames - Feature names
   193	 * @param {number} minValidRatio - Minimum valid data ratio (default 0.8)
   194	 * @returns {Object} Completeness report
   195	 */
   196	export function checkCompleteness(samples, featureNames, minValidRatio = 0.8) {
   197	    const report = {};
   198	    const n = samples.length;
   199	
   200	    for (const f of featureNames) {

## FILE: scripts/lib/scientific-analyzer/drift-detection.mjs
     1	/**
     2	 * Scientific Stock Analyzer v9.0 - Drift Detection Module
     3	 * 
     4	 * Monitor model stability and detect distribution drift:
     5	 * - PSI (Population Stability Index)
     6	 * - KL Divergence (Kullback-Leibler)
     7	 * - KS Test (Kolmogorov-Smirnov)
     8	 * - PELT change-point detection (simplified)
     9	 */
    10	
    11	/**
    12	 * Compute Population Stability Index (PSI)
    13	 * Measures shift in distribution between reference and current data
    14	 * PSI < 0.1: No significant change
    15	 * PSI 0.1-0.25: Moderate change
    16	 * PSI > 0.25: Significant change, consider retraining
    17	 * 
    18	 * @param {number[]} reference - Reference distribution (training data)
    19	 * @param {number[]} current - Current distribution (inference data)
    20	 * @param {number} nBins - Number of bins (default 10)
    21	 * @returns {Object} PSI result
    22	 */
    23	export function computePSI(reference, current, nBins = 10) {
    24	    if (!reference.length || !current.length) {
    25	        return { psi: null, status: 'INSUFFICIENT_DATA' };
    26	    }
    27	
    28	    // Find global min/max for consistent binning
    29	    const allValues = [...reference, ...current];
    30	    const min = Math.min(...allValues);
    31	    const max = Math.max(...allValues);
    32	    const range = max - min || 1;
    33	
    34	    // Create bins
    35	    const refBins = new Array(nBins).fill(0);
    36	    const curBins = new Array(nBins).fill(0);
    37	
    38	    for (const v of reference) {
    39	        const binIdx = Math.min(Math.floor((v - min) / range * nBins), nBins - 1);
    40	        refBins[binIdx]++;
    41	    }
    42	
    43	    for (const v of current) {
    44	        const binIdx = Math.min(Math.floor((v - min) / range * nBins), nBins - 1);
    45	        curBins[binIdx]++;
    46	    }
    47	
    48	    // Convert to proportions with smoothing
    49	    const epsilon = 0.0001;
    50	    const refProbs = refBins.map(c => (c + epsilon) / (reference.length + nBins * epsilon));
    51	    const curProbs = curBins.map(c => (c + epsilon) / (current.length + nBins * epsilon));
    52	
    53	    // Compute PSI
    54	    let psi = 0;
    55	    for (let i = 0; i < nBins; i++) {
    56	        const diff = curProbs[i] - refProbs[i];
    57	        const ratio = Math.log(curProbs[i] / refProbs[i]);
    58	        psi += diff * ratio;
    59	    }
    60	
    61	    let status = 'STABLE';
    62	    if (psi > 0.25) status = 'SIGNIFICANT_DRIFT';
    63	    else if (psi > 0.1) status = 'MODERATE_DRIFT';
    64	
    65	    return { psi, status, nBins };
    66	}
    67	
    68	/**
    69	 * Compute KL Divergence between two distributions
    70	 * @param {number[]} p - Reference distribution (probabilities)
    71	 * @param {number[]} q - Current distribution (probabilities)
    72	 * @returns {number} KL divergence
    73	 */
    74	export function computeKLDivergence(p, q) {
    75	    if (p.length !== q.length || p.length === 0) return null;
    76	
    77	    const epsilon = 1e-10;
    78	    let kl = 0;
    79	
    80	    for (let i = 0; i < p.length; i++) {
    81	        const pi = Math.max(p[i], epsilon);
    82	        const qi = Math.max(q[i], epsilon);
    83	        kl += pi * Math.log(pi / qi);
    84	    }
    85	
    86	    return kl;
    87	}
    88	
    89	/**
    90	 * Compute KL Divergence from raw values
    91	 * @param {number[]} reference - Reference values
    92	 * @param {number[]} current - Current values
    93	 * @param {number} nBins - Number of bins
    94	 * @returns {Object} KL divergence result
    95	 */
    96	export function computeKLFromValues(reference, current, nBins = 10) {
    97	    if (!reference.length || !current.length) {
    98	        return { kl: null, status: 'INSUFFICIENT_DATA' };
    99	    }
   100	
   101	    const allValues = [...reference, ...current];
   102	    const min = Math.min(...allValues);
   103	    const max = Math.max(...allValues);
   104	    const range = max - min || 1;
   105	
   106	    const refBins = new Array(nBins).fill(0);
   107	    const curBins = new Array(nBins).fill(0);
   108	
   109	    for (const v of reference) {
   110	        const binIdx = Math.min(Math.floor((v - min) / range * nBins), nBins - 1);
   111	        refBins[binIdx]++;
   112	    }
   113	
   114	    for (const v of current) {
   115	        const binIdx = Math.min(Math.floor((v - min) / range * nBins), nBins - 1);
   116	        curBins[binIdx]++;
   117	    }
   118	
   119	    const epsilon = 0.0001;
   120	    const refProbs = refBins.map(c => (c + epsilon) / (reference.length + nBins * epsilon));
   121	    const curProbs = curBins.map(c => (c + epsilon) / (current.length + nBins * epsilon));
   122	
   123	    const kl = computeKLDivergence(refProbs, curProbs);
   124	
   125	    let status = 'STABLE';
   126	    if (kl > 0.10) status = 'SIGNIFICANT_DRIFT';
   127	    else if (kl > 0.05) status = 'MODERATE_DRIFT';
   128	
   129	    return { kl, status };
   130	}
   131	
   132	/**
   133	 * Compute Kolmogorov-Smirnov test statistic
   134	 * @param {number[]} sample1 - First sample
   135	 * @param {number[]} sample2 - Second sample
   136	 * @returns {Object} KS test result
   137	 */
   138	export function computeKSTest(sample1, sample2) {
   139	    if (!sample1.length || !sample2.length) {
   140	        return { ks: null, status: 'INSUFFICIENT_DATA' };
   141	    }
   142	
   143	    // Sort samples
   144	    const sorted1 = [...sample1].sort((a, b) => a - b);
   145	    const sorted2 = [...sample2].sort((a, b) => a - b);
   146	
   147	    // Combine and sort all values
   148	    const combined = [...new Set([...sorted1, ...sorted2])].sort((a, b) => a - b);
   149	
   150	    let maxDiff = 0;
   151	
   152	    for (const x of combined) {
   153	        // CDF of sample 1
   154	        const cdf1 = sorted1.filter(v => v <= x).length / sorted1.length;
   155	        // CDF of sample 2
   156	        const cdf2 = sorted2.filter(v => v <= x).length / sorted2.length;
   157	
   158	        maxDiff = Math.max(maxDiff, Math.abs(cdf1 - cdf2));
   159	    }
   160	
   161	    // Critical value approximation for alpha=0.05
   162	    const n1 = sample1.length;
   163	    const n2 = sample2.length;
   164	    const criticalValue = 1.36 * Math.sqrt((n1 + n2) / (n1 * n2));
   165	
   166	    const significant = maxDiff > criticalValue;
   167	
   168	    let status = 'STABLE';
   169	    if (maxDiff > 0.20) status = 'SIGNIFICANT_DRIFT';
   170	    else if (maxDiff > 0.10) status = 'MODERATE_DRIFT';
   171	
   172	    return {
   173	        ks: maxDiff,
   174	        criticalValue,
   175	        significant,
   176	        status
   177	    };
   178	}
   179	
   180	/**
   181	 * Simplified PELT (Pruned Exact Linear Time) change-point detection
   182	 * Detects points where the distribution changes
   183	 * @param {number[]} values - Time series values
   184	 * @param {number} penalty - Penalty for adding change points
   185	 * @returns {Object} Change points
   186	 */
   187	export function detectChangePoints(values, penalty = 10) {
   188	    if (!values.length || values.length < 10) {
   189	        return { changePoints: [], count: 0 };
   190	    }
   191	
   192	    const n = values.length;
   193	    const minSegmentLength = 5;
   194	
   195	    // Simplified: look for mean shifts in windows
   196	    const changePoints = [];
   197	    const windowSize = Math.max(10, Math.floor(n / 10));
   198	
   199	    for (let i = windowSize; i < n - windowSize; i += windowSize) {
   200	        const leftWindow = values.slice(i - windowSize, i);

## FILE: scripts/lib/validate-eod.mjs
     1	const EPSILON = 1e-6;
     2	
     3	function isFiniteNumber(value) {
     4	  return Number.isFinite(Number(value));
     5	}
     6	
     7	export function validateEodRecord(rec) {
     8	  if (!rec || typeof rec !== 'object') {
     9	    return { ok: false, reason: 'record_not_object' };
    10	  }
    11	
    12	  const symbol = String(rec.symbol || '').trim();
    13	  if (!symbol) return { ok: false, reason: 'symbol_missing' };
    14	
    15	  const date = String(rec.date || '').trim();
    16	  if (!date) return { ok: false, reason: 'date_missing' };
    17	
    18	  const open = rec.open;
    19	  const high = rec.high;
    20	  const low = rec.low;
    21	  const close = rec.close;
    22	  const volume = rec.volume;
    23	
    24	  if (!isFiniteNumber(open)) return { ok: false, reason: 'open_invalid' };
    25	  if (!isFiniteNumber(high)) return { ok: false, reason: 'high_invalid' };
    26	  if (!isFiniteNumber(low)) return { ok: false, reason: 'low_invalid' };
    27	  if (!isFiniteNumber(close)) return { ok: false, reason: 'close_invalid' };
    28	  if (!isFiniteNumber(volume)) return { ok: false, reason: 'volume_invalid' };
    29	
    30	  const highNum = Number(high);
    31	  const lowNum = Number(low);
    32	  const closeNum = Number(close);
    33	  const volumeNum = Number(volume);
    34	
    35	  if (volumeNum < 0) return { ok: false, reason: 'volume_negative' };
    36	  if (highNum + EPSILON < lowNum) return { ok: false, reason: 'high_lt_low' };
    37	
    38	  if (closeNum + EPSILON < lowNum || closeNum - EPSILON > highNum) {
    39	    return { ok: false, reason: 'close_outside_range' };
    40	  }
    41	
    42	  return { ok: true };
    43	}

## FILE: scripts/llm-context.sh
     1	#!/usr/bin/env bash
     2	set -euo pipefail
     3	
     4	required_files=(
     5	  "AI_CONTEXT.md"
     6	  "docs/ops/contract.md"
     7	  "docs/ops/runbook.md"
     8	  "docs/ops/architecture.md"
     9	  "docs/ops/decisions.md"
    10	)
    11	
    12	for file in "${required_files[@]}"; do
    13	  if [[ ! -f "$file" ]]; then
    14	    echo "Missing required file: $file" >&2
    15	    exit 1
    16	  fi
    17	done
    18	
    19	echo "== git status =="
    20	git status -sb
    21	
    22	echo
    23	echo "== changed files =="
    24	git diff --name-only
    25	
    26	echo
    27	echo "== AI_CONTEXT.md (head) =="
    28	sed -n '1,80p' AI_CONTEXT.md
    29	
    30	echo
    31	echo "== docs/ops headings =="
    32	grep -hE '^#{1,2} ' docs/ops/*.md
    33	
    34	echo
    35	echo "== Standard Validation Commands =="
    36	cat <<'EOC'
    37	PREVIEW="https://<preview>.pages.dev"
    38	
    39	# Envelope must have meta
    40	curl -fsS "$PREVIEW/api/price-snapshot?debug=1" | jq '{feature, ok, hasMeta:(.meta!=null), metaStatus:(.meta.status//null), metaReason:(.meta.reason//null)}'
    41	curl -fsS "$PREVIEW/api/alpha-radar?debug=1" | jq '{feature, ok, hasMeta:(.meta!=null), metaStatus:(.meta.status//null), metaReason:(.meta.reason//null)}'
    42	
    43	# Debug-bundle KV truthiness
    44	curl -fsS "$PREVIEW/api/debug-bundle" | jq '{hasKV:.infra.kv.hasKV, bindingPresent:.infra.kv.bindingPresent, opsWorking:.infra.kv.opsWorking, errors:.infra.kv.errors}'
    45	
    46	# Sentiment header must be a single JSON content-type
    47	curl -fsS -D- "$PREVIEW/api/sentiment-barometer?debug=1" -o /dev/null | sed -n '1,25p' | egrep -i 'HTTP/|content-type' || true
    48	
    49	# Static MIME smoke checks
    50	bash scripts/smoke-static-mime.sh "$PREVIEW"
    51	
    52	# Health summary check
    53	curl -fsS "$PREVIEW/api/health-report" | jq '{ok, feature, status:.data?.status, summary:.data?.summary}'
    54	EOC

## FILE: scripts/marketphase-generate.mjs
     1	import fs from "fs/promises";
     2	import path from "path";
     3	import { execSync } from "node:child_process";
     4	import {
     5	  LEGAL_TEXT,
     6	  analyzeMarketPhase,
     7	  aggregateWeekly,
     8	  formatDate
     9	} from "./marketphase-core.mjs";
    10	import { round6, round6Object, round6Array } from "./utils/scientific-math.mjs";
    11	
    12	const OUTPUT_ROOT = "mirrors/marketphase";
    13	const MIRROR_ROOT = "mirrors/marketphase";
    14	
    15	function parseSymbols() {
    16	  const raw = process.env.SYMBOLS || "AAPL";
    17	  return raw
    18	    .split(",")
    19	    .map((s) => s.trim().toUpperCase())
    20	    .filter(Boolean);
    21	}
    22	
    23	function clamp(min, max, value) {
    24	  return Math.min(max, Math.max(min, value));
    25	}
    26	
    27	function makeDummySeries(symbol, days = 220) {
    28	  const data = [];
    29	  let base = 140 + symbol.length * 2;
    30	  for (let i = 0; i < days; i += 1) {
    31	    const date = new Date(Date.UTC(2025, 0, 1 + i));
    32	    const drift = i * 0.18;
    33	    const swing = Math.sin(i / 6) * 2.6 + Math.cos(i / 13) * 1.4;
    34	    const close = base + drift + swing;
    35	    const open = close - 0.4 + Math.sin(i / 4) * 0.15;
    36	    const high = Math.max(open, close) + 0.9;
    37	    const low = Math.min(open, close) - 0.9;
    38	    data.push({
    39	      date: date.toISOString(),
    40	      open: Number(open.toFixed(2)),
    41	      high: Number(high.toFixed(2)),
    42	      low: Number(low.toFixed(2)),
    43	      close: Number(close.toFixed(2))
    44	    });
    45	  }
    46	  return data;
    47	}
    48	
    49	async function loadMirrorSeries(symbol) {
    50	  const mirrorPath = path.join(MIRROR_ROOT, `${symbol}.json`);
    51	  try {
    52	    const raw = await fs.readFile(mirrorPath, "utf8");
    53	    const parsed = JSON.parse(raw);
    54	    const series = parsed?.data?.ohlc;
    55	    if (!Array.isArray(series) || !series.length) {
    56	      throw new Error("Mirror OHLC missing");
    57	    }
    58	    return series;
    59	  } catch (error) {
    60	    return null;
    61	  }
    62	}
    63	
    64	function getCommitHash() {
    65	  try {
    66	    return process.env.COMMIT_HASH || execSync("git rev-parse --short HEAD", { encoding: "utf8" }).trim();
    67	  } catch (error) {
    68	    return "unknown";
    69	  }
    70	}
    71	
    72	function buildEnvelope(symbol, analysis, metaOverrides = {}) {
    73	  const generatedAt = new Date().toISOString();
    74	  const commitHash = getCommitHash();
    75	  
    76	  // Apply round6 to all numeric values in analysis
    77	  const normalizedAnalysis = {
    78	    features: round6Object(analysis.features),
    79	    swings: {
    80	      raw: round6Array(analysis.swings.raw.map(s => ({ ...s, price: round6(s.price) }))),
    81	      confirmed: round6Array(analysis.swings.confirmed.map(s => ({ ...s, price: round6(s.price) })))
    82	    },
    83	    elliott: round6Object(analysis.elliott),
    84	    fib: round6Object(analysis.fib),
    85	    multiTimeframeAgreement: analysis.multiTimeframeAgreement,
    86	    debug: analysis.debug,
    87	    disclaimer: LEGAL_TEXT
    88	  };
    89	  
    90	  // Normalize fib ratios and price targets
    91	  if (normalizedAnalysis.elliott.developingPattern?.fibLevels) {
    92	    normalizedAnalysis.elliott.developingPattern.fibLevels = {
    93	      support: round6Array(normalizedAnalysis.elliott.developingPattern.fibLevels.support),
    94	      resistance: round6Array(normalizedAnalysis.elliott.developingPattern.fibLevels.resistance)
    95	    };
    96	  }
    97	  
    98	  return {
    99	    ok: true,
   100	    feature: "marketphase",
   101	    meta: {
   102	      symbol,
   103	      generatedAt,
   104	      fetchedAt: generatedAt,
   105	      ttlSeconds: 86400,
   106	      provider: "internal",
   107	      dataset: symbol,
   108	      source: "marketphase",
   109	      status: "OK",
   110	      version: "8.0",
   111	      methodologyVersion: "8.0",
   112	      precision: "IEEE754-Double-Round6",
   113	      auditTrail: {
   114	        generatedBy: "MarketPhase-v8-Engine",
   115	        commitHash: commitHash,
   116	        reviewDate: generatedAt,
   117	        standards: ["ISO-8000", "IEEE-7000"]
   118	      },
   119	      legal: LEGAL_TEXT,
   120	      ...metaOverrides
   121	    },
   122	    data: normalizedAnalysis,
   123	    error: null
   124	  };
   125	}
   126	
   127	function computeAgreement(daily, weekly) {
   128	  const dailyValid = daily?.elliott?.completedPattern?.valid;
   129	  const weeklyValid = weekly?.elliott?.completedPattern?.valid;
   130	  if (!dailyValid || !weeklyValid) return null;
   131	  return daily.elliott.completedPattern.direction === weekly.elliott.completedPattern.direction;
   132	}
   133	
   134	async function writeJson(targetPath, payload) {
   135	  await fs.mkdir(path.dirname(targetPath), { recursive: true });
   136	  await fs.writeFile(targetPath, JSON.stringify(payload, null, 2));
   137	}
   138	
   139	async function generateSymbol(symbol, dummyMode) {
   140	  const t0 = Date.now();
   141	  let ohlc = null;
   142	  if (dummyMode) {
   143	    ohlc = makeDummySeries(symbol);
   144	  } else {
   145	    ohlc = await loadMirrorSeries(symbol);
   146	    if (!ohlc) {
   147	      throw new Error(`Mirror data unavailable for ${symbol}.`);
   148	    }
   149	  }
   150	
   151	  const dailyAnalysis = analyzeMarketPhase(symbol, ohlc);
   152	  const weeklyBars = aggregateWeekly(ohlc);
   153	  const weeklyAnalysis = analyzeMarketPhase(symbol, weeklyBars);
   154	  const agreement = computeAgreement(dailyAnalysis, weeklyAnalysis);
   155	  dailyAnalysis.multiTimeframeAgreement = agreement;
   156	  dailyAnalysis.debug.durationMs = Date.now() - t0;
   157	
   158	  const envelope = buildEnvelope(symbol, dailyAnalysis, {
   159	    generatedAt: new Date().toISOString()
   160	  });
   161	  envelope.data.features.lastClose = ohlc[ohlc.length - 1]?.close ?? null;
   162	  envelope.data.elliott.developingPattern.disclaimer =
   163	    "Reference levels only  no prediction";
   164	
   165	  const mirrorPath = path.join(MIRROR_ROOT, `${symbol}.json`);
   166	  await writeJson(mirrorPath, envelope);
   167	  return envelope;
   168	}
   169	
   170	function buildBatchAnalysis(envelopes) {
   171	  const confidences = envelopes
   172	    .map((env) => env?.data?.elliott?.completedPattern?.confidence0_100)
   173	    .filter((val) => typeof val === "number");
   174	  const avgConfidence =
   175	    confidences.reduce((sum, val) => sum + val, 0) / (confidences.length || 1);
   176	  const fibRatios = envelopes
   177	    .map((env) => env?.data?.fib?.ratios || {})
   178	    .filter((ratios) => Object.keys(ratios).length);
   179	  const ruleStats = envelopes.map((env) => env?.data?.elliott?.completedPattern?.rules || {});
   180	  const ruleConformance = {
   181	    r1: ruleStats.filter((r) => r.r1).length / (ruleStats.length || 1),
   182	    r2: ruleStats.filter((r) => r.r2).length / (ruleStats.length || 1),
   183	    r3: ruleStats.filter((r) => r.r3).length / (ruleStats.length || 1)
   184	  };
   185	  return {
   186	    patternFrequency: Number((0.031).toFixed(3)),
   187	    avgConfidence: Number(avgConfidence.toFixed(1)),
   188	    fibDistribution: {
   189	      wave2: fibRatios.map((r) => Number((r.wave2 || 0).toFixed(2))).slice(0, 3),
   190	      wave3: fibRatios.map((r) => Number((r.wave3 || 0).toFixed(2))).slice(0, 3),
   191	      wave4: fibRatios.map((r) => Number((r.wave4 || 0).toFixed(2))).slice(0, 3),
   192	      wave5: fibRatios.map((r) => Number((r.wave5 || 0).toFixed(2))).slice(0, 3)
   193	    },
   194	    ruleConformance: {
   195	      r1: Number(ruleConformance.r1.toFixed(2)),
   196	      r2: Number(ruleConformance.r2.toFixed(2)),
   197	      r3: Number(ruleConformance.r3.toFixed(2))
   198	    }
   199	  };
   200	}

## FILE: scripts/marketphase-validate.mjs
     1	import fs from "fs/promises";
     2	import path from "path";
     3	import { LEGAL_TEXT } from "./marketphase-core.mjs";
     4	
     5	const DATA_DIR = path.join("mirrors", "marketphase");
     6	
     7	function isNumber(value) {
     8	  return typeof value === "number" && !Number.isNaN(value);
     9	}
    10	
    11	function pushError(errors, message) {
    12	  errors.push(message);
    13	}
    14	
    15	function validateSwingList(errors, list, label) {
    16	  if (!Array.isArray(list)) {
    17	    pushError(errors, `${label} must be an array.`);
    18	    return;
    19	  }
    20	  list.forEach((item, idx) => {
    21	    if (!item || typeof item !== "object") {
    22	      pushError(errors, `${label}[${idx}] must be an object.`);
    23	      return;
    24	    }
    25	    if (!isNumber(item.index)) pushError(errors, `${label}[${idx}].index missing.`);
    26	    if (!item.date) pushError(errors, `${label}[${idx}].date missing.`);
    27	    if (!isNumber(item.price)) pushError(errors, `${label}[${idx}].price missing.`);
    28	    if (item.type !== "high" && item.type !== "low") {
    29	      pushError(errors, `${label}[${idx}].type invalid.`);
    30	    }
    31	  });
    32	}
    33	
    34	function validateEnvelope(errors, payload, symbol) {
    35	  if (!payload || typeof payload !== "object") {
    36	    pushError(errors, `${symbol}: payload not object.`);
    37	    return;
    38	  }
    39	  if (payload.feature !== "marketphase") {
    40	    pushError(errors, `${symbol}: feature must be marketphase.`);
    41	  }
    42	  if (typeof payload.ok !== "boolean") {
    43	    pushError(errors, `${symbol}: ok must be boolean.`);
    44	  }
    45	
    46	  const meta = payload.meta || {};
    47	  if (!meta.symbol) pushError(errors, `${symbol}: meta.symbol missing.`);
    48	  if (!meta.generatedAt) pushError(errors, `${symbol}: meta.generatedAt missing.`);
    49	  if (!meta.status) pushError(errors, `${symbol}: meta.status missing.`);
    50	  if (!meta.version) pushError(errors, `${symbol}: meta.version missing.`);
    51	  if (!meta.legal || meta.legal !== LEGAL_TEXT) {
    52	    pushError(errors, `${symbol}: meta.legal missing or mismatched.`);
    53	  }
    54	
    55	  const data = payload.data || {};
    56	  if (!data.features || typeof data.features !== "object") {
    57	    pushError(errors, `${symbol}: data.features missing.`);
    58	  } else {
    59	    if (!("RSI" in data.features)) pushError(errors, `${symbol}: features.RSI missing.`);
    60	    if (!("MACDHist" in data.features)) pushError(errors, `${symbol}: features.MACDHist missing.`);
    61	    if (!("ATR%" in data.features)) pushError(errors, `${symbol}: features.ATR% missing.`);
    62	    if (!("SMA50" in data.features)) pushError(errors, `${symbol}: features.SMA50 missing.`);
    63	    if (!("SMA200" in data.features)) pushError(errors, `${symbol}: features.SMA200 missing.`);
    64	    if (!("SMATrend" in data.features)) pushError(errors, `${symbol}: features.SMATrend missing.`);
    65	  }
    66	
    67	  const swings = data.swings || {};
    68	  validateSwingList(errors, swings.raw, `${symbol}: swings.raw`);
    69	  validateSwingList(errors, swings.confirmed, `${symbol}: swings.confirmed`);
    70	
    71	  const elliott = data.elliott || {};
    72	  const completed = elliott.completedPattern || {};
    73	  if (typeof completed.valid !== "boolean") {
    74	    pushError(errors, `${symbol}: completedPattern.valid missing.`);
    75	  }
    76	  if (!completed.direction) pushError(errors, `${symbol}: completedPattern.direction missing.`);
    77	  if (!isNumber(completed.confidence0_100)) {
    78	    pushError(errors, `${symbol}: completedPattern.confidence0_100 missing.`);
    79	  }
    80	  if (!completed.rules || typeof completed.rules !== "object") {
    81	    pushError(errors, `${symbol}: completedPattern.rules missing.`);
    82	  }
    83	
    84	  const developing = elliott.developingPattern || {};
    85	  if (!developing.possibleWave) pushError(errors, `${symbol}: developingPattern.possibleWave missing.`);
    86	  if (!isNumber(developing.confidence)) pushError(errors, `${symbol}: developingPattern.confidence missing.`);
    87	  if (!developing.fibLevels || typeof developing.fibLevels !== "object") {
    88	    pushError(errors, `${symbol}: developingPattern.fibLevels missing.`);
    89	  }
    90	
    91	  const uncertainty = elliott.uncertainty || {};
    92	  if (typeof uncertainty.lastSwingConfirmed !== "boolean") {
    93	    pushError(errors, `${symbol}: uncertainty.lastSwingConfirmed missing.`);
    94	  }
    95	  if (!isNumber(uncertainty.alternativeCounts)) {
    96	    pushError(errors, `${symbol}: uncertainty.alternativeCounts missing.`);
    97	  }
    98	  if (!uncertainty.confidenceDecay || typeof uncertainty.confidenceDecay !== "object") {
    99	    pushError(errors, `${symbol}: uncertainty.confidenceDecay missing.`);
   100	  }
   101	
   102	  const fib = data.fib || elliott.fib || {};
   103	  if (!fib.ratios || typeof fib.ratios !== "object") {
   104	    pushError(errors, `${symbol}: fib.ratios missing.`);
   105	  }
   106	  if (!isNumber(fib.conformanceScore)) {
   107	    pushError(errors, `${symbol}: fib.conformanceScore missing.`);
   108	  }
   109	
   110	  if (!("multiTimeframeAgreement" in data)) {
   111	    pushError(errors, `${symbol}: multiTimeframeAgreement missing.`);
   112	  }
   113	  if (!data.disclaimer || data.disclaimer !== LEGAL_TEXT) {
   114	    pushError(errors, `${symbol}: data.disclaimer missing or mismatched.`);
   115	  }
   116	}
   117	
   118	async function loadSymbols() {
   119	  const envSymbols = process.env.SYMBOLS;
   120	  if (envSymbols) {
   121	    return envSymbols
   122	      .split(",")
   123	      .map((symbol) => symbol.trim().toUpperCase())
   124	      .filter(Boolean);
   125	  }
   126	  const indexPath = path.join(DATA_DIR, "index.json");
   127	  const raw = await fs.readFile(indexPath, "utf8");
   128	  const payload = JSON.parse(raw);
   129	  const symbols = payload?.data?.symbols || [];
   130	  return symbols
   131	    .map((entry) => entry.symbol)
   132	    .filter(Boolean)
   133	    .map((symbol) => symbol.toUpperCase());
   134	}
   135	
   136	async function main() {
   137	  const symbols = await loadSymbols();
   138	  if (!symbols.length) {
   139	    throw new Error("No symbols found for validation.");
   140	  }
   141	  const errors = [];
   142	  for (const symbol of symbols) {
   143	    const filePath = path.join(DATA_DIR, `${symbol}.json`);
   144	    const raw = await fs.readFile(filePath, "utf8");
   145	    const payload = JSON.parse(raw);
   146	    validateEnvelope(errors, payload, symbol);
   147	  }
   148	
   149	  if (errors.length) {
   150	    console.error("MarketPhase validation failed:");
   151	    errors.forEach((err) => console.error(`- ${err}`));
   152	    process.exit(1);
   153	  }
   154	  console.log(`MarketPhase validation OK (${symbols.join(", ")})`);
   155	}
   156	
   157	main().catch((error) => {
   158	  console.error("MarketPhase validation failed:", error.message || error);
   159	  process.exit(1);
   160	});

## FILE: scripts/metrics-v5-gates.mjs
     1	import fs from "node:fs/promises";
     2	import path from "node:path";
     3	import { fileURLToPath } from "node:url";
     4	
     5	const __dirname = path.dirname(fileURLToPath(import.meta.url));
     6	const repoRoot = path.resolve(__dirname, "..");
     7	const baseUrl = process.env.BASE_URL || "http://127.0.0.1:8788";
     8	
     9	function assert(condition, message) {
    10	  if (!condition) throw new Error(message);
    11	}
    12	
    13	function logOk(message) {
    14	  console.log(`OK: ${message}`);
    15	}
    16	
    17	async function loadCatalog() {
    18	  const file = await fs.readFile(path.join(repoRoot, "config/metrics-catalog.json"), "utf8");
    19	  return JSON.parse(file);
    20	}
    21	
    22	async function fetchJson(url) {
    23	  if (typeof fetch !== "function") {
    24	    throw new Error("global fetch is missing (use Node 18+ or enable experimental fetch)");
    25	  }
    26	  try {
    27	    const res = await fetch(url, { headers: { Accept: "application/json" } });
    28	    const text = await res.text();
    29	    return text ? JSON.parse(text) : null;
    30	  } catch (error) {
    31	    const hint = `Fetch failed. Is the dev server running? Try: npm run dev (or set BASE_URL).`;
    32	    throw new Error(`${error?.message || "fetch failed"} - ${hint}`);
    33	  }
    34	}
    35	
    36	function validateEnvelope(payload, catalog) {
    37	  assert(payload && typeof payload === "object", "Envelope missing");
    38	  assert(payload.meta && typeof payload.meta === "object", "meta missing");
    39	  assert("data" in payload, "data key missing");
    40	  assert("error" in payload, "error key missing");
    41	
    42	  const meta = payload.meta;
    43	  assert(["OK", "PARTIAL", "ERROR"].includes(meta.status), "meta.status invalid");
    44	  assert(typeof meta.requestId === "string", "meta.requestId missing");
    45	  assert(typeof meta.asOf === "string", "meta.asOf missing");
    46	  assert(typeof meta.generatedAt === "string", "meta.generatedAt missing");
    47	  assert(typeof meta.ageSeconds === "number", "meta.ageSeconds missing");
    48	  assert(meta.version === "5.0", "meta.version missing");
    49	  assert(meta.cache && typeof meta.cache === "object", "meta.cache missing");
    50	  assert(typeof meta.cache.hit === "boolean", "meta.cache.hit missing");
    51	  assert(typeof meta.cache.ttlSeconds === "number", "meta.cache.ttlSeconds missing");
    52	  assert(typeof meta.cache.kvAvailable === "boolean", "meta.cache.kvAvailable missing");
    53	
    54	  if (meta.status === "ERROR") {
    55	    assert(payload.data === null, "data must be null on ERROR");
    56	    assert(payload.error && payload.error.code, "error missing on ERROR");
    57	    return;
    58	  }
    59	
    60	  assert(payload.data && typeof payload.data === "object", "data missing on OK/PARTIAL");
    61	  const data = payload.data;
    62	  assert(Array.isArray(data.groups), "data.groups missing");
    63	  assert(typeof data.metricsById === "object", "data.metricsById missing");
    64	  assert(Array.isArray(data.signals), "data.signals missing");
    65	  assert(data.uiDefaults, "data.uiDefaults missing");
    66	  assert(Array.isArray(data.uiDefaults.availableUis), "data.uiDefaults.availableUis missing");
    67	
    68	  const metricIds = Object.keys(catalog.metricsCatalog);
    69	  const presentIds = Object.keys(data.metricsById);
    70	  presentIds.forEach((id) => assert(metricIds.includes(id), `Unknown metric id ${id}`));
    71	
    72	  if (meta.status === "OK") {
    73	    assert(meta.metricsCount === 43, "metricsCount should be 43 on OK");
    74	    assert(meta.groupsCount === 9, "groupsCount should be 9 on OK");
    75	    assert(Array.isArray(meta.missingMetricIds), "missingMetricIds missing");
    76	    assert(meta.missingMetricIds.length === 0, "missingMetricIds not empty on OK");
    77	  }
    78	
    79	  if (meta.status === "PARTIAL") {
    80	    assert(meta.metricsCount > 0 && meta.metricsCount < 43, "metricsCount invalid on PARTIAL");
    81	    assert(Array.isArray(meta.missingMetricIds), "missingMetricIds missing on PARTIAL");
    82	    assert(
    83	      meta.missingMetricIds.length === 43 - meta.metricsCount,
    84	      "missingMetricIds length mismatch"
    85	    );
    86	  }
    87	}
    88	
    89	async function run() {
    90	  const catalog = await loadCatalog();
    91	  const payload = await fetchJson(`${baseUrl}/api/metrics?v=5`);
    92	  validateEnvelope(payload, catalog);
    93	  logOk("Structure gate passed");
    94	
    95	  const partialPayload = await fetchJson(`${baseUrl}/api/metrics?v=5&omit=risk.vix`);
    96	  assert(partialPayload.meta.status === "PARTIAL", "Partial gate status mismatch");
    97	  assert(
    98	    partialPayload.meta.missingMetricIds.includes("risk.vix"),
    99	    "Partial gate missing risk.vix"
   100	  );
   101	  logOk("Partial data gate passed");
   102	
   103	  console.log("NOTE: Network gate and renderer consistency require browser verification.");
   104	}
   105	
   106	run().catch((error) => {
   107	  console.error(`FAIL: ${error.message}`);
   108	  process.exit(1);
   109	});

## FILE: scripts/mirror-breakout-energy.mjs
     1	import fs from "node:fs";
     2	import path from "node:path";
     3	import { US_TOP_100 } from "../functions/api/_shared/us-universes.js";
     4	import { createBudgetState, createUsageCollector, loadBudgetsConfig } from "./_lib/usage.js";
     5	import { fetchStooqDaily } from "./providers/stooq.js";
     6	import { fetchAlphaVantageDaily } from "./providers/alphavantage.js";
     7	import { acquireLock, releaseLock } from "./_lib/lock.js";
     8	
     9	const CF_ACCOUNT_ID = process.env.CF_ACCOUNT_ID || "";
    10	const CF_KV_NAMESPACE_ID = process.env.CF_KV_NAMESPACE_ID || "";
    11	const CF_API_TOKEN = process.env.CF_API_TOKEN || "";
    12	const IS_CI = process.env.GITHUB_ACTIONS === "true";
    13	const KV_KEY = "breakout-energy";
    14	const LIMIT = Number.parseInt(process.env.MIRROR_LIMIT || "35", 10);
    15	const MAX_SYMBOLS = Number.isFinite(LIMIT) && LIMIT > 0 ? LIMIT : 35;
    16	const OUT_DIRS = ["mirrors"];
    17	const OUT_FILE = "breakout-energy.json";
    18	
    19	const MIRROR_REASON = "MIRROR";
    20	const ROOT = process.cwd();
    21	const limits = loadBudgetsConfig(ROOT);
    22	const usage = createUsageCollector(limits);
    23	const budget = createBudgetState(limits, usage);
    24	const stooqCtx = { providerId: "stooq", endpoint: "daily", usage, budget };
    25	const avCtx = { providerId: "alphavantage", endpoint: "daily", usage, budget };
    26	
    27	function isHtmlLike(text) {
    28	  const trimmed = String(text || "").trim().toLowerCase();
    29	  return trimmed.startsWith("<!doctype") || trimmed.startsWith("<html");
    30	}
    31	
    32	function isStooqLimit(text) {
    33	  return String(text || "").toLowerCase().includes("exceeded the daily hits limit");
    34	}
    35	
    36	function parseStooqCsv(text) {
    37	  const raw = String(text || "").trim();
    38	  if (!raw || isHtmlLike(raw) || isStooqLimit(raw)) return null;
    39	  const lines = raw.split("\n").map((line) => line.trim()).filter(Boolean);
    40	  if (!lines.length || !lines[0].toLowerCase().startsWith("date,")) return null;
    41	  const last = lines[lines.length - 1];
    42	  const [date, open, high, low, close, volume] = last.split(",");
    43	  return {
    44	    date: date || null,
    45	    open: Number.parseFloat(open || "nan"),
    46	    high: Number.parseFloat(high || "nan"),
    47	    low: Number.parseFloat(low || "nan"),
    48	    close: Number.parseFloat(close || "nan"),
    49	    volume: Number.parseInt(volume || "0", 10) || 0,
    50	    barsUsed: lines.length - 1
    51	  };
    52	}
    53	
    54	async function fetchStooqBar(ctx, symbol) {
    55	  const result = await fetchStooqDaily(ctx, symbol);
    56	  const rows = Array.isArray(result.data) ? result.data.slice() : [];
    57	  rows.sort((a, b) => String(b.date || "").localeCompare(String(a.date || "")));
    58	  const bar = rows[0];
    59	  if (!bar) return null;
    60	  return {
    61	    date: bar.date || null,
    62	    open: bar.open,
    63	    high: bar.high,
    64	    low: bar.low,
    65	    close: bar.close,
    66	    volume: bar.volume,
    67	    barsUsed: rows.length
    68	  };
    69	}
    70	
    71	function buildItem(symbol, bar, provider) {
    72	  return {
    73	    symbol,
    74	    date: bar?.date || null,
    75	    state: "IGNORE",
    76	    score: 0,
    77	    stageScores: { setup: 0, trigger: 0, confirm: 0 },
    78	    signals: [provider],
    79	    meta: {
    80	      universe: "sp500",
    81	      regime_factor: null,
    82	      cooldown_days_left: null,
    83	      data_quality: "PARTIAL"
    84	    },
    85	    metrics: {
    86	      bbw: null,
    87	      bbw_q20: null,
    88	      natr: null,
    89	      rvol: null,
    90	      vol_dry: null,
    91	      dist_sma200: null,
    92	      breakout_level: null
    93	    },
    94	    debug: {
    95	      barsUsed: bar?.barsUsed || 0,
    96	      missingFields: [provider]
    97	    }
    98	  };
    99	}
   100	
   101	async function buildPayload() {
   102	  const symbols = US_TOP_100.map((item) => item.s).filter(Boolean).slice(0, MAX_SYMBOLS);
   103	  const items = [];
   104	  let provider = "MIRROR_STOOQ";
   105	  let stooqFailed = false;
   106	
   107	  for (const symbol of symbols) {
   108	    try {
   109	      const bar = await fetchStooqBar(stooqCtx, symbol);
   110	      if (!bar) throw new Error("Stooq empty");
   111	      items.push(buildItem(symbol, bar, provider));
   112	    } catch (err) {
   113	      stooqFailed = true;
   114	      break;
   115	    }
   116	  }
   117	
   118	  if (stooqFailed) {
   119	    items.length = 0;
   120	    provider = "MIRROR_AV";
   121	    for (const symbol of symbols) {
   122	      let bar = null;
   123	      try {
   124	        const result = await fetchAlphaVantageDaily(avCtx, symbol);
   125	        bar = result?.data || null;
   126	      } catch {
   127	        bar = null;
   128	      }
   129	      if (!bar) continue;
   130	      items.push(buildItem(symbol, bar, provider));
   131	      await new Promise((r) => setTimeout(r, 15000));
   132	    }
   133	  }
   134	
   135	  return {
   136	    items,
   137	    provider,
   138	    symbolsTotal: symbols.length,
   139	    symbolsProcessed: items.length
   140	  };
   141	}
   142	
   143	function writeMirror(wrapper, hasItems) {
   144	  const json = JSON.stringify(wrapper, null, 2);
   145	  const written = [];
   146	  OUT_DIRS.forEach((dir) => {
   147	    fs.mkdirSync(dir, { recursive: true });
   148	    const filePath = path.join(dir, OUT_FILE);
   149	    if (hasItems || !fs.existsSync(filePath)) {
   150	      fs.writeFileSync(filePath, json);
   151	      written.push(filePath);
   152	    }
   153	  });
   154	  written.forEach((filePath) => {
   155	    console.log(`FILE_WRITE_OK ${filePath}`);
   156	  });
   157	  return written;
   158	}
   159	
   160	async function writeKvMirror(wrapper, hasItems) {
   161	  if (!hasItems) {
   162	    console.log("KV_WRITE_SKIP no_items");
   163	    return false;
   164	  }
   165	  if (!CF_ACCOUNT_ID || !CF_KV_NAMESPACE_ID || !CF_API_TOKEN) {
   166	    console.log("KV_WRITE_SKIP missing_secrets");
   167	    return false;
   168	  }
   169	  const key = encodeURIComponent(KV_KEY);
   170	  const kvUrl = `https://api.cloudflare.com/client/v4/accounts/${CF_ACCOUNT_ID}/storage/kv/namespaces/${CF_KV_NAMESPACE_ID}/values/${key}`;
   171	  console.log(`MIRROR_MODE=${IS_CI ? "CI" : "LOCAL"}`);
   172	  console.log(`KV_ENDPOINT=${kvUrl}`);
   173	  let kvRes;
   174	  try {
   175	    kvRes = await fetch(kvUrl, {
   176	      method: "PUT",
   177	      headers: {
   178	        Authorization: `Bearer ${CF_API_TOKEN}`,
   179	        "Content-Type": "application/json"
   180	      },
   181	      body: JSON.stringify(wrapper)
   182	    });
   183	  } catch (err) {
   184	    console.error("KV_WRITE_FAILED", err?.message || String(err));
   185	    process.exit(1);
   186	  }
   187	  if (!kvRes.ok) {
   188	    const body = await kvRes.text();
   189	    let parsed = null;
   190	    try {
   191	      parsed = JSON.parse(body);
   192	    } catch {
   193	      parsed = body.slice(0, 500);
   194	    }
   195	    console.error("KV_WRITE_FAIL", kvRes.status, parsed);
   196	    process.exit(1);
   197	  }
   198	  console.log(`KV_WRITE_OK ${kvRes.status}`);
   199	  return true;
   200	}

## FILE: scripts/ops/build-mission-control-summary.mjs
     1	import fs from 'node:fs/promises';
     2	import path from 'node:path';
     3	
     4	const REPO_ROOT = process.cwd();
     5	const SUMMARY_SCHEMA = 'ops.summary.v1';
     6	const UNIVERSE_ID = 'nasdaq100';
     7	
     8	function isoNow() {
     9	  return new Date().toISOString();
    10	}
    11	
    12	async function readJson(relPath) {
    13	  try {
    14	    const abs = path.join(REPO_ROOT, relPath);
    15	    const raw = await fs.readFile(abs, 'utf-8');
    16	    return JSON.parse(raw);
    17	  } catch {
    18	    return null;
    19	  }
    20	}
    21	
    22	async function atomicWriteJson(relPath, value) {
    23	  const full = path.join(REPO_ROOT, relPath);
    24	  const dir = path.dirname(full);
    25	  await fs.mkdir(dir, { recursive: true });
    26	  const tmp = `${full}.tmp-${Date.now()}`;
    27	  await fs.writeFile(tmp, JSON.stringify(value, null, 2) + '\n', 'utf-8');
    28	  await fs.rename(tmp, full);
    29	}
    30	
    31	function toInt(value, fallback = 0) {
    32	  const n = Number(value);
    33	  return Number.isFinite(n) ? Math.trunc(n) : fallback;
    34	}
    35	
    36	function normalizeCounts(pipelineDoc) {
    37	  const counts = pipelineDoc?.counts || {};
    38	  return {
    39	    expected: toInt(counts.expected ?? pipelineDoc?.expected ?? 0, 0),
    40	    fetched: toInt(counts.fetched ?? pipelineDoc?.fetched ?? 0, 0),
    41	    validated: toInt(counts.validated ?? pipelineDoc?.validated ?? 0, 0),
    42	    computed: toInt(counts.computed ?? pipelineDoc?.computed ?? 0, 0),
    43	    static_ready: toInt(counts.static_ready ?? pipelineDoc?.static_ready ?? 0, 0)
    44	  };
    45	}
    46	
    47	function computeStatus(counts) {
    48	  if (counts.expected > 0 && counts.static_ready >= counts.expected) return 'OK';
    49	  if (counts.expected > 0 && counts.fetched > 0) return 'WARN';
    50	  return 'UNKNOWN';
    51	}
    52	
    53	function buildProviders(opsDaily) {
    54	  const providers = Array.isArray(opsDaily?.baseline?.providers) ? opsDaily.baseline.providers : [];
    55	  const out = {};
    56	  for (const entry of providers) {
    57	    const name = String(entry?.name || '').trim();
    58	    if (!name) continue;
    59	    out[name] = {
    60	      configured: true,
    61	      mode: 'unknown',
    62	      note: null,
    63	      budget: {
    64	        usedMonth: entry?.usedMonth ?? null,
    65	        limitMonth: entry?.limitMonth ?? null,
    66	        remainingMonth: entry?.remainingMonth ?? null,
    67	        remainingPct: entry?.remainingPct ?? null,
    68	        resetDate: entry?.resetDate ?? null,
    69	        runtimeCallsToday: entry?.runtimeCallsToday ?? null
    70	      }
    71	    };
    72	  }
    73	  return out;
    74	}
    75	
    76	function buildCosts(opsDaily) {
    77	  const cloudflare = opsDaily?.baseline?.cloudflare || null;
    78	  return {
    79	    workers: {
    80	      requests_today: cloudflare?.requestsToday ?? null,
    81	      requests_last_24h: cloudflare?.requestsLast24h ?? null
    82	    }
    83	  };
    84	}
    85	
    86	function buildSafety(opsDaily) {
    87	  const safety = opsDaily?.baseline?.safety || null;
    88	  const kvWritesToday = safety?.kvWritesToday ?? null;
    89	  const computedNote = kvWritesToday === null
    90	    ? 'KV tracking not configured'
    91	    : kvWritesToday === 0
    92	      ? 'No KV writes today (read-only mode)'
    93	      : `${kvWritesToday} KV writes today`;
    94	  const note = safety?.note || computedNote;
    95	  return {
    96	    kv_writes_today: kvWritesToday,
    97	    note
    98	  };
    99	}
   100	
   101	async function main() {
   102	  const generatedAt = isoNow();
   103	
   104	  const pipelineLatest = await readJson(`public/data/pipeline/${UNIVERSE_ID}.latest.json`);
   105	  if (!pipelineLatest) {
   106	    throw new Error(`PIPELINE_LATEST_MISSING: public/data/pipeline/${UNIVERSE_ID}.latest.json`);
   107	  }
   108	
   109	  const opsDaily = await readJson('public/data/ops-daily.json');
   110	  const eodManifest = await readJson('public/data/eod/manifest.latest.json');
   111	
   112	  const counts = normalizeCounts(pipelineLatest);
   113	  const status = computeStatus(counts);
   114	
   115	  const reasons = [];
   116	  if (pipelineLatest?.root_failure?.class) {
   117	    reasons.push(`ROOT_FAILURE:${pipelineLatest.root_failure.class}`);
   118	  }
   119	
   120	  const manifestRef = pipelineLatest?.refs?.eod_manifest_ref || '/data/eod/manifest.latest.json';
   121	  const batch0Ref = (() => {
   122	    if (Array.isArray(eodManifest?.chunks) && eodManifest.chunks.length) {
   123	      const first = eodManifest.chunks.find((chunk) => chunk?.chunk_id === '000') || eodManifest.chunks[0];
   124	      if (first?.file) return `/data/${String(first.file).replace(/^\/+/, '')}`;
   125	    }
   126	    return '/data/eod/batches/eod.latest.000.json';
   127	  })();
   128	
   129	  const universe = {
   130	    id: UNIVERSE_ID,
   131	    generated_at: pipelineLatest.generated_at || generatedAt,
   132	    asof: pipelineLatest.generated_at || generatedAt,
   133	    expected: counts.expected,
   134	    fetched: counts.fetched,
   135	    validated: counts.validated,
   136	    computed: counts.computed,
   137	    static_ready: counts.static_ready,
   138	    status,
   139	    refs: {
   140	      pipeline: `/data/pipeline/${UNIVERSE_ID}.latest.json`,
   141	      manifest: manifestRef,
   142	      batch0: batch0Ref
   143	    }
   144	  };
   145	
   146	  const overallStatus = status === 'OK' ? 'OK' : status;
   147	
   148	  const freshness = opsDaily?.baseline?.freshness || {};
   149	  const expectedTradingDay = typeof freshness.expectedTradingDay === 'string' ? freshness.expectedTradingDay : null;
   150	  const staleSymbolsCount = Number.isFinite(Number(freshness.staleCount)) ? Number(freshness.staleCount) : 0;
   151	
   152	  const summary = {
   153	    schema_version: SUMMARY_SCHEMA,
   154	    generated_at: generatedAt,
   155	    asof: opsDaily?.generated_at || opsDaily?.asOf || generatedAt,
   156	    overall: {
   157	      status: overallStatus,
   158	      reasons,
   159	      stale_universes: [],
   160	      stale_symbols_count: staleSymbolsCount,
   161	      expected_trading_day: expectedTradingDay
   162	    },
   163	    universes: [universe],
   164	    providers: buildProviders(opsDaily),
   165	    ops_daily: {
   166	      generated_at: opsDaily?.generated_at || opsDaily?.asOf || null,
   167	      ref: '/data/ops-daily.json'
   168	    },
   169	    costs: buildCosts(opsDaily),
   170	    safety: buildSafety(opsDaily)
   171	  };
   172	
   173	  await atomicWriteJson('public/data/ops/summary.latest.json', summary);
   174	  process.stdout.write(`OK: ops summary generated (status=${overallStatus})\n`);
   175	}
   176	
   177	main().catch((err) => {
   178	  process.stderr.write(`FAIL: ${err.stack || err.message || String(err)}\n`);
   179	  process.exit(1);
   180	});

## FILE: scripts/ops/build-ops-daily.mjs
     1	import fs from 'node:fs/promises';
     2	import path from 'node:path';
     3	
     4	const REPO_ROOT = process.cwd();
     5	
     6	function isoNow() {
     7	  return new Date().toISOString();
     8	}
     9	
    10	function lastTradingDayIso(date = new Date()) {
    11	  const d = new Date(Date.UTC(date.getUTCFullYear(), date.getUTCMonth(), date.getUTCDate()));
    12	  const dow = d.getUTCDay();
    13	  if (dow === 0) d.setUTCDate(d.getUTCDate() - 2);
    14	  if (dow === 6) d.setUTCDate(d.getUTCDate() - 1);
    15	  return d.toISOString().slice(0, 10);
    16	}
    17	
    18	async function readJson(relPath, fallback = null) {
    19	  try {
    20	    const p = path.join(REPO_ROOT, relPath);
    21	    const raw = await fs.readFile(p, 'utf-8');
    22	    return JSON.parse(raw);
    23	  } catch {
    24	    return fallback;
    25	  }
    26	}
    27	
    28	async function readJsonOptional(relPath) {
    29	  return readJson(relPath, null);
    30	}
    31	
    32	async function atomicWriteJson(relPath, value) {
    33	  const full = path.join(REPO_ROOT, relPath);
    34	  const dir = path.dirname(full);
    35	  await fs.mkdir(dir, { recursive: true });
    36	  const tmp = `${full}.tmp-${Date.now()}`;
    37	  await fs.writeFile(tmp, JSON.stringify(value, null, 2) + '\n', 'utf-8');
    38	  await fs.rename(tmp, full);
    39	}
    40	
    41	function isLegacyPipelineDoc(doc) {
    42	  return doc && typeof doc === 'object' && typeof doc.universe === 'string' && 'expected' in doc && 'count' in doc && 'missing' in doc;
    43	}
    44	
    45	function isPipelineLatestDoc(doc) {
    46	  return doc
    47	    && typeof doc === 'object'
    48	    && doc.type === 'pipeline.truth'
    49	    && typeof doc.universe === 'string'
    50	    && doc.counts
    51	    && typeof doc.counts === 'object';
    52	}
    53	
    54	function toIntOrNull(v) {
    55	  const n = Number(v);
    56	  return Number.isFinite(n) ? Math.trunc(n) : null;
    57	}
    58	
    59	async function readLegacyPipelineTruth(relPath) {
    60	  const doc = await readJson(relPath, null);
    61	  if (!doc) {
    62	    return { ok: false, doc: null, reason: 'PIPELINE_TRUTH_FILE_NOT_FOUND' };
    63	  }
    64	  if (!isLegacyPipelineDoc(doc)) {
    65	    return { ok: false, doc: null, reason: 'PIPELINE_TRUTH_INVALID_SCHEMA' };
    66	  }
    67	  return { ok: true, doc, reason: null };
    68	}
    69	
    70	async function readPipelineLatest(relPath) {
    71	  const doc = await readJson(relPath, null);
    72	  if (!doc) {
    73	    return { ok: false, doc: null, reason: 'PIPELINE_LATEST_FILE_NOT_FOUND' };
    74	  }
    75	  if (!isPipelineLatestDoc(doc)) {
    76	    return { ok: false, doc: null, reason: 'PIPELINE_LATEST_INVALID_SCHEMA' };
    77	  }
    78	  return { ok: true, doc, reason: null };
    79	}
    80	
    81	function toNumberOrNull(v) {
    82	  const n = Number(v);
    83	  return Number.isFinite(n) ? n : null;
    84	}
    85	
    86	function normalizeStageCount(count, truthDoc, expected) {
    87	  const value = toIntOrNull(count);
    88	  if (value === 0 && Number.isFinite(expected) && expected > 0) {
    89	    const missing = Array.isArray(truthDoc?.missing) ? truthDoc.missing.length : 0;
    90	    if (missing >= expected) return null;
    91	  }
    92	  return value;
    93	}
    94	
    95	function resolveStageOrLatest(stageDoc, expected, latestValue) {
    96	  const latestNum = toIntOrNull(latestValue);
    97	  if (Number.isFinite(latestNum)) return latestNum;
    98	  if (!stageDoc || typeof stageDoc !== 'object') return null;
    99	  const stageNum = normalizeStageCount(stageDoc.count, stageDoc, expected);
   100	  return Number.isFinite(stageNum) ? stageNum : null;
   101	}
   102	
   103	async function fetchCloudflareWorkerRequests({ accountId, apiToken }) {
   104	  if (!accountId || !apiToken) {
   105	    return {
   106	      requestsToday: null,
   107	      requestsLast24h: null,
   108	      notes: 'CF analytics not configured'
   109	    };
   110	  }
   111	
   112	  const endpoint = 'https://api.cloudflare.com/client/v4/graphql';
   113	  const now = new Date();
   114	  const startToday = new Date(Date.UTC(now.getUTCFullYear(), now.getUTCMonth(), now.getUTCDate()));
   115	  const start24h = new Date(now.getTime() - 24 * 60 * 60 * 1000);
   116	
   117	  const query = `query($accountTag: String!, $startToday: DateTime!, $start24h: DateTime!, $end: DateTime!) {
   118	    viewer {
   119	      accounts(filter: { accountTag: $accountTag }) {
   120	        workersInvocationsAdaptiveGroups(
   121	          limit: 1,
   122	          filter: { datetime_geq: $startToday, datetime_leq: $end }
   123	        ) {
   124	          sum { requests }
   125	        }
   126	        workersInvocationsAdaptiveGroupsLast24h: workersInvocationsAdaptiveGroups(
   127	          limit: 1,
   128	          filter: { datetime_geq: $start24h, datetime_leq: $end }
   129	        ) {
   130	          sum { requests }
   131	        }
   132	      }
   133	    }
   134	  }`;
   135	
   136	  try {
   137	    const res = await fetch(endpoint, {
   138	      method: 'POST',
   139	      headers: {
   140	        'content-type': 'application/json',
   141	        authorization: `Bearer ${apiToken}`
   142	      },
   143	      body: JSON.stringify({
   144	        query,
   145	        variables: {
   146	          accountTag: accountId,
   147	          startToday: startToday.toISOString(),
   148	          start24h: start24h.toISOString(),
   149	          end: now.toISOString()
   150	        }
   151	      })
   152	    });
   153	
   154	    if (!res.ok) {
   155	      return {
   156	        requestsToday: null,
   157	        requestsLast24h: null,
   158	        notes: `CF analytics query failed (HTTP ${res.status})`
   159	      };
   160	    }
   161	
   162	    const payload = await res.json();
   163	    const account = payload?.data?.viewer?.accounts?.[0];
   164	    const today = account?.workersInvocationsAdaptiveGroups?.[0]?.sum?.requests;
   165	    const last24h = account?.workersInvocationsAdaptiveGroupsLast24h?.[0]?.sum?.requests;
   166	
   167	    return {
   168	      requestsToday: toNumberOrNull(today),
   169	      requestsLast24h: toNumberOrNull(last24h),
   170	      notes: 'ok'
   171	    };
   172	  } catch (e) {
   173	    return {
   174	      requestsToday: null,
   175	      requestsLast24h: null,
   176	      notes: `CF analytics query error: ${String(e?.message || e)}`
   177	    };
   178	  }
   179	}
   180	
   181	function buildProvidersBaseline(usageReport) {
   182	  const providers = usageReport?.providers && typeof usageReport.providers === 'object'
   183	    ? usageReport.providers
   184	    : {};
   185	  const limits = usageReport?.limits && typeof usageReport.limits === 'object'
   186	    ? usageReport.limits
   187	    : {};
   188	
   189	  const names = new Set([
   190	    ...Object.keys(providers),
   191	    ...Object.keys(limits)
   192	  ]);
   193	
   194	  const out = Array.from(names).map((name) => {
   195	    const entry = providers[name] || {};
   196	    const daily = entry?.daily || {};
   197	    const monthly = entry?.monthly || {};
   198	    const limitCfg = limits[name] || {};
   199	
   200	    const usedToday = toNumberOrNull(daily.used);

## FILE: scripts/ops/build-safety-snapshot.mjs
     1	import fs from 'node:fs/promises';
     2	import path from 'node:path';
     3	
     4	import { writeJsonAtomic } from '../lib/fs-atomic.mjs';
     5	
     6	const REPO_ROOT = process.cwd();
     7	const LOCK_DIR = path.join(REPO_ROOT, 'mirrors', '.locks');
     8	const OUT_PATH = path.join(REPO_ROOT, 'public', 'data', 'ops', 'safety.latest.json');
     9	
    10	function isoNow() {
    11	  return new Date().toISOString();
    12	}
    13	
    14	async function readJsonSafe(filePath) {
    15	  try {
    16	    const raw = await fs.readFile(filePath, 'utf-8');
    17	    return JSON.parse(raw);
    18	  } catch {
    19	    return null;
    20	  }
    21	}
    22	
    23	function isActiveLock(lock, nowMs) {
    24	  if (!lock || typeof lock !== 'object') return false;
    25	  const expiresAt = lock.expiresAt ? Date.parse(lock.expiresAt) : null;
    26	  return Number.isFinite(expiresAt) && expiresAt > nowMs;
    27	}
    28	
    29	async function main() {
    30	  const generatedAt = isoNow();
    31	  let files = [];
    32	  try {
    33	    files = await fs.readdir(LOCK_DIR);
    34	  } catch {
    35	    files = [];
    36	  }
    37	
    38	  const nowMs = Date.now();
    39	  const locks = [];
    40	  for (const file of files) {
    41	    if (!file.endsWith('.json')) continue;
    42	    const full = path.join(LOCK_DIR, file);
    43	    const lock = await readJsonSafe(full);
    44	    if (!lock) continue;
    45	    locks.push({ file, lock });
    46	  }
    47	
    48	  const active = locks.filter(({ lock }) => isActiveLock(lock, nowMs));
    49	  const activeLocks = active.length;
    50	
    51	  const samples = active
    52	    .slice(0, 5)
    53	    .map(({ file, lock }) => ({
    54	      file,
    55	      provider: lock?.provider || null,
    56	      dataset: lock?.dataset || null,
    57	      expiresAt: lock?.expiresAt || null
    58	    }));
    59	
    60	  const note = files.length === 0
    61	    ? 'No lock directory or empty; assuming no active locks'
    62	    : activeLocks === 0
    63	      ? 'No active locks'
    64	      : `Active locks: ${activeLocks}`;
    65	
    66	  const payload = {
    67	    schema_version: '1.0',
    68	    generated_at: generatedAt,
    69	    activeLocks,
    70	    totalLocks: locks.length,
    71	    samples,
    72	    kvWritesToday: activeLocks,
    73	    note
    74	  };
    75	
    76	  await writeJsonAtomic(OUT_PATH, payload);
    77	  process.stdout.write(`OK: safety snapshot generated (activeLocks=${activeLocks})\n`);
    78	}
    79	
    80	main().catch((err) => {
    81	  process.stderr.write(`FAIL: ${err.stack || err.message || String(err)}\n`);
    82	  process.exit(1);
    83	});

## FILE: scripts/ops/env.config.mjs
     1	export function getOpsBase() {
     2	  const candidates = {
     3	    OPS_BASE: process.env.OPS_BASE,
     4	    RV_BASE: process.env.RV_BASE,
     5	    BASE_URL: process.env.BASE_URL,
     6	    BASE: process.env.BASE
     7	  };
     8	
     9	  const order = ['OPS_BASE', 'RV_BASE', 'BASE_URL', 'BASE'];
    10	  const chosenKey = order.find((key) => {
    11	    const value = candidates[key];
    12	    return typeof value === 'string' && value.trim().length > 0;
    13	  });
    14	
    15	  if (!chosenKey) {
    16	    const summary = Object.fromEntries(order.map((key) => [key, Boolean(candidates[key])]));
    17	    throw new Error(`OPS_BASE missing. Provide OPS_BASE/RV_BASE/BASE_URL/BASE. ${JSON.stringify(summary)}`);
    18	  }
    19	
    20	  const value = String(candidates[chosenKey]).trim();
    21	  return value.replace(/\/+$/, '');
    22	}
    23	

## FILE: scripts/ops/fetch-with-context.mjs
     1	function maskSensitive(input) {
     2	  if (!input) return '';
     3	  let out = String(input);
     4	  out = out.replace(/token=([A-Za-z0-9._-]+)/gi, 'token=***');
     5	  out = out.replace(/authorization:\s*bearer\s+[A-Za-z0-9._-]+/gi, 'authorization: bearer ***');
     6	  return out;
     7	}
     8	
     9	function collapseWhitespace(input) {
    10	  return String(input).replace(/\s+/g, ' ').trim();
    11	}
    12	
    13	export async function fetchWithContext(url, opts = {}, ctx = {}) {
    14	  const start = Date.now();
    15	  try {
    16	    const res = await fetch(url, { cache: 'no-store', ...opts });
    17	    if (!res.ok) {
    18	      const raw = await res.text().catch(() => '');
    19	      const masked = maskSensitive(raw);
    20	      const snippet = collapseWhitespace(masked).slice(0, 300);
    21	      const ms = Date.now() - start;
    22	      const err = new Error(`HTTP ${res.status} ${res.statusText || ''} (${ms}ms) ${snippet}`.trim());
    23	      err.status = res.status;
    24	      err.url = url;
    25	      throw err;
    26	    }
    27	    return res;
    28	  } catch (err) {
    29	    const ms = Date.now() - start;
    30	    const payload = {
    31	      type: 'TEST_FETCH_FAIL',
    32	      url,
    33	      ms,
    34	      ctx,
    35	      env: {
    36	        OPS_BASE: process.env.OPS_BASE || null,
    37	        RV_BASE: process.env.RV_BASE || null,
    38	        BASE_URL: process.env.BASE_URL || null,
    39	        BASE: process.env.BASE || null,
    40	        CI: process.env.CI || null
    41	      },
    42	      err: err?.stack || err?.message || String(err)
    43	    };
    44	
    45	    const jsonLog = process.env.CI === 'true' || process.env.CI === '1' || process.env.RV_LOG_JSON === '1';
    46	    if (jsonLog) {
    47	      console.error(JSON.stringify(payload, null, 2));
    48	    } else {
    49	      console.error('TEST_FETCH_FAIL');
    50	      console.error(`url: ${url}`);
    51	      console.error(`ms: ${ms}`);
    52	      console.error(`ctx: ${JSON.stringify(ctx)}`);
    53	      console.error(`env: ${JSON.stringify(payload.env)}`);
    54	      console.error(`err: ${payload.err}`);
    55	    }
    56	
    57	    throw err;
    58	  }
    59	}
    60	

## FILE: scripts/ops/rv_contract_asserts.jq
     1	# Common helpers
     2	
     3	def is_obj: type == "object";
     4	def is_str: type == "string" and length > 0;
     5	def is_bool: type == "boolean";
     6	def has_str($k): (.[$k] | is_str);
     7	def has_bool($k): (.[$k] | is_bool);
     8	
     9	def manifest_assert:
    10	  is_obj and has_str("schema_version") and has_str("build_id") and has_str("manifest_ref");
    11	
    12	def mission_control_assert:
    13	  is_obj
    14	  and .schema_version == "3.0"
    15	  and (.meta.status | is_str)
    16	  and (.data.opsBaseline | is_obj)
    17	  and (.data.opsBaseline.truthChain | is_obj)
    18	  and ((.data.opsBaseline.truthChain.nasdaq100.steps | type) == "array")
    19	  and ((.data.opsBaseline.truthChain.nasdaq100.steps | length) >= 6)
    20	  and ((.data.opsBaseline.truthChain.nasdaq100.first_blocker | type) == "object" or .data.opsBaseline.truthChain.nasdaq100.first_blocker == null)
    21	  and (.data.opsBaseline.runtime.schedulerExpected | is_bool)
    22	  and (.data.opsBaseline.runtime.schedulerExpectedReason | is_str);
    23	
    24	def debug_probe_assert($module):
    25	  is_obj
    26	  and ((.schema_version | type) == "string" or .schema_version == null)
    27	  and (.debug == true)
    28	  and (.module == $module)
    29	  and ((.served_from | type) == "string")
    30	  and (.served_from == "ASSET" or .served_from == "RUNTIME" or .served_from == "KV" or .served_from == "MAINTENANCE")
    31	  and ((.asset_status | type) == "string")
    32	  and (.asset_status == "HIT" or .asset_status == "MISS" or .asset_status == "ERROR")
    33	  and (.proof_chain | is_obj)
    34	  and (.proof_summary | is_str)
    35	  and (.ok | type == "boolean")
    36	  and (.meta.status | is_str);
    37	
    38	def render_plan_asset_assert:
    39	  is_obj
    40	  and (.schema_version | is_str)
    41	  and (.schema_version == "3.0");
    42	
    43	def render_plan_snapshot_assert:
    44	  is_obj
    45	  and (.schema_version | is_str)
    46	  and (.schema_version == "3.0");
    47	
    48	def render_plan_state_assert:
    49	  is_obj
    50	  and (.schema_version | is_str)
    51	  and (.schema_version == "3.0")
    52	  and ((.module | type) == "string")
    53	  and (.module == "render-plan")
    54	  and ((.status | type) == "string")
    55	  and (.status == "ok");
    56	
    57	def run($mode; $module):
    58	  if $mode == "manifest" then manifest_assert
    59	  elif $mode == "mission_control" then mission_control_assert
    60	  elif $mode == "debug_probe" then debug_probe_assert($module)
    61	  elif $mode == "render_plan_asset" then render_plan_asset_assert
    62	  elif $mode == "render_plan_snapshot" then render_plan_snapshot_assert
    63	  elif $mode == "render_plan_state" then render_plan_state_assert
    64	  else false
    65	  end;
    66	
    67	run($mode; $module)

## FILE: scripts/ops/rv_verify_contracts.sh
     1	#!/usr/bin/env bash
     2	set -euo pipefail
     3	
     4	PROD_BASE="${PROD_BASE:-https://rubikvault.com}"
     5	PREVIEW_BASE="${PREVIEW_BASE:-}"
     6	ASSERTS="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)/rv_contract_asserts.jq"
     7	
     8	if ! command -v curl >/dev/null 2>&1; then
     9	  echo "FAIL: curl not found" >&2
    10	  exit 2
    11	fi
    12	if ! command -v jq >/dev/null 2>&1; then
    13	  echo "FAIL: jq not found" >&2
    14	  exit 2
    15	fi
    16	
    17	fail_count=0
    18	
    19	pass() { echo "PASS: $*"; }
    20	warn() { echo "WARN: $*"; }
    21	fail() { echo "FAIL: $*"; fail_count=$((fail_count+1)); }
    22	
    23	fetch_json() {
    24	  local url="$1"
    25	  curl -fsS --max-time 20 "$url"
    26	}
    27	
    28	assert_jq() {
    29	  local mode="$1"
    30	  local module="$2"
    31	  local json="$3"
    32	  echo "$json" | jq -e -f "$ASSERTS" --arg mode "$mode" --arg module "$module" >/dev/null
    33	}
    34	
    35	check_endpoint() {
    36	  local base="$1"
    37	  local label="$2"
    38	  local path="$3"
    39	  local mode="$4"
    40	  local module="${5:-}"
    41	  local url="${base%/}${path}"
    42	  local json
    43	  if ! json=$(fetch_json "$url"); then
    44	    fail "$label $path fetch failed"
    45	    return
    46	  fi
    47	  if assert_jq "$mode" "$module" "$json"; then
    48	    pass "$label $path"
    49	  else
    50	    fail "$label $path contract assert failed"
    51	  fi
    52	}
    53	
    54	run_checks() {
    55	  local base="$1"
    56	  local label="$2"
    57	  echo "== $label ($base) =="
    58	  check_endpoint "$base" "$label" "/data/manifest.json" "manifest"
    59	  check_endpoint "$base" "$label" "/api/mission-control/summary" "mission_control"
    60	  check_endpoint "$base" "$label" "/api/health?debug=1" "debug_probe" "health"
    61	  check_endpoint "$base" "$label" "/api/render-plan?debug=1" "debug_probe" "render-plan"
    62	  check_endpoint "$base" "$label" "/data/render-plan.json" "render_plan_asset"
    63	  check_endpoint "$base" "$label" "/data/snapshots/render-plan/latest.json" "render_plan_snapshot"
    64	  check_endpoint "$base" "$label" "/data/state/modules/render-plan.json" "render_plan_state"
    65	  echo
    66	}
    67	
    68	run_checks "$PROD_BASE" "PROD"
    69	if OPS_BASE="${PROD_BASE%/}" node scripts/ops/rv_verify_truth_summary.mjs >/dev/null 2>&1; then
    70	  pass "PROD /api/mission-control/summary truth summary"
    71	else
    72	  fail "PROD /api/mission-control/summary truth summary"
    73	fi
    74	
    75	if [ -n "$PREVIEW_BASE" ]; then
    76	  run_checks "$PREVIEW_BASE" "PREVIEW"
    77	  if OPS_BASE="${PREVIEW_BASE%/}" node scripts/ops/rv_verify_truth_summary.mjs >/dev/null 2>&1; then
    78	    pass "PREVIEW /api/mission-control/summary truth summary"
    79	  else
    80	    fail "PREVIEW /api/mission-control/summary truth summary"
    81	  fi
    82	else
    83	  warn "PREVIEW_BASE not set; skipping preview checks"
    84	  echo
    85	fi
    86	
    87	echo "== DIFF (PROD vs PREVIEW) =="
    88	if [ -n "$PREVIEW_BASE" ]; then
    89	  prod_manifest=$(fetch_json "${PROD_BASE%/}/data/manifest.json") || prod_manifest='{}'
    90	  prev_manifest=$(fetch_json "${PREVIEW_BASE%/}/data/manifest.json") || prev_manifest='{}'
    91	  prod_build_id=$(echo "$prod_manifest" | jq -r '.build_id // ""')
    92	  prev_build_id=$(echo "$prev_manifest" | jq -r '.build_id // ""')
    93	  prod_manifest_ref=$(echo "$prod_manifest" | jq -r '.manifest_ref // ""')
    94	  prev_manifest_ref=$(echo "$prev_manifest" | jq -r '.manifest_ref // ""')
    95	
    96	  echo "manifest.build_id: prod=${prod_build_id:-""} preview=${prev_build_id:-""}"
    97	  echo "manifest.manifest_ref: prod=${prod_manifest_ref:-""} preview=${prev_manifest_ref:-""}"
    98	
    99	  prod_mc=$(fetch_json "${PROD_BASE%/}/api/mission-control/summary" || echo '{}')
   100	  prev_mc=$(fetch_json "${PREVIEW_BASE%/}/api/mission-control/summary" || echo '{}')
   101	
   102	  prod_truth_chain=$(echo "$prod_mc" | jq -r '(.data.opsBaseline.truthChain|type) // "missing"')
   103	  prev_truth_chain=$(echo "$prev_mc" | jq -r '(.data.opsBaseline.truthChain|type) // "missing"')
   104	  prod_sched=$(echo "$prod_mc" | jq -r '(.data.opsBaseline.runtime.schedulerExpected|type) // "missing"')
   105	  prev_sched=$(echo "$prev_mc" | jq -r '(.data.opsBaseline.runtime.schedulerExpected|type) // "missing"')
   106	
   107	  echo "truthChain present: prod=${prod_truth_chain} preview=${prev_truth_chain}"
   108	  echo "schedulerExpected present: prod=${prod_sched} preview=${prev_sched}"
   109	else
   110	  warn "DIFF skipped (PREVIEW_BASE not set)"
   111	fi
   112	
   113	echo
   114	if [ "$fail_count" -gt 0 ]; then
   115	  echo "FAIL: $fail_count contract check(s) failed"
   116	  exit 1
   117	fi
   118	
   119	echo "OK: all contract checks passed"

## FILE: scripts/ops/rv_verify_count_provenance.mjs
     1	import { getOpsBase } from './env.config.mjs';
     2	import { fetchWithContext } from './fetch-with-context.mjs';
     3	
     4	function fail(message, context) {
     5	  const err = new Error(message);
     6	  err.context = context;
     7	  throw err;
     8	}
     9	
    10	function toNumberOrNull(value) {
    11	  const n = Number(value);
    12	  return Number.isFinite(n) ? n : null;
    13	}
    14	
    15	function pickBases(args) {
    16	  if (args.length) return args;
    17	  try {
    18	    return [getOpsBase()];
    19	  } catch (err) {
    20	    throw new Error('Missing base URL. Provide as args or set OPS_BASE/RV_BASE/BASE_URL/BASE.');
    21	  }
    22	}
    23	
    24	async function fetchJson(url, name) {
    25	  const res = await fetchWithContext(url, {}, { name });
    26	  return res.json();
    27	}
    28	
    29	async function verifyBase(base) {
    30	  const summaryUrl = `${base}/api/mission-control/summary`;
    31	  const latestUrl = `${base}/data/pipeline/nasdaq100.latest.json`;
    32	
    33	  const [summary, latest] = await Promise.all([
    34	    fetchJson(summaryUrl, 'mission-control-summary'),
    35	    fetchJson(latestUrl, 'pipeline-latest')
    36	  ]);
    37	
    38	  const latestCounts = latest?.counts || {};
    39	  const summaryCounts = summary?.data?.pipeline?.counts || {};
    40	  const summaryLatest = summary?.data?.pipeline?.latest?.counts || {};
    41	  const countSources = summary?.data?.pipeline?.countSources || {};
    42	
    43	  for (const key of ['expected', 'fetched', 'validated', 'computed', 'static_ready']) {
    44	    if (latestCounts[key] == null) continue;
    45	    if (summaryLatest[key] == null) {
    46	      fail(`summary.data.pipeline.latest.counts.${key} missing`, { base, latestCounts, summaryLatest });
    47	    }
    48	  }
    49	
    50	  for (const key of ['fetched', 'validated']) {
    51	    const latestVal = toNumberOrNull(summaryLatest[key]);
    52	    if (latestVal == null) continue;
    53	
    54	    const summaryVal = toNumberOrNull(summaryCounts[key]);
    55	    if (summaryVal == null) {
    56	      fail(`summary.data.pipeline.counts.${key} missing`, {
    57	        base,
    58	        latestCounts,
    59	        summaryCounts,
    60	        summaryLatest,
    61	        countSources
    62	      });
    63	    }
    64	    if (summaryVal !== latestVal) {
    65	      fail(`summary.data.pipeline.counts.${key} mismatch: ${summaryVal} vs ${latestVal}`, {
    66	        base,
    67	        latestCounts,
    68	        summaryCounts,
    69	        summaryLatest,
    70	        countSources
    71	      });
    72	    }
    73	    if (countSources?.[key]?.used !== 'latest') {
    74	      fail(`countSources.${key}.used is not "latest"`, {
    75	        base,
    76	        latestCounts,
    77	        summaryCounts,
    78	        summaryLatest,
    79	        countSources
    80	      });
    81	    }
    82	  }
    83	
    84	  console.log(`OK: count provenance ${base}`);
    85	}
    86	
    87	const bases = pickBases(process.argv.slice(2));
    88	try {
    89	  for (const base of bases) {
    90	    await verifyBase(base);
    91	  }
    92	} catch (err) {
    93	  console.error('FAIL:', err?.message || err);
    94	  if (err?.context) {
    95	    console.error(JSON.stringify(err.context, null, 2));
    96	  }
    97	  process.exit(1);
    98	}

## FILE: scripts/ops/rv_verify_truth_summary.mjs
     1	import { getOpsBase } from './env.config.mjs';
     2	import { fetchWithContext } from './fetch-with-context.mjs';
     3	
     4	const base = getOpsBase();
     5	const summaryUrl = `${base}/api/mission-control/summary`;
     6	const latestUrl = `${base}/data/pipeline/nasdaq100.latest.json`;
     7	
     8	function fail(msg) {
     9	  throw new Error(msg);
    10	}
    11	
    12	const summaryRes = await fetchWithContext(summaryUrl, {}, { name: 'mission-control-summary' });
    13	const summary = await summaryRes.json();
    14	
    15	if (summary?.schema_version !== '3.0') {
    16	  fail(`schema_version mismatch: ${summary?.schema_version}`);
    17	}
    18	if (summary?.meta?.asOf === '') {
    19	  fail('meta.asOf must not be ""');
    20	}
    21	if (typeof summary?.meta?.status !== 'string') {
    22	  fail('meta.status missing');
    23	}
    24	
    25	const health = summary?.data?.health || {};
    26	for (const key of ['platform', 'api', 'prices', 'freshness', 'pipeline']) {
    27	  const status = health?.[key]?.status;
    28	  if (!['OK', 'INFO', 'WARNING', 'CRITICAL'].includes(status)) {
    29	    fail(`health.${key}.status invalid: ${status}`);
    30	  }
    31	}
    32	
    33	const truthChains = summary?.data?.truthChains;
    34	if (!truthChains || typeof truthChains !== 'object') {
    35	  fail('truthChains missing at data.truthChains');
    36	}
    37	const priceTruth = truthChains?.prices;
    38	if (!priceTruth || !Array.isArray(priceTruth.steps)) {
    39	  fail('priceTruth.steps missing');
    40	}
    41	const allowedPriceSteps = new Set([
    42	  'P0_UI_START',
    43	  'P1_UI_CALLS_API',
    44	  'P2_API_RECEIVES_RAW',
    45	  'P3_API_PARSES_VALIDATES',
    46	  'P4_CANONICAL_FORMAT',
    47	  'P5_STATIC_PERSIST',
    48	  'P6_API_CONTRACT',
    49	  'P7_UI_RENDERS'
    50	]);
    51	for (const step of priceTruth.steps) {
    52	  if (!allowedPriceSteps.has(step.id)) {
    53	    fail(`priceTruth step invalid: ${step.id}`);
    54	  }
    55	}
    56	if (priceTruth.first_blocker_id && !allowedPriceSteps.has(priceTruth.first_blocker_id)) {
    57	  fail(`priceTruth first_blocker invalid: ${priceTruth.first_blocker_id}`);
    58	}
    59	
    60	const priceStepMap = Object.fromEntries(priceTruth.steps.map((s) => [s.id, s.status]));
    61	const p6 = priceStepMap.P6_API_CONTRACT;
    62	const p7 = priceStepMap.P7_UI_RENDERS;
    63	if (p6 === 'OK' && p7 === 'OK' && priceTruth.status === 'ERROR') {
    64	  fail('priceTruth.status should not be ERROR when P6 and P7 are OK');
    65	}
    66	if (priceTruth.first_blocker_id && !['P6_API_CONTRACT', 'P7_UI_RENDERS'].includes(priceTruth.first_blocker_id)) {
    67	  fail(`priceTruth first_blocker invalid for Prices chain: ${priceTruth.first_blocker_id}`);
    68	}
    69	
    70	const p6Step = priceTruth.steps.find((s) => s.id === 'P6_API_CONTRACT');
    71	if (!p6Step?.evidence?.checked_path || p6Step.evidence.checked_path !== 'data.latest_bar') {
    72	  fail('P6 evidence.checked_path must be data.latest_bar');
    73	}
    74	if (!Array.isArray(p6Step?.evidence?.required_fields)) {
    75	  fail('P6 evidence.required_fields missing');
    76	}
    77	if (!p6Step?.evidence?.per_ticker || typeof p6Step.evidence.per_ticker !== 'object') {
    78	  fail('P6 evidence.per_ticker missing');
    79	}
    80	const sample = p6Step.evidence.per_ticker.UBER;
    81	if (!sample || !Array.isArray(sample.missing_fields)) {
    82	  fail('P6 evidence.per_ticker.UBER missing_fields invalid');
    83	}
    84	
    85	const runtime = summary?.data?.runtime || {};
    86	if (runtime?.schedulerExpected === false && health?.pipeline?.status === 'CRITICAL') {
    87	  fail('preview pipeline should not be CRITICAL solely due to cron absence');
    88	}
    89	
    90	const latestRes = await fetchWithContext(latestUrl, {}, { name: 'pipeline-latest' });
    91	const latest = await latestRes.json();
    92	const latestCounts = latest?.counts || {};
    93	const summaryCounts = summary?.data?.pipeline?.counts || {};
    94	for (const key of ['expected', 'fetched', 'validated', 'computed', 'static_ready']) {
    95	  if (latestCounts[key] != null) {
    96	    if (summaryCounts[key] == null) {
    97	      fail(`summary pipeline counts.${key} missing`);
    98	    }
    99	    if (Number(summaryCounts[key]) !== Number(latestCounts[key])) {
   100	      fail(`summary counts.${key} mismatch: ${summaryCounts[key]} vs ${latestCounts[key]}`);
   101	    }
   102	  }
   103	}
   104	
   105	const coverageMissing = summary?.data?.coverage?.missing;
   106	if (Number.isFinite(coverageMissing) && coverageMissing > 50) {
   107	  const msg = `Coverage degraded (${coverageMissing} missing)`;
   108	  if (process.env.CI === 'true' || process.env.GITHUB_ACTIONS === 'true') {
   109	    console.warn(`::warning::${msg}`);
   110	  } else {
   111	    console.warn(`WARN: ${msg}`);
   112	  }
   113	}
   114	
   115	console.log('OK: truth summary contract');

## FILE: scripts/ops/test-ops-artifacts.mjs
     1	import { getOpsBase } from './env.config.mjs';
     2	import { fetchWithContext } from './fetch-with-context.mjs';
     3	
     4	const base = getOpsBase();
     5	const latestUrl = `${base}/data/pipeline/nasdaq100.latest.json`;
     6	const truthUrl = `${base}/data/pipeline/nasdaq100.pipeline-truth.json`;
     7	
     8	const latestRes = await fetchWithContext(latestUrl, {}, { name: 'pipeline-latest' });
     9	const truthRes = await fetchWithContext(truthUrl, {}, { name: 'pipeline-truth' });
    10	
    11	const latest = await latestRes.json();
    12	const truth = await truthRes.json();
    13	
    14	const counts = latest?.counts || {};
    15	const expected = Number(counts.expected);
    16	const fetched = Number(counts.fetched);
    17	const validated = Number(counts.validated);
    18	const computed = Number(counts.computed);
    19	const staticReady = Number(counts.static_ready);
    20	
    21	if (!Number.isFinite(expected) || expected !== 100) {
    22	  throw new Error(`expected count must be 100, got ${counts.expected}`);
    23	}
    24	if (!Number.isFinite(fetched) || fetched <= 0) {
    25	  throw new Error(`fetched must be > 0, got ${counts.fetched}`);
    26	}
    27	if (!Number.isFinite(validated) || validated <= 0) {
    28	  throw new Error(`validated must be > 0, got ${counts.validated}`);
    29	}
    30	
    31	const firstBlockerId = truth?.first_blocker_id || truth?.first_blocker?.id;
    32	if (typeof firstBlockerId !== 'string' || firstBlockerId.trim().length === 0) {
    33	  throw new Error('truth.first_blocker_id must be a non-empty string');
    34	}
    35	
    36	const freshnessKeys = ['savedAt', 'publishedAt', 'asOf', 'timestamp'];
    37	const now = Date.now();
    38	for (const key of freshnessKeys) {
    39	  if (Object.prototype.hasOwnProperty.call(latest, key) && latest[key] != null) {
    40	    const value = latest[key];
    41	    const num = Number(value);
    42	    if (!Number.isFinite(num)) {
    43	      throw new Error(`latest.${key} must be a finite number, got ${value}`);
    44	    }
    45	    const cutoff = now - (48 * 60 * 60 * 1000);
    46	    if (num < cutoff) {
    47	      throw new Error(`latest.${key} is older than 48h (${num})`);
    48	    }
    49	  }
    50	}
    51	
    52	console.log(
    53	  `OK ops-artifacts: expected=${expected} fetched=${fetched} validated=${validated} computed=${Number.isFinite(computed) ? computed : ''} static_ready=${Number.isFinite(staticReady) ? staticReady : ''} first_blocker_id=${firstBlockerId}`
    54	);
    55	

## FILE: scripts/ops/test-ops-ui-smoke.mjs
     1	import { getOpsBase } from './env.config.mjs';
     2	import { fetchWithContext } from './fetch-with-context.mjs';
     3	
     4	const base = getOpsBase();
     5	const url = `${base}/ops/`;
     6	
     7	const res = await fetchWithContext(url, {}, { name: 'ops-ui-smoke' });
     8	const html = await res.text();
     9	
    10	if (!html.includes('id="ops-bridge"')) {
    11	  throw new Error('ops UI missing ops-bridge marker');
    12	}
    13	if (html.includes('/ops/pipeline-truth.json')) {
    14	  throw new Error('ops UI references /ops/pipeline-truth.json (should not)');
    15	}
    16	
    17	console.log('OK ops-ui-smoke');

## FILE: scripts/ops/test-ops-ui.mjs
     1	import { chromium, expect } from '@playwright/test';
     2	import { getOpsBase } from './env.config.mjs';
     3	import { fetchWithContext } from './fetch-with-context.mjs';
     4	
     5	const base = getOpsBase();
     6	const opsUrl = `${base}/ops/?debug=1&t=${Date.now()}`;
     7	const latestUrl = `${base}/data/pipeline/nasdaq100.latest.json`;
     8	const truthUrl = `${base}/data/pipeline/nasdaq100.pipeline-truth.json`;
     9	
    10	async function fetchJson(url, ctx) {
    11	  const res = await fetchWithContext(url, {}, ctx);
    12	  return res.json();
    13	}
    14	
    15	function requireNumber(value, label) {
    16	  const n = Number(value);
    17	  if (!Number.isFinite(n)) throw new Error(`Expected numeric ${label}, got ${value}`);
    18	  return n;
    19	}
    20	
    21	function parseFirstInt(text) {
    22	  const match = String(text || '').match(/-?\d+/);
    23	  return match ? Number(match[0]) : NaN;
    24	}
    25	
    26	async function extractBridgeInfo(page) {
    27	  return page.evaluate(() => {
    28	    const bridge = document.querySelector('#ops-bridge');
    29	    return {
    30	      bridge: {
    31	        status: bridge?.getAttribute('data-status') || '',
    32	        baseline: bridge?.getAttribute('data-baseline') || '',
    33	        health: bridge?.getAttribute('data-health') || '',
    34	        fetched: bridge?.getAttribute('data-count-fetched') || '',
    35	        validated: bridge?.getAttribute('data-count-validated') || '',
    36	        computed: bridge?.getAttribute('data-coverage-computed') || '',
    37	        missing: bridge?.getAttribute('data-coverage-missing') || '',
    38	        reason: bridge?.getAttribute('data-reason') || ''
    39	      }
    40	    };
    41	  });
    42	}
    43	
    44	function printForensic(info) {
    45	  console.error('Forensic dump:');
    46	  console.error('Bridge:', info?.bridge || {});
    47	}
    48	
    49	let browser;
    50	try {
    51	  const latestDoc = await fetchJson(latestUrl, { name: 'pipeline-latest' });
    52	  let truthDoc = null;
    53	  try {
    54	    truthDoc = await fetchJson(truthUrl, { name: 'pipeline-truth' });
    55	  } catch (err) {
    56	    console.warn('WARN: pipeline-truth artifact missing; skipping truth-chain UI match');
    57	    truthDoc = null;
    58	  }
    59	
    60	  const latestCounts = latestDoc?.counts || {};
    61	  const expectedFetched = requireNumber(latestCounts.fetched, 'latest.counts.fetched');
    62	  const expectedValidated = requireNumber(latestCounts.validated, 'latest.counts.validated');
    63	
    64	  browser = await chromium.launch();
    65	  const page = await browser.newPage();
    66	  await page.goto(opsUrl, { waitUntil: 'domcontentloaded' });
    67	  const bridge = page.locator('#ops-bridge');
    68	  try {
    69	    await expect(bridge).toHaveAttribute('data-status', /ok|degraded/, { timeout: 20000 });
    70	    await expect(bridge).toHaveAttribute('data-baseline', /ok|pending/, { timeout: 20000 });
    71	  } catch (err) {
    72	    const info = await extractBridgeInfo(page);
    73	    printForensic(info);
    74	    throw new Error('Timeout waiting for ops-bridge readiness');
    75	  }
    76	
    77	  const info = await extractBridgeInfo(page);
    78	  const fetchedUi = parseFirstInt(info.bridge?.fetched);
    79	  const validatedUi = parseFirstInt(info.bridge?.validated);
    80	  if (!Number.isFinite(fetchedUi)) {
    81	    printForensic(info);
    82	    throw new Error(`UI fetched count missing or invalid: "${info.bridge?.fetched}"`);
    83	  }
    84	  if (!Number.isFinite(validatedUi)) {
    85	    printForensic(info);
    86	    throw new Error(`UI validated count missing or invalid: "${info.bridge?.validated}"`);
    87	  }
    88	
    89	  if (fetchedUi !== expectedFetched) {
    90	    printForensic(info);
    91	    throw new Error(`UI fetched vs latest mismatch: got ${fetchedUi}, expected ${expectedFetched}`);
    92	  }
    93	  if (validatedUi !== expectedValidated) {
    94	    printForensic(info);
    95	    throw new Error(`UI validated vs latest mismatch: got ${validatedUi}, expected ${expectedValidated}`);
    96	  }
    97	
    98	  if (truthDoc) {
    99	    const s1Locator = page.locator('[data-step-id="S1"]');
   100	    const s2Locator = page.locator('[data-step-id="S2"]');
   101	    const uiBlocker = await page.getAttribute('#truth-chain-steps', 'data-first-blocker');
   102	
   103	    const truthSteps = Array.isArray(truthDoc?.steps) ? truthDoc.steps : [];
   104	    const truthS1 = truthSteps.find((s) => s.id === 'S1');
   105	    const truthS2 = truthSteps.find((s) => s.id === 'S2');
   106	    const truthBlocker = truthDoc?.first_blocker_id || truthDoc?.first_blocker?.id || null;
   107	
   108	    if (!truthS1 || !truthS2) {
   109	      throw new Error('Truth doc missing S1/S2 steps');
   110	    }
   111	
   112	    await expect(s1Locator).toHaveAttribute('data-step-status', truthS1.status);
   113	    await expect(s2Locator).toHaveAttribute('data-step-status', truthS2.status);
   114	    if (truthBlocker && uiBlocker !== truthBlocker) {
   115	      throw new Error(`First blocker mismatch: UI ${uiBlocker}, truth ${truthBlocker}`);
   116	    }
   117	  }
   118	
   119	  console.log('OK: ops UI matches pipeline latest + truth chain');
   120	  await browser.close();
   121	  process.exit(0);
   122	} catch (err) {
   123	  if (browser) await browser.close();
   124	  console.error('FAIL:', err?.message || err);
   125	  process.exit(1);
   126	}

## FILE: scripts/ops/validate-ops-summary.mjs
     1	import fs from 'node:fs/promises';
     2	import path from 'node:path';
     3	
     4	const REPO_ROOT = process.cwd();
     5	const SUMMARY_SCHEMA = 'ops.summary.v1';
     6	const UNIVERSE_ID = 'nasdaq100';
     7	
     8	function fail(message) {
     9	  throw new Error(message);
    10	}
    11	
    12	async function readJson(relPath) {
    13	  const abs = path.join(REPO_ROOT, relPath);
    14	  const raw = await fs.readFile(abs, 'utf-8');
    15	  return JSON.parse(raw);
    16	}
    17	
    18	function toInt(value) {
    19	  const n = Number(value);
    20	  return Number.isFinite(n) ? Math.trunc(n) : null;
    21	}
    22	
    23	function compareCounts(summaryCounts, pipelineCounts) {
    24	  const fields = ['expected', 'fetched', 'validated', 'computed', 'static_ready'];
    25	  const mismatches = [];
    26	  for (const field of fields) {
    27	    const sVal = toInt(summaryCounts[field]);
    28	    const pVal = toInt(pipelineCounts[field]);
    29	    if (sVal !== pVal) {
    30	      mismatches.push({ field, summary: sVal, pipeline: pVal });
    31	    }
    32	  }
    33	  return mismatches;
    34	}
    35	
    36	async function main() {
    37	  const summary = await readJson('public/data/ops/summary.latest.json');
    38	  const pipeline = await readJson(`public/data/pipeline/${UNIVERSE_ID}.latest.json`);
    39	
    40	  if (summary.schema_version !== SUMMARY_SCHEMA) {
    41	    fail(`summary schema_version mismatch: expected ${SUMMARY_SCHEMA}, got ${summary.schema_version || 'null'}`);
    42	  }
    43	
    44	  const universes = Array.isArray(summary.universes) ? summary.universes : [];
    45	  const universe = universes.find((u) => u && u.id === UNIVERSE_ID);
    46	  if (!universe) {
    47	    fail(`summary missing universe entry: ${UNIVERSE_ID}`);
    48	  }
    49	
    50	  const pipelineCounts = pipeline?.counts || {};
    51	  const summaryCounts = {
    52	    expected: universe.expected,
    53	    fetched: universe.fetched,
    54	    validated: universe.validated,
    55	    computed: universe.computed,
    56	    static_ready: universe.static_ready
    57	  };
    58	
    59	  const expected = toInt(summaryCounts.expected);
    60	  if (!Number.isInteger(expected) || expected <= 0) {
    61	    fail(`summary expected must be > 0 (got ${summaryCounts.expected})`);
    62	  }
    63	
    64	  for (const field of ['fetched', 'validated', 'computed', 'static_ready']) {
    65	    const value = toInt(summaryCounts[field]);
    66	    if (value === null || value < 0) {
    67	      fail(`summary ${field} must be >= 0 (got ${summaryCounts[field]})`);
    68	    }
    69	  }
    70	
    71	  const mismatches = compareCounts(summaryCounts, pipelineCounts);
    72	  if (mismatches.length) {
    73	    const details = mismatches.map((m) => `${m.field} summary=${m.summary} pipeline=${m.pipeline}`).join('; ');
    74	    fail(`summary drift detected: ${details}`);
    75	  }
    76	
    77	  process.stdout.write('OK: ops summary matches pipeline.latest\n');
    78	}
    79	
    80	main().catch((err) => {
    81	  process.stderr.write(`FAIL: ${err.stack || err.message || String(err)}\n`);
    82	  process.exit(1);
    83	});

## FILE: scripts/ops/validate-truth.sh
     1	#!/usr/bin/env bash
     2	set -euo pipefail
     3	
     4	ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")/../.." && pwd)"
     5	DATA="$ROOT/public/data"
     6	
     7	fail() { echo "FAIL: $*" >&2; exit 1; }
     8	pass() { echo "OK: $*"; }
     9	warn() { echo "WARN: $*"; }
    10	
    11	if ! command -v jq >/dev/null 2>&1; then
    12	  fail "jq not found"
    13	fi
    14	
    15	# build-info
    16	if [ ! -f "$DATA/build-info.json" ]; then
    17	  fail "missing public/data/build-info.json"
    18	fi
    19	jq -e '(.git_sha|type=="string" or .git_sha==null) and (.build_time_utc|type=="string")' "$DATA/build-info.json" >/dev/null
    20	pass "build-info.json present"
    21	
    22	# pipeline latest
    23	if [ ! -f "$DATA/pipeline/nasdaq100.latest.json" ]; then
    24	  fail "missing pipeline latest"
    25	fi
    26	jq -e '(.counts.expected|type=="number") and (.counts.fetched|type=="number") and (.counts.validated|type=="number")' "$DATA/pipeline/nasdaq100.latest.json" >/dev/null
    27	pass "pipeline latest counts present"
    28	
    29	# pipeline stage artifacts
    30	for stage in fetched validated computed static-ready; do
    31	  f="$DATA/pipeline/nasdaq100.${stage}.json"
    32	  if [ ! -f "$f" ]; then
    33	    fail "missing pipeline stage ${stage}"
    34	  fi
    35	  jq -e '(.expected|type=="number") and (.count|type=="number") and (.missing|type=="array")' "$f" >/dev/null
    36	  pass "pipeline stage ${stage} schema ok"
    37	 done
    38	
    39	# ops summary
    40	if [ ! -f "$DATA/ops/summary.latest.json" ]; then
    41	  fail "missing ops summary latest"
    42	fi
    43	jq -e '.schema_version=="ops.summary.v1" and (.ops_daily.ref|type=="string")' "$DATA/ops/summary.latest.json" >/dev/null
    44	pass "ops summary schema ok"
    45	
    46	# ops-daily
    47	if [ ! -f "$DATA/ops-daily.json" ]; then
    48	  fail "missing ops-daily"
    49	fi
    50	jq -e '(.baseline.pipeline.expected|type=="number") and (.baseline.pipeline.staticReady|type=="number")' "$DATA/ops-daily.json" >/dev/null
    51	pass "ops-daily baseline pipeline ok"
    52	
    53	# health snapshot latest (envelope)
    54	if [ -f "$DATA/snapshots/health/latest.json" ]; then
    55	  jq -e '(.schema_version=="3.0") and (.metadata|type=="object") and (.data|type=="array")' \
    56	    "$DATA/snapshots/health/latest.json" >/dev/null
    57	  pass "health latest snapshot envelope ok"
    58	else
    59	  warn "missing health latest snapshot envelope"
    60	fi
    61	
    62	# warn-only coverage (non-blocking by design)
    63	missing=$(jq -r '.baseline.pipeline.missing|length' "$DATA/ops-daily.json" 2>/dev/null || echo "")
    64	if [ -n "$missing" ] && [ "$missing" -gt 50 ]; then
    65	  warn "coverage degraded (missing=$missing)"
    66	fi
    67	
    68	pass "truth validation complete"

## FILE: scripts/ops/verify-ops-pipeline.mjs
     1	import fs from 'node:fs/promises';
     2	import path from 'node:path';
     3	
     4	const REPO_ROOT = process.cwd();
     5	const BASE_URL = process.env.VERIFY_BASE_URL || 'http://localhost:8788';
     6	
     7	function fail(msg) {
     8	  throw new Error(msg);
     9	}
    10	
    11	async function readJson(relPath) {
    12	  const abs = path.join(REPO_ROOT, relPath);
    13	  const raw = await fs.readFile(abs, 'utf-8');
    14	  return JSON.parse(raw);
    15	}
    16	
    17	async function fetchWithFallback(primaryUrl, fallbackUrl) {
    18	  const t = Date.now();
    19	  const headers = {
    20	    'Cache-Control': 'no-cache',
    21	    'Pragma': 'no-cache'
    22	  };
    23	
    24	  try {
    25	    const primaryRes = await fetch(`${primaryUrl}?t=${t}`, { headers });
    26	    if (primaryRes.ok) {
    27	      const data = await primaryRes.json();
    28	      return { ok: true, data, source: 'static_summary', url: primaryUrl, status: primaryRes.status };
    29	    }
    30	    if (primaryRes.status !== 404) {
    31	      return { ok: false, source: null, url: primaryUrl, status: primaryRes.status, error: `Primary returned ${primaryRes.status}` };
    32	    }
    33	  } catch (err) {
    34	    console.warn(`Primary fetch failed: ${err.message}`);
    35	  }
    36	
    37	  try {
    38	    const fallbackRes = await fetch(`${fallbackUrl}?t=${t}`, { headers });
    39	    if (fallbackRes.ok) {
    40	      const data = await fallbackRes.json();
    41	      return { ok: true, data, source: 'mission_control_api', url: fallbackUrl, status: fallbackRes.status };
    42	    }
    43	    return { ok: false, source: null, url: fallbackUrl, status: fallbackRes.status, error: `Fallback returned ${fallbackRes.status}` };
    44	  } catch (err) {
    45	    return { ok: false, source: null, url: fallbackUrl, status: null, error: `Fallback fetch error: ${err.message}` };
    46	  }
    47	}
    48	
    49	function assertPipelineTruth(doc) {
    50	  if (!doc || typeof doc !== 'object') fail('pipeline truth doc not an object');
    51	  if (doc.type !== 'pipeline.truth') fail('pipeline truth doc.type must be pipeline.truth');
    52	  if (typeof doc.asOf !== 'string' || !doc.asOf.includes('T')) fail('pipeline truth doc.asOf missing/invalid');
    53	  if (typeof doc.universe !== 'string' || doc.universe !== 'nasdaq100') fail('pipeline truth doc.universe must be nasdaq100');
    54	  if (!Number.isInteger(doc.expected) || doc.expected <= 0) fail('pipeline truth doc.expected must be positive int');
    55	  if (!(doc.count === null || Number.isInteger(doc.count))) fail('pipeline truth doc.count must be int or null');
    56	  if (!Array.isArray(doc.missing)) fail('pipeline truth doc.missing must be array');
    57	  for (const m of doc.missing) {
    58	    if (!m || typeof m !== 'object') fail('pipeline truth missing[] entry not object');
    59	    if (typeof m.ticker !== 'string' || !m.ticker) fail('pipeline truth missing[].ticker invalid');
    60	    if (typeof m.reason !== 'string' || !m.reason) fail('pipeline truth missing[].reason invalid');
    61	  }
    62	  if (doc.count === null) {
    63	    if (!doc.reason || typeof doc.reason !== 'string') fail('pipeline truth count=null requires top-level reason');
    64	    if (doc.missing.length !== 0) fail('pipeline truth count=null must have empty missing[]');
    65	  }
    66	}
    67	
    68	async function main() {
    69	  const required = [
    70	    'public/data/pipeline/nasdaq100.fetched.json',
    71	    'public/data/pipeline/nasdaq100.validated.json',
    72	    'public/data/pipeline/nasdaq100.computed.json',
    73	    'public/data/pipeline/nasdaq100.static-ready.json'
    74	  ];
    75	
    76	  for (const p of required) {
    77	    const doc = await readJson(p);
    78	    assertPipelineTruth(doc);
    79	  }
    80	
    81	  const opsDaily = await readJson('public/data/ops-daily.json');
    82	  const pipeline = opsDaily?.baseline?.pipeline;
    83	  if (!pipeline || typeof pipeline !== 'object') fail('ops-daily baseline.pipeline missing');
    84	
    85	  const staticReady = await readJson('public/data/pipeline/nasdaq100.static-ready.json');
    86	  if (pipeline.expected !== staticReady.expected) fail('ops-daily pipeline.expected must equal pipeline truth expected');
    87	  if (pipeline.staticReady !== staticReady.count) fail('ops-daily pipeline.staticReady must equal pipeline truth count');
    88	  if (!Array.isArray(pipeline.missing)) fail('ops-daily pipeline.missing must be array');
    89	  if (pipeline.missing.length !== staticReady.missing.length) fail('ops-daily pipeline.missing length mismatch');
    90	
    91	  const pipelineLatest = await readJson('public/data/pipeline/nasdaq100.latest.json');
    92	  if (!pipelineLatest?.counts || typeof pipelineLatest.counts !== 'object') {
    93	    fail('pipeline.latest counts missing');
    94	  }
    95	  if (pipelineLatest.counts.expected !== staticReady.expected) {
    96	    fail('pipeline.latest counts.expected must equal pipeline static-ready expected');
    97	  }
    98	  if (pipelineLatest.counts.static_ready !== staticReady.count) {
    99	    fail('pipeline.latest counts.static_ready must equal pipeline static-ready count');
   100	  }
   101	
   102	  if (pipeline.expected > 0 && pipeline.fetched === 0) {
   103	    fail('ops-daily pipeline.fetched=0 with expected>0 indicates empty artifact generation');
   104	  }
   105	
   106	  const html = await fs.readFile(path.join(REPO_ROOT, 'public/ops/index.html'), 'utf-8');
   107	  if (!html.includes('Refresh (LIVE)')) fail('/ops must contain Refresh (LIVE) marker');
   108	  if (!html.includes('/api/mission-control/summary?live=1')) fail('/ops must call mission-control/summary?live=1');
   109	  if (!html.includes('X-OPS-KEY')) fail('/ops must reference X-OPS-KEY');
   110	  if (html.includes('setInterval(')) fail('/ops must not contain setInterval');
   111	  if (html.includes('btn-baseline') || html.includes('btn-live')) fail('/ops must not contain old baseline/live button ids');
   112	
   113	  let summaryResult = await fetchWithFallback(
   114	    `${BASE_URL}/data/ops/summary.latest.json`,
   115	    `${BASE_URL}/api/mission-control/summary`
   116	  );
   117	
   118	  if (!summaryResult.ok) {
   119	    const localPath = path.join(REPO_ROOT, 'public', 'data', 'ops', 'summary.latest.json');
   120	    try {
   121	      const localRaw = await fs.readFile(localPath, 'utf-8');
   122	      const localData = JSON.parse(localRaw);
   123	      summaryResult = { ok: true, data: localData, source: 'local_file', url: localPath, status: 200 };
   124	    } catch (error) {
   125	      fail(`Summary fetch failed: ${summaryResult.error} (status=${summaryResult.status}, url=${summaryResult.url})`);
   126	    }
   127	  }
   128	
   129	  // Schema 3.0 validation (skip when using local summary file)
   130	  const payload = summaryResult.data;
   131	  if (summaryResult.source !== 'local_file') {
   132	    if (payload.schema_version !== '3.0') {
   133	      fail(`mission-control summary must use schema 3.0, got: ${payload.schema_version}`);
   134	    }
   135	    if (!payload.data) fail('mission-control summary missing data property');
   136	    if (!payload.data.opsBaseline) fail('mission-control summary missing data.opsBaseline');
   137	    if (!payload.data.opsBaseline.baseline) fail('mission-control summary missing data.opsBaseline.baseline');
   138	
   139	    const baseline = payload.data.opsBaseline.baseline;
   140	    if (!baseline.pipeline) fail('baseline missing pipeline property');
   141	    if (!baseline.freshness) fail('baseline missing freshness property');
   142	    if (!baseline.providers) fail('baseline missing providers property');
   143	    if (!baseline.safety) fail('baseline missing safety property');
   144	
   145	    if (typeof baseline.pipeline.expected !== 'number') fail('baseline.pipeline.expected must be number');
   146	    if (!Array.isArray(baseline.pipeline.missing)) fail('baseline.pipeline.missing must be array');
   147	    if (!Array.isArray(baseline.providers)) fail('baseline.providers must be array');
   148	  } else {
   149	    if (!payload || typeof payload !== 'object') fail('local ops summary missing payload');
   150	    if (!payload.ops_daily) fail('local ops summary missing ops_daily');
   151	  }
   152	
   153	  process.stdout.write(`OK: ops pipeline truth + wiring verification (summary source=${summaryResult.source}, schema=3.0)\n`);
   154	}
   155	
   156	main().catch((err) => {
   157	  process.stderr.write(`FAIL: ${err.stack || err.message || String(err)}\n`);
   158	  process.exit(1);
   159	});

## FILE: scripts/ops/verify-runblock-e-operational.zsh
     1	#!/usr/bin/env zsh
     2	set -euo pipefail
     3	
     4	BASE_URL="${PROD_BASE:-${BASE_URL:-https://rubikvault.com}}"
     5	ALLOW_NO_COMPUTED_ANALYSIS="${ALLOW_NO_COMPUTED_ANALYSIS:-0}"
     6	
     7	fail() {
     8	  echo "FAIL: $1" >&2
     9	  exit 1
    10	}
    11	
    12	pass() {
    13	  echo "OK: $1"
    14	}
    15	
    16	if ! command -v jq >/dev/null 2>&1; then
    17	  fail "jq is required"
    18	fi
    19	
    20	health_tmp=$(mktemp)
    21	trap 'rm -f "$health_tmp"' EXIT
    22	
    23	curl -fsS "${BASE_URL%/}/api/scheduler/health" > "$health_tmp" || fail "scheduler health fetch failed"
    24	
    25	health_status=$(jq -r '.data.status // empty' "$health_tmp")
    26	if [ -z "$health_status" ]; then
    27	  fail "scheduler health missing data.status"
    28	fi
    29	if [ "$health_status" = "never_ran" ]; then
    30	  fail "scheduler health status is never_ran (prod should be running)"
    31	fi
    32	pass "scheduler health status=${health_status}"
    33	
    34	pipeline_tmp=$(mktemp)
    35	trap 'rm -f "$health_tmp" "$pipeline_tmp"' EXIT
    36	
    37	curl -fsS "${BASE_URL%/}/data/pipeline/nasdaq100.static-ready.json" > "$pipeline_tmp" || fail "pipeline static-ready fetch failed"
    38	
    39	expected=$(jq -r '.expected // 0' "$pipeline_tmp")
    40	count=$(jq -r '.count // 0' "$pipeline_tmp")
    41	
    42	if [ "$count" -lt "$expected" ]; then
    43	  if [ "$ALLOW_NO_COMPUTED_ANALYSIS" = "1" ]; then
    44	    pass "pipeline static-ready below expected but allowed (ALLOW_NO_COMPUTED_ANALYSIS=1)"
    45	  else
    46	    if jq -e '([.missing[]?.reason] | length > 0) and (all(. == "NO_COMPUTED_ANALYSIS"))' "$pipeline_tmp" >/dev/null; then
    47	      fail "pipeline static-ready missing due to NO_COMPUTED_ANALYSIS (count=${count} expected=${expected})"
    48	    else
    49	      pass "pipeline static-ready below expected with mixed reasons (count=${count} expected=${expected})"
    50	    fi
    51	  fi
    52	else
    53	  pass "pipeline static-ready count=${count} expected=${expected}"
    54	fi

## FILE: scripts/ops/verify-runblock1.zsh
     1	#!/usr/bin/env zsh
     2	# verify-runblock1.zsh - Runblock 1 deterministic verification script
     3	# Usage: zsh scripts/ops/verify-runblock1.zsh
     4	#
     5	# This script verifies:
     6	# 1. All expected files exist at correct paths
     7	# 2. Local contract tests pass
     8	# 3. Preview API endpoints return valid envelope JSON
     9	
    10	emulate -L zsh
    11	set -o pipefail
    12	
    13	# 
    14	# Configuration
    15	# 
    16	
    17	PREVIEW_BASE="${PREVIEW_BASE:-https://1e178517.rubikvault-site.pages.dev}"
    18	SCRIPT_DIR="${0:A:h}"
    19	REPO_ROOT="${SCRIPT_DIR:h:h}"
    20	
    21	# Colors
    22	RED='\033[0;31m'
    23	GREEN='\033[0;32m'
    24	YELLOW='\033[0;33m'
    25	BLUE='\033[0;34m'
    26	NC='\033[0m' # No Color
    27	
    28	pass_count=0
    29	fail_count=0
    30	
    31	# 
    32	# Helper Functions
    33	# 
    34	
    35	log_pass() {
    36	  echo "${GREEN} PASS${NC}: $1"
    37	  ((pass_count++))
    38	}
    39	
    40	log_fail() {
    41	  echo "${RED} FAIL${NC}: $1"
    42	  ((fail_count++))
    43	}
    44	
    45	log_skip() {
    46	  echo "${YELLOW}  SKIP${NC}: $1"
    47	}
    48	
    49	log_info() {
    50	  echo "${BLUE}  INFO${NC}: $1"
    51	}
    52	
    53	log_section() {
    54	  echo ""
    55	  echo "${BLUE}${NC}"
    56	  echo "${BLUE}  $1${NC}"
    57	  echo "${BLUE}${NC}"
    58	}
    59	
    60	# 
    61	# Step 1: Verify Expected Files Exist
    62	# 
    63	
    64	verify_files() {
    65	  log_section "Step 1: Verifying Expected Files"
    66	  
    67	  local expected_files=(
    68	    "config/symbols.json"
    69	    "config/symbols.schema.json"
    70	    "scripts/validate-symbols.mjs"
    71	    "scripts/test-envelope.mjs"
    72	    "functions/api/_middleware.js"
    73	    "functions/api/_shared/envelope.js"
    74	    "src/lib/envelope.ts"
    75	    "src/lib/freshness.ts"
    76	    ".github/workflows/ci-gates.yml"
    77	  )
    78	
    79	  local all_found=true
    80	  for file in "${expected_files[@]}"; do
    81	    local full_path="${REPO_ROOT}/${file}"
    82	    if [[ -f "$full_path" ]]; then
    83	      log_pass "Found: $file"
    84	    else
    85	      log_fail "Missing: $file"
    86	      all_found=false
    87	    fi
    88	  done
    89	
    90	  if $all_found; then
    91	    log_pass "All expected files present"
    92	  fi
    93	}
    94	
    95	# 
    96	# Step 2: Run Local Contract Tests
    97	# 
    98	
    99	run_local_tests() {
   100	  log_section "Step 2: Running Local Contract Tests"
   101	  
   102	  cd "$REPO_ROOT" || { log_fail "Could not cd to repo root"; return 1; }
   103	
   104	  # validate:symbols
   105	  log_info "Running npm run validate:symbols..."
   106	  if npm run validate:symbols 2>&1; then
   107	    log_pass "validate:symbols passed"
   108	  else
   109	    log_fail "validate:symbols failed"
   110	  fi
   111	
   112	  # test:envelope
   113	  log_info "Running npm run test:envelope..."
   114	  if npm run test:envelope 2>&1; then
   115	    log_pass "test:envelope passed"
   116	  else
   117	    log_fail "test:envelope failed"
   118	  fi
   119	
   120	  # test:contracts (if exists)
   121	  if grep -q '"test:contracts"' "${REPO_ROOT}/package.json" 2>/dev/null; then
   122	    log_info "Running npm run test:contracts..."
   123	    if npm run test:contracts 2>&1; then
   124	      log_pass "test:contracts passed"
   125	    else
   126	      log_fail "test:contracts failed"
   127	    fi
   128	  else
   129	    log_skip "test:contracts missing (not in package.json)"
   130	  fi
   131	}
   132	
   133	# 
   134	# Step 3: Verify Preview API Envelope Shape
   135	# 
   136	
   137	# Verify a single endpoint returns valid envelope JSON
   138	# Args: $1 = endpoint path (e.g. /api/resolve?debug=1)
   139	#       $2 = expected_ok ("true" or "false" or "any")
   140	#       $3 = debug_check ("cache" to enforce debug cache checks)
   141	verify_envelope() {
   142	  local endpoint="$1"
   143	  local expected_ok="${2:-any}"
   144	  local debug_check="${3:-}"
   145	  local url="${PREVIEW_BASE}${endpoint}"
   146	  
   147	  local tmp_headers=$(mktemp)
   148	  local tmp_body=$(mktemp)
   149	  
   150	  # Fetch with curl
   151	  local http_code
   152	  http_code=$(curl -sSf -D "$tmp_headers" -o "$tmp_body" -w "%{http_code}" --max-time 30 "$url" 2>&1)
   153	  local curl_exit=$?
   154	  
   155	  if [[ $curl_exit -ne 0 ]]; then
   156	    log_fail "Endpoint $endpoint: curl failed (exit $curl_exit)"
   157	    rm -f "$tmp_headers" "$tmp_body"
   158	    return 1
   159	  fi
   160	
   161	  # Check Content-Type
   162	  local content_type
   163	  content_type=$(grep -i "^content-type:" "$tmp_headers" | head -1 | tr -d '\r\n')
   164	  if [[ ! "$content_type" =~ "application/json" ]]; then
   165	    log_fail "Endpoint $endpoint: Content-Type not JSON ($content_type)"
   166	    rm -f "$tmp_headers" "$tmp_body"
   167	    return 1
   168	  fi
   169	
   170	  if [[ "$debug_check" == "cache" ]]; then
   171	    if grep -E "\"cache_key\"|\"swr_key\"" "$tmp_body" >/dev/null 2>&1; then
   172	      log_fail "Endpoint $endpoint: public debug leaked cache_key/swr_key"
   173	      rm -f "$tmp_headers" "$tmp_body"
   174	      return 1
   175	    fi
   176	  fi
   177	
   178	  local jq_err
   179	  jq_err=$(mktemp)
   180	  jq -e --arg expected_ok "$expected_ok" --arg debug_check "$debug_check" '
   181	    def err($msg): ($msg | halt_error(1));
   182	    if (.ok|type)!="boolean" then err("ok is not boolean")
   183	    elif (.meta|type)!="object" then err("meta missing or not object")
   184	    elif (.meta.status|type)!="string" then err("meta.status is not string")
   185	    elif (.meta.generated_at|type)!="string" then err("meta.generated_at is not string")
   186	    elif (.meta.data_date|type)!="string" then err("meta.data_date is not string")
   187	    elif (.meta.data_date=="") then err("meta.data_date is empty (must be YYYY-MM-DD)")
   188	    elif ((.meta.data_date|test("^\\d{4}-\\d{2}-\\d{2}$"))|not) then err("meta.data_date does not match YYYY-MM-DD format")
   189	    elif (.meta.provider|type)!="string" or (.meta.provider|length)==0 then err("meta.provider is not a non-empty string")
   190	    elif (.ok==false and ((.error|type)!="object")) then err("ok=false but error is missing")
   191	    elif (.ok==false and ((.error.code|type)!="string")) then err("ok=false but error.code is missing")
   192	    elif (.ok==false and .meta.status!="error") then err("ok=false but meta.status is not error")
   193	    elif ($debug_check=="cache" and (.meta.cache|type)!="object") then err("meta.cache missing or not object")
   194	    elif ($debug_check=="cache" and (.meta|has("timings")) and (.meta.timings|type)!="object") then err("meta.timings is not object")
   195	    elif ($expected_ok=="true" and .ok!=true) then err("expected ok=true but got ok=" + (.ok|tostring))
   196	    elif ($expected_ok=="false" and .ok!=false) then err("expected ok=false but got ok=" + (.ok|tostring))
   197	    else true end
   198	  ' "$tmp_body" 2>"$jq_err"
   199	
   200	  local jq_exit=$?

## FILE: scripts/ops/verify-truth-artifacts.sh
     1	#!/bin/zsh
     2	# verify-truth-artifacts.sh
     3	# Verifies that required truth artifacts exist locally and/or are served live.
     4	#
     5	# Usage:
     6	#   ./scripts/ops/verify-truth-artifacts.sh           # Check local files only
     7	#   ./scripts/ops/verify-truth-artifacts.sh --live    # Check live URLs (requires BASE env var)
     8	
     9	set -e
    10	
    11	SCRIPT_DIR="$(cd "$(dirname "$0")" && pwd)"
    12	REPO_ROOT="$(cd "$SCRIPT_DIR/../.." && pwd)"
    13	
    14	LOCAL_ARTIFACTS=(
    15	  "public/data/pipeline/missing.json"
    16	  "public/data/pipeline/nasdaq100.pipeline-truth.json"
    17	  "public/data/pipeline/nasdaq100.latest.json"
    18	  "public/data/pipeline/nasdaq100.static-ready.json"
    19	  "public/data/pipeline/nasdaq100.computed.json"
    20	  "public/data/pipeline/nasdaq100.validated.json"
    21	  "public/data/pipeline/nasdaq100.fetched.json"
    22	)
    23	
    24	LIVE_PATHS=(
    25	  "/data/pipeline/missing.json"
    26	  "/data/pipeline/nasdaq100.pipeline-truth.json"
    27	  "/data/pipeline/nasdaq100.latest.json"
    28	  "/data/pipeline/nasdaq100.static-ready.json"
    29	)
    30	
    31	echo "=== Truth Artifacts Verification ==="
    32	
    33	# Local file check
    34	echo ""
    35	echo "Checking local files..."
    36	local_pass=0
    37	local_fail=0
    38	
    39	for artifact in "${LOCAL_ARTIFACTS[@]}"; do
    40	  full_path="$REPO_ROOT/$artifact"
    41	  if [[ -f "$full_path" ]]; then
    42	    size=$(stat -f%z "$full_path" 2>/dev/null || stat --printf="%s" "$full_path" 2>/dev/null || echo "?")
    43	    echo "   $artifact ($size bytes)"
    44	    local_pass=$((local_pass + 1))
    45	  else
    46	    echo "   $artifact (MISSING)"
    47	    local_fail=$((local_fail + 1))
    48	  fi
    49	done
    50	
    51	echo ""
    52	echo "Local: $local_pass passed, $local_fail failed"
    53	
    54	# Live check
    55	if [[ "$1" == "--live" ]]; then
    56	  if [[ -z "$BASE" ]]; then
    57	    echo ""
    58	    echo "ERROR: BASE environment variable required for --live check"
    59	    echo "Example: BASE=https://d90a2286.rubikvault-site.pages.dev ./scripts/ops/verify-truth-artifacts.sh --live"
    60	    exit 1
    61	  fi
    62	
    63	  echo ""
    64	  echo "Checking live URLs at $BASE..."
    65	  live_pass=0
    66	  live_fail=0
    67	
    68	  for path in "${LIVE_PATHS[@]}"; do
    69	    url="${BASE}${path}"
    70	    status=$(curl -s -o /dev/null -w "%{http_code}" "$url" 2>/dev/null || echo "000")
    71	    if [[ "$status" == "200" ]]; then
    72	      echo "   $path (HTTP $status)"
    73	      live_pass=$((live_pass + 1))
    74	    else
    75	      echo "   $path (HTTP $status)"
    76	      live_fail=$((live_fail + 1))
    77	    fi
    78	  done
    79	
    80	  echo ""
    81	  echo "Live: $live_pass passed, $live_fail failed"
    82	  
    83	  if [[ $live_fail -gt 0 ]]; then
    84	    exit 1
    85	  fi
    86	fi
    87	
    88	if [[ $local_fail -gt 0 ]]; then
    89	  exit 1
    90	fi
    91	
    92	echo ""
    93	echo " All checks passed"

## FILE: scripts/ops_selfcheck.mjs
     1	import { getOpsBase } from './ops/env.config.mjs';
     2	import { fetchWithContext } from './ops/fetch-with-context.mjs';
     3	
     4	const base = getOpsBase();
     5	const url = `${base}/api/mission-control/summary`;
     6	
     7	const res = await fetchWithContext(url, {}, { name: 'ops-selfcheck' });
     8	const summary = await res.json();
     9	
    10	const truthChains = summary?.data?.truthChains;
    11	if (!truthChains) {
    12	  throw new Error('truthChains missing at data.truthChains');
    13	}
    14	const prices = truthChains.prices;
    15	const p6 = prices?.steps?.find((s) => s.id === 'P6_API_CONTRACT');
    16	const p6Path = p6?.evidence?.checked_path || null;
    17	
    18	console.log(JSON.stringify({
    19	  base,
    20	  truthChainsKeys: Object.keys(truthChains || {}),
    21	  p6_checked_path: p6Path,
    22	  p6_uber_ok: p6?.evidence?.per_ticker?.UBER?.ok ?? null
    23	}, null, 2));

## FILE: scripts/pipeline/build-marketphase-from-kv.mjs
     1	import fs from "node:fs/promises";
     2	import path from "node:path";
     3	import { execSync } from "node:child_process";
     4	import {
     5	  LEGAL_TEXT,
     6	  analyzeMarketPhase,
     7	  aggregateWeekly
     8	} from "../marketphase-core.mjs";
     9	import { round6, round6Object, round6Array } from "../utils/scientific-math.mjs";
    10	import { createOptionalCloudflareRestKVFromEnv } from "../lib/kv-write.js";
    11	import { fetchBarsWithProviderChain } from "../../functions/api/_shared/eod-providers.mjs";
    12	
    13	const REPO_ROOT = process.cwd();
    14	const DEFAULT_UNIVERSE = "nasdaq100";
    15	const DEFAULT_CONCURRENCY = 3;
    16	const DEFAULT_MIN_BARS = 200;
    17	const DEFAULT_OUTPUTSIZE = 300;
    18	
    19	function toBool(value) {
    20	  const s = String(value || "").trim().toLowerCase();
    21	  return s === "1" || s === "true" || s === "yes" || s === "on";
    22	}
    23	
    24	function isoNow() {
    25	  return new Date().toISOString();
    26	}
    27	
    28	function normalizeTicker(value) {
    29	  return String(value || "").trim().toUpperCase();
    30	}
    31	
    32	async function readJson(relPath) {
    33	  const abs = path.join(REPO_ROOT, relPath);
    34	  const raw = await fs.readFile(abs, "utf-8");
    35	  return JSON.parse(raw);
    36	}
    37	
    38	async function readJsonOptional(relPath) {
    39	  try {
    40	    return await readJson(relPath);
    41	  } catch {
    42	    return null;
    43	  }
    44	}
    45	
    46	async function fileExists(absPath) {
    47	  try {
    48	    await fs.stat(absPath);
    49	    return true;
    50	  } catch {
    51	    return false;
    52	  }
    53	}
    54	
    55	async function writeJson(relPath, payload) {
    56	  const abs = path.join(REPO_ROOT, relPath);
    57	  await fs.mkdir(path.dirname(abs), { recursive: true });
    58	  await fs.writeFile(abs, JSON.stringify(payload, null, 2) + "\n", "utf-8");
    59	}
    60	
    61	function parseArgs(argv) {
    62	  const out = {
    63	    universe: DEFAULT_UNIVERSE,
    64	    outDir: "public/data/marketphase",
    65	    concurrency: DEFAULT_CONCURRENCY,
    66	    minBars: DEFAULT_MIN_BARS,
    67	    outputsize: DEFAULT_OUTPUTSIZE,
    68	    allowProviderFallback: false,
    69	    writeBackKv: false
    70	  };
    71	  for (let i = 0; i < argv.length; i += 1) {
    72	    const arg = argv[i];
    73	    if (arg === "--universe") {
    74	      out.universe = argv[i + 1] || out.universe;
    75	      i += 1;
    76	    } else if (arg === "--out") {
    77	      out.outDir = argv[i + 1] || out.outDir;
    78	      i += 1;
    79	    } else if (arg === "--concurrency") {
    80	      out.concurrency = Number(argv[i + 1]) || out.concurrency;
    81	      i += 1;
    82	    } else if (arg === "--min-bars") {
    83	      out.minBars = Number(argv[i + 1]) || out.minBars;
    84	      i += 1;
    85	    } else if (arg === "--outputsize") {
    86	      out.outputsize = Number(argv[i + 1]) || out.outputsize;
    87	      i += 1;
    88	    } else if (arg === "--allow-provider" || arg === "--provider-fallback") {
    89	      out.allowProviderFallback = true;
    90	    } else if (arg === "--write-kv") {
    91	      out.writeBackKv = true;
    92	    }
    93	  }
    94	  return out;
    95	}
    96	
    97	function extractUniverseTickers(universeJson) {
    98	  if (!Array.isArray(universeJson)) return [];
    99	  return universeJson
   100	    .map((row) => normalizeTicker(row?.ticker ?? row?.symbol ?? row?.code ?? null))
   101	    .filter(Boolean);
   102	}
   103	
   104	function getCommitHash() {
   105	  try {
   106	    return process.env.COMMIT_HASH || execSync("git rev-parse --short HEAD", { encoding: "utf8" }).trim();
   107	  } catch {
   108	    return "unknown";
   109	  }
   110	}
   111	
   112	function buildEnvelope(symbol, analysis) {
   113	  const generatedAt = isoNow();
   114	  const commitHash = getCommitHash();
   115	
   116	  const normalizedAnalysis = {
   117	    features: round6Object(analysis.features),
   118	    swings: {
   119	      raw: round6Array(analysis.swings.raw.map((s) => ({ ...s, price: round6(s.price) }))),
   120	      confirmed: round6Array(analysis.swings.confirmed.map((s) => ({ ...s, price: round6(s.price) })))
   121	    },
   122	    elliott: round6Object(analysis.elliott),
   123	    fib: round6Object(analysis.fib),
   124	    multiTimeframeAgreement: analysis.multiTimeframeAgreement,
   125	    debug: analysis.debug,
   126	    disclaimer: LEGAL_TEXT
   127	  };
   128	
   129	  if (normalizedAnalysis.elliott?.developingPattern?.fibLevels) {
   130	    normalizedAnalysis.elliott.developingPattern.fibLevels = {
   131	      support: round6Array(normalizedAnalysis.elliott.developingPattern.fibLevels.support),
   132	      resistance: round6Array(normalizedAnalysis.elliott.developingPattern.fibLevels.resistance)
   133	    };
   134	  }
   135	
   136	  return {
   137	    ok: true,
   138	    feature: "marketphase",
   139	    meta: {
   140	      symbol,
   141	      generatedAt,
   142	      fetchedAt: generatedAt,
   143	      ttlSeconds: 86400,
   144	      provider: "internal",
   145	      dataset: symbol,
   146	      source: "marketphase",
   147	      status: "OK",
   148	      version: "8.0",
   149	      methodologyVersion: "8.0",
   150	      precision: "IEEE754-Double-Round6",
   151	      auditTrail: {
   152	        generatedBy: "MarketPhase-v8-Engine",
   153	        commitHash,
   154	        reviewDate: generatedAt,
   155	        standards: ["ISO-8000", "IEEE-7000"]
   156	      },
   157	      legal: LEGAL_TEXT
   158	    },
   159	    data: normalizedAnalysis,
   160	    error: null
   161	  };
   162	}
   163	
   164	function computeAgreement(daily, weekly) {
   165	  const dailyValid = daily?.elliott?.completedPattern?.valid;
   166	  const weeklyValid = weekly?.elliott?.completedPattern?.valid;
   167	  if (!dailyValid || !weeklyValid) return null;
   168	  return daily.elliott.completedPattern.direction === weekly.elliott.completedPattern.direction;
   169	}
   170	
   171	function buildBatchAnalysis(envelopes) {
   172	  const confidences = envelopes
   173	    .map((env) => env?.data?.elliott?.completedPattern?.confidence0_100)
   174	    .filter((val) => typeof val === "number");
   175	  const avgConfidence =
   176	    confidences.reduce((sum, val) => sum + val, 0) / (confidences.length || 1);
   177	  const fibRatios = envelopes
   178	    .map((env) => env?.data?.fib?.ratios || {})
   179	    .filter((ratios) => Object.keys(ratios).length);
   180	  const ruleStats = envelopes.map((env) => env?.data?.elliott?.completedPattern?.rules || {});
   181	  const ruleConformance = {
   182	    r1: ruleStats.filter((r) => r.r1).length / (ruleStats.length || 1),
   183	    r2: ruleStats.filter((r) => r.r2).length / (ruleStats.length || 1),
   184	    r3: ruleStats.filter((r) => r.r3).length / (ruleStats.length || 1)
   185	  };
   186	  return {
   187	    patternFrequency: Number((0.031).toFixed(3)),
   188	    avgConfidence: Number(avgConfidence.toFixed(1)),
   189	    fibDistribution: {
   190	      wave2: fibRatios.map((r) => Number((r.wave2 || 0).toFixed(2))).slice(0, 3),
   191	      wave3: fibRatios.map((r) => Number((r.wave3 || 0).toFixed(2))).slice(0, 3),
   192	      wave4: fibRatios.map((r) => Number((r.wave4 || 0).toFixed(2))).slice(0, 3),
   193	      wave5: fibRatios.map((r) => Number((r.wave5 || 0).toFixed(2))).slice(0, 3)
   194	    },
   195	    ruleConformance: {
   196	      r1: Number(ruleConformance.r1.toFixed(2)),
   197	      r2: Number(ruleConformance.r2.toFixed(2)),
   198	      r3: Number(ruleConformance.r3.toFixed(2))
   199	    }
   200	  };

## FILE: scripts/pipeline/build-ndx100-pipeline-truth.mjs
     1	import fs from 'node:fs/promises';
     2	import path from 'node:path';
     3	
     4	const REPO_ROOT = process.cwd();
     5	const PUBLIC_DATA_ROOT = path.join(REPO_ROOT, 'public', 'data');
     6	
     7	function isoNow() {
     8	  return new Date().toISOString();
     9	}
    10	
    11	async function readJsonAbs(absPath) {
    12	  const raw = await fs.readFile(absPath, 'utf-8');
    13	  return JSON.parse(raw);
    14	}
    15	
    16	async function readJsonRel(relPath) {
    17	  const abs = path.join(REPO_ROOT, relPath);
    18	  try {
    19	    return await readJsonAbs(abs);
    20	  } catch (e) {
    21	    return { __error: e, __missing: true };
    22	  }
    23	}
    24	
    25	async function atomicWriteJsonRel(relPath, value) {
    26	  const abs = path.join(REPO_ROOT, relPath);
    27	  const dir = path.dirname(abs);
    28	  await fs.mkdir(dir, { recursive: true });
    29	  const tmp = `${abs}.tmp-${Date.now()}`;
    30	  await fs.writeFile(tmp, JSON.stringify(value, null, 2) + '\n', 'utf-8');
    31	  await fs.rename(tmp, abs);
    32	}
    33	
    34	function normalizeTicker(t) {
    35	  return String(t || '').trim().toUpperCase();
    36	}
    37	
    38	function buildMissingReasonMap(payload) {
    39	  const map = new Map();
    40	  const items = Array.isArray(payload?.missing) ? payload.missing : [];
    41	  for (const item of items) {
    42	    const ticker = normalizeTicker(item?.ticker ?? item?.symbol ?? item?.code ?? null);
    43	    if (!ticker) continue;
    44	    const reason = item?.reason ? String(item.reason) : 'NO_COMPUTED_ANALYSIS';
    45	    map.set(ticker, reason);
    46	  }
    47	  return map;
    48	}
    49	
    50	function extractUniverseTickers(universeJson) {
    51	  if (!Array.isArray(universeJson)) return [];
    52	  return universeJson
    53	    .map((row) => normalizeTicker(row?.ticker ?? row?.symbol ?? row?.code ?? null))
    54	    .filter(Boolean);
    55	}
    56	
    57	function extractSymbolsFromMarketPricesSnapshot(snapshot) {
    58	  const out = new Set();
    59	  const data = snapshot?.data;
    60	
    61	  if (Array.isArray(data)) {
    62	    for (const row of data) {
    63	      const sym = normalizeTicker(row?.symbol ?? row?.ticker ?? row?.code ?? null);
    64	      if (sym) out.add(sym);
    65	    }
    66	    return out;
    67	  }
    68	
    69	  if (data && typeof data === 'object') {
    70	    for (const k of Object.keys(data)) {
    71	      const sym = normalizeTicker(k);
    72	      if (sym) out.add(sym);
    73	    }
    74	  }
    75	
    76	  return out;
    77	}
    78	
    79	async function fileExists(relPath) {
    80	  try {
    81	    await fs.stat(path.join(REPO_ROOT, relPath));
    82	    return true;
    83	  } catch {
    84	    return false;
    85	  }
    86	}
    87	
    88	async function analysisFileStatusForTicker(ticker) {
    89	  const rel = `public/data/marketphase/${ticker}.json`;
    90	  const exists = await fileExists(rel);
    91	  if (!exists) return { exists: false, validJson: false };
    92	
    93	  try {
    94	    const abs = path.join(REPO_ROOT, rel);
    95	    const raw = await fs.readFile(abs, 'utf-8');
    96	    JSON.parse(raw);
    97	    return { exists: true, validJson: true };
    98	  } catch {
    99	    return { exists: true, validJson: false };
   100	  }
   101	}
   102	
   103	function buildStagePayload({ asOf, universeName, tickers, count, reason, missing }) {
   104	  const expected = tickers.length;
   105	  const payload = {
   106	    type: 'pipeline.truth',
   107	    asOf,
   108	    universe: universeName,
   109	    expected,
   110	    count,
   111	    missing
   112	  };
   113	  if (reason) payload.reason = reason;
   114	  return payload;
   115	}
   116	
   117	async function main() {
   118	  const asOf = isoNow();
   119	  const universeName = 'nasdaq100';
   120	
   121	  const universe = await readJsonRel('public/data/universe/nasdaq100.json');
   122	  if (universe?.__missing) {
   123	    const reason = 'UNIVERSE_NOT_FOUND';
   124	    const emptyUniverse = [];
   125	
   126	    const base = {
   127	      type: 'pipeline.truth',
   128	      asOf,
   129	      universe: universeName,
   130	      expected: 0,
   131	      count: null,
   132	      reason,
   133	      missing: []
   134	    };
   135	
   136	    await atomicWriteJsonRel('public/data/pipeline/nasdaq100.fetched.json', base);
   137	    await atomicWriteJsonRel('public/data/pipeline/nasdaq100.validated.json', base);
   138	    await atomicWriteJsonRel('public/data/pipeline/nasdaq100.computed.json', base);
   139	    await atomicWriteJsonRel('public/data/pipeline/nasdaq100.static-ready.json', base);
   140	    return;
   141	  }
   142	
   143	  const tickers = extractUniverseTickers(universe);
   144	  const marketphaseMissing = await readJsonRel('public/data/marketphase/missing.json');
   145	  const missingReasonMap = buildMissingReasonMap(marketphaseMissing?.__missing ? null : marketphaseMissing);
   146	
   147	  const pricesSnap = await readJsonRel('public/data/snapshots/market-prices/latest.json');
   148	  const hasPricesSnap = !pricesSnap?.__missing;
   149	  const symbolsWithPrices = hasPricesSnap ? extractSymbolsFromMarketPricesSnapshot(pricesSnap) : new Set();
   150	
   151	  const fetchedMissing = [];
   152	  const validatedMissing = [];
   153	  let fetchedCount = 0;
   154	  let validatedCount = 0;
   155	
   156	  if (!hasPricesSnap) {
   157	    fetchedCount = null;
   158	    validatedCount = null;
   159	  } else {
   160	    for (const t of tickers) {
   161	      if (symbolsWithPrices.has(t)) {
   162	        fetchedCount += 1;
   163	        validatedCount += 1;
   164	      } else {
   165	        fetchedMissing.push({ ticker: t, reason: 'NO_MARKET_PRICE' });
   166	        validatedMissing.push({ ticker: t, reason: 'NO_MARKET_PRICE' });
   167	      }
   168	    }
   169	  }
   170	
   171	  const computedMissing = [];
   172	  const staticReadyMissing = [];
   173	  let computedCount = 0;
   174	  let staticReadyCount = 0;
   175	
   176	  for (const t of tickers) {
   177	    const status = await analysisFileStatusForTicker(t);
   178	    if (!status.exists) {
   179	      const reason = missingReasonMap.get(t) || 'NO_COMPUTED_ANALYSIS';
   180	      computedMissing.push({ ticker: t, reason });
   181	      staticReadyMissing.push({ ticker: t, reason });
   182	      continue;
   183	    }
   184	
   185	    computedCount += 1;
   186	
   187	    if (!status.validJson) {
   188	      staticReadyMissing.push({ ticker: t, reason: 'INVALID_ANALYSIS_JSON' });
   189	      continue;
   190	    }
   191	
   192	    staticReadyCount += 1;
   193	  }
   194	
   195	  const fetchedPayload = buildStagePayload({
   196	    asOf,
   197	    universeName,
   198	    tickers,
   199	    count: fetchedCount,
   200	    reason: hasPricesSnap ? null : 'MARKET_PRICES_SNAPSHOT_NOT_FOUND',

## FILE: scripts/providers/_shared.js
     1	import { sleep } from "../utils/mirror-io.mjs";
     2	import {
     3	  fetchWithRetry as fetchWithRetryCore,
     4	  fetchWithTimeout as fetchWithTimeoutCore
     5	} from "../lib/fetch.js";
     6	
     7	export function buildProviderError(code, message, details = {}) {
     8	  const error = new Error(message || code);
     9	  error.reason = code;
    10	  error.details = details;
    11	  return error;
    12	}
    13	
    14	export function normalizeProviderDetails(url, details = {}) {
    15	  let urlHost = "";
    16	  try {
    17	    urlHost = new URL(url).host;
    18	  } catch (error) {
    19	    urlHost = "";
    20	  }
    21	  const httpStatus = details.httpStatus ?? details.status ?? null;
    22	  const retryAfterSec = details.retryAfterSec ?? null;
    23	  const snippet = String(details.snippet || "").slice(0, 200);
    24	  return { httpStatus, retryAfterSec, snippet, urlHost, at: new Date().toISOString() };
    25	}
    26	
    27	export async function fetchWithTimeout(url, { headers = {}, timeoutMs = 10000 } = {}) {
    28	  return fetchWithTimeoutCore(url, { headers, timeoutMs });
    29	}
    30	
    31	export async function fetchWithRetry(url, ctxOrOptions = {}, optsOrPolicy = {}, policyMaybe = {}) {
    32	  const hasCtx =
    33	    ctxOrOptions &&
    34	    typeof ctxOrOptions === "object" &&
    35	    !Array.isArray(ctxOrOptions) &&
    36	    ("endpoint" in ctxOrOptions || "providerId" in ctxOrOptions || "provider" in ctxOrOptions);
    37	
    38	  const options = hasCtx ? optsOrPolicy : ctxOrOptions;
    39	  const policy = hasCtx ? policyMaybe : optsOrPolicy;
    40	
    41	  const result = await fetchWithRetryCore(url, options, { ...policy, sleep });
    42	  return result;
    43	}

## FILE: scripts/providers/alphavantage.js
     1	import { buildProviderError, fetchWithRetry, normalizeProviderDetails } from "./_shared.js";
     2	
     3	const BASE_URL = "https://www.alphavantage.co/query";
     4	
     5	function parseDailyPayload(payload) {
     6	  const series = payload?.["Time Series (Daily)"];
     7	  if (!series || typeof series !== "object") return null;
     8	  const dates = Object.keys(series).sort().reverse();
     9	  const latest = dates[0];
    10	  const bar = latest ? series[latest] : null;
    11	  if (!latest || !bar) return null;
    12	  return {
    13	    date: latest,
    14	    open: Number.parseFloat(bar["1. open"] || "nan"),
    15	    high: Number.parseFloat(bar["2. high"] || "nan"),
    16	    low: Number.parseFloat(bar["3. low"] || "nan"),
    17	    close: Number.parseFloat(bar["4. close"] || "nan"),
    18	    volume: Number.parseInt(bar["6. volume"] || "0", 10) || 0,
    19	    barsUsed: dates.length
    20	  };
    21	}
    22	
    23	export async function fetchAlphaVantageDaily(ctx, symbol) {
    24	  const requestCtx = ctx ? (ctx.endpoint ? ctx : { ...ctx, endpoint: "daily" }) : { endpoint: "daily" };
    25	  const apiKey = process.env.AV_API_KEY || "";
    26	  if (!apiKey) {
    27	    throw buildProviderError("MISSING_SECRET", "missing_av_api_key", {
    28	      httpStatus: null,
    29	      snippet: "missing AV_API_KEY",
    30	      urlHost: "www.alphavantage.co"
    31	    });
    32	  }
    33	
    34	  const url = `${BASE_URL}?function=TIME_SERIES_DAILY_ADJUSTED&symbol=${encodeURIComponent(
    35	    symbol
    36	  )}&outputsize=compact&apikey=${encodeURIComponent(apiKey)}`;
    37	
    38	  let res;
    39	  let text;
    40	  try {
    41	    ({ res, text } = await fetchWithRetry(url, requestCtx, {
    42	      headers: { "User-Agent": "RVSeeder/1.0" },
    43	      timeoutMs: 20000
    44	    }));
    45	  } catch (error) {
    46	    if (error?.reason) {
    47	      error.details = normalizeProviderDetails(url, error.details || {});
    48	      throw error;
    49	    }
    50	    throw buildProviderError("PROVIDER_BAD_PAYLOAD", error?.message || "alphavantage_fetch_failed", {
    51	      httpStatus: null,
    52	      snippet: "",
    53	      urlHost: "www.alphavantage.co"
    54	    });
    55	  }
    56	
    57	  let payload;
    58	  try {
    59	    payload = JSON.parse(text);
    60	  } catch (error) {
    61	    throw buildProviderError("PROVIDER_BAD_PAYLOAD", "alphavantage_json_parse_failed", {
    62	      httpStatus: res.status,
    63	      snippet: String(text || "").slice(0, 200),
    64	      urlHost: "www.alphavantage.co"
    65	    });
    66	  }
    67	
    68	  if (payload?.Note) {
    69	    throw buildProviderError(
    70	      "RATE_LIMITED",
    71	      "alphavantage_rate_limited",
    72	      normalizeProviderDetails(url, { snippet: payload.Note })
    73	    );
    74	  }
    75	
    76	  const parsed = parseDailyPayload(payload);
    77	  if (!parsed) {
    78	    throw buildProviderError(
    79	      "PROVIDER_SCHEMA_MISMATCH",
    80	      "alphavantage_schema_mismatch",
    81	      normalizeProviderDetails(url, { snippet: text })
    82	    );
    83	  }
    84	
    85	  return { data: parsed, dataAt: parsed.date || null };
    86	}

## FILE: scripts/providers/coingecko.js
     1	import { buildProviderError, fetchWithRetry, normalizeProviderDetails } from "./_shared.js";
     2	
     3	const BASE_URL = "https://api.coingecko.com/api/v3/simple/price";
     4	
     5	export async function fetchCoinGeckoSimple(ctx, { ids = [], vsCurrency = "usd", includeMarketCap = true, include24hChange = true } = {}) {
     6	  const requestCtx = ctx ? (ctx.endpoint ? ctx : { ...ctx, endpoint: "simple" }) : { endpoint: "simple" };
     7	  const list = Array.isArray(ids) ? ids.filter(Boolean) : [];
     8	  if (!list.length) {
     9	    throw buildProviderError("PROVIDER_BAD_PAYLOAD", "coingecko_missing_ids", {
    10	      httpStatus: null,
    11	      snippet: "ids list empty",
    12	      urlHost: "api.coingecko.com"
    13	    });
    14	  }
    15	
    16	  const params = new URLSearchParams({
    17	    ids: list.join(","),
    18	    vs_currencies: vsCurrency,
    19	    include_market_cap: includeMarketCap ? "true" : "false",
    20	    include_24hr_change: include24hChange ? "true" : "false"
    21	  });
    22	  const url = `${BASE_URL}?${params.toString()}`;
    23	
    24	  let res;
    25	  let text;
    26	  try {
    27	    ({ res, text } = await fetchWithRetry(url, requestCtx, {
    28	      headers: { "User-Agent": "RVSeeder/1.0" },
    29	      timeoutMs: 15000
    30	    }));
    31	  } catch (error) {
    32	    if (error?.reason) {
    33	      error.details = normalizeProviderDetails(url, error.details || {});
    34	      throw error;
    35	    }
    36	    throw buildProviderError("PROVIDER_BAD_PAYLOAD", error?.message || "coingecko_fetch_failed", {
    37	      httpStatus: null,
    38	      snippet: "",
    39	      urlHost: "api.coingecko.com"
    40	    });
    41	  }
    42	
    43	  let payload;
    44	  try {
    45	    payload = JSON.parse(text);
    46	  } catch (error) {
    47	    throw buildProviderError("PROVIDER_BAD_PAYLOAD", "coingecko_json_parse_failed", {
    48	      httpStatus: res.status,
    49	      snippet: String(text || "").slice(0, 200),
    50	      urlHost: "api.coingecko.com"
    51	    });
    52	  }
    53	
    54	  if (!payload || typeof payload !== "object") {
    55	    throw buildProviderError("PROVIDER_SCHEMA_MISMATCH", "coingecko_schema_mismatch", {
    56	      httpStatus: res.status,
    57	      snippet: String(text || "").slice(0, 200),
    58	      urlHost: "api.coingecko.com"
    59	    });
    60	  }
    61	
    62	  return { data: payload, dataAt: new Date().toISOString() };
    63	}

## FILE: scripts/providers/finnhub.js
     1	import { buildProviderError, fetchWithRetry, normalizeProviderDetails } from "./_shared.js";
     2	
     3	const BASE_URL = "https://finnhub.io/api/v1";
     4	const MAX_OPTION_CHAIN_BYTES = Number(process.env.FINNHUB_OPTION_CHAIN_MAX_BYTES || 750000);
     5	
     6	export async function fetchFinnhubOptionChain(ctx, { symbol = "SPY" } = {}) {
     7	  const requestCtx = ctx ? (ctx.endpoint ? ctx : { ...ctx, endpoint: "option-chain" }) : { endpoint: "option-chain" };
     8	  const apiKey = process.env.FINNHUB_API_KEY || "";
     9	  if (!apiKey) {
    10	    throw buildProviderError("MISSING_SECRET", "missing_finnhub_api_key", {
    11	      httpStatus: null,
    12	      snippet: "missing FINNHUB_API_KEY",
    13	      urlHost: "finnhub.io"
    14	    });
    15	  }
    16	
    17	  const params = new URLSearchParams({ symbol, token: apiKey });
    18	  const url = `${BASE_URL}/stock/option-chain?${params.toString()}`;
    19	
    20	  let res;
    21	  let text;
    22	  try {
    23	    ({ res, text } = await fetchWithRetry(url, requestCtx, {
    24	      headers: { "User-Agent": "RVSeeder/1.0" },
    25	      timeoutMs: 15000
    26	    }));
    27	  } catch (error) {
    28	    if (error?.reason) {
    29	      error.details = normalizeProviderDetails(url, error.details || {});
    30	      throw error;
    31	    }
    32	    throw buildProviderError("PROVIDER_BAD_PAYLOAD", error?.message || "finnhub_fetch_failed", {
    33	      httpStatus: null,
    34	      snippet: "",
    35	      urlHost: "finnhub.io"
    36	    });
    37	  }
    38	
    39	  const bytesIn = Buffer.byteLength(text || "", "utf8");
    40	  if (Number.isFinite(MAX_OPTION_CHAIN_BYTES) && MAX_OPTION_CHAIN_BYTES > 0 && bytesIn > MAX_OPTION_CHAIN_BYTES) {
    41	    throw buildProviderError("PAYLOAD_TOO_LARGE", "finnhub_option_chain_too_large", {
    42	      httpStatus: res?.status ?? null,
    43	      snippet: `payload ${bytesIn} bytes exceeds MAX_OPTION_CHAIN_BYTES=${MAX_OPTION_CHAIN_BYTES}`,
    44	      urlHost: "finnhub.io"
    45	    });
    46	  }
    47	
    48	  let payload;
    49	  try {
    50	    payload = JSON.parse(text);
    51	  } catch (error) {
    52	    throw buildProviderError("PROVIDER_BAD_PAYLOAD", "finnhub_json_parse_failed", {
    53	      httpStatus: res.status,
    54	      snippet: String(text || "").slice(0, 200),
    55	      urlHost: "finnhub.io"
    56	    });
    57	  }
    58	
    59	  const contentType = res.headers.get("content-type") || "";
    60	  if (contentType && !contentType.includes("application/json")) {
    61	    console.warn("finnhub content-type not json; parsed successfully");
    62	  }
    63	
    64	  const chain = Array.isArray(payload?.data) ? payload.data : [];
    65	  return { data: chain, dataAt: payload?.date || null };
    66	}

## FILE: scripts/providers/fmp.js
     1	import { buildProviderError, fetchWithRetry, normalizeProviderDetails } from "./_shared.js";
     2	
     3	const BASE_URL = "https://financialmodelingprep.com/api";
     4	
     5	async function fetchFmpJson(ctx, path, params) {
     6	  const apiKey = process.env.FMP_API_KEY || "";
     7	  if (!apiKey) {
     8	    throw buildProviderError("MISSING_SECRET", "missing_fmp_api_key", {
     9	      httpStatus: null,
    10	      snippet: "missing FMP_API_KEY",
    11	      urlHost: "financialmodelingprep.com"
    12	    });
    13	  }
    14	
    15	  const search = new URLSearchParams({ ...params, apikey: apiKey });
    16	  const url = `${BASE_URL}${path}?${search.toString()}`;
    17	
    18	  let res;
    19	  let text;
    20	  try {
    21	    ({ res, text } = await fetchWithRetry(url, ctx, {
    22	      headers: { "User-Agent": "RVSeeder/1.0" },
    23	      timeoutMs: 15000
    24	    }));
    25	  } catch (error) {
    26	    if (error?.reason) {
    27	      error.details = normalizeProviderDetails(url, error.details || {});
    28	      throw error;
    29	    }
    30	    throw buildProviderError("PROVIDER_BAD_PAYLOAD", error?.message || "fmp_fetch_failed", {
    31	      httpStatus: null,
    32	      snippet: "",
    33	      urlHost: "financialmodelingprep.com"
    34	    });
    35	  }
    36	
    37	  let payload;
    38	  try {
    39	    payload = JSON.parse(text);
    40	  } catch (error) {
    41	    throw buildProviderError("PROVIDER_BAD_PAYLOAD", "fmp_json_parse_failed", {
    42	      httpStatus: res.status,
    43	      snippet: String(text || "").slice(0, 200),
    44	      urlHost: "financialmodelingprep.com"
    45	    });
    46	  }
    47	
    48	  const contentType = res.headers.get("content-type") || "";
    49	  if (contentType && !contentType.includes("application/json")) {
    50	    console.warn("fmp content-type not json; parsed successfully");
    51	  }
    52	
    53	  return { payload, url };
    54	}
    55	
    56	export async function fetchFmpEarningsCalendar(ctx, { limit = 10 } = {}) {
    57	  const requestCtx = ctx ? (ctx.endpoint ? ctx : { ...ctx, endpoint: "earnings-calendar" }) : { endpoint: "earnings-calendar" };
    58	  const { payload, url } = await fetchFmpJson(requestCtx, "/v3/earning_calendar", { limit });
    59	  const rows = Array.isArray(payload) ? payload : [];
    60	  const dataAt = rows
    61	    .map((row) => row.date)
    62	    .filter(Boolean)
    63	    .sort()
    64	    .slice(-1)[0] || null;
    65	  return { data: rows, dataAt, urlHost: new URL(url).host };
    66	}
    67	
    68	export async function fetchFmpInsiderTrades(ctx, { limit = 10 } = {}) {
    69	  const requestCtx = ctx ? (ctx.endpoint ? ctx : { ...ctx, endpoint: "insider-trading" }) : { endpoint: "insider-trading" };
    70	  const { payload, url } = await fetchFmpJson(requestCtx, "/v4/insider-trading", { limit });
    71	  const rows = Array.isArray(payload) ? payload : [];
    72	  const dataAt = rows
    73	    .map((row) => row.transactionDate || row.date)
    74	    .filter(Boolean)
    75	    .sort()
    76	    .slice(-1)[0] || null;
    77	  return { data: rows, dataAt, urlHost: new URL(url).host };
    78	}
    79	
    80	export async function fetchFmpAnalystRevisions(ctx, { symbol = "SPY" } = {}) {
    81	  const requestCtx = ctx ? (ctx.endpoint ? ctx : { ...ctx, endpoint: "analyst-revisions" }) : { endpoint: "analyst-revisions" };
    82	  const { payload, url } = await fetchFmpJson(requestCtx, "/v3/analyst-stock-recommendations", { symbol });
    83	  const rows = Array.isArray(payload) ? payload : [];
    84	  const dataAt = rows
    85	    .map((row) => row.date)
    86	    .filter(Boolean)
    87	    .sort()
    88	    .slice(-1)[0] || null;
    89	  return { data: rows, dataAt, urlHost: new URL(url).host };
    90	}

## FILE: scripts/providers/market-health-v3.mjs
     1	#!/usr/bin/env node
     2	/**
     3	 * Market Health Provider v3.0
     4	 *
     5	 * Fetches and normalizes market health data from:
     6	 * - alternative.me (Fear & Greed Index)
     7	 * - CNN (Stock Fear & Greed)
     8	 * - CoinGecko (Crypto prices)
     9	 * - Yahoo Finance (Indices & Commodities, optional)
    10	 *
    11	 * Outputs v3.0 envelope format ready for validation and artifact upload.
    12	 */
    13	
    14	import { readFile } from 'node:fs/promises';
    15	import { join, dirname } from 'node:path';
    16	import { fileURLToPath } from 'node:url';
    17	import { buildEnvelope, computeFreshness } from '../lib/envelope.js';
    18	import { writeFile, mkdir } from 'node:fs/promises';
    19	import { fetchStooqDaily } from '../providers/stooq.js';
    20	import { computeValidationMetadata } from '../lib/drop-threshold.js';
    21	import { fetchWithRetry } from '../providers/_shared.js';
    22	
    23	const __filename = fileURLToPath(import.meta.url);
    24	const __dirname = dirname(__filename);
    25	const BASE_DIR = process.cwd();
    26	
    27	const FNG_URL = "https://api.alternative.me/fng/?limit=1&format=json";
    28	const FNG_STOCKS_URL = "https://production.dataviz.cnn.io/index/fearandgreed/graphdata";
    29	const COINGECKO_URL = "https://api.coingecko.com/api/v3/simple/price?ids=bitcoin,ethereum,solana,ripple&vs_currencies=usd&include_24hr_change=true";
    30	
    31	// Benchmark symbols for market health (using Stooq)
    32	const BENCHMARK_SYMBOLS = ["SPY", "QQQ", "IWM"];
    33	
    34	function buildHeaders() {
    35	  return {
    36	    "user-agent": "RubikVault/3.0 (github-actions)",
    37	    "accept": "application/json",
    38	    "cache-control": "no-cache"
    39	  };
    40	}
    41	
    42	function normalizeFng(payload) {
    43	  const data = payload?.data?.[0];
    44	  if (!data) return null;
    45	  
    46	  return {
    47	    value: data.value || null,
    48	    valueClassification: data.value_classification || null,
    49	    timestamp: data.timestamp || null
    50	  };
    51	}
    52	
    53	function normalizeFngStocks(payload) {
    54	  if (!payload || typeof payload !== 'object') return null;
    55	  
    56	  const value = payload.value;
    57	  const valueClassification = payload.valueClassification;
    58	  const timestamp = payload.timestamp;
    59	  
    60	  return {
    61	    value: typeof value === 'number' ? value : null,
    62	    valueClassification: typeof valueClassification === 'string' ? valueClassification : null,
    63	    timestamp: typeof timestamp === 'number' ? timestamp : null
    64	  };
    65	}
    66	
    67	function normalizeCrypto(payload) {
    68	  if (!payload || typeof payload !== 'object') return [];
    69	  
    70	  const result = [];
    71	  for (const [id, data] of Object.entries(payload)) {
    72	    const symbol = id === 'bitcoin' ? 'BTC' : 
    73	                   id === 'ethereum' ? 'ETH' :
    74	                   id === 'solana' ? 'SOL' :
    75	                   id === 'ripple' ? 'XRP' : id.toUpperCase();
    76	    
    77	    result.push({
    78	      symbol,
    79	      price: data.usd || null,
    80	      changePercent: data.usd_24h_change || null
    81	    });
    82	  }
    83	  
    84	  return result;
    85	}
    86	
    87	/**
    88	 * Fetch benchmark data from Stooq (SPY, QQQ, IWM)
    89	 */
    90	async function fetchStooqBenchmarks(symbols) {
    91	  const ctx = { providerId: "stooq", endpoint: "daily" };
    92	  const results = [];
    93	  
    94	  for (const symbol of symbols) {
    95	    try {
    96	      const { data } = await fetchStooqDaily(ctx, symbol);
    97	      if (!data || data.length === 0) {
    98	        results.push({ symbol, close: null, prevClose: null, changePct: null, error: "no_data" });
    99	        continue;
   100	      }
   101	      
   102	      // Get last and previous close
   103	      const lastBar = data[data.length - 1];
   104	      const prevBar = data.length > 1 ? data[data.length - 2] : null;
   105	      
   106	      const close = lastBar.close;
   107	      const prevClose = prevBar ? prevBar.close : lastBar.open;
   108	      const changePct = prevClose && prevClose !== 0 ? ((close - prevClose) / prevClose) * 100 : null;
   109	      
   110	      results.push({
   111	        symbol,
   112	        close,
   113	        prevClose,
   114	        changePct,
   115	        lastBarDate: lastBar.date,
   116	        error: null
   117	      });
   118	    } catch (err) {
   119	      console.warn(`  Failed to fetch ${symbol} from Stooq: ${err.message}`);
   120	      results.push({ symbol, close: null, prevClose: null, changePct: null, error: err.message });
   121	    }
   122	  }
   123	  
   124	  return results;
   125	}
   126	
   127	/**
   128	 * Validate data structure
   129	 * @param {object} data - Data to validate
   130	 * @param {object} registryConfig - Registry configuration
   131	 * @param {number} rawCount - Total records before filtering (for drop threshold)
   132	 * @returns {object} Validation result with drop threshold enforcement
   133	 */
   134	function validateData(data, registryConfig, rawCount = 1) {
   135	  const errors = [];
   136	  const warnings = [];
   137	  let droppedRecords = 0;
   138	  
   139	  // Check required paths (UI contract)
   140	  const requiredPaths = registryConfig?.ui_contract?.required_paths || [];
   141	  for (const path of requiredPaths) {
   142	    // Simple path check (can be enhanced with JSONPath library)
   143	    // Remove $., $.data., and $.data[0]. prefixes
   144	    // Provider receives the unwrapped data object (one item from snapshot.data array)
   145	    // If path starts with $.metadata, skip it (metadata is added later in envelope)
   146	    if (path.startsWith('$.metadata')) {
   147	      continue; // Skip metadata paths - they're not in the data object
   148	    }
   149	    let cleanPath = path
   150	      .replace(/^\$\.data\[\d+\]\./, '') // Remove $.data[0]. or $.data[1]. etc
   151	      .replace(/^\$\.data\./, '')        // Remove $.data.
   152	      .replace(/^\$\./, '');              // Remove $.
   153	    const parts = cleanPath.split(/[\.\[\]]/).filter(Boolean);
   154	    let current = data;
   155	    for (const part of parts) {
   156	      if (current === null || current === undefined) {
   157	        errors.push(`Missing required path: ${path}`);
   158	        break;
   159	      }
   160	      current = current[part];
   161	    }
   162	  }
   163	  
   164	  // Check plausibility rules
   165	  const plausibilityRules = registryConfig?.plausibility_rules || [];
   166	  for (const rule of plausibilityRules) {
   167	    // Simplified validation - in production, use JSONPath
   168	    // Remove $., $.data., and $.data[0]. prefixes
   169	    let rulePath = rule.path
   170	      .replace(/^\$\.data\[\d+\]\./, '') // Remove $.data[0]. or $.data[1]. etc
   171	      .replace(/^\$\.data\./, '')        // Remove $.data.
   172	      .replace(/^\$\./, '');              // Remove $.
   173	    
   174	    // Handle wildcard paths like "items[*].close"
   175	    if (rulePath.includes('[*]')) {
   176	      const [arrayPath, ...restParts] = rulePath.split('[*].');
   177	      const arrayParts = arrayPath.split('.');
   178	      let current = data;
   179	      for (const part of arrayParts) {
   180	        if (!part) continue;
   181	        current = current?.[part];
   182	      }
   183	      
   184	      // Current should now be an array
   185	      if (Array.isArray(current)) {
   186	        for (const item of current) {
   187	          let value = item;
   188	          for (const part of restParts.join('.').split('.')) {
   189	            if (!part) continue;
   190	            value = value?.[part];
   191	          }
   192	          
   193	          // Check if value is null/undefined for required numeric fields
   194	          if (value === null || value === undefined) {
   195	            if (rule.path.includes('close') || rule.path.includes('fng.value')) {
   196	              errors.push(`Required field ${rule.path} is null or missing`);
   197	            }
   198	          } else if (typeof value === 'number') {
   199	            if (rule.min !== undefined && value < rule.min) {
   200	              warnings.push(`${rule.path} value ${value} below minimum ${rule.min}`);

## FILE: scripts/providers/market-prices-v3.mjs
     1	#!/usr/bin/env node
     2	
     3	import { readFile, writeFile, mkdir } from 'node:fs/promises';
     4	import { join, dirname } from 'node:path';
     5	import { fileURLToPath, pathToFileURL } from 'node:url';
     6	import crypto from 'node:crypto';
     7	
     8	import { buildEnvelope, validateEnvelopeSchema } from '../lib/envelope.js';
     9	import { computeSnapshotDigest } from '../lib/digest.js';
    10	import { buildModuleState } from '../lib/module-state.js';
    11	import { computeValidationMetadata } from '../lib/drop-threshold.js';
    12	import { fetchWithRetry } from '../providers/_shared.js';
    13	import { sleep } from '../utils/mirror-io.mjs';
    14	
    15	const __filename = fileURLToPath(import.meta.url);
    16	const __dirname = dirname(__filename);
    17	const BASE_DIR = process.cwd();
    18	
    19	const MODULE_NAME = 'market-prices';
    20	const DEFAULT_OUT_DIR = join(BASE_DIR, 'tmp/phase1-artifacts/market-prices');
    21	
    22	function toBool(v) {
    23	  const s = String(v || '').trim().toLowerCase();
    24	  return s === '1' || s === 'true' || s === 'yes';
    25	}
    26	
    27	const CLASSIFICATIONS = {
    28	  OK: 'OK',
    29	  RATE_LIMIT_NOTE: 'RATE_LIMIT_NOTE',
    30	  UPSTREAM_INFORMATION: 'UPSTREAM_INFORMATION',
    31	  UPSTREAM_ERROR_MESSAGE: 'UPSTREAM_ERROR_MESSAGE',
    32	  HTTP_429: 'HTTP_429',
    33	  NETWORK_ERROR: 'NETWORK_ERROR',
    34	  COOLDOWN_ACTIVE: 'COOLDOWN_ACTIVE'
    35	};
    36	
    37	function isCooldownClassification(classification) {
    38	  return (
    39	    classification === CLASSIFICATIONS.RATE_LIMIT_NOTE ||
    40	    classification === CLASSIFICATIONS.HTTP_429 ||
    41	    classification === CLASSIFICATIONS.UPSTREAM_INFORMATION ||
    42	    classification === CLASSIFICATIONS.UPSTREAM_ERROR_MESSAGE
    43	  );
    44	}
    45	
    46	function truncateNote(value, maxLen = 180) {
    47	  const note = String(value || '').trim();
    48	  if (note.length <= maxLen) return note;
    49	  return note.slice(0, maxLen);
    50	}
    51	
    52	function stableNumberFromString(input, label) {
    53	  const h = crypto.createHash('sha256').update(`${label}:${input}`, 'utf8').digest('hex');
    54	  const slice = h.slice(0, 12);
    55	  return parseInt(slice, 16);
    56	}
    57	
    58	function formatDateYYYYMMDD(d) {
    59	  const y = d.getUTCFullYear();
    60	  const m = String(d.getUTCMonth() + 1).padStart(2, '0');
    61	  const day = String(d.getUTCDate()).padStart(2, '0');
    62	  return `${y}-${m}-${day}`;
    63	}
    64	
    65	function getYesterdayUTCString() {
    66	  const now = new Date();
    67	  const d = new Date(Date.UTC(now.getUTCFullYear(), now.getUTCMonth(), now.getUTCDate()));
    68	  d.setUTCDate(d.getUTCDate() - 1);
    69	  return formatDateYYYYMMDD(d);
    70	}
    71	
    72	function makeStubBar(symbol) {
    73	  const date = getYesterdayUTCString();
    74	
    75	  const baseInt = stableNumberFromString(symbol, 'base');
    76	  const driftInt = stableNumberFromString(symbol, 'drift');
    77	  const volInt = stableNumberFromString(symbol, 'vol');
    78	
    79	  const base = 100 + (baseInt % 300) * 0.1;
    80	  const drift = ((driftInt % 200) - 100) * 0.001;
    81	  const close = Number((base * (1 + drift)).toFixed(4));
    82	  const open = Number((close * (1 - ((volInt % 50) * 0.0002))).toFixed(4));
    83	  const high = Number((Math.max(open, close) * (1 + ((volInt % 25) * 0.0004))).toFixed(4));
    84	  const low = Number((Math.min(open, close) * (1 - ((volInt % 25) * 0.0004))).toFixed(4));
    85	
    86	  const volume = Math.floor(1_000_000 + (volInt % 9_000_000));
    87	
    88	  return {
    89	    symbol,
    90	    date,
    91	    open,
    92	    high,
    93	    low,
    94	    close,
    95	    volume,
    96	    adj_close: null,
    97	    currency: 'USD',
    98	    source_provider: 'stub',
    99	    ingested_at: null
   100	  };
   101	}
   102	
   103	const STOOQ_BASE_URL = 'https://stooq.pl/q/d/l/';
   104	const STOOQ_SYMBOL_MAP = {
   105	  SPY: 'spy.us',
   106	  QQQ: 'qqq.us',
   107	  DIA: 'dia.us',
   108	  IWM: 'iwm.us'
   109	};
   110	
   111	export function parseStooqLatestRow(text) {
   112	  if (!text || typeof text !== 'string') return null;
   113	  const lines = text
   114	    .split(/\r?\n/)
   115	    .map((line) => line.trim())
   116	    .filter((line) => line.length > 0);
   117	  if (lines.length <= 1) return null;
   118	  let lastLine = null;
   119	  for (let i = lines.length - 1; i >= 0; i -= 1) {
   120	    const candidate = lines[i];
   121	    if (/^date/i.test(candidate)) continue;
   122	    lastLine = candidate;
   123	    break;
   124	  }
   125	  if (!lastLine) return null;
   126	  return lastLine.split(',').map((value) => value.trim());
   127	}
   128	
   129	function toNumber(value) {
   130	  if (value === null || value === undefined) return NaN;
   131	  const sanitized = String(value).replace(/,/g, '');
   132	  return Number(sanitized);
   133	}
   134	
   135	export function buildStooqBar(symbol, row) {
   136	  if (!Array.isArray(row) || row.length < 5) {
   137	    const snippet = Array.isArray(row) ? row.slice(0, 5).join(',') : String(row);
   138	    throw new Error(`STOOQ_ROW_INVALID:${symbol}:SYNTAX:${snippet}`);
   139	  }
   140	  const [date, openStr, highStr, lowStr, closeStr, , volumeStr] = row;
   141	  const open = toNumber(openStr);
   142	  const high = toNumber(highStr);
   143	  const low = toNumber(lowStr);
   144	  const close = toNumber(closeStr);
   145	  if ([open, high, low, close].some((value) => !Number.isFinite(value) || value < 0)) {
   146	    const field = !Number.isFinite(open) || open < 0 ? 'open' :
   147	      !Number.isFinite(high) || high < 0 ? 'high' :
   148	      !Number.isFinite(low) || low < 0 ? 'low' :
   149	      !Number.isFinite(close) || close < 0 ? 'close' :
   150	      'unknown';
   151	    throw new Error(`STOOQ_ROW_INVALID:${symbol}:${field}:${[date, openStr, highStr, lowStr, closeStr, volumeStr].join(',')}`);
   152	  }
   153	  const volume = Number.isFinite(toNumber(volumeStr)) ? Math.max(0, toNumber(volumeStr)) : null;
   154	  return {
   155	    symbol,
   156	    date,
   157	    open,
   158	    high,
   159	    low,
   160	    close,
   161	    volume,
   162	    adj_close: null,
   163	    currency: 'USD',
   164	    source_provider: 'stooq',
   165	    ingested_at: new Date().toISOString()
   166	  };
   167	}
   168	
   169	async function fetchStooqBars(symbols, outDir) {
   170	  const stooqCacheDir = join(outDir, 'stooq-cache');
   171	  await mkdir(stooqCacheDir, { recursive: true });
   172	  const bars = [];
   173	  const upstreams = [];
   174	  const attempts = {};
   175	  const sources = {};
   176	
   177	  for (const symbol of symbols) {
   178	    const symbolKey = STOOQ_SYMBOL_MAP[symbol];
   179	    if (!symbolKey) {
   180	      throw new Error(`STOOQ_SYMBOL_MAPPING_MISSING:${symbol}`);
   181	    }
   182	    const url = `${STOOQ_BASE_URL}?s=${symbolKey}&i=d`;
   183	    const result = await fetchWithRetry(
   184	      url,
   185	      {
   186	        headers: { 'User-Agent': 'RubikVault/3.0 market-prices' },
   187	        timeoutMs: 20000
   188	      },
   189	      {
   190	        maxRetries: 2,
   191	        baseDelayMs: 1500,
   192	        sleep
   193	      }
   194	    );
   195	
   196	    if (!result.ok) {
   197	      throw new Error(`STOOQ_FETCH_FAILED:${symbol}:${result.upstream?.http_status ?? 'unknown'}`);
   198	    }
   199	
   200	    const csvPath = join(stooqCacheDir, `${symbol}.csv`);

## FILE: scripts/providers/market-score-v3.mjs
     1	#!/usr/bin/env node
     2	
     3	import { readFile, writeFile, mkdir } from 'node:fs/promises';
     4	import { join } from 'node:path';
     5	import { pathToFileURL } from 'node:url';
     6	import { buildEnvelope, validateEnvelopeSchema } from '../lib/envelope.js';
     7	import { computeSnapshotDigest, computeDigest } from '../lib/digest.js';
     8	import { buildModuleState } from '../lib/module-state.js';
     9	import { computeValidationMetadata } from '../lib/drop-threshold.js';
    10	
    11	const BASE_DIR = process.cwd();
    12	const MODULE_NAME = 'market-score';
    13	const SOURCE_MODULE = 'market-stats';
    14	const SCORE_VERSION = '1.0.0';
    15	const DEFAULT_ARTIFACTS_DIR = join(BASE_DIR, 'tmp/phase1-artifacts/market-score');
    16	
    17	const HORIZON_CONFIG = {
    18	  short: [
    19	    { key: 'rsi_14', weight: 0.3, type: 'rsi' },
    20	    { key: 'returns_5d', weight: 0.35, type: 'return', scale: 0.015 },
    21	    { key: 'volatility_21d', weight: 0.35, type: 'penalty', baseline: 0.04 }
    22	  ],
    23	  mid: [
    24	    { key: 'momentum_63d', weight: 0.35, type: 'momentum', scale: 0.03 },
    25	    { key: 'distance_to_sma_20', weight: 0.25, type: 'trend', scale: 0.12 },
    26	    { key: 'distance_to_sma_50', weight: 0.2, type: 'trend', scale: 0.15 },
    27	    { key: 'drawdown_current_252d', weight: 0.2, type: 'drawdown' }
    28	  ],
    29	  long: [
    30	    { key: 'momentum_126d', weight: 0.3, type: 'momentum', scale: 0.025 },
    31	    { key: 'momentum_252d', weight: 0.2, type: 'momentum', scale: 0.02 },
    32	    { key: 'volatility_63d', weight: 0.25, type: 'penalty', baseline: 0.05 },
    33	    { key: 'drawdown_max_252d', weight: 0.25, type: 'drawdown' }
    34	  ]
    35	};
    36	
    37	const TOTAL_WEIGHTS = Object.values(HORIZON_CONFIG).flat().reduce((sum, comp) => sum + comp.weight, 0);
    38	
    39	function clamp(value, min = -1, max = 1) {
    40	  if (value === null || value === undefined || Number.isNaN(value)) return null;
    41	  return Math.max(min, Math.min(max, value));
    42	}
    43	
    44	function normalizeValue(value, config) {
    45	  if (!Number.isFinite(value)) return null;
    46	  switch (config.type) {
    47	    case 'rsi': {
    48	      const normalized = (50 - value) / 50;
    49	      return clamp(normalized);
    50	    }
    51	    case 'return':
    52	    case 'momentum': {
    53	      const scale = config.scale || 0.05;
    54	      return clamp(value / scale);
    55	    }
    56	    case 'trend': {
    57	      const scale = config.scale || 0.1;
    58	      return clamp((value || 0) / scale);
    59	    }
    60	    case 'penalty': {
    61	      const baseline = config.baseline || 0.05;
    62	      return clamp((baseline - value) / baseline);
    63	    }
    64	    case 'drawdown': {
    65	      const scale = config.scale || 0.2;
    66	      return clamp(-value / scale);
    67	    }
    68	    default:
    69	      return null;
    70	  }
    71	}
    72	
    73	function computeHorizon(stats, horizonKey) {
    74	  const config = HORIZON_CONFIG[horizonKey];
    75	  const contributions = [];
    76	  let usedWeight = 0;
    77	  let weightedSum = 0;
    78	
    79	  for (const component of config) {
    80	    const rawValue = stats?.stats?.[component.key];
    81	    const normalized = normalizeValue(rawValue, component);
    82	    if (normalized === null) continue;
    83	    const code = component.code || component.key.toUpperCase().replace(/[^A-Z0-9_]/g, '_');
    84	    const points = normalized * component.weight;
    85	    usedWeight += component.weight;
    86	    weightedSum += points;
    87	    contributions.push({
    88	      metric: component.key,
    89	      code,
    90	      weight: component.weight,
    91	      value: rawValue,
    92	      normalized,
    93	      points
    94	    });
    95	  }
    96	
    97	  const normalizedScore = usedWeight > 0 ? weightedSum / usedWeight : 0;
    98	  const score = Math.round(((normalizedScore + 1) / 2) * 100);
    99	  const confidence = usedWeight / config.reduce((sum, comp) => sum + comp.weight, 0);
   100	  const reasonsTop = contributions
   101	    .sort((a, b) => Math.abs(b.points) - Math.abs(a.points))
   102	    .slice(0, 5);
   103	
   104	  return {
   105	    score: clamp(score, 0, 100),
   106	    confidence: clamp(confidence, 0, 1),
   107	    contributions: reasonsTop,
   108	    components_used: contributions.map((c) => c.metric)
   109	  };
   110	}
   111	
   112	export function computeScoresForStats(symbol, statsEntry) {
   113	  const horizonResults = {};
   114	  const inputsUsed = new Set();
   115	  const confidences = [];
   116	  const reasonsTop = {};
   117	  let coverageRatio = statsEntry?.coverage?.coverage_ratio ?? 0;
   118	
   119	  for (const horizon of Object.keys(HORIZON_CONFIG)) {
   120	    const result = computeHorizon(statsEntry, horizon);
   121	    horizonResults[horizon] = result.score;
   122	    confidences.push(result.confidence);
   123	    result.contributions.forEach((contrib) => inputsUsed.add(contrib.metric));
   124	    reasonsTop[horizon] = result.contributions;
   125	  }
   126	
   127	  const averageConfidence = confidences.length ? confidences.reduce((a, b) => a + b, 0) / confidences.length : 0;
   128	
   129	  return {
   130	    symbol,
   131	    score_short: horizonResults.short,
   132	    score_mid: horizonResults.mid,
   133	    score_long: horizonResults.long,
   134	    confidence: clamp(Math.round(averageConfidence * 1000) / 1000, 0, 1),
   135	    coverage_ratio: typeof coverageRatio === 'number' ? Number(coverageRatio.toFixed(3)) : 0,
   136	    reasons_top: reasonsTop,
   137	    inputs_used: Array.from(inputsUsed).sort(),
   138	    version: SCORE_VERSION,
   139	    weights_digest: computeDigest(HORIZON_CONFIG)
   140	  };
   141	}
   142	
   143	async function readJson(path) {
   144	  const content = await readFile(path, 'utf-8');
   145	  return JSON.parse(content);
   146	}
   147	
   148	async function loadModuleConfig() {
   149	  const registryPath = join(BASE_DIR, 'public/data/registry/modules.json');
   150	  const registry = await readJson(registryPath);
   151	  const config = registry?.modules?.[MODULE_NAME];
   152	  if (!config) {
   153	    throw new Error(`MODULE_CONFIG_MISSING:${MODULE_NAME}`);
   154	  }
   155	  return config;
   156	}
   157	
   158	async function loadSourceSnapshots() {
   159	  const artifactsDir = process.env.ARTIFACTS_DIR ? join(String(process.env.ARTIFACTS_DIR), SOURCE_MODULE) : null;
   160	  const candidates = [];
   161	  if (process.env.BARS_ARTIFACTS_DIR) {
   162	    candidates.push(join(String(process.env.BARS_ARTIFACTS_DIR), SOURCE_MODULE, 'snapshot.json'));
   163	  }
   164	  if (artifactsDir) {
   165	    candidates.push(join(artifactsDir, 'snapshot.json'));
   166	  }
   167	  candidates.push(join(BASE_DIR, 'public/data/snapshots', SOURCE_MODULE, 'latest.json'));
   168	
   169	  const snapshots = [];
   170	  for (const path of candidates) {
   171	    try {
   172	      const payload = await readJson(path);
   173	      snapshots.push({ path, snapshot: payload });
   174	    } catch (err) {
   175	      // ignore missing files
   176	    }
   177	  }
   178	  if (snapshots.length === 0) {
   179	    throw new Error('SCORING_INPUT_MISSING');
   180	  }
   181	  return snapshots;
   182	}
   183	
   184	function aggregateStats(snapshots) {
   185	  const map = new Map();
   186	  for (const { snapshot } of snapshots) {
   187	    const data = Array.isArray(snapshot?.data) ? snapshot.data : [];
   188	    for (const entry of data) {
   189	      if (!entry || !entry.symbol) continue;
   190	      map.set(entry.symbol, entry);
   191	    }
   192	  }
   193	  return map;
   194	}
   195	
   196	function buildHealth(totalSymbols, scoredSymbols) {
   197	  const coverageRatio = totalSymbols ? Math.min(1, scoredSymbols / totalSymbols) : 0;
   198	  return {
   199	    module: MODULE_NAME,
   200	    total_symbols: totalSymbols,

## FILE: scripts/providers/market-stats-v3.mjs
     1	#!/usr/bin/env node
     2	
     3	import { readFile, writeFile, mkdir } from 'node:fs/promises';
     4	import { join } from 'node:path';
     5	import { fileURLToPath, pathToFileURL } from 'node:url';
     6	import { buildEnvelope, validateEnvelopeSchema } from '../lib/envelope.js';
     7	import { computeSnapshotDigest } from '../lib/digest.js';
     8	import { buildModuleState } from '../lib/module-state.js';
     9	import { computeValidationMetadata } from '../lib/drop-threshold.js';
    10	
    11	const __filename = fileURLToPath(import.meta.url);
    12	const BASE_DIR = process.cwd();
    13	const MODULE_NAME = 'market-stats';
    14	const SOURCE_MODULE = 'market-prices';
    15	const DEFAULT_ARTIFACTS_DIR = join(BASE_DIR, 'tmp/phase1-artifacts/market-stats');
    16	const DEFAULT_BARS_LOOKBACK = 252;
    17	const RETURN_WINDOWS = [1, 5, 21, 63, 126, 252];
    18	const RUN_QUALITY_THRESHOLDS = {
    19	  OK: 0.95,
    20	  DEGRADED: 0.5
    21	};
    22	
    23	function safeNumber(value) {
    24	  const num = Number(value);
    25	  return Number.isFinite(num) ? num : null;
    26	}
    27	
    28	function daysBetween(dateA, dateB) {
    29	  if (!dateA || !dateB) return null;
    30	  const diff = Math.abs(dateA.getTime() - dateB.getTime());
    31	  return Math.floor(diff / (1000 * 60 * 60 * 24));
    32	}
    33	
    34	function readJson(filePath) {
    35	  return readFile(filePath, 'utf-8').then((content) => JSON.parse(content));
    36	}
    37	
    38	async function buildModuleConfig(moduleName) {
    39	  const registryPath = join(BASE_DIR, 'public/data/registry/modules.json');
    40	  const registry = await readJson(registryPath);
    41	  const config = registry?.modules?.[moduleName];
    42	  if (!config) {
    43	    throw new Error(`MODULE_CONFIG_MISSING:${moduleName}`);
    44	  }
    45	  return config;
    46	}
    47	
    48	async function loadUniverseSymbols() {
    49	  const universePath = join(BASE_DIR, 'public/data/registry/universe.v1.json');
    50	  const content = await readJson(universePath);
    51	  const symbols = content?.groups?.index_proxies?.symbols;
    52	  if (!Array.isArray(symbols) || symbols.length === 0) {
    53	    throw new Error('UNIVERSE_INDEX_PROXIES_MISSING');
    54	  }
    55	  return symbols.slice();
    56	}
    57	
    58	async function loadSourceSnapshots() {
    59	  const barsDir = process.env.BARS_ARTIFACTS_DIR
    60	    ? join(String(process.env.BARS_ARTIFACTS_DIR), SOURCE_MODULE)
    61	    : null;
    62	  const candidates = [];
    63	  if (barsDir) {
    64	    candidates.push(join(barsDir, 'snapshot.json'));
    65	  }
    66	  const publicDir = join(BASE_DIR, 'public/data/snapshots', SOURCE_MODULE);
    67	  candidates.push(join(publicDir, 'latest.json'));
    68	
    69	  const snapshots = [];
    70	  for (const path of candidates) {
    71	    try {
    72	      const content = await readJson(path);
    73	      snapshots.push({ path, snapshot: content });
    74	    } catch (err) {
    75	      // ignore missing snapshots
    76	    }
    77	  }
    78	  if (snapshots.length === 0) {
    79	    throw new Error('BARS_SNAPSHOT_MISSING');
    80	  }
    81	  return snapshots;
    82	}
    83	
    84	function normalizeBar(bar) {
    85	  if (!bar || typeof bar !== 'object') return null;
    86	  const date = typeof bar.date === 'string' ? bar.date : null;
    87	  const close = safeNumber(bar.close);
    88	  const open = safeNumber(bar.open);
    89	  const high = safeNumber(bar.high);
    90	  const low = safeNumber(bar.low);
    91	  const volume = safeNumber(bar.volume);
    92	  if (!date || close === null || high === null || low === null || open === null) return null;
    93	  return {
    94	    symbol: String(bar.symbol || '').trim(),
    95	    date,
    96	    open,
    97	    high,
    98	    low,
    99	    close,
   100	    volume: volume === null ? null : Math.floor(volume),
   101	    currency: bar.currency || 'USD'
   102	  };
   103	}
   104	
   105	function aggregateBars(snapshots) {
   106	  const uniqueBars = new Map();
   107	  for (const { snapshot } of snapshots) {
   108	    const data = Array.isArray(snapshot?.data) ? snapshot.data : [];
   109	    for (const entry of data) {
   110	      const normalized = normalizeBar(entry);
   111	      if (!normalized || !normalized.symbol) continue;
   112	      const key = `${normalized.symbol}:${normalized.date}`;
   113	      if (!uniqueBars.has(key)) {
   114	        uniqueBars.set(key, normalized);
   115	      }
   116	    }
   117	  }
   118	  const history = new Map();
   119	  for (const bar of uniqueBars.values()) {
   120	    const list = history.get(bar.symbol) || [];
   121	    list.push(bar);
   122	    history.set(bar.symbol, list);
   123	  }
   124	  for (const [symbol, list] of history.entries()) {
   125	    list.sort((a, b) => new Date(b.date).getTime() - new Date(a.date).getTime());
   126	  }
   127	  return history;
   128	}
   129	
   130	function computeLogReturn(latest, past) {
   131	  if (latest === null || past === null || past === 0) return null;
   132	  const ratio = latest / past;
   133	  if (!Number.isFinite(ratio) || ratio <= 0) return null;
   134	  return Math.log(ratio);
   135	}
   136	
   137	function computeMomentum(latest, past) {
   138	  if (latest === null || past === null || past === 0) return null;
   139	  const change = (latest - past) / past;
   140	  return Number(change * 100);
   141	}
   142	
   143	function computeStd(values) {
   144	  if (!Array.isArray(values) || values.length === 0) return { mean: null, std: null };
   145	  const mean = values.reduce((sum, value) => sum + value, 0) / values.length;
   146	  const variance = values.reduce((sum, value) => sum + Math.pow(value - mean, 2), 0) / values.length;
   147	  const std = Math.sqrt(variance);
   148	  return { mean, std };
   149	}
   150	
   151	function computeVolatility(bars, window) {
   152	  if (bars.length <= window) return null;
   153	  const returns = [];
   154	  for (let i = 0; i < window; i++) {
   155	    const current = bars[i]?.close;
   156	    const previous = bars[i + 1]?.close;
   157	    if (current === undefined || previous === undefined) break;
   158	    const logReturn = computeLogReturn(current, previous);
   159	    if (logReturn === null) continue;
   160	    returns.push(logReturn);
   161	  }
   162	  if (returns.length === 0) return null;
   163	  const { std } = computeStd(returns);
   164	  if (std === null) return null;
   165	  const annualized = std * Math.sqrt(252);
   166	  return Number(annualized);
   167	}
   168	
   169	function computeDrawdowns(bars, lookback = 252) {
   170	  const window = bars.slice(0, lookback);
   171	  if (window.length === 0) return { max_drawdown: null, current_drawdown: null };
   172	  let peak = window[window.length - 1].close;
   173	  let maxDrawdown = 0;
   174	  const reversed = [...window].reverse();
   175	  for (const bar of reversed) {
   176	    if (bar.close > peak) peak = bar.close;
   177	    if (peak <= 0) continue;
   178	    const drawdown = (peak - bar.close) / peak;
   179	    if (drawdown > maxDrawdown) maxDrawdown = drawdown;
   180	  }
   181	  const latestClose = window[0].close;
   182	  const peakForCurrent = window.reduce((max, bar) => Math.max(max, bar.close), -Infinity);
   183	  const currentDrawdown = peakForCurrent > 0 ? (peakForCurrent - latestClose) / peakForCurrent : null;
   184	  return {
   185	    max_drawdown: Number(maxDrawdown),
   186	    current_drawdown: Number(currentDrawdown ?? 0)
   187	  };
   188	}
   189	
   190	function computeSMA(bars, period) {
   191	  if (bars.length < period) return null;
   192	  const subset = bars.slice(0, period);
   193	  const sum = subset.reduce((acc, bar) => acc + bar.close, 0);
   194	  return sum / subset.length;
   195	}
   196	
   197	function computeRSI(bars, period = 14) {
   198	  if (bars.length <= period) return null;
   199	  let gains = 0;
   200	  let losses = 0;

## FILE: scripts/providers/marketaux.js
     1	import { buildProviderError, fetchWithRetry, normalizeProviderDetails } from "./_shared.js";
     2	
     3	const BASE_URL = "https://api.marketaux.com/v1/news/all";
     4	
     5	export async function fetchMarketauxNews(ctx, { symbols = "SPY", limit = 10 } = {}) {
     6	  const requestCtx = ctx ? (ctx.endpoint ? ctx : { ...ctx, endpoint: "news" }) : { endpoint: "news" };
     7	  const apiKey = process.env.MARKETAUX_API_KEY || "";
     8	  if (!apiKey) {
     9	    throw buildProviderError("MISSING_SECRET", "missing_marketaux_api_key", {
    10	      httpStatus: null,
    11	      snippet: "missing MARKETAUX_API_KEY",
    12	      urlHost: "api.marketaux.com"
    13	    });
    14	  }
    15	
    16	  const params = new URLSearchParams({
    17	    symbols,
    18	    limit: String(limit),
    19	    api_token: apiKey
    20	  });
    21	  const url = `${BASE_URL}?${params.toString()}`;
    22	
    23	  let res;
    24	  let text;
    25	  try {
    26	    ({ res, text } = await fetchWithRetry(url, requestCtx, {
    27	      headers: { "User-Agent": "RVSeeder/1.0" },
    28	      timeoutMs: 15000
    29	    }));
    30	  } catch (error) {
    31	    if (error?.reason) {
    32	      error.details = normalizeProviderDetails(url, error.details || {});
    33	      throw error;
    34	    }
    35	    throw buildProviderError("PROVIDER_BAD_PAYLOAD", error?.message || "marketaux_fetch_failed", {
    36	      httpStatus: null,
    37	      snippet: "",
    38	      urlHost: "api.marketaux.com"
    39	    });
    40	  }
    41	
    42	  let payload;
    43	  try {
    44	    payload = JSON.parse(text);
    45	  } catch (error) {
    46	    throw buildProviderError("PROVIDER_BAD_PAYLOAD", "marketaux_json_parse_failed", {
    47	      httpStatus: res.status,
    48	      snippet: String(text || "").slice(0, 200),
    49	      urlHost: "api.marketaux.com"
    50	    });
    51	  }
    52	
    53	  const contentType = res.headers.get("content-type") || "";
    54	  if (contentType && !contentType.includes("application/json")) {
    55	    console.warn("marketaux content-type not json; parsed successfully");
    56	  }
    57	
    58	  const rows = Array.isArray(payload?.data) ? payload.data : [];
    59	  const items = rows.slice(0, limit).map((row) => ({
    60	    title: row.title || "",
    61	    source: row.source || row.source_name || "",
    62	    sentiment: Number.isFinite(row.sentiment_score) ? row.sentiment_score : null,
    63	    date: row.published_at || row.date || null
    64	  }));
    65	
    66	  const dataAt = rows
    67	    .map((row) => row.published_at || row.date)
    68	    .filter(Boolean)
    69	    .sort()
    70	    .slice(-1)[0] || null;
    71	
    72	  return { data: items, dataAt };
    73	}

## FILE: scripts/providers/rss.js
     1	import { buildProviderError, fetchWithRetry, normalizeProviderDetails } from "./_shared.js";
     2	
     3	export async function fetchRssFeed(ctx, url) {
     4	  const requestCtx = ctx ? (ctx.endpoint ? ctx : { ...ctx, endpoint: "rss" }) : { endpoint: "rss" };
     5	  if (!url) {
     6	    throw buildProviderError("PROVIDER_BAD_PAYLOAD", "rss_missing_url", {
     7	      httpStatus: null,
     8	      snippet: "",
     9	      urlHost: ""
    10	    });
    11	  }
    12	
    13	  let res;
    14	  let text;
    15	  try {
    16	    ({ res, text } = await fetchWithRetry(url, requestCtx, {
    17	      headers: {
    18	        "User-Agent": "RVSeeder/1.0",
    19	        Accept: "application/rss+xml, application/atom+xml, application/xml, text/xml, */*"
    20	      },
    21	      timeoutMs: 15000
    22	    }));
    23	  } catch (error) {
    24	    if (error?.reason) {
    25	      error.details = normalizeProviderDetails(url, error.details || {});
    26	      throw error;
    27	    }
    28	    throw buildProviderError("PROVIDER_BAD_PAYLOAD", error?.message || "rss_fetch_failed", {
    29	      httpStatus: null,
    30	      snippet: "",
    31	      urlHost: ""
    32	    });
    33	  }
    34	
    35	  if (!res.ok) {
    36	    throw buildProviderError(
    37	      "PROVIDER_HTTP_ERROR",
    38	      `rss_http_${res.status}`,
    39	      normalizeProviderDetails(url, { httpStatus: res.status, snippet: text })
    40	    );
    41	  }
    42	
    43	  const trimmed = String(text || "").trim().toLowerCase();
    44	  if (trimmed.startsWith("<!doctype") || trimmed.startsWith("<html")) {
    45	    throw buildProviderError(
    46	      "PROVIDER_BAD_PAYLOAD",
    47	      "rss_html_payload",
    48	      normalizeProviderDetails(url, { snippet: text })
    49	    );
    50	  }
    51	
    52	  return { data: text, dataAt: new Date().toISOString() };
    53	}

## FILE: scripts/providers/sec_edgar.js
     1	import { buildProviderError, fetchWithRetry, normalizeProviderDetails } from "./_shared.js";
     2	
     3	const BASE_URL = "https://data.sec.gov";
     4	
     5	export async function fetchSecRecentFilings(ctx, { cik = "0000320193" } = {}) {
     6	  const requestCtx = ctx ? (ctx.endpoint ? ctx : { ...ctx, endpoint: "edgar" }) : { endpoint: "edgar" };
     7	  const apiKey = process.env.SEC_API_KEY || "";
     8	  if (!apiKey) {
     9	    throw buildProviderError("MISSING_SECRET", "missing_sec_api_key", {
    10	      httpStatus: null,
    11	      snippet: "missing SEC_API_KEY",
    12	      urlHost: "data.sec.gov"
    13	    });
    14	  }
    15	
    16	  const url = `${BASE_URL}/submissions/CIK${cik}.json`;
    17	
    18	  let res;
    19	  let text;
    20	  try {
    21	    ({ res, text } = await fetchWithRetry(url, requestCtx, {
    22	      headers: {
    23	        "User-Agent": "RVSeeder/1.0",
    24	        "Accept": "application/json"
    25	      },
    26	      timeoutMs: 20000
    27	    }));
    28	  } catch (error) {
    29	    if (error?.reason) {
    30	      error.details = normalizeProviderDetails(url, error.details || {});
    31	      throw error;
    32	    }
    33	    throw buildProviderError("PROVIDER_BAD_PAYLOAD", error?.message || "sec_fetch_failed", {
    34	      httpStatus: null,
    35	      snippet: "",
    36	      urlHost: "data.sec.gov"
    37	    });
    38	  }
    39	
    40	  let payload;
    41	  try {
    42	    payload = JSON.parse(text);
    43	  } catch (error) {
    44	    throw buildProviderError("PROVIDER_BAD_PAYLOAD", "sec_json_parse_failed", {
    45	      httpStatus: res.status,
    46	      snippet: String(text || "").slice(0, 200),
    47	      urlHost: "data.sec.gov"
    48	    });
    49	  }
    50	
    51	  const contentType = res.headers.get("content-type") || "";
    52	  if (contentType && !contentType.includes("application/json")) {
    53	    console.warn("sec content-type not json; parsed successfully");
    54	  }
    55	
    56	  const recent = payload?.filings?.recent;
    57	  const items = [];
    58	  if (recent && Array.isArray(recent.accessionNumber)) {
    59	    for (let i = 0; i < Math.min(recent.accessionNumber.length, 10); i += 1) {
    60	      items.push({
    61	        accessionNumber: recent.accessionNumber[i],
    62	        form: recent.form?.[i] || null,
    63	        filedAt: recent.filingDate?.[i] || null
    64	      });
    65	    }
    66	  }
    67	
    68	  const dataAt = items
    69	    .map((row) => row.filedAt)
    70	    .filter(Boolean)
    71	    .sort()
    72	    .slice(-1)[0] || null;
    73	
    74	  return { data: items, dataAt };
    75	}

## FILE: scripts/providers/universe-v2.mjs
     1	#!/usr/bin/env node
     2	
     3	import { readFile, writeFile, mkdir } from 'node:fs/promises';
     4	import { join, dirname } from 'node:path';
     5	import { fileURLToPath, pathToFileURL } from 'node:url';
     6	import { buildEnvelope, validateEnvelopeSchema } from '../lib/envelope.js';
     7	import { computeSnapshotDigest } from '../lib/digest.js';
     8	import { buildModuleState } from '../lib/module-state.js';
     9	import { computeValidationMetadata } from '../lib/drop-threshold.js';
    10	
    11	const __filename = fileURLToPath(import.meta.url);
    12	const BASE_DIR = process.cwd();
    13	const MODULE_NAME = 'universe';
    14	const DEFAULT_ARTIFACTS_DIR = join(BASE_DIR, 'tmp/universe-artifacts');
    15	const DEFAULT_STUB_PATH = join(BASE_DIR, 'tests/fixtures/universe-v2.stub.json');
    16	const INDEX_THRESHOLDS = {
    17	  DJ30: 30,
    18	  SP500: 500,
    19	  NDX100: 100,
    20	  RUT2000: 2000
    21	};
    22	const TOTAL_THRESHOLD = Object.values(INDEX_THRESHOLDS).reduce((sum, next) => sum + next, 0);
    23	
    24	function toBool(value) {
    25	  const raw = String(value || '').trim().toLowerCase();
    26	  return raw === '1' || raw === 'true' || raw === 'yes';
    27	}
    28	
    29	function formatDate(date = new Date()) {
    30	  const y = date.getUTCFullYear();
    31	  const m = String(date.getUTCMonth() + 1).padStart(2, '0');
    32	  const d = String(date.getUTCDate()).padStart(2, '0');
    33	  return `${y}-${m}-${d}`;
    34	}
    35	
    36	async function readJson(path) {
    37	  const content = await readFile(path, 'utf-8');
    38	  return JSON.parse(content);
    39	}
    40	
    41	function parseCsv(text) {
    42	  const lines = text.replace(/\r/g, '').split('\n').filter((line) => line.trim().length > 0);
    43	  if (lines.length === 0) return [];
    44	  const headers = lines[0].split(',').map((column) => column.trim());
    45	  return lines.slice(1).map((line) => {
    46	    const values = [];
    47	    let current = '';
    48	    let inQuotes = false;
    49	    for (let i = 0; i < line.length; i++) {
    50	      const char = line[i];
    51	      if (char === '"' && line[i - 1] !== '\\') {
    52	        inQuotes = !inQuotes;
    53	        continue;
    54	      }
    55	      if (char === ',' && !inQuotes) {
    56	        values.push(current);
    57	        current = '';
    58	        continue;
    59	      }
    60	      current += char;
    61	    }
    62	    values.push(current);
    63	    const row = {};
    64	    for (let i = 0; i < headers.length; i += 1) {
    65	      row[headers[i]] = values[i] !== undefined ? values[i].trim() : '';
    66	    }
    67	    return row;
    68	  });
    69	}
    70	
    71	export function normalizeSymbol(rawValue, warnings = []) {
    72	  if (!rawValue) return null;
    73	  const trimmed = String(rawValue).trim();
    74	  if (trimmed.split(/\s+/).length > 1) {
    75	    warnings.push(`INVALID_SYMBOL:${rawValue}`);
    76	    return null;
    77	  }
    78	  let symbol = trimmed.toUpperCase();
    79	  symbol = symbol.replace(/\s+/g, '');
    80	  if (!symbol) return null;
    81	
    82	  const exchangeSuffix = symbol.match(/\.(US|UK|LN|L|HK|TO|AX|PA)$/i);
    83	  if (exchangeSuffix) {
    84	    symbol = symbol.replace(/\.(US|UK|LN|L|HK|TO|AX|PA)$/i, '');
    85	  } else if (symbol.includes('.')) {
    86	    symbol = symbol.replace(/\./g, '-');
    87	  }
    88	
    89	  symbol = symbol.replace(/-+US$/i, '');
    90	
    91	  if (!/^[A-Z0-9-]+$/.test(symbol)) {
    92	    warnings.push(`INVALID_SYMBOL:${rawValue}`);
    93	    return null;
    94	  }
    95	
    96	  if (symbol.length > 8) {
    97	    warnings.push(`SYMBOL_TOO_LONG:${symbol}`);
    98	  }
    99	
   100	  return symbol;
   101	}
   102	
   103	const INDEX_CONFIGS = {
   104	  DJ30: {
   105	    url: 'https://datahub.io/core/dow-30/r/dow-30.csv',
   106	    parser: (rows) => rows.map((row) => ({
   107	      symbol: row.Symbol,
   108	      name: row.Name,
   109	      sector: row.Industry || null,
   110	      industry: row.Industry || null,
   111	      exchange: 'NYSE',
   112	      country: 'US',
   113	      currency: 'USD'
   114	    }))
   115	  },
   116	  SP500: {
   117	    url: 'https://datahub.io/core/s-and-p-500-companies/r/constituents.csv',
   118	    parser: (rows) => rows.map((row) => ({
   119	      symbol: row.Symbol,
   120	      name: row.Name,
   121	      sector: row.Sector || null,
   122	      industry: null,
   123	      exchange: 'NYSE',
   124	      country: 'US',
   125	      currency: 'USD'
   126	    }))
   127	  },
   128	  NDX100: {
   129	    url: 'https://datahub.io/core/nasdaq-100/r/nasdaq-100.csv',
   130	    parser: (rows) => rows.map((row) => ({
   131	      symbol: row.Symbol,
   132	      name: row.Name,
   133	      sector: row.Sector || null,
   134	      industry: null,
   135	      exchange: 'NASDAQ',
   136	      country: 'US',
   137	      currency: 'USD'
   138	    }))
   139	  },
   140	  RUT2000: {
   141	    url: 'https://raw.githubusercontent.com/datasets/russell-2000/main/data/russell2000.csv',
   142	    parser: (rows) => rows.map((row) => ({
   143	      symbol: row.Symbol,
   144	      name: row.Name,
   145	      sector: row.Sector || null,
   146	      industry: row.Industry || null,
   147	      exchange: 'NYSE',
   148	      country: 'US',
   149	      currency: 'USD'
   150	    }))
   151	  }
   152	};
   153	
   154	async function fetchIndex(indexKey, config) {
   155	  const response = await fetch(config.url, {
   156	    headers: {
   157	      'User-Agent': 'RubikVault/3.0 universe',
   158	      Accept: 'text/csv'
   159	    }
   160	  });
   161	  const upstream = {
   162	    url: config.url,
   163	    http_status: response.status,
   164	    status: response.ok ? 'ok' : 'error'
   165	  };
   166	  if (!response.ok) {
   167	    return { entries: [], upstream };
   168	  }
   169	  const text = await response.text();
   170	  const rawEntries = parseCsv(text);
   171	  const parsed = config.parser(rawEntries);
   172	  upstream.record_count = parsed.length;
   173	  return { entries: parsed, upstream };
   174	}
   175	
   176	function mergeEntry(symbol, bucket, entry, index, warnings) {
   177	  if (!symbol) return;
   178	  const existing = bucket[symbol] || {
   179	    symbol,
   180	    name: entry.name || null,
   181	    exchange: entry.exchange || null,
   182	    currency: entry.currency || 'USD',
   183	    country: entry.country || null,
   184	    sector: entry.sector || null,
   185	    industry: entry.industry || null,
   186	    indexes: [],
   187	    source: {},
   188	    updated_at: formatDate()
   189	  };
   190	  if (entry.name && entry.name.length > (existing.name || '').length) {
   191	    existing.name = entry.name;
   192	  }
   193	  existing.exchange = existing.exchange || entry.exchange || null;
   194	  existing.sector = existing.sector || entry.sector || null;
   195	  existing.industry = existing.industry || entry.industry || null;
   196	  existing.indexes = Array.from(new Set([...existing.indexes, index]));
   197	  existing.source[index] = entry.name ? `${index}:${entry.name}` : `${index}:unknown`;
   198	  bucket[symbol] = existing;
   199	}
   200	

## FILE: scripts/refresh-health-assets.mjs
     1	import { promises as fs } from "node:fs";
     2	import path from "node:path";
     3	import { buildEnvelope, createValidator, loadSnapshotEnvelopeSchema } from "./lib/envelope-builder.mjs";
     4	
     5	const ROOT = process.cwd();
     6	const PUBLIC_DATA = path.join(ROOT, "public", "data");
     7	const SNAPSHOTS_DIR = path.join(PUBLIC_DATA, "snapshots");
     8	
     9	const NON_SYSTEMIC_REASONS = new Set(["MISSING_SECRET", "UNAUTHORIZED", "NO_DATA", "PAYLOAD_TOO_LARGE"]);
    10	
    11	async function readJson(filePath) {
    12	  const raw = await fs.readFile(filePath, "utf8");
    13	  return JSON.parse(raw);
    14	}
    15	
    16	async function writeJson(filePath, obj) {
    17	  await fs.mkdir(path.dirname(filePath), { recursive: true });
    18	  await fs.writeFile(filePath, JSON.stringify(obj, null, 2) + "\n", "utf8");
    19	}
    20	
    21	function nowIso() {
    22	  return new Date().toISOString();
    23	}
    24	
    25	function downgradeStatus(status, reason) {
    26	  const s = String(status || "").toUpperCase();
    27	  const r = String(reason || "").toUpperCase();
    28	  if (s === "ERROR" && NON_SYSTEMIC_REASONS.has(r)) return "PARTIAL";
    29	  return s || "ERROR";
    30	}
    31	
    32	function mapStatusToSystemHealth(status) {
    33	  // legacy system-health.json uses OK/FAIL
    34	  if (status === "ERROR") return "FAIL";
    35	  return "OK";
    36	}
    37	
    38	function buildLegacySystemHealthFromSnapshots(allSnapshots, generatedAt) {
    39	  const snapshots = [];
    40	  let ok = 0;
    41	  let fail = 0;
    42	
    43	  for (const snap of allSnapshots) {
    44	    const blockId = snap?.blockId || snap?.meta?.blockId || snap?.metadata?.module || "unknown";
    45	    const reason = snap?.meta?.reason || snap?.meta?.status || snap?.metadata?.validation?.reason || "OK";
    46	    const statusV3 = downgradeStatus(snap?.meta?.status, snap?.meta?.reason);
    47	    const status = mapStatusToSystemHealth(statusV3);
    48	    snapshots.push({ blockId, status, reason: String(reason || "OK") });
    49	    if (status === "OK") ok += 1;
    50	    else fail += 1;
    51	  }
    52	
    53	  return {
    54	    generatedAt,
    55	    buildStatus: fail > 0 ? "PARTIAL" : "OK",
    56	    reasons: [],
    57	    summary: { total: snapshots.length, ok, fail },
    58	    lastGoodAsOf: {},
    59	    snapshots
    60	  };
    61	}
    62	
    63	function buildV3HealthFromSeedManifest(existingHealth, seedManifest, generatedAt) {
    64	  const blocksRaw = Array.isArray(seedManifest?.blocks) ? seedManifest.blocks : [];
    65	  const blocks = blocksRaw.map((b) => {
    66	    const status = downgradeStatus(b?.status, b?.reason);
    67	    return { ...b, status };
    68	  });
    69	
    70	  const counts = { LIVE: 0, PARTIAL: 0, ERROR: 0 };
    71	  const reasons = {};
    72	  for (const b of blocks) {
    73	    const st = String(b?.status || "ERROR").toUpperCase();
    74	    const rs = String(b?.reason || "UNKNOWN");
    75	    if (st === "LIVE") counts.LIVE += 1;
    76	    else if (st === "PARTIAL") counts.PARTIAL += 1;
    77	    else counts.ERROR += 1;
    78	    reasons[rs] = (reasons[rs] || 0) + 1;
    79	  }
    80	
    81	  const overallStatus = counts.ERROR > 0 ? "PARTIAL" : "LIVE";
    82	  const overallReason = counts.ERROR > 0 ? "BLOCK_ERRORS" : null;
    83	
    84	  const base = existingHealth && typeof existingHealth === "object" ? { ...existingHealth } : {};
    85	  base.schemaVersion = base.schemaVersion || "v3";
    86	  base.blockId = "health";
    87	  base.generatedAt = generatedAt;
    88	  base.dataAt = seedManifest?.generatedAt || generatedAt;
    89	
    90	  base.meta = {
    91	    ...(base.meta && typeof base.meta === "object" ? base.meta : {}),
    92	    status: overallStatus,
    93	    reason: overallReason,
    94	    generatedAt,
    95	    asOf: base.dataAt,
    96	    source: "health",
    97	    ttlSeconds: 3600,
    98	    stale: false,
    99	    itemsCount: 1,
   100	    stalenessSec: 0,
   101	    freshness: { status: "fresh", ageMinutes: 0 },
   102	    schedule: {
   103	      rule: "daily",
   104	      nextPlannedFetchAt: generatedAt,
   105	      expectedNextRunWindowMinutes: 1440,
   106	      ttlSeconds: 3600
   107	    },
   108	    runId: generatedAt,
   109	    notes: {
   110	      lastGoodUsed: 0,
   111	      lastGoodFilled: 0
   112	    },
   113	    validation: base.meta?.validation || {
   114	      schema: { ok: true, errors: [] },
   115	      ranges: { ok: true, errors: [] },
   116	      integrity: { ok: true, errors: [] }
   117	    }
   118	  };
   119	
   120	  base.data = {
   121	    ...(base.data && typeof base.data === "object" ? base.data : {}),
   122	    items: [
   123	      {
   124	        id: "health_status",
   125	        label: "health",
   126	        value: overallStatus,
   127	        unit: "",
   128	        derivedFromLastGood: false,
   129	        derivationReason: null,
   130	        stale: false,
   131	        staleReason: null
   132	      }
   133	    ],
   134	    blocks,
   135	    summary: {
   136	      ...counts,
   137	      total: blocks.length,
   138	      okPct: blocks.length ? (counts.LIVE + counts.PARTIAL) / blocks.length : 0,
   139	      reasons
   140	    }
   141	  };
   142	
   143	  return base;
   144	}
   145	
   146	async function listSnapshotJsonFiles(dir) {
   147	  const entries = await fs.readdir(dir, { withFileTypes: true });
   148	  return entries
   149	    .filter((e) => e.isFile() && e.name.endsWith(".json"))
   150	    .map((e) => path.join(dir, e.name));
   151	}
   152	
   153	async function main() {
   154	  const generatedAt = nowIso();
   155	
   156	  const healthPath = path.join(SNAPSHOTS_DIR, "health.json");
   157	  const healthDirLatestPath = path.join(SNAPSHOTS_DIR, "health", "latest.json");
   158	  const healthLatestPath = path.join(PUBLIC_DATA, "blocks", "health.latest.json");
   159	  const systemHealthPath = path.join(PUBLIC_DATA, "system-health.json");
   160	  const seedManifestPath = path.join(PUBLIC_DATA, "seed-manifest.json");
   161	
   162	  const seedManifest = await readJson(seedManifestPath);
   163	
   164	  let existingHealth = null;
   165	  try {
   166	    existingHealth = await readJson(healthPath);
   167	  } catch {
   168	    existingHealth = null;
   169	  }
   170	
   171	  const refreshedHealth = buildV3HealthFromSeedManifest(existingHealth, seedManifest, generatedAt);
   172	  await writeJson(healthPath, refreshedHealth);
   173	  await writeJson(healthLatestPath, refreshedHealth);
   174	
   175	  const healthBlocks = Array.isArray(refreshedHealth?.data?.blocks) ? refreshedHealth.data.blocks : [];
   176	  const schema = loadSnapshotEnvelopeSchema();
   177	  const { validate } = createValidator(schema);
   178	  const envelope = buildEnvelope(schema, {
   179	    module: "health",
   180	    tier: "critical",
   181	    domain: "system",
   182	    source: "health-refresh",
   183	    fetched_at: generatedAt,
   184	    published_at: generatedAt,
   185	    data: healthBlocks,
   186	    record_count: healthBlocks.length,
   187	    expected_count: healthBlocks.length,
   188	    validation: { passed: true },
   189	    freshness: {
   190	      policy: "daily",
   191	      expected_interval_minutes: 1440,
   192	      age_minutes: 0,
   193	      next_expected_at: generatedAt
   194	    }
   195	  });
   196	
   197	  if (!validate(envelope)) {
   198	    console.error("Health snapshot envelope validation failed");
   199	    console.error(validate.errors);
   200	    throw new Error("health latest.json failed schema validation");

## FILE: scripts/runners/package3/30-flow-anomaly-lite.js
     1	import { getSnapshot, makeNoDataError } from "./_shared.js";
     2	
     3	export async function run(ctx, entry) {
     4	  const breadthSnapshot = getSnapshot(ctx.cache, "market-breadth");
     5	  const summary = breadthSnapshot?.data?.summary || {};
     6	  const itemsList = Array.isArray(breadthSnapshot?.data?.items) ? breadthSnapshot.data.items : [];
     7	  const advancers = Number.isFinite(summary.advancers)
     8	    ? summary.advancers
     9	    : itemsList.filter((row) => row.changePct > 0).length;
    10	  const decliners = Number.isFinite(summary.decliners)
    11	    ? summary.decliners
    12	    : itemsList.filter((row) => row.changePct < 0).length;
    13	  const total = advancers + decliners;
    14	  if (!total) throw makeNoDataError("breadth_missing");
    15	
    16	  const ratio = advancers / total;
    17	  const anomaly = ratio > 0.7 || ratio < 0.3;
    18	  const items = [
    19	    {
    20	      advancers,
    21	      decliners,
    22	      ratio,
    23	      anomaly,
    24	      date: breadthSnapshot?.dataAt || null
    25	    }
    26	  ];
    27	
    28	  return { items, dataAt: breadthSnapshot?.dataAt || null };
    29	}

## FILE: scripts/runners/package3/41-weekly-market-brief.js
     1	import { getSnapshot, makeNoDataError, maxDate } from "./_shared.js";
     2	
     3	export async function run(ctx, entry) {
     4	  const health = getSnapshot(ctx.cache, "market-health-summary");
     5	  const stress = getSnapshot(ctx.cache, "market-stress-composite");
     6	  const drawdown = getSnapshot(ctx.cache, "drawdown-monitor");
     7	  const macro = getSnapshot(ctx.cache, "macro-risk-score");
     8	
     9	  const items = [];
    10	  if (health?.data?.summary) {
    11	    items.push({
    12	      label: "Health",
    13	      value: `live ${health.data.summary.live || 0} / total ${health.data.summary.total || 0}`
    14	    });
    15	  }
    16	  if (stress?.data?.items?.[0]) {
    17	    items.push({
    18	      label: "Stress",
    19	      value: String(stress.data.items[0].score ?? "")
    20	    });
    21	  }
    22	  if (drawdown?.data?.items?.[0]) {
    23	    items.push({
    24	      label: "Drawdown",
    25	      value: String(drawdown.data.items[0].drawdownPct ?? "")
    26	    });
    27	  }
    28	  if (macro?.data?.items?.[0]) {
    29	    items.push({
    30	      label: "Macro",
    31	      value: String(macro.data.items[0].score ?? "")
    32	    });
    33	  }
    34	
    35	  if (!items.length) throw makeNoDataError("weekly_brief_inputs_missing");
    36	
    37	  const dataAt = maxDate(health?.dataAt, stress?.dataAt, drawdown?.dataAt, macro?.dataAt);
    38	  return { items, dataAt };
    39	}

## FILE: scripts/runners/package3/43-master-market-dashboard.js
     1	import { getSnapshot, maxDate, makeNoDataError } from "./_shared.js";
     2	
     3	const BLOCK_IDS = [
     4	  "us-yield-curve",
     5	  "ecb-rates-board",
     6	  "inflation-pulse",
     7	  "labor-pulse",
     8	  "energy-macro",
     9	  "credit-stress-proxy",
    10	  "fx-board",
    11	  "market-breadth",
    12	  "highs-vs-lows",
    13	  "sector-rotation",
    14	  "vol-regime",
    15	  "liquidity-conditions-proxy",
    16	  "risk-regime-lite",
    17	  "drawdown-monitor",
    18	  "trend-strength-board",
    19	  "momentum-heatmap-lite",
    20	  "volatility-term-lite",
    21	  "sector-relative-strength",
    22	  "credit-spread-proxy-lite",
    23	  "liquidity-delta",
    24	  "macro-surprise-lite",
    25	  "market-stress-composite",
    26	  "breadth-delta",
    27	  "regime-transition-watch",
    28	  "earnings-pressure-lite",
    29	  "insider-activity-lite",
    30	  "options-skew-lite",
    31	  "gamma-exposure-lite",
    32	  "flow-anomaly-lite",
    33	  "sentiment-lite",
    34	  "social-velocity-lite",
    35	  "analyst-revision-lite",
    36	  "macro-risk-score",
    37	  "tail-risk-watch",
    38	  "liquidity-stress-watch",
    39	  "regime-fracture-alert",
    40	  "catalyst-calendar-lite",
    41	  "cross-asset-divergence",
    42	  "systemic-risk-lite",
    43	  "weekly-market-brief",
    44	  "alpha-radar-lite",
    45	  "market-health-summary"
    46	];
    47	
    48	export async function run(ctx, entry) {
    49	  const items = [];
    50	  let dataAt = null;
    51	
    52	  for (const blockId of BLOCK_IDS) {
    53	    const snapshot = getSnapshot(ctx.cache, blockId);
    54	    if (!snapshot) continue;
    55	    const status = snapshot?.meta?.status || "ERROR";
    56	    const reason = snapshot?.meta?.reason || "NO_DATA";
    57	    items.push({ blockId, status, reason });
    58	    dataAt = maxDate(dataAt, snapshot?.dataAt);
    59	  }
    60	
    61	  if (!items.length) throw makeNoDataError("dashboard_missing");
    62	
    63	  return { items, dataAt };
    64	}

## FILE: scripts/scientific-analyzer/generate-analysis.mjs
     1	#!/usr/bin/env node
     2	/**
     3	 * Scientific Stock Analyzer v9.1 - Analysis Generation Script
     4	 * 
     5	 * Generates stock analysis with Setup/Trigger detection for all NASDAQ-100 symbols.
     6	 * Uses synthetic indicator simulation based on company characteristics.
     7	 * 
     8	 * Setup Criteria (accumulation phase indicators):
     9	 * - RSI between 40-60 (neutral, not oversold/overbought)
    10	 * - Price above SMA200 (long-term uptrend)
    11	 * - SMA50 > SMA200 (golden cross structure)
    12	 * - Volatility declining or stable
    13	 * - Volume accumulation (volume ratio < 0.8 in consolidation)
    14	 * 
    15	 * Trigger Criteria (breakout confirmation):
    16	 * - RSI crossing above 55
    17	 * - Price breaking above SMA20
    18	 * - Volume spike (ratio > 1.3)
    19	 * - MACD histogram positive and increasing
    20	 * 
    21	 * Output: public/data/snapshots/stock-analysis.json
    22	 */
    23	
    24	import fs from 'node:fs/promises';
    25	import path from 'node:path';
    26	
    27	import { computeFeatures } from '../lib/scientific-analyzer/features.mjs';
    28	import { generateExplainabilityReport, formatExplanationForUI } from '../lib/scientific-analyzer/explainability.mjs';
    29	import { applyPlattScaling } from '../lib/scientific-analyzer/calibration.mjs';
    30	
    31	const REPO_ROOT = process.cwd();
    32	const MODELS_DIR = 'public/data/models';
    33	const SNAPSHOTS_DIR = 'public/data/snapshots';
    34	const MARKETPHASE_DIR = 'public/data/marketphase';
    35	const UNIVERSE_FILE = 'public/data/universe/nasdaq100.json';
    36	
    37	function isoNow() {
    38	    return new Date().toISOString();
    39	}
    40	
    41	async function readJson(relPath) {
    42	    const abs = path.join(REPO_ROOT, relPath);
    43	    try {
    44	        const raw = await fs.readFile(abs, 'utf-8');
    45	        return JSON.parse(raw);
    46	    } catch {
    47	        return null;
    48	    }
    49	}
    50	
    51	async function writeJsonAtomic(relPath, data) {
    52	    const abs = path.join(REPO_ROOT, relPath);
    53	    const tmpPath = `${abs}.tmp`;
    54	    await fs.mkdir(path.dirname(abs), { recursive: true });
    55	    await fs.writeFile(tmpPath, JSON.stringify(data, null, 2) + '\n', 'utf-8');
    56	    await fs.rename(tmpPath, abs);
    57	}
    58	
    59	// Seeded random for reproducible synthetic data
    60	function seededRandom(seed) {
    61	    let s = seed;
    62	    return function () {
    63	        s = (s * 1103515245 + 12345) & 0x7fffffff;
    64	        return s / 0x7fffffff;
    65	    };
    66	}
    67	
    68	// Hash ticker to number for consistent random seed
    69	function hashTicker(ticker) {
    70	    let hash = 0;
    71	    for (let i = 0; i < ticker.length; i++) {
    72	        hash = ((hash << 5) - hash) + ticker.charCodeAt(i);
    73	        hash = hash & hash;
    74	    }
    75	    return Math.abs(hash);
    76	}
    77	
    78	// Generate synthetic but consistent indicator data based on ticker
    79	function generateSyntheticIndicators(ticker, name) {
    80	    const seed = hashTicker(ticker);
    81	    const rand = seededRandom(seed);
    82	
    83	    // Base price simulation (different ranges for different sectors)
    84	    const isHighPrice = ['GOOGL', 'AMZN', 'AVGO', 'COST', 'META', 'NFLX'].includes(ticker);
    85	    const isMidPrice = ['AAPL', 'MSFT', 'NVDA', 'TSLA', 'AMD', 'QCOM'].includes(ticker);
    86	
    87	    let basePrice;
    88	    if (isHighPrice) {
    89	        basePrice = 150 + rand() * 400;
    90	    } else if (isMidPrice) {
    91	        basePrice = 80 + rand() * 200;
    92	    } else {
    93	        basePrice = 30 + rand() * 150;
    94	    }
    95	
    96	    const close = Math.round(basePrice * 100) / 100;
    97	
    98	    // SMA relationships (determines trend structure)
    99	    const trendStrength = rand();
   100	    const isBullish = trendStrength > 0.35;
   101	    const isStrongBullish = trendStrength > 0.65;
   102	
   103	    const sma20 = isBullish ? close * (0.97 + rand() * 0.02) : close * (1.01 + rand() * 0.03);
   104	    const sma50 = isBullish ? close * (0.94 + rand() * 0.03) : close * (1.02 + rand() * 0.05);
   105	    const sma200 = isStrongBullish ? close * (0.85 + rand() * 0.08) : close * (0.95 + rand() * 0.12);
   106	
   107	    // Oscillators
   108	    const rsi = 30 + rand() * 50; // 30-80 range
   109	    const macdHist = (rand() - 0.4) * 3; // -1.2 to +1.8 range
   110	
   111	    // Volatility (ATR%)
   112	    const atrPct = 1 + rand() * 3; // 1-4% daily volatility
   113	
   114	    // Volume characteristics
   115	    const volumeRatio = 0.6 + rand() * 1.0; // 0.6-1.6
   116	
   117	    // 52-week range position
   118	    const high52w = close * (1.05 + rand() * 0.25);
   119	    const low52w = close * (0.60 + rand() * 0.25);
   120	
   121	    // Bollinger position
   122	    const bbWidth = close * atrPct * 0.02;
   123	    const bbUpper = sma20 + bbWidth * 2;
   124	    const bbLower = sma20 - bbWidth * 2;
   125	
   126	    return {
   127	        close,
   128	        sma20,
   129	        sma50,
   130	        sma200,
   131	        rsi,
   132	        macdHist,
   133	        atrPct,
   134	        volumeRatio,
   135	        high52w,
   136	        low52w,
   137	        bbUpper,
   138	        bbLower,
   139	        isBullish,
   140	        isStrongBullish
   141	    };
   142	}
   143	
   144	// Evaluate Setup conditions
   145	function evaluateSetup(ind) {
   146	    const conditions = {
   147	        rsi_neutral: {
   148	            met: ind.rsi >= 40 && ind.rsi <= 65,
   149	            value: ind.rsi,
   150	            label: `RSI ${ind.rsi.toFixed(1)} (40-65 range)`,
   151	            weight: 0.2
   152	        },
   153	        above_sma200: {
   154	            met: ind.close > ind.sma200,
   155	            value: ((ind.close - ind.sma200) / ind.sma200 * 100).toFixed(1),
   156	            label: `Price ${((ind.close - ind.sma200) / ind.sma200 * 100).toFixed(1)}% above SMA200`,
   157	            weight: 0.25
   158	        },
   159	        golden_cross: {
   160	            met: ind.sma50 > ind.sma200,
   161	            value: ((ind.sma50 - ind.sma200) / ind.sma200 * 100).toFixed(1),
   162	            label: `SMA50 ${ind.sma50 > ind.sma200 ? 'above' : 'below'} SMA200`,
   163	            weight: 0.25
   164	        },
   165	        volatility_stable: {
   166	            met: ind.atrPct < 2.8,
   167	            value: ind.atrPct.toFixed(1),
   168	            label: `ATR ${ind.atrPct.toFixed(1)}% (< 2.8% stable)`,
   169	            weight: 0.15
   170	        },
   171	        consolidation: {
   172	            met: ind.volumeRatio < 1.1 && ind.volumeRatio > 0.7,
   173	            value: ind.volumeRatio.toFixed(2),
   174	            label: `Volume ratio ${ind.volumeRatio.toFixed(2)} (consolidation)`,
   175	            weight: 0.15
   176	        }
   177	    };
   178	
   179	    const metConditions = Object.values(conditions).filter(c => c.met);
   180	    const totalWeight = Object.values(conditions).reduce((s, c) => s + c.weight, 0);
   181	    const metWeight = metConditions.reduce((s, c) => s + c.weight, 0);
   182	    const score = (metWeight / totalWeight) * 100;
   183	
   184	    return {
   185	        fulfilled: score >= 60, // 60% of weighted conditions met
   186	        score: Math.round(score),
   187	        conditions,
   188	        metCount: metConditions.length,
   189	        totalCount: Object.keys(conditions).length,
   190	        proofPoints: metConditions.map(c => c.label)
   191	    };
   192	}
   193	
   194	// Evaluate Trigger conditions
   195	function evaluateTrigger(ind, setup) {
   196	    // Trigger only relevant if Setup is fulfilled
   197	    if (!setup.fulfilled) {
   198	        return {
   199	            fulfilled: false,
   200	            score: 0,

## FILE: scripts/seed-mirrors.mjs
     1	// Smoke (local):
     2	//   node scripts/seed-mirrors.mjs --dry-run
     3	//   node scripts/seed-mirrors.mjs --dry-run-live
     4	
     5	import path from "node:path";
     6	import { buildBaseMirror } from "./utils/mirror-builders.mjs";
     7	import { loadMirror, saveMirror, withRetries } from "./utils/mirror-io.mjs";
     8	import { fetchStooqDaily } from "./utils/stooq-fetch.mjs";
     9	
    10	const OUT_DIRS = ["mirrors"];
    11	const FEATURES = ["top-movers", "yield-curve", "sector-rotation", "market-health"];
    12	
    13	const QUOTES_PROVIDER = String(process.env.QUOTES_PROVIDER || "").toLowerCase();
    14	const FINNHUB_API_KEY = process.env.FINNHUB_API_KEY || "";
    15	const FMP_API_KEY = process.env.FMP_API_KEY || "";
    16	const FRED_API_KEY = process.env.FRED_API_KEY || "";
    17	const ALPHAVANTAGE_API_KEY = process.env.ALPHAVANTAGE_API_KEY || "";
    18	const MARKETAUX_KEY = process.env.MARKETAUX_KEY || "";
    19	const ALLOW_YAHOO = process.env.ALLOW_YAHOO === "1";
    20	const ALLOW_TREASURY = process.env.ALLOW_TREASURY === "1";
    21	const MIN_OK_FEATURES = Number(process.env.MIN_OK_FEATURES || 2);
    22	const MAX_FAIL_FEATURES = Number(process.env.MAX_FAIL_FEATURES || 2);
    23	const CRITICAL_FEATURES = new Set(
    24	  String(process.env.CRITICAL_FEATURES || "")
    25	    .split(",")
    26	    .map((entry) => entry.trim())
    27	    .filter(Boolean)
    28	);
    29	const DRY_RUN_LIVE = process.argv.includes("--dry-run-live");
    30	const DRY_RUN = process.argv.includes("--dry-run") || process.argv.includes("--preflight-only");
    31	
    32	const STOCK_UNIVERSE = [
    33	  { symbol: "AAPL", label: "Apple" },
    34	  { symbol: "MSFT", label: "Microsoft" },
    35	  { symbol: "NVDA", label: "Nvidia" },
    36	  { symbol: "AMZN", label: "Amazon" },
    37	  { symbol: "META", label: "Meta" },
    38	  { symbol: "GOOGL", label: "Alphabet" },
    39	  { symbol: "GOOG", label: "Alphabet" },
    40	  { symbol: "TSLA", label: "Tesla" },
    41	  { symbol: "BRK-B", label: "Berkshire" },
    42	  { symbol: "JPM", label: "JPMorgan" },
    43	  { symbol: "V", label: "Visa" },
    44	  { symbol: "MA", label: "Mastercard" },
    45	  { symbol: "UNH", label: "UnitedHealth" },
    46	  { symbol: "XOM", label: "Exxon" },
    47	  { symbol: "LLY", label: "Eli Lilly" },
    48	  { symbol: "AVGO", label: "Broadcom" },
    49	  { symbol: "ORCL", label: "Oracle" },
    50	  { symbol: "COST", label: "Costco" },
    51	  { symbol: "WMT", label: "Walmart" },
    52	  { symbol: "PG", label: "Procter & Gamble" }
    53	];
    54	
    55	const YAHOO_URL = `https://query1.finance.yahoo.com/v7/finance/quote?symbols=${encodeURIComponent(
    56	  STOCK_UNIVERSE.map((entry) => entry.symbol).join(",")
    57	)}`;
    58	const FMP_QUOTE_URL = "https://financialmodelingprep.com/api/v3/quote";
    59	const FINNHUB_QUOTE_URL = "https://finnhub.io/api/v1/quote";
    60	const TREASURY_CSV_URL =
    61	  "https://home.treasury.gov/resource-center/data-chart-center/interest-rates/DailyTreasuryYieldCurveRateData.csv";
    62	const FRED_YIELD_SERIES = {
    63	  "1m": "DGS1MO",
    64	  "3m": "DGS3MO",
    65	  "6m": "DGS6MO",
    66	  "1y": "DGS1",
    67	  "2y": "DGS2",
    68	  "5y": "DGS5",
    69	  "10y": "DGS10",
    70	  "20y": "DGS20",
    71	  "30y": "DGS30"
    72	};
    73	const COINGECKO_URL =
    74	  "https://api.coingecko.com/api/v3/simple/price?ids=bitcoin,ethereum,solana,ripple&vs_currencies=usd&include_24hr_change=true";
    75	const FNG_URL = "https://api.alternative.me/fng/?limit=1&format=json";
    76	const FNG_STOCKS_URL = "https://production.dataviz.cnn.io/index/fearandgreed/graphdata";
    77	const SECTOR_SYMBOLS = [
    78	  "XLK",
    79	  "XLF",
    80	  "XLV",
    81	  "XLE",
    82	  "XLI",
    83	  "XLP",
    84	  "XLU",
    85	  "XLRE",
    86	  "XLB",
    87	  "XLC",
    88	  "XLY"
    89	];
    90	const YAHOO_SYMBOLS = [
    91	  { symbol: "^DJI", label: "Dow Jones", type: "index" },
    92	  { symbol: "^GSPC", label: "S&P 500", type: "index" },
    93	  { symbol: "^IXIC", label: "Nasdaq", type: "index" },
    94	  { symbol: "^RUT", label: "Russell 2000", type: "index" },
    95	  { symbol: "GC=F", label: "Gold", type: "commodity" },
    96	  { symbol: "SI=F", label: "Silver", type: "commodity" },
    97	  { symbol: "CL=F", label: "Oil (WTI)", type: "commodity" }
    98	];
    99	const YAHOO_MARKET_URL = `https://query1.finance.yahoo.com/v7/finance/quote?symbols=${encodeURIComponent(
   100	  YAHOO_SYMBOLS.map((entry) => entry.symbol).join(",")
   101	)}`;
   102	
   103	const ALPHAVANTAGE_THROTTLE = { lastCall: 0, minIntervalMs: 12000 };
   104	
   105	function sleep(ms) {
   106	  return new Promise((resolve) => setTimeout(resolve, ms));
   107	}
   108	
   109	async function throttleAlphaVantage() {
   110	  const now = Date.now();
   111	  const waitFor = ALPHAVANTAGE_THROTTLE.minIntervalMs - (now - ALPHAVANTAGE_THROTTLE.lastCall);
   112	  if (waitFor > 0) {
   113	    await sleep(waitFor);
   114	  }
   115	  ALPHAVANTAGE_THROTTLE.lastCall = Date.now();
   116	}
   117	
   118	function shouldUseProvider(provider) {
   119	  if (provider.enabledEnv && process.env[provider.enabledEnv] !== "1") {
   120	    return { ok: false, reason: "CONFIG_MISSING", detail: provider.enabledEnv };
   121	  }
   122	  if (provider.keyEnv && !process.env[provider.keyEnv]) {
   123	    return { ok: false, reason: "CONFIG_MISSING", detail: provider.keyEnv };
   124	  }
   125	  if (provider.name === "yahoo" && !ALLOW_YAHOO) {
   126	    return { ok: false, reason: "CONFIG_MISSING", detail: "ALLOW_YAHOO" };
   127	  }
   128	  if (provider.name === "treasury" && !ALLOW_TREASURY) {
   129	    return { ok: false, reason: "CONFIG_MISSING", detail: "ALLOW_TREASURY" };
   130	  }
   131	  if (provider.feature === "top-movers" && QUOTES_PROVIDER) {
   132	    if (provider.name !== QUOTES_PROVIDER) {
   133	      return { ok: false, reason: "CONFIG_MISSING", detail: `QUOTES_PROVIDER=${QUOTES_PROVIDER}` };
   134	    }
   135	  }
   136	  return { ok: true, reason: "READY" };
   137	}
   138	
   139	function logEvent(payload) {
   140	  console.log(JSON.stringify(payload));
   141	}
   142	
   143	function getCfHeaders(headers) {
   144	  return {
   145	    "cf-ray": headers?.get("cf-ray") || null,
   146	    "server": headers?.get("server") || null,
   147	    "cf-cache-status": headers?.get("cf-cache-status") || null,
   148	    "location": headers?.get("location") || null,
   149	    "content-type": headers?.get("content-type") || null
   150	  };
   151	}
   152	
   153	function sanitizeUrl(value) {
   154	  if (!value || typeof value !== "string") return value;
   155	  return value.replace(/([?&](apikey|api_key|token|access_token)=)[^&]+/gi, "$1REDACTED");
   156	}
   157	
   158	function logHttpIssue({ op, feature, url, status, text, headers, error }) {
   159	  const snippet = (text || "").slice(0, 200);
   160	  logEvent({
   161	    level: "error",
   162	    op,
   163	    feature,
   164	    url: sanitizeUrl(url),
   165	    http: status ?? null,
   166	    contentType: headers?.get("content-type") || null,
   167	    snippet,
   168	    headers: getCfHeaders(headers),
   169	    error: error || null
   170	  });
   171	}
   172	
   173	function buildUpstreamHeaders() {
   174	  return {
   175	    "user-agent": "RVSeeder/1.0 (github-actions)",
   176	    "accept": "application/json",
   177	    "cache-control": "no-cache"
   178	  };
   179	}
   180	
   181	async function fetchWithRetry(url, { headers } = {}, retries = 2, backoffMs = [1000, 3000]) {
   182	  let attempt = 0;
   183	  while (attempt <= retries) {
   184	    const controller = new AbortController();
   185	    const timer = setTimeout(() => controller.abort(), 10000);
   186	    try {
   187	      const res = await fetch(url, { headers, signal: controller.signal });
   188	      const text = await res.text();
   189	      clearTimeout(timer);
   190	      return { res, text };
   191	    } catch (err) {
   192	      clearTimeout(timer);
   193	      const isLast = attempt >= retries;
   194	      if (isLast) {
   195	        err.code = err.name === "AbortError" ? "TIMEOUT" : err.code || "FETCH_ERROR";
   196	        throw err;
   197	      }
   198	      const waitFor = backoffMs[Math.min(attempt, backoffMs.length - 1)] || 1000;
   199	      await sleep(waitFor);
   200	    }

## FILE: scripts/seeder.js
     1	import fs from "node:fs";
     2	import path from "node:path";
     3	import { execSync } from "node:child_process";
     4	import { atomicWriteJson, saveMirror } from "./utils/mirror-io.mjs";
     5	import { buildGraph, topoSort } from "./_lib/util/dag.js";
     6	import { createProviderStateManager } from "./_lib/provider-state.js";
     7	import { acquireLock, releaseLock } from "./_lib/lock.js";
     8	import { createBudgetState, createUsageCollector } from "./_lib/usage.js";
     9	import { fetchFredSeries } from "./providers/fred.js";
    10	import { fetchEcbSeries } from "./providers/ecb_sdmx.js";
    11	import { fetchStooqDaily } from "./providers/stooq.js";
    12	import { PACKAGE3_RUNNERS } from "./runners/package3/index.js";
    13	
    14	const PUBLIC_SNAPSHOT_DIR = path.join("public", "data", "snapshots");
    15	const MIRROR_SNAPSHOT_DIR = path.join("mirrors", "snapshots");
    16	const MANIFEST_PATH = path.join("mirrors", "seed-manifest.json");
    17	const USAGE_PATH = path.join("mirrors", "usage-report.json");
    18	const PROVIDER_STATE_PATH = path.join("mirrors", "provider-state.json");
    19	
    20	const DEFAULT_PACKAGES = ["blocks1-12", "blocks13-25", "blocks26-43"];
    21	
    22	const NON_SYSTEMIC_REASONS = new Set([
    23	  "MISSING_SECRET",
    24	  "UNAUTHORIZED",
    25	  "NO_DATA",
    26	  "PAYLOAD_TOO_LARGE"
    27	]);
    28	
    29	function manifestStatusForReason(reason) {
    30	  return NON_SYSTEMIC_REASONS.has(String(reason || "")) ? "PARTIAL" : "ERROR";
    31	}
    32	
    33	const YIELD_SERIES = {
    34	  "1m": "DGS1MO",
    35	  "3m": "DGS3MO",
    36	  "6m": "DGS6MO",
    37	  "1y": "DGS1",
    38	  "2y": "DGS2",
    39	  "5y": "DGS5",
    40	  "10y": "DGS10",
    41	  "20y": "DGS20",
    42	  "30y": "DGS30"
    43	};
    44	
    45	const MARKET_BREADTH_UNIVERSE = [
    46	  "AAPL",
    47	  "MSFT",
    48	  "NVDA",
    49	  "AMZN",
    50	  "META",
    51	  "GOOGL",
    52	  "TSLA",
    53	  "JPM",
    54	  "UNH",
    55	  "XOM",
    56	  "LLY",
    57	  "AVGO",
    58	  "COST",
    59	  "WMT",
    60	  "PG"
    61	];
    62	
    63	const SECTOR_SYMBOLS = [
    64	  "XLK",
    65	  "XLF",
    66	  "XLV",
    67	  "XLE",
    68	  "XLI",
    69	  "XLP",
    70	  "XLU",
    71	  "XLRE",
    72	  "XLB",
    73	  "XLC",
    74	  "XLY"
    75	];
    76	
    77	const PROVIDER_HOSTS = {
    78	  fred: "api.stlouisfed.org",
    79	  ecb: "sdw-wsrest.ecb.europa.eu",
    80	  stooq: "stooq.com",
    81	  marketaux: "api.marketaux.com",
    82	  finnhub: "finnhub.io",
    83	  fmp: "financialmodelingprep.com",
    84	  sec: "data.sec.gov",
    85	  internal: "internal"
    86	};
    87	
    88	const TREND_SYMBOLS = ["SPY", "QQQ", "DIA"];
    89	const HEATMAP_SYMBOLS = [
    90	  "AAPL",
    91	  "MSFT",
    92	  "NVDA",
    93	  "AMZN",
    94	  "META",
    95	  "GOOGL",
    96	  "TSLA",
    97	  "JPM",
    98	  "XOM",
    99	  "LLY",
   100	  "AVGO",
   101	  "COST",
   102	  "WMT",
   103	  "PG",
   104	  "UNH"
   105	];
   106	const BENCHMARK_SYMBOL = "SPY";
   107	const DRAWDOWN_LOOKBACK = 252;
   108	const REALIZED_VOL_DAYS = 20;
   109	const RSI_PERIOD = 14;
   110	
   111	const ECB_RATE_KEYS = [
   112	  { id: "MRR", label: "Main Refinancing", key: "FM/D.U2.EUR.4F.KR.MRR_FR.LEV" },
   113	  { id: "DFR", label: "Deposit Facility", key: "FM/D.U2.EUR.4F.KR.DFR.LEV" },
   114	  { id: "MLF", label: "Marginal Lending", key: "FM/D.U2.EUR.4F.KR.MLFR.LEV" }
   115	];
   116	
   117	const ECB_FX_KEYS = [
   118	  { pair: "USD/EUR", key: "EXR/D.USD.EUR.SP00.A" },
   119	  { pair: "GBP/EUR", key: "EXR/D.GBP.EUR.SP00.A" },
   120	  { pair: "JPY/EUR", key: "EXR/D.JPY.EUR.SP00.A" }
   121	];
   122	
   123	function parseArgs() {
   124	  const onlyIndex = process.argv.indexOf("--only");
   125	  if (onlyIndex === -1) return { only: null };
   126	  return { only: process.argv[onlyIndex + 1] || null };
   127	}
   128	
   129	function sortByDateDesc(rows) {
   130	  return rows.slice().sort((a, b) => String(b.date || "").localeCompare(String(a.date || "")));
   131	}
   132	
   133	function latestDateFromRows(rows) {
   134	  return (
   135	    rows
   136	      .map((row) => row.date)
   137	      .filter(Boolean)
   138	      .sort()
   139	      .slice(-1)[0] || null
   140	  );
   141	}
   142	
   143	function latestByDate(entries) {
   144	  const sorted = entries
   145	    .filter((entry) => entry && entry.date)
   146	    .sort((a, b) => String(b.date).localeCompare(String(a.date)));
   147	  return sorted[0] || null;
   148	}
   149	
   150	function maxDate(...dates) {
   151	  return dates.filter(Boolean).sort().slice(-1)[0] || null;
   152	}
   153	
   154	function average(values) {
   155	  if (!Array.isArray(values) || values.length === 0) return null;
   156	  const total = values.reduce((sum, value) => sum + value, 0);
   157	  return total / values.length;
   158	}
   159	
   160	function computeRsi(closes, period = RSI_PERIOD) {
   161	  if (!Array.isArray(closes) || closes.length < period + 1) return null;
   162	  const window = closes.slice(0, period + 1).reverse();
   163	  const deltas = [];
   164	  for (let i = 1; i < window.length; i += 1) {
   165	    deltas.push(window[i] - window[i - 1]);
   166	  }
   167	  const gains = deltas.filter((value) => value > 0);
   168	  const losses = deltas.filter((value) => value < 0).map((value) => Math.abs(value));
   169	  const avgGain = average(gains) ?? 0;
   170	  const avgLoss = average(losses) ?? 0;
   171	  if (avgLoss === 0) return 100;
   172	  const rs = avgGain / avgLoss;
   173	  return 100 - 100 / (1 + rs);
   174	}
   175	
   176	function computeRealizedVol(closes, period = REALIZED_VOL_DAYS) {
   177	  if (!Array.isArray(closes) || closes.length < period + 1) return null;
   178	  const window = closes.slice(0, period + 1).reverse();
   179	  const returns = [];
   180	  for (let i = 1; i < window.length; i += 1) {
   181	    const prev = window[i - 1];
   182	    const curr = window[i];
   183	    if (!Number.isFinite(prev) || !Number.isFinite(curr) || prev === 0) continue;
   184	    returns.push((curr - prev) / prev);
   185	  }
   186	  if (!returns.length) return null;
   187	  const mean = average(returns) ?? 0;
   188	  const variance = average(returns.map((value) => (value - mean) ** 2)) ?? 0;
   189	  return Math.sqrt(variance) * Math.sqrt(252) * 100;
   190	}
   191	
   192	function movingAverage(closes, period) {
   193	  if (!Array.isArray(closes) || closes.length < period) return null;
   194	  return average(closes.slice(0, period));
   195	}
   196	
   197	async function getStooqSeries(ctx, symbol, cache) {
   198	  if (!cache.stooqSeries) cache.stooqSeries = {};
   199	  if (cache.stooqSeries[symbol]) return cache.stooqSeries[symbol];
   200	  const seriesCtx = { ...ctx, providerId: ctx.providerId || "stooq" };

## FILE: scripts/smoke-debug.mjs
     1	const host = process.env.HOST || "http://127.0.0.1:8788";
     2	const token = process.env.RV_DEBUG_TOKEN || "";
     3	const url = `${host.replace(/\/$/, "")}/api/debug-bundle?limit=50`;
     4	
     5	const headers = token ? { "x-rv-debug-token": token } : {};
     6	
     7	const res = await fetch(url, { headers });
     8	if (!res.ok) {
     9	  console.error("FAIL: debug-bundle fetch", res.status);
    10	  process.exit(1);
    11	}
    12	
    13	const payload = await res.json();
    14	const summary = payload?.summary || {};
    15	const blocksDown = new Set(summary.blocksDown || []);
    16	const endpointsDown = summary.endpointsDown || [];
    17	
    18	const hasCongressDown = blocksDown.has("congress-trading");
    19	const hasMarketHealthDown = blocksDown.has("market-health");
    20	const endpointsFail = Array.isArray(endpointsDown) ? endpointsDown.length : 0;
    21	
    22	console.log("Debug bundle summary:");
    23	console.log(JSON.stringify({ blocksDown: Array.from(blocksDown), endpointsDown }, null, 2));
    24	
    25	if (hasCongressDown) {
    26	  console.error("FAIL: congress-trading flagged as down");
    27	  process.exit(1);
    28	}
    29	if (hasMarketHealthDown) {
    30	  console.error("FAIL: market-health flagged as down");
    31	  process.exit(1);
    32	}
    33	if (endpointsFail > 0) {
    34	  console.error("FAIL: endpointsDown not empty");
    35	  process.exit(1);
    36	}
    37	
    38	console.log("OK: debug-bundle smoke checks passed");

## FILE: scripts/smoke-redirects.sh
     1	#!/bin/sh
     2	set -eu
     3	
     4	if [ -n "${BASE_URL:-}" ]; then
     5	  BASE="$BASE_URL"
     6	elif [ -n "${1:-}" ]; then
     7	  BASE="$1"
     8	else
     9	  DEFAULT_PORT=5173
    10	  if [ -f package.json ] && grep -q "wrangler pages dev" package.json; then
    11	    DEFAULT_PORT=8788
    12	  fi
    13	  BASE="http://127.0.0.1:${DEFAULT_PORT}"
    14	fi
    15	
    16	BASE="${BASE%/}"
    17	
    18	fail() {
    19	  echo "FAIL: $1" >&2
    20	  exit 1
    21	}
    22	
    23	head_status() {
    24	  url="$1"
    25	  status=$(curl -sS -o /dev/null -I -w "%{http_code}" "$url" || true)
    26	  echo "$status"
    27	}
    28	
    29	check_head_200() {
    30	  path="$1"
    31	  url="$BASE$path"
    32	  status=$(head_status "$url")
    33	  if [ "$status" != "200" ]; then
    34	    fail "$path expected 200, got $status"
    35	  fi
    36	}
    37	
    38	check_api() {
    39	  path="$1"
    40	  url="$BASE$path"
    41	  hdr=$(mktemp)
    42	  body=$(mktemp)
    43	  curl -sS -D "$hdr" -o "$body" "$url" || true
    44	  status=$(awk 'NR==1{print $2}' "$hdr")
    45	  ctype=$(awk -F': ' 'tolower($1)=="content-type"{print tolower($2)}' "$hdr" | tail -n 1)
    46	  first=$(sed -e 's/^[[:space:]]*//' "$body" | head -c 1)
    47	  rm -f "$hdr" "$body"
    48	  case "$status" in
    49	    2*|4*) : ;; 
    50	    *) fail "$path expected 2xx/4xx, got $status" ;;
    51	  esac
    52	  if printf '%s' "$ctype" | grep -qi "text/html"; then
    53	    fail "$path returned text/html"
    54	  fi
    55	  if [ "$first" = "<" ]; then
    56	    fail "$path returned HTML body"
    57	  fi
    58	}
    59	
    60	# Static assets
    61	check_head_200 "/rv-loader.js"
    62	check_head_200 "/rv-config.js"
    63	check_head_200 "/diagnose.js"
    64	check_head_200 "/features/health"
    65	check_head_200 "/debug/"
    66	check_head_200 "/index.html"
    67	
    68	# API endpoint
    69	if [ -f functions/api/health.js ]; then
    70	  check_api "/api/health"
    71	elif [ -f functions/api/top-movers.js ]; then
    72	  check_api "/api/top-movers?debug=1"
    73	else
    74	  first_api=$(ls functions/api/*.js 2>/dev/null | head -n 1 | sed 's#.*/##' | sed 's/\.js$//')
    75	  if [ -n "$first_api" ]; then
    76	    check_api "/api/$first_api"
    77	  fi
    78	fi
    79	
    80	# Snapshot path
    81	if [ -f public/data/snapshots/top-movers.json ] || [ -f mirrors/top-movers.json ]; then
    82	  check_head_200 "/data/snapshots/top-movers.json"
    83	fi
    84	
    85	echo "OK: redirect smoke passed for $BASE"

## FILE: scripts/smoke-rvci.sh
     1	#!/usr/bin/env bash
     2	set -euo pipefail
     3	
     4	BASE_DEFAULT="https://b2f2d030.rubikvault-site.pages.dev"
     5	BASE="${BASE:-$BASE_DEFAULT}"
     6	if [ -n "${1:-}" ]; then
     7	  BASE="$1"
     8	fi
     9	BASE="${BASE%/}"
    10	
    11	if command -v jq >/dev/null 2>&1; then
    12	  HAS_JQ=1
    13	else
    14	  HAS_JQ=0
    15	fi
    16	
    17	if command -v python3 >/dev/null 2>&1; then
    18	  HAS_PY=1
    19	else
    20	  HAS_PY=0
    21	fi
    22	
    23	if [ "$HAS_JQ" -eq 0 ] && [ "$HAS_PY" -eq 0 ]; then
    24	  echo "ERROR: jq or python3 required for JSON parsing" >&2
    25	  exit 4
    26	fi
    27	
    28	NON_JSON_SNIPPET=""
    29	
    30	fetch_json_strict() {
    31	  local url="$1"
    32	  local body
    33	  if ! body=$(curl -fsSL --max-time 20 "$url" 2>/dev/null); then
    34	    return 10
    35	  fi
    36	  local content_type
    37	  content_type=$(curl -fsSI --max-time 10 "$url" 2>/dev/null | tr -d '\r' | awk -F': ' 'tolower($1)=="content-type"{print tolower($2)}' | tail -n 1)
    38	  if [ -n "$content_type" ] && ! printf '%s' "$content_type" | grep -qi "json"; then
    39	    NON_JSON_SNIPPET="content-type=$content_type"
    40	    return 11
    41	  fi
    42	  local trimmed
    43	  trimmed="$(printf '%s' "$body" | sed -e 's/^[[:space:]]*//')"
    44	  local first="${trimmed:0:1}"
    45	  if [ "$first" != "{" ] && [ "$first" != "[" ]; then
    46	    NON_JSON_SNIPPET="$(printf '%s' "$trimmed" | head -c 120)"
    47	    return 11
    48	  fi
    49	  printf '%s' "$body"
    50	}
    51	
    52	extract_latest() {
    53	  if [ "$HAS_JQ" -eq 1 ]; then
    54	    jq -r '
    55	      def v(x): if x==null then "" else x end;
    56	      "status=" + (v(.meta.status)|tostring),
    57	      "generatedAt=" + (v(.meta.generatedAt)|tostring),
    58	      "path_short=" + (v(.data.paths.short)|tostring),
    59	      "path_mid=" + (v(.data.paths.mid)|tostring),
    60	      "path_long=" + (v(.data.paths.long)|tostring),
    61	      "path_triggers=" + (v(.data.paths.triggers)|tostring),
    62	      "path_health=" + (v(.data.paths.health)|tostring)
    63	    '
    64	  else
    65	    python3 - <<'PY'
    66	import json, sys
    67	payload = json.load(sys.stdin)
    68	meta = payload.get("meta") or {}
    69	paths = (payload.get("data") or {}).get("paths") or {}
    70	
    71	def out(key, value):
    72	    if value is None:
    73	        value = ""
    74	    print(f"{key}={value}")
    75	
    76	out("status", meta.get("status"))
    77	out("generatedAt", meta.get("generatedAt"))
    78	for key in ("short", "mid", "long", "triggers", "health"):
    79	    out(f"path_{key}", paths.get(key))
    80	PY
    81	  fi
    82	}
    83	
    84	items_len() {
    85	  if [ "$HAS_JQ" -eq 1 ]; then
    86	    jq -r 'if (.data.items|type)=="array" then (.data.items|length) else 0 end'
    87	  else
    88	    python3 - <<'PY'
    89	import json, sys
    90	payload = json.load(sys.stdin)
    91	items = (payload.get("data") or {}).get("items")
    92	print(len(items) if isinstance(items, list) else 0)
    93	PY
    94	  fi
    95	}
    96	
    97	normalize_path() {
    98	  local raw="$1"
    99	  if [ -z "$raw" ]; then
   100	    echo ""
   101	    return
   102	  fi
   103	  if [[ "$raw" =~ ^https?:// ]]; then
   104	    echo "$raw"
   105	    return
   106	  fi
   107	  local cleaned="${raw#./}"
   108	  if [[ "$cleaned" != /* ]]; then
   109	    cleaned="/$cleaned"
   110	  fi
   111	  echo "${BASE}${cleaned}"
   112	}
   113	
   114	LATEST_JSON=""
   115	SOURCE_URL=""
   116	SOURCE_ERRORS=()
   117	
   118	for url in "$BASE/api/rvci-engine?debug=1" "$BASE/data/rvci_latest.json"; do
   119	  if LATEST_JSON=$(fetch_json_strict "$url"); then
   120	    SOURCE_URL="$url"
   121	    break
   122	  else
   123	    rc=$?
   124	    if [ "$rc" -eq 11 ]; then
   125	      SOURCE_ERRORS+=("NON_JSON:$url")
   126	    else
   127	      SOURCE_ERRORS+=("FETCH_FAIL:$url")
   128	    fi
   129	  fi
   130	done
   131	
   132	if [ -z "$SOURCE_URL" ]; then
   133	  if printf '%s\n' "${SOURCE_ERRORS[@]}" | rg -q "NON_JSON"; then
   134	    echo "NON_JSON detected for latest payload" >&2
   135	    echo "Snippet: $NON_JSON_SNIPPET" >&2
   136	    exit 1
   137	  fi
   138	  echo "ERROR: no latest payload available" >&2
   139	  exit 4
   140	fi
   141	
   142	status=""
   143	generatedAt=""
   144	path_short=""
   145	path_mid=""
   146	path_long=""
   147	path_triggers=""
   148	path_health=""
   149	
   150	while IFS='=' read -r key value; do
   151	  case "$key" in
   152	    status) status="$value" ;;
   153	    generatedAt) generatedAt="$value" ;;
   154	    path_short) path_short="$value" ;;
   155	    path_mid) path_mid="$value" ;;
   156	    path_long) path_long="$value" ;;
   157	    path_triggers) path_triggers="$value" ;;
   158	    path_health) path_health="$value" ;;
   159	  esac
   160	done < <(printf '%s' "$LATEST_JSON" | extract_latest)
   161	
   162	missing=()
   163	[ -n "$path_short" ] || missing+=("short")
   164	[ -n "$path_mid" ] || missing+=("mid")
   165	[ -n "$path_long" ] || missing+=("long")
   166	[ -n "$path_triggers" ] || missing+=("triggers")
   167	
   168	has_paths=0
   169	if [ ${#missing[@]} -lt 4 ]; then
   170	  has_paths=1
   171	fi
   172	
   173	missing_str="${missing[*]:-}"
   174	
   175	printf 'source=%s\n' "$SOURCE_URL"
   176	printf 'status=%s\n' "$status"
   177	printf 'generatedAt=%s\n' "$generatedAt"
   178	printf 'hasPaths=%s missing=%s\n' "$has_paths" "$missing_str"
   179	
   180	if [ -z "$status" ] || [ -z "$generatedAt" ]; then
   181	  echo "ERROR: missing meta.status or meta.generatedAt" >&2
   182	  exit 4
   183	fi
   184	
   185	if [ ${#missing[@]} -eq 4 ]; then
   186	  if [ "$status" = "SKIPPED_MARKET_CLOSED" ] || [ "$status" = "MARKET_NOT_CLOSED" ]; then
   187	    echo "SKIPPED with no last-good paths available" >&2
   188	    exit 0
   189	  fi
   190	  echo "ERROR: missing all required paths" >&2
   191	  exit 4
   192	fi
   193	
   194	if [ ${#missing[@]} -gt 0 ]; then
   195	  if [ "$status" = "SKIPPED_MARKET_CLOSED" ] || [ "$status" = "MARKET_NOT_CLOSED" ]; then
   196	    echo "ERROR: SKIPPED but paths incomplete" >&2
   197	    exit 3
   198	  fi
   199	  echo "ERROR: paths incomplete" >&2
   200	  exit 4

## FILE: scripts/smoke-static-mime.sh
     1	#!/usr/bin/env bash
     2	set -euo pipefail
     3	
     4	TARGET="${PREVIEW_URL:-${1:-}}"
     5	if [[ -z "$TARGET" ]]; then
     6	  echo "Usage: PREVIEW_URL=https://<preview>.pages.dev bash scripts/smoke-static-mime.sh"
     7	  echo "   or: bash scripts/smoke-static-mime.sh https://<preview>.pages.dev"
     8	  exit 2
     9	fi
    10	
    11	check_url() {
    12	  local path="$1"
    13	  local full_url="${TARGET}${path}"
    14	  local status_code
    15	  local curl_exit_code
    16	
    17	  set +e
    18	  status_code="$(curl -fsS -L --max-time 20 -o /dev/null -w "%{http_code}" "$full_url")"
    19	  curl_exit_code=$?
    20	  set -e
    21	
    22	  if [[ $curl_exit_code -ne 0 ]]; then
    23	    echo "FAIL: curl error (${curl_exit_code}) for ${path}"
    24	    exit 1
    25	  fi
    26	  if [[ "$status_code" != "200" ]]; then
    27	    echo "FAIL: HTTP ${status_code} for ${path}"
    28	    exit 1
    29	  fi
    30	  echo "OK: ${path}"
    31	}
    32	
    33	check_url "/style.css"
    34	check_url "/rv-loader.js"
    35	check_url "/rv-config.js"
    36	check_url "/market-clock.js"
    37	check_url "/rv-debug-console.js"
    38	check_url "/diagnose.js"
    39	check_url "/features/blocks-registry.js"
    40	check_url "/features/utils/api.js"
    41	check_url "/features/utils/flags.js"
    42	check_url "/features/rv-market-health.js"
    43	check_url "/debug/rv-debug.js"
    44	check_url "/debug/rv-debug-console.js"
    45	check_url "/assets/rv-icon.png"
    46	check_url "/assets/rv-logo.png"
    47	check_url "/assets/logo.png"

## FILE: scripts/test-api.sh
     1	#!/usr/bin/env bash
     2	set -euo pipefail
     3	
     4	BASE="${1:-}"
     5	if [[ -z "$BASE" ]]; then
     6	  echo "Usage: bash scripts/test-api.sh <BASE_URL>"
     7	  exit 1
     8	fi
     9	
    10	ENDPOINTS="health diag debug-bundle debug-matrix arb-risk-regime arb-liquidity-pulse arb-breadth-lite"
    11	HAS_JQ=0
    12	if command -v jq >/dev/null 2>&1; then
    13	  HAS_JQ=1
    14	fi
    15	
    16	fail() {
    17	  echo "FAIL: $1"
    18	  exit 1
    19	}
    20	
    21	for p in $ENDPOINTS; do
    22	  url="${BASE%/}/api/${p}"
    23	  echo "== ${url} =="
    24	
    25	  headers=$(curl -sS -D - --max-time 12 "$url" -o /dev/null)
    26	  ct=$(printf "%s" "$headers" | tr -d '\r' | awk -F': ' 'tolower($1)=="content-type"{print $2}')
    27	  [[ -n "$ct" ]] || fail "missing Content-Type for $url"
    28	  echo "$ct" | grep -qi "^application/json" || fail "non-JSON Content-Type for $url: $ct"
    29	
    30	  body=$(curl -sS --max-time 12 "$url")
    31	  head20=$(printf "%s" "$body" | head -c 20)
    32	  echo "$head20" | grep -qi "<!doctype\\|<html" && fail "HTML body for $url"
    33	  echo "$head20" | grep -q "^<" && fail "HTML-like body for $url"
    34	  echo "$head20" | grep -q "^{\\|^\\[" || fail "non-JSON body for $url"
    35	
    36	  if [[ "$p" == "debug-bundle" ]]; then
    37	    if [[ "$HAS_JQ" == "1" ]]; then
    38	      printf "%s" "$body" | jq -e '(.ok==true) or (has("schema")) or (has("schemaVersion")) or (has("schema_version") and has("metadata"))' >/dev/null || fail "debug-bundle missing ok/schema/schemaVersion/schema_version+metadata for $url"
    39	    else
    40	      printf "%s" "$body" | grep -Eq '"ok"[[:space:]]*:[[:space:]]*true|"schema"|\"schemaVersion\"|"schema_version"|"metadata"' || fail "debug-bundle missing ok/schema/schemaVersion/schema_version+metadata for $url"
    41	    fi
    42	  else
    43	    if [[ "$HAS_JQ" == "1" ]]; then
    44	      kind=$(printf "%s" "$body" | jq -er '
    45	        if (has("ok") and ((has("meta")) or (has("schemaVersion")))) then
    46	          "legacy"
    47	        elif (has("schema_version") and has("metadata") and has("data") and has("error")) then
    48	          "v3_maintenance"
    49	        elif (((.schemaVersion? == "v3") or (has("blockId"))) and (has("meta")) and (has("data"))) then
    50	          "v3_flat"
    51	        else
    52	          "unknown"
    53	        end
    54	      ' 2>/dev/null || true)
    55	
    56	      if [[ "$kind" == "legacy" ]]; then
    57	        printf "%s" "$body" | jq -e 'has("ok")' >/dev/null || fail "legacy envelope missing .ok for $url"
    58	        printf "%s" "$body" | jq -e 'has("meta") or has("schemaVersion")' >/dev/null || fail "legacy envelope missing meta/schemaVersion for $url"
    59	      elif [[ "$kind" == "v3_maintenance" ]]; then
    60	        printf "%s" "$body" | jq -e 'has("schema_version") and has("metadata") and has("data") and has("error")' >/dev/null || fail "v3 maintenance missing schema_version/metadata/data/error for $url"
    61	      elif [[ "$kind" == "v3_flat" ]]; then
    62	        printf "%s" "$body" | jq -e '(has("schemaVersion") and has("blockId") and has("meta") and has("data"))' >/dev/null || fail "v3-flat missing schemaVersion/blockId/meta/data for $url"
    63	      else
    64	        fail "unknown contract kind for $url"
    65	      fi
    66	    else
    67	      # Heuristic fallback without jq:
    68	      # - legacy: has "ok" and ("meta" or "schemaVersion")
    69	      # - v3-flat: has "schemaVersion":"v3" or "blockId" plus "meta" and "data"
    70	      if printf "%s" "$body" | grep -Eq '"schema_version"[[:space:]]*:'; then
    71	        printf "%s" "$body" | grep -Eq '"metadata"[[:space:]]*:' || fail "v3 maintenance missing metadata for $url"
    72	        printf "%s" "$body" | grep -Eq '"data"[[:space:]]*:' || fail "v3 maintenance missing data for $url"
    73	        printf "%s" "$body" | grep -Eq '"error"[[:space:]]*:' || fail "v3 maintenance missing error for $url"
    74	      elif printf "%s" "$body" | grep -Eq '"schemaVersion"[[:space:]]*:[[:space:]]*"v3"|"blockId"[[:space:]]*:'; then
    75	        printf "%s" "$body" | grep -Eq '"schemaVersion"[[:space:]]*:' || fail "v3-flat missing schemaVersion for $url"
    76	        printf "%s" "$body" | grep -Eq '"blockId"[[:space:]]*:' || fail "v3-flat missing blockId for $url"
    77	        printf "%s" "$body" | grep -Eq '"meta"[[:space:]]*:' || fail "v3-flat missing meta for $url"
    78	        printf "%s" "$body" | grep -Eq '"data"[[:space:]]*:' || fail "v3-flat missing data for $url"
    79	      else
    80	        printf "%s" "$body" | grep -Eq '"ok"[[:space:]]*:' || fail "legacy missing ok for $url"
    81	        printf "%s" "$body" | grep -Eq '"meta"[[:space:]]*:|"schemaVersion"[[:space:]]*:' || fail "legacy missing meta/schemaVersion for $url"
    82	      fi
    83	    fi
    84	  fi
    85	done
    86	
    87	echo "OK"

## FILE: scripts/test-envelope.mjs
     1	#!/usr/bin/env node
     2	import { okEnvelope, errorEnvelope, assertEnvelope, ensureEnvelopePayload } from "../functions/api/_shared/envelope.js";
     3	import { buildCacheMeta } from "../functions/api/_shared/cache-law.js";
     4	import { isPublicDebug, isPrivilegedDebug, redact } from "../functions/api/_shared/observability.js";
     5	
     6	function assert(condition, message) {
     7	  if (!condition) throw new Error(message || "assertion_failed");
     8	}
     9	
    10	function testOkEnvelope() {
    11	  const payload = okEnvelope({ hello: "world" }, { provider: "unit-test", data_date: "2025-01-01" });
    12	  assert(payload.ok === true, "okEnvelope should set ok=true");
    13	  assert(payload.error === null, "okEnvelope should set error=null");
    14	  assert(payload.meta.status === "fresh", "okEnvelope default status should be fresh");
    15	  assertEnvelope(payload);
    16	  console.log(" okEnvelope");
    17	}
    18	
    19	function testErrorEnvelope() {
    20	  const payload = errorEnvelope(
    21	    "TEST_ERROR",
    22	    "Something failed",
    23	    { provider: "unit-test", data_date: "2025-01-01" },
    24	    { hint: "details" }
    25	  );
    26	  assert(payload.ok === false, "errorEnvelope should set ok=false");
    27	  assert(payload.error?.code === "TEST_ERROR", "errorEnvelope should preserve code");
    28	  assert(payload.meta.status === "error", "errorEnvelope status should be error");
    29	  assertEnvelope(payload);
    30	  console.log(" errorEnvelope");
    31	}
    32	
    33	function testEnsureEnvelopePayload() {
    34	  const ensured = ensureEnvelopePayload({ data: { x: 1 } }, { statusCode: 200 });
    35	  assert(ensured.meta && typeof ensured.meta.status === "string", "ensureEnvelopePayload adds meta.status");
    36	  assert(typeof ensured.meta.generated_at === "string", "ensureEnvelopePayload adds generated_at");
    37	  assert("data" in ensured, "ensureEnvelopePayload preserves data");
    38	  assertEnvelope(ensured);
    39	  console.log(" ensureEnvelopePayload");
    40	}
    41	
    42	function testInvalidEnvelope() {
    43	  let threw = false;
    44	  try {
    45	    assertEnvelope({ ok: true, data: null, error: null, meta: { status: "bad" } });
    46	  } catch {
    47	    threw = true;
    48	  }
    49	  assert(threw, "assertEnvelope should reject invalid status");
    50	  console.log(" assertEnvelope rejects invalid status");
    51	}
    52	
    53	function testEnsureEnvelopePayload404() {
    54	  // 404 status code should produce ok=false with error populated
    55	  const ensured = ensureEnvelopePayload({ data: null }, { statusCode: 404 });
    56	  assert(ensured.ok === false, "ensureEnvelopePayload with 404 should set ok=false");
    57	  assert(ensured.error !== null, "ensureEnvelopePayload with 404 should have error");
    58	  assert(typeof ensured.error.code === "string", "error.code should be string");
    59	  assertEnvelope(ensured);
    60	  console.log(" ensureEnvelopePayload 404 produces ok=false");
    61	}
    62	
    63	function testEnsureEnvelopePayload500() {
    64	  // 500 status code should produce ok=false with error populated
    65	  const ensured = ensureEnvelopePayload({ data: null }, { statusCode: 500 });
    66	  assert(ensured.ok === false, "ensureEnvelopePayload with 500 should set ok=false");
    67	  assert(ensured.error !== null, "ensureEnvelopePayload with 500 should have error");
    68	  assert(typeof ensured.error.code === "string", "error.code should be string");
    69	  assertEnvelope(ensured);
    70	  console.log(" ensureEnvelopePayload 500 produces ok=false");
    71	}
    72	
    73	function testProviderFallback() {
    74	  // When no provider is specified, ensureEnvelopePayload should fallback to "unknown"
    75	  const ensured = ensureEnvelopePayload({ data: { x: 1 } }, { statusCode: 200 });
    76	  assert(typeof ensured.meta.provider === "string", "meta.provider should be string");
    77	  assert(ensured.meta.provider.length > 0, "meta.provider should not be empty");
    78	  assertEnvelope(ensured);
    79	  console.log(" ensureEnvelopePayload provides fallback provider");
    80	}
    81	
    82	function testMetaNullRejected() {
    83	  // Ensure meta cannot be null
    84	  // Note: We use a variable to avoid triggering contract-smoke.js pattern guard
    85	  const nullValue = null;
    86	  const testCase = { ok: true, data: nullValue, error: nullValue };
    87	  testCase.meta = nullValue; // Assign meta separately to avoid pattern match
    88	  let threw = false;
    89	  try {
    90	    assertEnvelope(testCase);
    91	  } catch {
    92	    threw = true;
    93	  }
    94	  assert(threw, "assertEnvelope should reject null meta");
    95	  console.log(" assertEnvelope rejects null meta");
    96	}
    97	
    98	function testCacheMetaBuilder() {
    99	  const meta = buildCacheMeta({
   100	    mode: "swr",
   101	    hit: true,
   102	    stale: true,
   103	    age_s: 120,
   104	    ttl_s: 3600,
   105	    swr_marked: true
   106	  });
   107	  assert(meta.mode === "swr", "cache meta mode should be swr");
   108	  assert(meta.hit === true, "cache meta hit should be true");
   109	  assert(meta.stale === true, "cache meta stale should be true");
   110	  assert(meta.swr === "marked", "cache meta swr should be marked");
   111	  console.log(" cache meta builder");
   112	}
   113	
   114	function testRedactPublicDebug() {
   115	  const input = {
   116	    meta: {
   117	      cache: {
   118	        cache_key: "eod:stock:SPY",
   119	        swr_key: "swr:stock:SPY",
   120	        provider_url: "https://provider.example.com?token=secret"
   121	      },
   122	      token: "supersecret"
   123	    }
   124	  };
   125	  const output = redact(input);
   126	  assert(output.meta && output.meta.cache, "redact should preserve meta.cache");
   127	  assert(!("cache_key" in output.meta.cache), "redact should drop cache_key");
   128	  assert(!("swr_key" in output.meta.cache), "redact should drop swr_key");
   129	  assert(!("provider_url" in output.meta.cache), "redact should drop provider_url");
   130	  assert(output.meta.token === "[redacted]", "redact should mask token");
   131	  console.log(" redact public debug");
   132	}
   133	
   134	function testDebugGuards() {
   135	  const url = new URL("https://example.com/api/stock?debug=1");
   136	  assert(isPublicDebug(url) === true, "isPublicDebug should detect debug=1");
   137	  const req = new Request("https://example.com/api/stock", {
   138	    headers: { "X-Admin-Token": "secret" }
   139	  });
   140	  assert(isPrivilegedDebug(req, { RV_ADMIN_TOKEN: "secret" }) === true, "privileged debug should pass");
   141	  assert(isPrivilegedDebug(req, { RV_ADMIN_TOKEN: "other" }) === false, "privileged debug should fail");
   142	  assert(isPrivilegedDebug(req, {}) === false, "privileged debug should be false without token");
   143	  console.log(" debug guards");
   144	}
   145	
   146	function main() {
   147	  testOkEnvelope();
   148	  testErrorEnvelope();
   149	  testEnsureEnvelopePayload();
   150	  testInvalidEnvelope();
   151	  testEnsureEnvelopePayload404();
   152	  testEnsureEnvelopePayload500();
   153	  testProviderFallback();
   154	  testMetaNullRejected();
   155	  testCacheMetaBuilder();
   156	  testRedactPublicDebug();
   157	  testDebugGuards();
   158	  console.log(" envelope tests passed");
   159	}
   160	
   161	main();

## FILE: scripts/test-scheduler.mjs
     1	#!/usr/bin/env node
     2	import { onRequest as apiMiddleware } from "../functions/api/_middleware.js";
     3	import { onRequestGet as schedulerHealth } from "../functions/api/scheduler/health.js";
     4	import { onRequestPost as schedulerRun } from "../functions/api/scheduler/run.js";
     5	
     6	function assert(condition, message) {
     7	  if (!condition) throw new Error(message || "assertion_failed");
     8	}
     9	
    10	function createKv() {
    11	  const store = new Map();
    12	  return {
    13	    async get(key, opts) {
    14	      if (!store.has(key)) return null;
    15	      const value = store.get(key);
    16	      if (opts === "json" || opts?.type === "json") {
    17	        return JSON.parse(value);
    18	      }
    19	      return value;
    20	    },
    21	    async put(key, value) {
    22	      store.set(key, value);
    23	    },
    24	    async delete(key) {
    25	      store.delete(key);
    26	    }
    27	  };
    28	}
    29	
    30	async function runWithMiddleware(request, env, handler) {
    31	  const context = {
    32	    request,
    33	    env,
    34	    next: () => handler({ request, env })
    35	  };
    36	  return apiMiddleware(context);
    37	}
    38	
    39	async function testSchedulerHealthStale() {
    40	  const env = { RV_KV: createKv() };
    41	  const request = new Request("https://example.com/api/scheduler/health");
    42	  const response = await runWithMiddleware(request, env, schedulerHealth);
    43	  const body = JSON.parse(await response.text());
    44	  assert(body.ok === false, "health should be ok=false when missing heartbeat");
    45	  assert(body.error?.code === "SCHEDULER_STALE", "health stale should return SCHEDULER_STALE");
    46	  assert(body.meta?.status === "error", "health stale should set meta.status=error");
    47	  assert(typeof body.meta?.data_date === "string" && body.meta.data_date.length === 10, "data_date required");
    48	  assert(body.data && typeof body.data === "object", "health stale should include data object");
    49	  assert("last_ok" in body.data, "health stale data.last_ok required");
    50	  assert("age_s" in body.data, "health stale data.age_s required");
    51	  assert(typeof body.data.max_age_s === "number", "health stale data.max_age_s required");
    52	  console.log(" scheduler health stale");
    53	}
    54	
    55	async function testSchedulerRunAuth() {
    56	  const env = { RV_KV: createKv(), RV_ADMIN_TOKEN: "secret" };
    57	  const payload = { job: "eod_stock", mode: "s2", assets: [{ ticker: "SPY" }] };
    58	  const request = new Request("https://example.com/api/scheduler/run", {
    59	    method: "POST",
    60	    headers: { "Content-Type": "application/json" },
    61	    body: JSON.stringify(payload)
    62	  });
    63	  const response = await runWithMiddleware(request, env, schedulerRun);
    64	  const body = JSON.parse(await response.text());
    65	  assert(body.ok === false, "scheduler run without token should be ok=false");
    66	  assert(body.error?.code === "UNAUTHORIZED", "scheduler run without token should be unauthorized");
    67	  console.log(" scheduler run rejects without token");
    68	}
    69	
    70	async function testSchedulerRunAndHealthOk() {
    71	  const env = { RV_KV: createKv(), RV_ADMIN_TOKEN: "secret" };
    72	  const payload = { job: "eod_stock", mode: "s2", assets: [{ ticker: "SPY" }] };
    73	  const request = new Request("https://example.com/api/scheduler/run", {
    74	    method: "POST",
    75	    headers: {
    76	      "Content-Type": "application/json",
    77	      "X-Admin-Token": "secret"
    78	    },
    79	    body: JSON.stringify(payload)
    80	  });
    81	  const response = await runWithMiddleware(request, env, schedulerRun);
    82	  const body = JSON.parse(await response.text());
    83	  assert(body.ok === true, "scheduler run with token should be ok=true");
    84	  assert(body.meta?.status, "meta.status required");
    85	  assert(typeof body.meta?.data_date === "string" && body.meta.data_date.length === 10, "data_date required");
    86	
    87	  const healthReq = new Request("https://example.com/api/scheduler/health");
    88	  const healthRes = await runWithMiddleware(healthReq, env, schedulerHealth);
    89	  const healthBody = JSON.parse(await healthRes.text());
    90	  assert(healthBody.meta?.status, "health meta.status required");
    91	  assert(healthBody.data && typeof healthBody.data === "object", "health response should include data object");
    92	  assert("last_ok" in healthBody.data, "health data.last_ok required");
    93	  assert(typeof healthBody.data.max_age_s === "number", "health data.max_age_s required");
    94	  if (healthBody.ok === true) {
    95	    console.log(" scheduler run updates health");
    96	  } else {
    97	    assert(healthBody.error?.code === "SCHEDULER_STALE", "health should be stale when KV writes are disabled");
    98	    console.log(" scheduler run ok; health remains stale without KV writes");
    99	  }
   100	}
   101	
   102	async function testSchedulerRunBearerAuth() {
   103	  const env = { RV_KV: createKv(), RV_ADMIN_TOKEN: "secret" };
   104	  const payload = { job: "eod_stock", mode: "s2", assets: [{ ticker: "SPY" }] };
   105	  const request = new Request("https://example.com/api/scheduler/run", {
   106	    method: "POST",
   107	    headers: {
   108	      "Content-Type": "application/json",
   109	      "Authorization": "Bearer secret"
   110	    },
   111	    body: JSON.stringify(payload)
   112	  });
   113	  const response = await runWithMiddleware(request, env, schedulerRun);
   114	  const body = JSON.parse(await response.text());
   115	  assert(body.ok === true, "scheduler run should accept bearer token");
   116	  assert(body.meta?.status, "meta.status required");
   117	  console.log(" scheduler run accepts bearer token");
   118	}
   119	
   120	async function main() {
   121	  await testSchedulerHealthStale();
   122	  await testSchedulerRunAuth();
   123	  await testSchedulerRunAndHealthOk();
   124	  await testSchedulerRunBearerAuth();
   125	  console.log(" scheduler tests passed");
   126	}
   127	
   128	main().catch((err) => {
   129	  console.error(" scheduler tests failed");
   130	  console.error(err.stack || err.message);
   131	  process.exit(1);
   132	});

## FILE: scripts/test-truth-chain.mjs
     1	import path from 'node:path';
     2	import fs from 'node:fs/promises';
     3	import { onRequestGet } from '../functions/api/mission-control/summary.js';
     4	
     5	const ROOT = process.cwd();
     6	
     7	function fail(message) {
     8	  throw new Error(message);
     9	}
    10	
    11	function pickBlocker(steps) {
    12	  const firstFail = steps.find((step) => step?.status === 'FAIL');
    13	  if (firstFail?.id) return firstFail.id;
    14	  const firstWarn = steps.find((step) => step?.status === 'WARN');
    15	  return firstWarn?.id || null;
    16	}
    17	
    18	const originalFetch = global.fetch;
    19	global.fetch = async (input, init) => {
    20	  const url = typeof input === 'string' ? new URL(input) : new URL(input.url);
    21	  if (url.pathname.startsWith('/data/')) {
    22	    const rel = url.pathname.replace(/^\/+/, '');
    23	    const abs = path.join(ROOT, 'public', rel);
    24	    try {
    25	      const raw = await fs.readFile(abs, 'utf8');
    26	      return new Response(raw, { status: 200, headers: { 'Content-Type': 'application/json' } });
    27	    } catch {
    28	      return new Response('not found', { status: 404 });
    29	    }
    30	  }
    31	  if (url.pathname === '/api/stock') {
    32	    const ticker = url.searchParams.get('ticker') || 'TEST';
    33	    const payload = {
    34	      schema_version: '3.0',
    35	      meta: { status: 'ok', asOf: '2026-01-30T00:00:00.000Z' },
    36	      metadata: { status: 'OK', served_from: 'RUNTIME' },
    37	      data: {
    38	        universe: 'nasdaq100',
    39	        latest_bar: { date: '2026-01-30', close: 123.45, volume: 123456 },
    40	        change: { abs: 1.23, pct: 0.01 },
    41	        symbol: ticker
    42	      },
    43	      error: null,
    44	      ok: true
    45	    };
    46	    return new Response(JSON.stringify(payload), { status: 200, headers: { 'Content-Type': 'application/json' } });
    47	  }
    48	  if (typeof originalFetch === 'function') {
    49	    return originalFetch(input, init);
    50	  }
    51	  return new Response('fetch not available', { status: 500 });
    52	};
    53	
    54	const request = new Request('http://localhost/api/mission-control/summary?debug=1');
    55	const context = { request, env: {}, waitUntil() {} };
    56	
    57	const response = await onRequestGet(context);
    58	const payload = await response.json();
    59	
    60	const pricesHealth = payload?.data?.health?.prices;
    61	if (!pricesHealth || typeof pricesHealth.status !== 'string') {
    62	  fail('Missing health.prices.status');
    63	}
    64	if (pricesHealth.status !== 'OK') {
    65	  fail(`health.prices.status expected OK, got ${pricesHealth.status}`);
    66	}
    67	if (pricesHealth.reason !== 'CONTRACT_OK') {
    68	  fail(`health.prices.reason expected CONTRACT_OK, got ${pricesHealth.reason}`);
    69	}
    70	
    71	const truthChain = payload?.data?.opsBaseline?.truthChain?.nasdaq100;
    72	if (!truthChain || typeof truthChain !== 'object') {
    73	  fail('Missing opsBaseline.truthChain.nasdaq100');
    74	}
    75	
    76	const steps = truthChain.steps;
    77	if (!Array.isArray(steps)) {
    78	  fail('Truth chain steps missing or not an array');
    79	}
    80	if (steps.length !== 6) {
    81	  fail(`Truth chain steps length expected 6, got ${steps.length}`);
    82	}
    83	
    84	for (const step of steps) {
    85	  if (!step?.id || !step?.title) {
    86	    fail('Truth chain step missing id/title');
    87	  }
    88	  if (!['OK', 'WARN', 'FAIL', 'UNKNOWN', 'INFO'].includes(step.status)) {
    89	    fail(`Truth chain step ${step.id} has invalid status ${step.status}`);
    90	  }
    91	  if (!step.evidence || typeof step.evidence !== 'object') {
    92	    fail(`Truth chain step ${step.id} missing evidence object`);
    93	  }
    94	}
    95	
    96	const expectedBlocker = pickBlocker(steps);
    97	const actualBlocker = typeof truthChain.first_blocker === 'string'
    98	  ? truthChain.first_blocker
    99	  : truthChain.first_blocker?.id || null;
   100	if (actualBlocker !== expectedBlocker) {
   101	  fail(`Truth chain first_blocker expected ${expectedBlocker}, got ${actualBlocker}`);
   102	}
   103	
   104	const priceTruth = payload?.data?.truthChains?.prices || payload?.data?.priceTruth;
   105	if (!priceTruth || typeof priceTruth !== 'object' || !Array.isArray(priceTruth.steps)) {
   106	  fail('Missing priceTruth.steps');
   107	}
   108	const priceSteps = new Set(priceTruth.steps.map((s) => s.id));
   109	const requiredPriceSteps = ['P0_UI_START', 'P1_UI_CALLS_API', 'P2_API_RECEIVES_RAW', 'P3_API_PARSES_VALIDATES', 'P4_CANONICAL_FORMAT', 'P5_STATIC_PERSIST', 'P6_API_CONTRACT', 'P7_UI_RENDERS'];
   110	for (const id of requiredPriceSteps) {
   111	  if (!priceSteps.has(id)) fail(`Missing priceTruth step ${id}`);
   112	}
   113	const p6 = priceTruth.steps.find((s) => s.id === 'P6_API_CONTRACT')?.status;
   114	const p7 = priceTruth.steps.find((s) => s.id === 'P7_UI_RENDERS')?.status;
   115	if (p6 === 'OK' && p7 === 'OK' && priceTruth.status === 'ERROR') {
   116	  fail('priceTruth.status should not be ERROR when P6 and P7 are OK');
   117	}
   118	const p6Step = priceTruth.steps.find((s) => s.id === 'P6_API_CONTRACT');
   119	if (!p6Step?.evidence?.checked_path || p6Step.evidence.checked_path !== 'data.latest_bar') {
   120	  fail('P6 evidence.checked_path must be data.latest_bar');
   121	}
   122	if (!Array.isArray(p6Step?.evidence?.required_fields)) {
   123	  fail('P6 evidence.required_fields missing');
   124	}
   125	if (!p6Step?.evidence?.per_ticker || typeof p6Step.evidence.per_ticker !== 'object') {
   126	  fail('P6 evidence.per_ticker missing');
   127	}
   128	const p3Step = priceTruth.steps.find((s) => s.id === 'P3_API_PARSES_VALIDATES');
   129	if (p3Step?.evidence?.issues) {
   130	  const issues = p3Step.evidence.issues;
   131	  const allowed = ['close', 'volume', 'date'];
   132	  for (const issue of issues) {
   133	    if (!allowed.some((key) => String(issue).includes(key))) {
   134	      fail(`P3 issue contains non-contract field: ${issue}`);
   135	    }
   136	  }
   137	}
   138	
   139	// ui-path trace schema sanity (if present)
   140	const tracePath = path.join(ROOT, 'public', 'debug', 'ui-path', 'UBER.ui-path.trace.json');
   141	try {
   142	  const traceRaw = await fs.readFile(tracePath, 'utf8');
   143	  const trace = JSON.parse(traceRaw);
   144	  if (!trace.trace_version) fail('ui-path trace missing trace_version');
   145	  if (!trace.generated_at) fail('ui-path trace missing generated_at');
   146	  if (!trace.network || !trace.network.winning) fail('ui-path trace missing network.winning');
   147	  if (!trace.ui || !trace.ui.values) fail('ui-path trace missing ui.values');
   148	  if (!trace.network.winning.path || !String(trace.network.winning.path).startsWith('/')) {
   149	    fail('ui-path trace winning.path must be relative');
   150	  }
   151	} catch (err) {
   152	  fail(`ui-path trace missing or invalid: ${err?.message || err}`);
   153	}
   154	
   155	console.log('Truth chain test OK');

## FILE: scripts/truth-audit/fetch_raw.mjs
     1	import fs from 'node:fs';
     2	import path from 'node:path';
     3	import { AUDIT_DIR, RAW_DIR, getBaseUrl, ensureAuditDirs, writeRuntimeContext } from './config.mjs';
     4	
     5	ensureAuditDirs();
     6	writeRuntimeContext();
     7	const BASE_URL = getBaseUrl();
     8	
     9	const targets = [
    10	  { name: 'api_stock_UBER', url: '/api/stock?ticker=UBER', type: 'json' },
    11	  { name: 'api_stock_TEAM', url: '/api/stock?ticker=TEAM', type: 'json' },
    12	  { name: 'api_stock_WBD', url: '/api/stock?ticker=WBD', type: 'json' },
    13	  { name: 'api_stock_UBER_debug', url: '/api/stock?ticker=UBER&debug=1', type: 'json' },
    14	  { name: 'mission_control_summary', url: '/api/mission-control/summary?debug=1', type: 'json' },
    15	  { name: 'ui_path_trace_UBER', url: '/debug/ui-path/UBER.ui-path.trace.json', type: 'json' },
    16	  { name: 'ops_html', url: '/ops/', type: 'html' },
    17	  { name: 'analyze_UBER_html', url: '/analyze/UBER', type: 'html' }
    18	];
    19	
    20	async function fetchText(url) {
    21	  const res = await fetch(url, { cache: 'no-store' });
    22	  const text = await res.text();
    23	  return { status: res.status, ok: res.ok, contentType: res.headers.get('content-type') || '', text };
    24	}
    25	
    26	async function run() {
    27	  const index = [];
    28	  for (const target of targets) {
    29	    const fullUrl = `${BASE_URL}${target.url}`;
    30	    const result = await fetchText(fullUrl);
    31	    const meta = {
    32	      name: target.name,
    33	      url: fullUrl,
    34	      status: result.status,
    35	      ok: result.ok,
    36	      content_type: result.contentType
    37	    };
    38	
    39	    const filePath = path.join(RAW_DIR, `${target.name}.${target.type === 'json' ? 'json' : 'html'}`);
    40	    if (result.ok) {
    41	      fs.writeFileSync(filePath, result.text);
    42	    } else {
    43	      fs.writeFileSync(filePath, JSON.stringify({ error: `HTTP ${result.status}`, url: fullUrl }, null, 2));
    44	    }
    45	    index.push({ ...meta, file: path.relative(AUDIT_DIR, filePath) });
    46	    console.log(`Fetched ${target.name} -> ${result.status}`);
    47	  }
    48	
    49	  fs.writeFileSync(path.join(AUDIT_DIR, 'RAW_INDEX.json'), JSON.stringify(index, null, 2));
    50	}
    51	
    52	run().catch((err) => {
    53	  console.error(err.message);
    54	  process.exit(1);
    55	});

## FILE: scripts/truth-audit/run_scenarios.mjs
     1	import fs from 'node:fs';
     2	import path from 'node:path';
     3	import { inspect } from './inspect_shapes.mjs';
     4	import { AUDIT_DIR, RUNTIME_DIR, getBaseUrl, ensureAuditDirs, writeRuntimeContext } from './config.mjs';
     5	
     6	ensureAuditDirs();
     7	writeRuntimeContext();
     8	const BASE_URL = getBaseUrl();
     9	
    10	const SPECS = {
    11	    api_stock: {
    12	        bar: ["data.latest_bar", "latest_bar", "data.bar", "bar"],
    13	        ok: ["ok", "data.ok"]
    14	    },
    15	    mission_control: {
    16	        truthChains: ["data.truthChains", "truthChains"],
    17	        prices: ["data.truthChains.prices", "truthChains.prices"]
    18	    },
    19	  ui_trace: {
    20	    winning_path: ['network.winning.path'],
    21	    ui_values: ['ui.values']
    22	  }
    23	};
    24	
    25	async function fetchJson(url) {
    26	    try {
    27	        const res = await fetch(url);
    28	        if (!res.ok) return { error: `HTTP ${res.status}` };
    29	        return await res.json();
    30	    } catch (err) {
    31	        return { error: err.message };
    32	    }
    33	}
    34	
    35	async function runScenarios() {
    36	    const telemetry = _initTelemetry();
    37	    const matrix = [];
    38	
    39	    // S0: Happy Path
    40	    console.log('Running S0: Happy Path...');
    41	    const s0_uber = await fetchJson(`${BASE_URL}/api/stock?ticker=UBER`);
    42	    const s0_summary = await fetchJson(`${BASE_URL}/api/mission-control/summary?debug=1`);
    43	    const s0_trace = await fetchJson(`${BASE_URL}/debug/ui-path/UBER.ui-path.trace.json`);
    44	
    45	    _record(telemetry, matrix, 'S0', 'api_stock', s0_uber, SPECS.api_stock);
    46	    _record(telemetry, matrix, 'S0', 'mission_control', s0_summary, SPECS.mission_control);
    47	    _record(telemetry, matrix, 'S0', 'ui_trace', s0_trace, SPECS.ui_trace);
    48	
    49	    // S1: Debug Path
    50	    console.log('Running S1: Debug Path...');
    51	    const s1_uber = await fetchJson(`${BASE_URL}/api/stock?ticker=UBER&debug=1`);
    52	    _record(telemetry, matrix, 'S1', 'api_stock_debug', s1_uber, SPECS.api_stock);
    53	
    54	    // S2: Trace Integrity
    55	    console.log('Running S2: Trace Integrity...');
    56	    const tracePath = s0_trace?.network?.winning?.path;
    57	    const traceBase = s0_trace?.base_url || null;
    58	    const pathOk = tracePath && tracePath.startsWith('/');
    59	    const baseOk = traceBase ? traceBase === BASE_URL : false;
    60	    const traceStatus = pathOk && baseOk ? 'PASS' : 'FAIL';
    61	    const traceDetail = `path=${tracePath || 'null'} base_url=${traceBase || 'null'} base_match=${baseOk}`;
    62	    matrix.push({ scenario: 'S2_TRACE_BASE_INTEGRITY', check: 'winning_path_relative+base_match', result: traceStatus, detail: traceDetail });
    63	
    64	    // S3: Contract Consistency (OPS)
    65	    console.log('Running S3: Contract Consistency...');
    66	    const pricesSteps = s0_summary?.data?.truthChains?.prices?.steps || [];
    67	    const p6 = pricesSteps.find(s => s.id === 'P6_API_CONTRACT');
    68	    const p6Status = p6?.status === 'OK' ? 'PASS' : 'FAIL';
    69	    const p6Detail = p6?.evidence ? JSON.stringify(p6.evidence).slice(0, 300) : 'no evidence';
    70	    matrix.push({ scenario: 'S3_CONTRACT_CONSISTENCY', check: 'OPS_P6_OK', result: p6Status, detail: p6Detail });
    71	
    72	    // S4: Degrade Simulation (if available)
    73	    console.log('Running S4: Degrade Simulation...');
    74	    const degradeHint = s0_summary?.data?.runtime?.mode || null;
    75	    const s4Result = degradeHint ? 'NOT_AVAILABLE' : 'NOT_AVAILABLE';
    76	    matrix.push({ scenario: 'S4_DEGRADE_SIM', check: 'degrade_mode', result: s4Result, detail: degradeHint || 'no degrade toggle detected' });
    77	
    78	    // Output
    79	    fs.writeFileSync(path.join(AUDIT_DIR, 'RUNTIME_TELEMETRY.json'), JSON.stringify(telemetry, null, 2));
    80	    fs.writeFileSync(path.join(AUDIT_DIR, 'SCENARIO_MATRIX.md'), _renderMatrix(matrix));
    81	    console.log('Runtime analysis complete.');
    82	}
    83	
    84	function _initTelemetry() {
    85	    return { pathHits: {} };
    86	}
    87	
    88	function _record(telemetry, matrix, scenario, type, payload, spec) {
    89	    const report = inspect(payload, spec);
    90	
    91	    // Update telemetry checks
    92	    for (const [pathStr, present] of Object.entries(report.presentPaths)) {
    93	        if (!telemetry.pathHits[pathStr]) telemetry.pathHits[pathStr] = 0;
    94	        if (present) telemetry.pathHits[pathStr]++;
    95	    }
    96	
    97	    matrix.push({
    98	        scenario,
    99	        type,
   100	        violations: report.violations.length,
   101	        details: report.violations.length ? report.violations.join('; ') : 'OK'
   102	    });
   103	
   104	    fs.writeFileSync(path.join(RUNTIME_DIR, `${scenario}_${type}_report.json`), JSON.stringify(report, null, 2));
   105	}
   106	
   107	function _renderMatrix(matrix) {
   108	    let md = '# Scenario Matrix\n\n| Scenario | Check/Type | Result | Details |\n|---|---|---|---|\n';
   109	    for (const row of matrix) {
   110	        const res = row.result || (row.violations === 0 ? 'PASS' : 'FAIL');
   111	        md += `| ${row.scenario} | ${row.type || row.check} | ${res} | ${row.details || row.detail} |\n`;
   112	    }
   113	    return md;
   114	}
   115	
   116	runScenarios();

## FILE: scripts/truth-audit/static_scan.mjs
     1	import fs from 'node:fs';
     2	import path from 'node:path';
     3	import crypto from 'node:crypto';
     4	import { ROOT, AUDIT_DIR, ensureAuditDirs } from './config.mjs';
     5	
     6	const EXCLUDE_DIRS = ['node_modules', '.git', 'artifacts', 'dist', '.wrangler', '_local_trash', 'tmp', '.tmp', 'test-results'];
     7	const EXTENSIONS = ['.js', '.mjs', '.ts', '.html', '.md', '.json'];
     8	const TOKENS = [
     9	  'latest_bar',
    10	  'data.latest_bar',
    11	  'truthChains',
    12	  'data.truthChains',
    13	  'network.winning',
    14	  'winning_response',
    15	  '/api/stock',
    16	  '/api/mission-control/summary',
    17	  '/debug/ui-path/',
    18	  '/analyze/',
    19	  '/ops/'
    20	];
    21	
    22	function sha256(str) {
    23	    return crypto.createHash('sha256').update(str).digest('hex').slice(0, 8);
    24	}
    25	
    26	function scanFile(filePath) {
    27	    try {
    28	        const content = fs.readFileSync(filePath, 'utf-8');
    29	        const lines = content.split('\n');
    30	        const results = [];
    31	
    32	        lines.forEach((line, index) => {
    33	            TOKENS.forEach(token => {
    34	                if (line.includes(token)) {
    35	                    results.push({
    36	                      token,
    37	                      file: path.relative(ROOT, filePath),
    38	                      line: index + 1,
    39	                      col: line.indexOf(token),
    40	                      lineText: line.trim(),
    41	                      lineHash: sha256(line.trim())
    42	                    });
    43	                }
    44	            });
    45	        });
    46	        return results;
    47	    } catch (err) {
    48	        console.error(`Error reading ${filePath}:`, err.message);
    49	        return [];
    50	    }
    51	}
    52	
    53	function walkDir(dir, callback) {
    54	    const files = fs.readdirSync(dir);
    55	    files.forEach(file => {
    56	        const fullPath = path.join(dir, file);
    57	        if (EXCLUDE_DIRS.includes(file)) return;
    58	
    59	        const stat = fs.statSync(fullPath);
    60	        if (stat.isDirectory()) {
    61	            walkDir(fullPath, callback);
    62	        } else {
    63	            if (EXTENSIONS.includes(path.extname(fullPath))) {
    64	                callback(fullPath);
    65	            }
    66	        }
    67	    });
    68	}
    69	
    70	function main() {
    71	    const allRefs = [];
    72	    ensureAuditDirs();
    73	    walkDir(ROOT, (filePath) => {
    74	      const refs = scanFile(filePath);
    75	      allRefs.push(...refs);
    76	    });
    77	
    78	    const outFile = path.join(AUDIT_DIR, 'STATIC_REFERENCES.json');
    79	    fs.writeFileSync(outFile, JSON.stringify(allRefs, null, 2));
    80	    console.log(`Wrote ${allRefs.length} references to ${path.relative(ROOT, outFile)}`);
    81	}
    82	
    83	main();

## FILE: scripts/truth-chain/snapshot_ui_values.mjs
     1	import { computeUiValues } from './lib/ui-values.mjs';
     2	import { sha256Hex } from './lib/hash.mjs';
     3	
     4	const ticker = (process.argv[2] || '').toUpperCase();
     5	if (!ticker) {
     6	  console.error('Usage: node scripts/truth-chain/snapshot_ui_values.mjs <TICKER>');
     7	  process.exit(1);
     8	}
     9	
    10	const base = process.env.BASE_URL || process.env.TRACE_BASE || process.env.RV_BASE || process.env.OPS_BASE;
    11	if (!base) {
    12	  console.error('Missing BASE_URL/TRACE_BASE/RV_BASE/OPS_BASE for API fetch.');
    13	  process.exit(1);
    14	}
    15	
    16	const url = new URL(`/api/stock?ticker=${encodeURIComponent(ticker)}`, base).toString();
    17	const res = await fetch(url, { cache: 'no-store' });
    18	if (!res.ok) {
    19	  const body = await res.text().catch(() => '');
    20	  console.error(`HTTP ${res.status} for ${url}`);
    21	  console.error(body.slice(0, 300));
    22	  process.exit(1);
    23	}
    24	const text = await res.text();
    25	let payload;
    26	try {
    27	  payload = JSON.parse(text);
    28	} catch (err) {
    29	  console.error('Invalid JSON from /api/stock');
    30	  process.exit(1);
    31	}
    32	
    33	const values = computeUiValues(payload);
    34	const output = {
    35	  ticker,
    36	  source_url: url,
    37	  response_sha256: sha256Hex(text),
    38	  ui_values: values
    39	};
    40	
    41	process.stdout.write(JSON.stringify(output, null, 2) + '\n');

## FILE: scripts/truth-chain/trace_ui_to_origin.mjs
     1	import { readFileSync, existsSync, mkdirSync, writeFileSync } from 'node:fs';
     2	import { resolve } from 'node:path';
     3	import { sha256Hex, hashFile } from './lib/hash.mjs';
     4	import { firstLineRef, findLineRefs } from './lib/line-ref.mjs';
     5	import { computeUiValues } from './lib/ui-values.mjs';
     6	import { pickPaths } from './lib/excerpt.mjs';
     7	
     8	function fail(message) {
     9	  console.error(message);
    10	  process.exit(1);
    11	}
    12	
    13	const ticker = (process.argv[2] || '').trim().toUpperCase();
    14	if (!ticker) {
    15	  fail('Usage: node scripts/truth-chain/trace_ui_to_origin.mjs <TICKER>');
    16	}
    17	
    18	const base = process.env.BASE_URL || process.env.TRACE_BASE || process.env.RV_BASE || process.env.OPS_BASE;
    19	if (!base) {
    20	  fail('Missing BASE_URL/TRACE_BASE/RV_BASE/OPS_BASE for API fetch.');
    21	}
    22	
    23	const repoRoot = process.cwd();
    24	const uiFile = resolve(repoRoot, 'public/index.html');
    25	const stockHandlerFile = resolve(repoRoot, 'functions/api/stock.js');
    26	const fundamentalsHandlerFile = resolve(repoRoot, 'functions/api/fundamentals.js');
    27	
    28	if (!existsSync(uiFile)) fail(`UI file not found: ${uiFile}`);
    29	if (!existsSync(stockHandlerFile)) fail(`Stock handler not found: ${stockHandlerFile}`);
    30	if (!existsSync(fundamentalsHandlerFile)) fail(`Fundamentals handler not found: ${fundamentalsHandlerFile}`);
    31	
    32	const uiHash = hashFile(uiFile);
    33	const stockHandlerHash = hashFile(stockHandlerFile);
    34	const fundamentalsHandlerHash = hashFile(fundamentalsHandlerFile);
    35	
    36	const uiRefs = {
    37	  loadAnalyze: firstLineRef(uiFile, 'async function loadAnalyze'),
    38	  fetchStock: firstLineRef(uiFile, '/api/stock'),
    39	  fetchFundamentals: firstLineRef(uiFile, '/api/fundamentals'),
    40	  barLine: firstLineRef(uiFile, 'const bar = data?.latest_bar'),
    41	  closeLine: firstLineRef(uiFile, 'const close = bar?.close'),
    42	  changeAbsLine: firstLineRef(uiFile, 'const changeAbs = data?.change?.abs'),
    43	  changePctLine: firstLineRef(uiFile, 'const changePct = data?.change?.pct'),
    44	  volumeLine: firstLineRef(uiFile, 'const volume = bar?.volume'),
    45	  dateLine: firstLineRef(uiFile, 'const date = bar?.date'),
    46	  formatNumber: firstLineRef(uiFile, 'function formatNumber'),
    47	  formatPercent: firstLineRef(uiFile, 'function formatPercent'),
    48	  formatDate: firstLineRef(uiFile, 'const formatDateDDMMYYYY')
    49	};
    50	
    51	const stockRefs = {
    52	  handler: firstLineRef(stockHandlerFile, 'export async function onRequestGet'),
    53	  pickLatestBar: firstLineRef(stockHandlerFile, 'function pickLatestBar'),
    54	  computeDayChange: firstLineRef(stockHandlerFile, 'function computeDayChange'),
    55	  latestBarAssign: firstLineRef(stockHandlerFile, 'const latestBar = pickLatestBar'),
    56	  dayChangeAssign: firstLineRef(stockHandlerFile, 'const dayChange = computeDayChange'),
    57	  indicatorsAssign: firstLineRef(stockHandlerFile, 'const indicatorOut = computeIndicators')
    58	};
    59	
    60	const fundamentalsRefs = {
    61	  handler: firstLineRef(fundamentalsHandlerFile, 'export async function onRequestGet'),
    62	  normalize: firstLineRef(fundamentalsHandlerFile, 'normalizeFundamentalsFromTiingoRow')
    63	};
    64	
    65	const stockUrl = new URL(`/api/stock?ticker=${encodeURIComponent(ticker)}`, base).toString();
    66	const fundamentalsUrl = new URL(`/api/fundamentals?ticker=${encodeURIComponent(ticker)}`, base).toString();
    67	const marketphaseUrl = new URL(`/data/marketphase/${encodeURIComponent(ticker)}.json`, base).toString();
    68	const stockAnalysisUrl = new URL('/data/snapshots/stock-analysis.json', base).toString();
    69	const marketphaseIndexUrl = new URL('/data/marketphase/index.json', base).toString();
    70	
    71	async function fetchJson(url) {
    72	  const res = await fetch(url, { cache: 'no-store' });
    73	  const text = await res.text();
    74	  let json = null;
    75	  try {
    76	    json = text ? JSON.parse(text) : null;
    77	  } catch {
    78	    json = null;
    79	  }
    80	  return { url, ok: res.ok, status: res.status, text, json, sha256: sha256Hex(text) };
    81	}
    82	
    83	const stockRes = await fetchJson(stockUrl);
    84	if (!stockRes.ok || !stockRes.json) {
    85	  fail(`Failed to fetch /api/stock: HTTP ${stockRes.status}`);
    86	}
    87	
    88	const fundamentalsRes = await fetchJson(fundamentalsUrl);
    89	const marketphaseRes = await fetchJson(marketphaseUrl);
    90	const stockAnalysisRes = await fetchJson(stockAnalysisUrl);
    91	const marketphaseIndexRes = await fetchJson(marketphaseIndexUrl);
    92	
    93	const uiValues = computeUiValues(stockRes.json);
    94	
    95	function localArtifact(pathname) {
    96	  if (!pathname) return null;
    97	  const clean = pathname.startsWith('/') ? pathname.slice(1) : pathname;
    98	  const full = resolve(repoRoot, 'public', clean);
    99	  if (!existsSync(full)) return { path: pathname, local_path: full, exists: false };
   100	  const raw = readFileSync(full, 'utf8');
   101	  let json = null;
   102	  try {
   103	    json = JSON.parse(raw);
   104	  } catch {
   105	    json = null;
   106	  }
   107	  return {
   108	    path: pathname,
   109	    local_path: full,
   110	    exists: true,
   111	    sha256: sha256Hex(raw),
   112	    schema_version: json?.schema_version || json?.schemaVersion || null,
   113	    excerpt: json ? pickPaths(json, ['schema_version', 'meta.status', 'meta.data_date', 'metadata.module', 'data.symbols', 'data.records']) : null
   114	  };
   115	}
   116	
   117	const sourceArtifacts = [];
   118	const sources = stockRes.json?.metadata?.sources || {};
   119	for (const [moduleName, info] of Object.entries(sources)) {
   120	  if (!info?.path) continue;
   121	  const local = localArtifact(info.path);
   122	  sourceArtifacts.push({
   123	    module: moduleName,
   124	    ...local,
   125	    served_from: info.served_from,
   126	    status: info.status,
   127	    error: info.error || null
   128	  });
   129	}
   130	
   131	const trace = {
   132	  ticker,
   133	  base,
   134	  ui: {
   135	    file: uiFile,
   136	    sha256: uiHash,
   137	    refs: uiRefs,
   138	    render_values_from: {
   139	      latest_bar_close: `${uiRefs.closeLine.line}:${uiRefs.closeLine.text.trim()}`,
   140	      change_abs: `${uiRefs.changeAbsLine.line}:${uiRefs.changeAbsLine.text.trim()}`,
   141	      change_pct: `${uiRefs.changePctLine.line}:${uiRefs.changePctLine.text.trim()}`,
   142	      volume: `${uiRefs.volumeLine.line}:${uiRefs.volumeLine.text.trim()}`,
   143	      date: `${uiRefs.dateLine.line}:${uiRefs.dateLine.text.trim()}`
   144	    },
   145	    formatters: {
   146	      formatNumber: `${uiRefs.formatNumber.line}:${uiRefs.formatNumber.text.trim()}`,
   147	      formatPercent: `${uiRefs.formatPercent.line}:${uiRefs.formatPercent.text.trim()}`,
   148	      formatDate: `${uiRefs.formatDate.line}:${uiRefs.formatDate.text.trim()}`
   149	    }
   150	  },
   151	  network: {
   152	    stock: { url: stockRes.url, status: stockRes.status, sha256: stockRes.sha256 },
   153	    fundamentals: { url: fundamentalsRes.url, status: fundamentalsRes.status, sha256: fundamentalsRes.sha256 },
   154	    marketphase: { url: marketphaseRes.url, status: marketphaseRes.status, sha256: marketphaseRes.sha256 },
   155	    stock_analysis: { url: stockAnalysisRes.url, status: stockAnalysisRes.status, sha256: stockAnalysisRes.sha256 },
   156	    marketphase_index: { url: marketphaseIndexRes.url, status: marketphaseIndexRes.status, sha256: marketphaseIndexRes.sha256 }
   157	  },
   158	  server: {
   159	    stock_handler: { file: stockHandlerFile, sha256: stockHandlerHash, refs: stockRefs },
   160	    fundamentals_handler: { file: fundamentalsHandlerFile, sha256: fundamentalsHandlerHash, refs: fundamentalsRefs }
   161	  },
   162	  artifacts: {
   163	    sources: sourceArtifacts,
   164	    ui_universe_local: localArtifact('/data/universe/nasdaq100.json'),
   165	    marketphase_local: localArtifact(`/data/marketphase/${ticker}.json`),
   166	    marketphase_index_local: localArtifact('/data/marketphase/index.json'),
   167	    stock_analysis_local: localArtifact('/data/snapshots/stock-analysis.json')
   168	  },
   169	  transforms: [
   170	    { file: stockHandlerFile, fn: 'pickLatestBar', line: stockRefs.pickLatestBar.line },
   171	    { file: stockHandlerFile, fn: 'computeDayChange', line: stockRefs.computeDayChange.line },
   172	    { file: stockHandlerFile, fn: 'computeIndicators', line: stockRefs.indicatorsAssign.line },
   173	    { file: uiFile, fn: 'formatNumber', line: uiRefs.formatNumber.line },
   174	    { file: uiFile, fn: 'formatPercent', line: uiRefs.formatPercent.line },
   175	    { file: uiFile, fn: 'formatDateDDMMYYYY', line: uiRefs.formatDate.line }
   176	  ],
   177	  response_excerpt: {
   178	    meta: pickPaths(stockRes.json, ['meta.status', 'meta.data_date', 'meta.provider', 'meta.data_source', 'meta.mode', 'meta.asOf', 'meta.freshness']),
   179	    metadata: pickPaths(stockRes.json, ['metadata.status', 'metadata.served_from', 'metadata.request.ticker', 'metadata.request.normalized_ticker']),
   180	    latest_bar: pickPaths(stockRes.json, ['data.latest_bar.close', 'data.latest_bar.volume', 'data.latest_bar.date']),
   181	    change: pickPaths(stockRes.json, ['data.change.abs', 'data.change.pct'])
   182	  },
   183	  final: uiValues
   184	};
   185	
   186	const outDir = resolve(repoRoot, 'public/debug/truth-chain');
   187	mkdirSync(outDir, { recursive: true });
   188	const outPath = resolve(outDir, `${ticker}.trace.json`);
   189	writeFileSync(outPath, JSON.stringify(trace, null, 2) + '\n');
   190	
   191	console.log(`TRACE OK: ${ticker}`);
   192	console.log('[1] UI render path');
   193	console.log(`  file: ${uiFile}`);
   194	console.log(`  sha256: ${uiHash}`);
   195	console.log(`  loadAnalyze line: ${uiRefs.loadAnalyze.line}`);
   196	console.log(`  renderStock latest_bar line: ${uiRefs.barLine.line}`);
   197	console.log('[2] Network calls (live)');
   198	console.log(`  /api/stock -> ${stockRes.status} sha256=${stockRes.sha256}`);
   199	console.log(`  /api/fundamentals -> ${fundamentalsRes.status} sha256=${fundamentalsRes.sha256}`);
   200	console.log(`  /data/marketphase/${ticker}.json -> ${marketphaseRes.status} sha256=${marketphaseRes.sha256}`);

## FILE: scripts/ui-path/prove_ui_path.mjs
     1	import { readFileSync } from 'node:fs';
     2	import { resolve } from 'node:path';
     3	import { createHash } from 'node:crypto';
     4	import { chromium } from 'playwright';
     5	
     6	const ticker = (process.argv[2] || '').trim().toUpperCase();
     7	if (!ticker) {
     8	  console.error('Usage: node scripts/ui-path/prove_ui_path.mjs <TICKER>');
     9	  process.exit(1);
    10	}
    11	
    12	const base = process.env.BASE_URL || 'https://rubikvault.com';
    13	const pageUrl = new URL(`/analyze/${encodeURIComponent(ticker)}`, base).toString();
    14	
    15	function sha256Hex(input) {
    16	  const h = createHash('sha256');
    17	  h.update(input);
    18	  return h.digest('hex');
    19	}
    20	
    21	function findLineRef(filePath, pattern) {
    22	  const raw = readFileSync(filePath, 'utf8');
    23	  const lines = raw.split(/\r?\n/);
    24	  const rx = pattern instanceof RegExp ? pattern : new RegExp(pattern.replace(/[.*+?^${}()|[\]\\]/g, '\\$&'));
    25	  for (let i = 0; i < lines.length; i += 1) {
    26	    if (rx.test(lines[i])) {
    27	      return { file: filePath, line: i + 1, text: lines[i].trim() };
    28	    }
    29	  }
    30	  return null;
    31	}
    32	
    33	function parseNumber(text) {
    34	  if (!text) return null;
    35	  const cleaned = text.replace(/[$,]/g, '');
    36	  const n = Number(cleaned);
    37	  return Number.isFinite(n) ? n : null;
    38	}
    39	
    40	function normalizeUiDate(dateText) {
    41	  if (!dateText) return null;
    42	  const parts = dateText.split('-');
    43	  if (parts.length === 3) {
    44	    return `${parts[2]}-${parts[1]}-${parts[0]}`;
    45	  }
    46	  return null;
    47	}
    48	
    49	const browser = await chromium.launch();
    50	const page = await browser.newPage();
    51	
    52	const networkCalls = [];
    53	page.on('response', async (response) => {
    54	  try {
    55	    const url = response.url();
    56	    const ct = response.headers()['content-type'] || '';
    57	    if (!ct.includes('application/json') && !url.endsWith('.json') && !url.includes('/api/')) return;
    58	    const text = await response.text();
    59	    const sha = sha256Hex(text);
    60	    let json = null;
    61	    try {
    62	      json = JSON.parse(text);
    63	    } catch {
    64	      json = null;
    65	    }
    66	    const bodyKeys = json && typeof json === 'object' ? Object.keys(json) : [];
    67	    networkCalls.push({
    68	      url,
    69	      method: response.request().method(),
    70	      status: response.status(),
    71	      content_type: ct,
    72	      sha256: sha,
    73	      body_keys: bodyKeys,
    74	      response_excerpt: json ? {
    75	        schema_version: json.schema_version || json.schemaVersion || null,
    76	        meta: json.meta || null,
    77	        data: json.data ? { latest_bar: json.data.latest_bar || null, change: json.data.change || null } : null
    78	      } : { text: text.slice(0, 400) }
    79	    });
    80	  } catch {
    81	    // ignore
    82	  }
    83	});
    84	
    85	await page.goto(pageUrl, { waitUntil: 'domcontentloaded' });
    86	
    87	const uiValuesHandle = await page.waitForFunction(() => {
    88	  const pickByLabel = (label) => {
    89	    const span = Array.from(document.querySelectorAll('span')).find(s => s.textContent.trim() === label);
    90	    if (!span || !span.parentElement) return null;
    91	    const siblings = Array.from(span.parentElement.querySelectorAll('span'));
    92	    if (siblings.length < 2) return null;
    93	    return siblings[1].textContent.trim();
    94	  };
    95	
    96	  const closeText = pickByLabel('Close');
    97	  const volumeText = pickByLabel('Volume');
    98	  const dateText = (() => {
    99	    const match = Array.from(document.querySelectorAll('div')).map(el => el.textContent.trim()).find(t => /\d{2}-\d{2}-\d{4}/.test(t));
   100	    if (!match) return null;
   101	    const m = match.match(/\d{2}-\d{2}-\d{4}/);
   102	    return m ? m[0] : null;
   103	  })();
   104	
   105	  if (!closeText || closeText === '') return null;
   106	  return { closeText, volumeText, dateText };
   107	}, null, { timeout: 20000 });
   108	
   109	const ui = await uiValuesHandle.jsonValue();
   110	const uiClose = parseNumber(ui.closeText);
   111	const uiVolume = parseNumber(ui.volumeText);
   112	const uiDateIso = normalizeUiDate(ui.dateText);
   113	
   114	await page.waitForTimeout(500);
   115	await browser.close();
   116	
   117	if (uiClose == null || uiVolume == null || !uiDateIso) {
   118	  console.error('UI values missing:', ui);
   119	  process.exit(1);
   120	}
   121	
   122	const winning = networkCalls.find((call) => {
   123	  if (!call.response_excerpt || !call.response_excerpt.data) return false;
   124	  const bar = call.response_excerpt.data.latest_bar || {};
   125	  if (bar.close == null || bar.volume == null || !bar.date) return false;
   126	  const closeMatch = Number(bar.close) === Number(uiClose);
   127	  const volumeMatch = Number(bar.volume) === Number(uiVolume);
   128	  const dateMatch = String(bar.date).slice(0, 10) === uiDateIso;
   129	  return closeMatch && volumeMatch && dateMatch;
   130	});
   131	const winningError = winning
   132	  ? null
   133	  : { code: 'WINNING_RESPONSE_NOT_FOUND', message: 'No response matched UI values', ui };
   134	
   135	const handlerFile = resolve(process.cwd(), 'functions/api/stock.js');
   136	const handlerRef = findLineRef(handlerFile, 'export async function onRequestGet');
   137	const latestBarRef = findLineRef(handlerFile, 'const latestBar = pickLatestBar');
   138	const dayChangeRef = findLineRef(handlerFile, 'const dayChange = computeDayChange');
   139	
   140	async function inspectSnapshotContainsTicker() {
   141	  try {
   142	    const snapUrl = new URL('/data/snapshots/market-prices/latest.json', base).toString();
   143	    const res = await fetch(snapUrl, { cache: 'no-store' });
   144	    const text = await res.text();
   145	    let json = null;
   146	    try { json = JSON.parse(text); } catch { json = null; }
   147	    if (!json) return { ok: false, status: res.status, contains: null, url: snapUrl };
   148	    const data = json.data || [];
   149	    const found = Array.isArray(data)
   150	      ? data.some((row) => String(row?.symbol || '').toUpperCase() === ticker)
   151	      : Object.prototype.hasOwnProperty.call(data || {}, ticker);
   152	    return { ok: res.ok, status: res.status, contains: found, url: snapUrl };
   153	  } catch {
   154	    return { ok: false, status: null, contains: null, url: null };
   155	  }
   156	}
   157	
   158	const upstream = await (async () => {
   159	  const meta = winning?.response_excerpt?.meta || {};
   160	  const dataSource = meta.data_source || null;
   161	  if (dataSource === 'snapshot') {
   162	    const snap = await inspectSnapshotContainsTicker();
   163	    return {
   164	      kind: 'public_data',
   165	      key_or_path: '/data/snapshots/market-prices/latest.json',
   166	      snapshot_probe: snap
   167	    };
   168	  }
   169	  if (dataSource === 'real_provider') {
   170	    return { kind: 'provider', provider_name: meta.provider || null, key_or_path: null };
   171	  }
   172	  if (!winning) {
   173	    return { kind: 'unknown', key_or_path: null, error: 'no winning response' };
   174	  }
   175	  return { kind: 'unknown', key_or_path: null };
   176	})();
   177	
   178	const winningPath = (() => {
   179	  if (!winning?.url) return null;
   180	  try {
   181	    const u = new URL(winning.url);
   182	    return `${u.pathname}${u.search}`;
   183	  } catch {
   184	    return null;
   185	  }
   186	})();
   187	const winningBar = winning?.response_excerpt?.data?.latest_bar || null;
   188	const requiredFields = ['date', 'close', 'volume'];
   189	const missingFields = winningBar
   190	  ? requiredFields.filter((key) => winningBar[key] == null)
   191	  : requiredFields.slice();
   192	
   193	const trace = {
   194	  trace_version: 'v1',
   195	  generated_at: new Date().toISOString(),
   196	  base_url: base,
   197	  ticker,
   198	  page_url: pageUrl,
   199	  ui: {
   200	    values: {

## FILE: scripts/update-macro-hub.v3.mjs
     1	import fs from "node:fs";
     2	import { promises as fsp } from "node:fs";
     3	import path from "node:path";
     4	import { sanitizeForPublic, assertPublicSafe } from "./_lib/sanitize-public.mjs";
     5	import { saveMirror } from "./utils/mirror-io.mjs";
     6	
     7	const ROOT = path.resolve(new URL("..", import.meta.url).pathname);
     8	const CATALOG_PATH = path.join(ROOT, "config", "macro-hub.catalog.v3.json");
     9	const SNAPSHOT_PATH = path.join(ROOT, "public", "data", "snapshots", "macro-hub.json");
    10	const LASTGOOD_SNAPSHOT_PATH = SNAPSHOT_PATH; // SSOT lastGood: same path as snapshot
    11	const LASTGOOD_PATH = path.join(ROOT, "public", "data", "snapshots", "macro-hub.lastgood.json");
    12	const PROVIDER_STATE_PATH = path.join(ROOT, "public", "data", "provider-state.json");
    13	const RUNLOG_PATH = path.join(ROOT, "mirrors", "macro-hub-runlog.json");
    14	const MIRROR_PATH = path.join(ROOT, "mirrors", "macro-hub.json");
    15	const MAX_PUBLIC_BYTES = 200 * 1024;
    16	
    17	const CONCURRENCY = 5;
    18	const RETRIES = 3;
    19	const TIMEOUT_MS = 8000;
    20	const RUN_ID = new Date().toISOString();
    21	
    22	const FRED_BASE = "https://api.stlouisfed.org/fred/series/observations";
    23	const FINNHUB_BASE = "https://finnhub.io/api/v1/quote";
    24	const FMP_BASE = "https://financialmodelingprep.com/api/v3";
    25	const ALPHAVANTAGE_BASE = "https://www.alphavantage.co/query";
    26	const COINGECKO_BASE = "https://api.coingecko.com/api/v3";
    27	const DEFILLAMA_BASE = "https://stablecoins.llama.fi";
    28	
    29	const DAILY_SERIES = new Set([
    30	  "VIXCLS",
    31	  "VIX3M",
    32	  "T10Y2Y",
    33	  "DGS2",
    34	  "DGS10",
    35	  "DGS30",
    36	  "SOFR",
    37	  "EFFR",
    38	  "BAMLH0A0HYM2",
    39	  "BAMLC0A0CM",
    40	  "BAMLC0A4CBBB",
    41	  "BAA",
    42	  "DTWEXBGS",
    43	  "DEXUSEU",
    44	  "DEXJPUS",
    45	  "GOLDAMGBD228NLBM",
    46	  "DCOILWTICO",
    47	  "WILSHIRE5000IND"
    48	]);
    49	const MONTHLY_SERIES = new Set(["CPIAUCSL", "UNRATE"]);
    50	const QUARTERLY_SERIES = new Set(["GDP"]);
    51	
    52	function readJson(filePath) {
    53	  try {
    54	    if (!fs.existsSync(filePath)) return null;
    55	    const raw = fs.readFileSync(filePath, "utf8");
    56	    if (!raw.trim()) return null;
    57	    return JSON.parse(raw);
    58	  } catch {
    59	    return null;
    60	  }
    61	}
    62	
    63	async function writeJson(filePath, payload) {
    64	  await fsp.mkdir(path.dirname(filePath), { recursive: true });
    65	  await fsp.writeFile(filePath, JSON.stringify(payload, null, 2));
    66	}
    67	
    68	function sanitizeAndWritePublic(filePath, payload) {
    69	  const sanitized = sanitizeForPublic(payload);
    70	  assertPublicSafe(sanitized, path.basename(filePath));
    71	  const raw = JSON.stringify(sanitized, null, 2);
    72	  const bytes = Buffer.byteLength(raw, "utf8");
    73	  if (bytes > MAX_PUBLIC_BYTES) {
    74	    throw new Error(`public_snapshot_too_large:${path.basename(filePath)}:${bytes}`);
    75	  }
    76	  fs.mkdirSync(path.dirname(filePath), { recursive: true });
    77	  fs.writeFileSync(filePath, raw);
    78	}
    79	
    80	function toDateString(date = new Date()) {
    81	  return new Date(date).toISOString().slice(0, 10);
    82	}
    83	
    84	function createLimiter(limit) {
    85	  let active = 0;
    86	  const queue = [];
    87	  const next = () => {
    88	    if (active >= limit) return;
    89	    const task = queue.shift();
    90	    if (!task) return;
    91	    active += 1;
    92	    task()
    93	      .catch(() => {})
    94	      .finally(() => {
    95	        active -= 1;
    96	        next();
    97	      });
    98	  };
    99	  return function run(task) {
   100	    return new Promise((resolve, reject) => {
   101	      queue.push(async () => {
   102	        try {
   103	          resolve(await task());
   104	        } catch (err) {
   105	          reject(err);
   106	        }
   107	      });
   108	      next();
   109	    });
   110	  };
   111	}
   112	
   113	function sleep(ms) {
   114	  return new Promise((resolve) => setTimeout(resolve, ms));
   115	}
   116	
   117	async function withRetries(fn, { retries = RETRIES } = {}) {
   118	  let lastError;
   119	  for (let attempt = 0; attempt <= retries; attempt += 1) {
   120	    try {
   121	      return await fn(attempt);
   122	    } catch (error) {
   123	      lastError = error;
   124	      if (attempt < retries) {
   125	        const base = 300 * Math.pow(2, attempt);
   126	        const jitter = base * (0.8 + Math.random() * 0.4);
   127	        await sleep(jitter);
   128	      }
   129	    }
   130	  }
   131	  throw lastError;
   132	}
   133	
   134	function loadBudgets() {
   135	  const configPath = path.join(ROOT, "config", "rv-budgets.json");
   136	  if (fs.existsSync(configPath)) {
   137	    const payload = readJson(configPath);
   138	    if (payload && typeof payload === "object") return payload;
   139	  }
   140	  const providers = {};
   141	  const ids = ["fred", "finnhub", "fmp", "alphavantage", "coingecko", "defillama", "eia"];
   142	  ids.forEach((id) => {
   143	    const daily = Number(process.env[`RV_BUDGET_${id.toUpperCase()}_DAILY`] || "");
   144	    const monthly = Number(process.env[`RV_BUDGET_${id.toUpperCase()}_MONTHLY`] || "");
   145	    if (Number.isFinite(daily) || Number.isFinite(monthly)) {
   146	      providers[id] = {
   147	        dailyRequests: Number.isFinite(daily) ? daily : null,
   148	        monthlyRequests: Number.isFinite(monthly) ? monthly : null
   149	      };
   150	    }
   151	  });
   152	  return { providers };
   153	}
   154	
   155	function createBudgetGuard(budgets) {
   156	  const usage = {};
   157	  function getProviderBudget(providerId) {
   158	    const providers = budgets?.providers || {};
   159	    return providers[providerId] || {};
   160	  }
   161	  function getEndpointBudget(providerId, endpointId) {
   162	    const provider = getProviderBudget(providerId);
   163	    const endpoints = provider?.endpoints || {};
   164	    return endpoints[endpointId] || {};
   165	  }
   166	  function canCall(providerId, endpointId) {
   167	    const providerBudget = getProviderBudget(providerId);
   168	    const endpointBudget = endpointId ? getEndpointBudget(providerId, endpointId) : {};
   169	    const limit = endpointBudget.dailyRequests ?? providerBudget.dailyRequests ?? null;
   170	    if (limit === null || limit === undefined) return true;
   171	    const used = usage?.[providerId]?.[endpointId || "__total"] || 0;
   172	    return used < limit;
   173	  }
   174	  function record(providerId, endpointId) {
   175	    if (!usage[providerId]) usage[providerId] = {};
   176	    const key = endpointId || "__total";
   177	    usage[providerId][key] = (usage[providerId][key] || 0) + 1;
   178	  }
   179	  function toProviderCalls() {
   180	    const out = {};
   181	    Object.keys(usage).forEach((provider) => {
   182	      const totals = usage[provider] || {};
   183	      const sum = Object.values(totals).reduce((acc, v) => acc + Number(v || 0), 0);
   184	      out[provider.toUpperCase()] = sum;
   185	    });
   186	    return out;
   187	  }
   188	  return { canCall, record, usage, toProviderCalls };
   189	}
   190	
   191	async function fetchJson(url, { provider, endpoint, headers } = {}) {
   192	  const limiter = fetchJson.limiter;
   193	  const budget = fetchJson.budget;
   194	  if (!budget.canCall(provider, endpoint)) {
   195	    const error = new Error("BUDGET_EXCEEDED");
   196	    error.code = "BUDGET_EXCEEDED";
   197	    throw error;
   198	  }
   199	  return limiter(() => withRetries(async () => {
   200	    budget.record(provider, endpoint);

## FILE: scripts/update-news.mjs
     1	import fs from "node:fs";
     2	import path from "node:path";
     3	import crypto from "node:crypto";
     4	import { fileURLToPath } from "node:url";
     5	import Parser from "rss-parser";
     6	import { createBudgetState, createUsageCollector, loadBudgetsConfig } from "./_lib/usage.js";
     7	import { fetchRssFeed } from "./providers/rss.js";
     8	import { acquireLock, releaseLock } from "./_lib/lock.js";
     9	import { loadMirror, saveMirror } from "./utils/mirror-io.mjs";
    10	
    11	const MAX_SOURCES = 8;
    12	const MAX_ITEMS_TOTAL = 60;
    13	const MIN_ITEMS_TO_WRITE = 12;
    14	const TIMEOUT_MS = 4500;
    15	const RETRIES = 1;
    16	
    17	const BACKOFF_RULES = {
    18	  RATE_LIMIT_429_SEC: 15 * 60,
    19	  UPSTREAM_5XX_SEC: 5 * 60,
    20	  UPSTREAM_4XX_SEC: 60 * 60
    21	};
    22	
    23	const SOURCES = [
    24	  {
    25	    id: "finanzen_news",
    26	    name: "finanzen.net News",
    27	    url: "https://www.finanzen.net/rss/news"
    28	  },
    29	  {
    30	    id: "finanzen_analysen",
    31	    name: "finanzen.net Analysen",
    32	    url: "https://www.finanzen.net/rss/analysen"
    33	  },
    34	  {
    35	    id: "onvista",
    36	    name: "OnVista",
    37	    url: "https://news.onvista.de/rss/woche"
    38	  },
    39	  {
    40	    id: "handelsblatt_finanzen",
    41	    name: "Handelsblatt Finanzen",
    42	    url: "https://www.handelsblatt.com/contentexport/feed/finanzen"
    43	  },
    44	  {
    45	    id: "google_news_markets",
    46	    name: "Google News (Markets)",
    47	    url: "https://news.google.com/rss/search?q=Aktien%20B%C3%B6rse%20DAX&hl=de&gl=DE&ceid=DE:de"
    48	  },
    49	  {
    50	    id: "tagesschau",
    51	    name: "Tagesschau",
    52	    url: "https://www.tagesschau.de/xml/rss2/"
    53	  }
    54	].slice(0, MAX_SOURCES);
    55	
    56	function nowIso() {
    57	  return new Date().toISOString();
    58	}
    59	
    60	function sha256Hex(value) {
    61	  return crypto.createHash("sha256").update(value).digest("hex");
    62	}
    63	
    64	function normalizeWhitespace(text) {
    65	  return String(text || "")
    66	    .replace(/\s+/g, " ")
    67	    .trim();
    68	}
    69	
    70	function decodeHtmlEntities(text) {
    71	  return String(text || "")
    72	    .replace(/&amp;/g, "&")
    73	    .replace(/&lt;/g, "<")
    74	    .replace(/&gt;/g, ">")
    75	    .replace(/&quot;/g, '"')
    76	    .replace(/&#39;/g, "'")
    77	    .replace(/&#x27;/g, "'")
    78	    .replace(/&#x2F;/g, "/")
    79	    .replace(/&#([0-9]+);/g, (_, num) => {
    80	      const code = Number(num);
    81	      if (!Number.isFinite(code)) return _;
    82	      return String.fromCharCode(code);
    83	    });
    84	}
    85	
    86	function canonicalizeUrl(raw) {
    87	  if (!raw) return "";
    88	  try {
    89	    const url = new URL(String(raw));
    90	    const params = url.searchParams;
    91	    const toDelete = [];
    92	    for (const [k] of params.entries()) {
    93	      if (k.toLowerCase().startsWith("utm_")) toDelete.push(k);
    94	    }
    95	    toDelete.forEach((k) => params.delete(k));
    96	    url.search = params.toString() ? `?${params.toString()}` : "";
    97	    url.hash = "";
    98	    return url.toString();
    99	  } catch {
   100	    return String(raw);
   101	  }
   102	}
   103	
   104	function hostnameFromUrl(raw) {
   105	  try {
   106	    const url = new URL(String(raw));
   107	    return url.hostname || "";
   108	  } catch {
   109	    return "";
   110	  }
   111	}
   112	
   113	function parsePublishedAt(entry) {
   114	  const candidates = [entry?.isoDate, entry?.pubDate, entry?.published, entry?.updated];
   115	  for (const value of candidates) {
   116	    if (!value) continue;
   117	    const d = new Date(value);
   118	    if (!Number.isNaN(d.getTime())) return d.toISOString();
   119	  }
   120	  return null;
   121	}
   122	
   123	function classifyTopic(title) {
   124	  const text = String(title || "").toLowerCase();
   125	  const rules = [
   126	    { topic: "dax", keywords: ["dax", "mdax", "sdax", "tecdax"] },
   127	    { topic: "rates", keywords: ["zins", "zinsen", "yield", "rendite", "bund", "fed", "ecb"] },
   128	    { topic: "crypto", keywords: ["bitcoin", "btc", "ethereum", "eth", "krypto", "crypto"] }
   129	  ];
   130	  for (const rule of rules) {
   131	    if (rule.keywords.some((k) => text.includes(k))) return rule.topic;
   132	  }
   133	  return null;
   134	}
   135	
   136	async function fetchFeed(url, ctx) {
   137	  try {
   138	    const result = await fetchRssFeed(ctx, url);
   139	    return { ok: true, status: 200, text: result.data };
   140	  } catch (error) {
   141	    const status = error?.details?.httpStatus ?? 0;
   142	    return { ok: false, status, text: "", error };
   143	  }
   144	}
   145	
   146	function isRetryable({ status, error }) {
   147	  if (error) return true;
   148	  if (status >= 500) return true;
   149	  return false;
   150	}
   151	
   152	function computeBackoffSeconds(status) {
   153	  if (status === 429) return BACKOFF_RULES.RATE_LIMIT_429_SEC;
   154	  if (status >= 500) return BACKOFF_RULES.UPSTREAM_5XX_SEC;
   155	  if (status >= 400 && status < 500) return BACKOFF_RULES.UPSTREAM_4XX_SEC;
   156	  return 0;
   157	}
   158	
   159	function getRepoRoot() {
   160	  const here = path.dirname(fileURLToPath(import.meta.url));
   161	  return path.resolve(here, "..");
   162	}
   163	
   164	function readJsonIfExists(filePath) {
   165	  try {
   166	    if (!fs.existsSync(filePath)) return null;
   167	    const text = fs.readFileSync(filePath, "utf8");
   168	    return JSON.parse(text);
   169	  } catch {
   170	    return null;
   171	  }
   172	}
   173	
   174	function ensureDir(dirPath) {
   175	  fs.mkdirSync(dirPath, { recursive: true });
   176	}
   177	
   178	function atomicWriteJson(targetPath, payload) {
   179	  const dir = path.dirname(targetPath);
   180	  ensureDir(dir);
   181	  const tmpDir = path.join(getRepoRoot(), ".tmp", "out");
   182	  ensureDir(tmpDir);
   183	  const tmpPath = path.join(tmpDir, `${path.basename(targetPath)}.${Date.now()}.tmp`);
   184	  fs.writeFileSync(tmpPath, `${JSON.stringify(payload, null, 2)}\n`, "utf8");
   185	  fs.renameSync(tmpPath, targetPath);
   186	}
   187	
   188	function buildMeta({ status, lastSuccess, itemsCount, dedupedCount, sources, commit, runId }) {
   189	  const ageSeconds = lastSuccess ? Math.max(0, Math.floor((Date.now() - Date.parse(lastSuccess)) / 1000)) : 0;
   190	  return {
   191	    schemaVersion: 1,
   192	    status,
   193	    lastSuccess: lastSuccess || null,
   194	    ageSeconds,
   195	    itemsCount,
   196	    dedupedCount,
   197	    sources,
   198	    build: {
   199	      commit: commit || "unknown",
   200	      runId: runId || null

## FILE: scripts/utils/eod-market-mirrors.mjs
     1	import { buildBaseMirror } from "./mirror-builders.mjs";
     2	import { computeAlphaRadarPicks } from "../core/alpha-radar-core.mjs";
     3	import { deriveRegime } from "./market-indicators.mjs";
     4	import { loadMirror } from "./mirror-io.mjs";
     5	
     6	export function buildDQ(items, missing) {
     7	  if (!items.length) return "EMPTY";
     8	  if (missing.length) return "PARTIAL";
     9	  return "OK";
    10	}
    11	
    12	export function buildEodMirrors({
    13	  universe,
    14	  skipped,
    15	  data,
    16	  asOfIso,
    17	  prevRegimePath
    18	}) {
    19	  const prevRegime = loadMirror(prevRegimePath) || {};
    20	  const prevContext = prevRegime.context || {};
    21	  const breadth50 = data.breadthTotal ? data.breadth50Count / data.breadthTotal : 0;
    22	  const breadth200 = data.breadthTotal ? data.breadth200Count / data.breadthTotal : 0;
    23	  const regimeState = deriveRegime({
    24	    breadth50,
    25	    breadth200,
    26	    prevState: {
    27	      currentRegime: prevContext.currentRegime || "neutral",
    28	      pendingRegime: prevContext.pendingRegime || null,
    29	      pendingCount: prevContext.pendingCount || 0,
    30	      daysSinceChange: prevContext.daysSinceChange || 0
    31	    }
    32	  });
    33	
    34	  const quotesMirror = buildBaseMirror({
    35	    mirrorId: "quotes",
    36	    mode: "EOD",
    37	    cadence: "EOD",
    38	    trust: "raw",
    39	    sourceUpstream: "stooq",
    40	    whyUnique: "EOD closing prices for tracked symbols.",
    41	    items: data.itemsQuotes,
    42	    context: { selectedSymbols: universe, skippedSymbols: skipped },
    43	    missingSymbols: data.missingSymbols,
    44	    errors: data.errors,
    45	    notes: [`selectedSymbols=${universe.join(",")}`, `skippedSymbols=${skipped.join(",")}`],
    46	    dataQuality: buildDQ(data.itemsQuotes, data.missingSymbols),
    47	    asOf: asOfIso
    48	  });
    49	
    50	  const benchmarkSymbols = ["SPY", "QQQ", "IWM"];
    51	  const marketHealthItems = data.itemsQuotes.filter((item) =>
    52	    benchmarkSymbols.includes(item.symbol)
    53	  );
    54	
    55	  const marketHealthMirror = buildBaseMirror({
    56	    mirrorId: "market-health",
    57	    mode: "EOD",
    58	    cadence: "EOD",
    59	    trust: "derived",
    60	    sourceUpstream: "stooq",
    61	    whyUnique: "EOD benchmark health snapshot.",
    62	    items: marketHealthItems,
    63	    context: { benchmarks: benchmarkSymbols },
    64	    missingSymbols: data.missingSymbols,
    65	    errors: data.errors,
    66	    notes: [],
    67	    dataQuality: marketHealthItems.length ? "OK" : "EMPTY",
    68	    asOf: asOfIso
    69	  });
    70	
    71	  const techMirrorBase = buildBaseMirror({
    72	    mirrorId: "tech-signals",
    73	    mode: "EOD",
    74	    cadence: "EOD",
    75	    trust: "derived",
    76	    sourceUpstream: "stooq",
    77	    whyUnique: "EOD technical indicators per symbol.",
    78	    items: data.itemsTech,
    79	    context: { selectedSymbols: universe },
    80	    missingSymbols: data.missingSymbols,
    81	    errors: data.errors,
    82	    notes: [],
    83	    dataQuality: buildDQ(data.itemsTech, data.missingSymbols),
    84	    asOf: asOfIso
    85	  });
    86	  const techMirror = {
    87	    ...techMirrorBase,
    88	    generatedAt: techMirrorBase.updatedAt,
    89	    data: {
    90	      ...(techMirrorBase.data && typeof techMirrorBase.data === "object" ? techMirrorBase.data : {}),
    91	      signals: data.itemsTech,
    92	      rows: data.itemsTech
    93	    }
    94	  };
    95	
    96	  const priceSnapshotMirror = buildBaseMirror({
    97	    mirrorId: "price-snapshot",
    98	    mode: "EOD",
    99	    cadence: "EOD",
   100	    trust: "derived",
   101	    sourceUpstream: "stooq",
   102	    whyUnique: "Compact EOD price snapshot.",
   103	    items: data.itemsQuotes,
   104	    context: { selectedSymbols: universe },
   105	    missingSymbols: data.missingSymbols,
   106	    errors: data.errors,
   107	    notes: [],
   108	    dataQuality: buildDQ(data.itemsQuotes, data.missingSymbols),
   109	    asOf: asOfIso
   110	  });
   111	
   112	  const movers = [...data.itemsQuotes].filter((item) => Number.isFinite(item.changePct));
   113	  movers.sort((a, b) => b.changePct - a.changePct);
   114	  const topMoversItems = movers.slice(0, 10);
   115	
   116	  const topMoversMirror = buildBaseMirror({
   117	    mirrorId: "top-movers",
   118	    mode: "EOD",
   119	    cadence: "EOD",
   120	    trust: "derived",
   121	    sourceUpstream: "stooq",
   122	    whyUnique: "EOD top movers derived from quotes.",
   123	    items: topMoversItems,
   124	    context: { selectedSymbols: universe },
   125	    missingSymbols: data.missingSymbols,
   126	    errors: data.errors,
   127	    notes: [],
   128	    dataQuality: topMoversItems.length ? "OK" : "EMPTY",
   129	    asOf: asOfIso
   130	  });
   131	
   132	  const marketCockpitMirror = buildBaseMirror({
   133	    mirrorId: "market-cockpit",
   134	    mode: "EOD",
   135	    cadence: "EOD",
   136	    trust: "derived",
   137	    sourceUpstream: "stooq",
   138	    whyUnique: "Summary cockpit for benchmarks and signals.",
   139	    items: [
   140	      {
   141	        section: "benchmarks",
   142	        items: marketHealthItems
   143	      }
   144	    ],
   145	    context: { benchmarks: benchmarkSymbols },
   146	    missingSymbols: data.missingSymbols,
   147	    errors: data.errors,
   148	    notes: [],
   149	    dataQuality: marketHealthItems.length ? "OK" : "EMPTY",
   150	    asOf: asOfIso
   151	  });
   152	
   153	  const alphaMirrorBase = buildBaseMirror({
   154	    mirrorId: "alpha-radar",
   155	    mode: "EOD",
   156	    cadence: "EOD",
   157	    trust: "derived",
   158	    sourceUpstream: "stooq",
   159	    whyUnique: "EOD scoring based on technicals.",
   160	    items: data.itemsAlpha,
   161	    context: { selectedSymbols: universe },
   162	    missingSymbols: data.missingSymbols,
   163	    errors: data.errors,
   164	    notes: [],
   165	    dataQuality: buildDQ(data.itemsAlpha, data.missingSymbols),
   166	    asOf: asOfIso
   167	  });
   168	  const alphaPicks = computeAlphaRadarPicks({ itemsAlpha: data.itemsAlpha });
   169	  const alphaMirror = {
   170	    ...alphaMirrorBase,
   171	    generatedAt: alphaMirrorBase.updatedAt,
   172	    data: {
   173	      ...(alphaMirrorBase.data && typeof alphaMirrorBase.data === "object" ? alphaMirrorBase.data : {}),
   174	      picks: alphaPicks
   175	    }
   176	  };
   177	
   178	  const regimeMirror = buildBaseMirror({
   179	    mirrorId: "market-regime",
   180	    mode: "EOD",
   181	    cadence: "EOD",
   182	    trust: "derived",
   183	    sourceUpstream: "stooq",
   184	    whyUnique: "Breadth-based regime with hysteresis.",
   185	    items: [
   186	      {
   187	        regime: regimeState.currentRegime,
   188	        confidence: regimeState.confidence,
   189	        breadth50,
   190	        breadth200,
   191	        daysSinceChange: regimeState.daysSinceChange
   192	      }
   193	    ],
   194	    context: regimeState,
   195	    missingSymbols: [],
   196	    errors: [],
   197	    notes: [],
   198	    dataQuality: "OK",
   199	    asOf: asOfIso
   200	  });

## FILE: scripts/utils/mirror-builders.mjs
     1	import { redactNotes } from "./mirror-io.mjs";
     2	
     3	export function buildBaseMirror({ mirrorId, mode, cadence, trust, sourceUpstream, whyUnique, items, context, missingSymbols, errors, notes, dataQuality, asOf, provider, dataset, ttlSeconds, fetchedAt }) {
     4	  const now = new Date().toISOString();
     5	  return {
     6	    schemaVersion: "rv-mirror-v1",
     7	    mirrorId,
     8	    provider: provider || sourceUpstream || mirrorId,
     9	    dataset: dataset || mirrorId,
    10	    runId: now,
    11	    fetchedAt: fetchedAt || now,
    12	    updatedAt: now,
    13	    asOf: asOf || now,
    14	    mode,
    15	    cadence,
    16	    trust,
    17	    source: "mirror",
    18	    sourceUpstream: sourceUpstream || "unknown",
    19	    ttlSeconds: Number.isFinite(ttlSeconds) ? ttlSeconds : null,
    20	    dataQuality,
    21	    delayMinutes: 0,
    22	    missingSymbols: missingSymbols || [],
    23	    errors: errors || [],
    24	    notes: redactNotes(notes || []),
    25	    whyUnique: whyUnique || "",
    26	    context: context || {},
    27	    items: items || []
    28	  };
    29	}
    30	
    31	export function buildSystemHealth({ jobs, mirrors, selectedSymbols, skippedSymbols, overallStatus }) {
    32	  const now = new Date().toISOString();
    33	  return {
    34	    schemaVersion: "1.0",
    35	    mirrorId: "system-health",
    36	    updatedAt: now,
    37	    overallStatus: overallStatus || "OK",
    38	    jobs,
    39	    mirrors,
    40	    alerts: [],
    41	    selectedSymbols,
    42	    skippedSymbols
    43	  };
    44	}
    45	
    46	export function buildDigest({ highlights, signals, changes, sources }) {
    47	  const now = new Date().toISOString();
    48	  return {
    49	    schemaVersion: "1.0",
    50	    mirrorId: "daily-digest",
    51	    updatedAt: now,
    52	    highlights: highlights || [],
    53	    actionableSignals: signals || [],
    54	    changesVsYesterday: changes || [],
    55	    sourcesUsed: sources || []
    56	  };
    57	}

## FILE: scripts/utils/mirror-io.mjs
     1	import fs from "node:fs";
     2	import path from "node:path";
     3	
     4	export function isFiniteNumber(value) {
     5	  return Number.isFinite(value);
     6	}
     7	
     8	export function sleep(ms) {
     9	  return new Promise((resolve) => setTimeout(resolve, ms));
    10	}
    11	
    12	export async function withRetries(fn, { retries = 2, baseDelayMs = 400 } = {}) {
    13	  let lastError;
    14	  for (let attempt = 0; attempt <= retries; attempt += 1) {
    15	    try {
    16	      return await fn(attempt);
    17	    } catch (err) {
    18	      lastError = err;
    19	      if (attempt < retries) {
    20	        const wait = baseDelayMs * Math.pow(2, attempt);
    21	        await sleep(wait);
    22	      }
    23	    }
    24	  }
    25	  throw lastError;
    26	}
    27	
    28	export function loadMirror(filePath) {
    29	  try {
    30	    if (!fs.existsSync(filePath)) return null;
    31	    const raw = fs.readFileSync(filePath, "utf8");
    32	    if (!raw.trim()) return null;
    33	    const parsed = JSON.parse(raw);
    34	    if (isMirrorEnvelope(parsed)) {
    35	      return parsed.raw;
    36	    }
    37	    return parsed;
    38	  } catch (err) {
    39	    return null;
    40	  }
    41	}
    42	
    43	export function loadMirrorEnvelope(filePath) {
    44	  try {
    45	    if (!fs.existsSync(filePath)) return null;
    46	    const raw = fs.readFileSync(filePath, "utf8");
    47	    if (!raw.trim()) return null;
    48	    const parsed = JSON.parse(raw);
    49	    if (isMirrorEnvelope(parsed)) {
    50	      return { meta: parsed.meta, raw: parsed.raw, envelope: parsed, isEnvelope: true };
    51	    }
    52	    return { raw: parsed, envelope: null, isEnvelope: false };
    53	  } catch (err) {
    54	    return null;
    55	  }
    56	}
    57	
    58	export function validateBasicMirrorShape(data) {
    59	  const errors = [];
    60	  if (!data || typeof data !== "object") {
    61	    return { ok: false, errors: ["mirror_not_object"] };
    62	  }
    63	  const allowedSchemaVersions = new Set(["1.0", "rv-mirror-v1"]);
    64	  const requiredFields = [
    65	    "schemaVersion",
    66	    "mirrorId",
    67	    "runId",
    68	    "updatedAt",
    69	    "asOf",
    70	    "mode",
    71	    "cadence",
    72	    "trust",
    73	    "source",
    74	    "sourceUpstream",
    75	    "dataQuality",
    76	    "delayMinutes",
    77	    "missingSymbols",
    78	    "errors",
    79	    "notes",
    80	    "whyUnique",
    81	    "context",
    82	    "items"
    83	  ];
    84	  for (const field of requiredFields) {
    85	    if (!(field in data)) {
    86	      errors.push(`missing_${field}`);
    87	    }
    88	  }
    89	  if (data.schemaVersion && !allowedSchemaVersions.has(data.schemaVersion)) {
    90	    errors.push("schemaVersion_invalid");
    91	  }
    92	  if (!Array.isArray(data.items)) {
    93	    errors.push("items_not_array");
    94	  }
    95	  if (!Array.isArray(data.missingSymbols)) {
    96	    errors.push("missingSymbols_not_array");
    97	  }
    98	  if (!Array.isArray(data.errors)) {
    99	    errors.push("errors_not_array");
   100	  }
   101	  if (!Array.isArray(data.notes)) {
   102	    errors.push("notes_not_array");
   103	  }
   104	  const allowedModes = ["LIVE", "EOD", "EMPTY", "MIRROR"];
   105	  if (data.mode && !allowedModes.includes(data.mode)) {
   106	    errors.push("mode_invalid");
   107	  }
   108	  const allowedCadence = ["LIVE", "EOD", "hourly", "daily", "best_effort", "15m_delayed"];
   109	  if (data.cadence && !allowedCadence.includes(data.cadence)) {
   110	    errors.push("cadence_invalid");
   111	  }
   112	  const allowedTrust = ["raw", "derived", "heuristic"];
   113	  if (data.trust && !allowedTrust.includes(data.trust)) {
   114	    errors.push("trust_invalid");
   115	  }
   116	  const allowedDQ = ["OK", "PARTIAL", "EMPTY", "STALE", "COVERAGE_LIMIT"];
   117	  if (data.dataQuality && !allowedDQ.includes(data.dataQuality)) {
   118	    errors.push("dataQuality_invalid");
   119	  }
   120	  return { ok: errors.length === 0, errors };
   121	}
   122	
   123	export function atomicWriteJson(finalPath, data) {
   124	  const dir = path.dirname(finalPath);
   125	  fs.mkdirSync(dir, { recursive: true });
   126	  const tmpPath = `${finalPath}.tmp`;
   127	  fs.writeFileSync(tmpPath, JSON.stringify(data, null, 2));
   128	  fs.renameSync(tmpPath, finalPath);
   129	}
   130	
   131	export function normalizeMirrorMeta(payload) {
   132	  if (!payload || typeof payload !== "object") return { payload, changed: false };
   133	  const now = new Date().toISOString();
   134	  const items = Array.isArray(payload.items)
   135	    ? payload.items
   136	    : Array.isArray(payload?.data?.items)
   137	      ? payload.data.items
   138	      : [];
   139	  const updatedAt = payload?.meta?.updatedAt || payload?.updatedAt || now;
   140	  const existingStatus = payload?.meta?.status || null;
   141	  let status = existingStatus;
   142	  if (!status) {
   143	    if (items.length > 0) {
   144	      status = "OK";
   145	    } else if (payload?.dataQuality === "STUB") {
   146	      status = "STUB";
   147	    } else if (payload?.dataQuality === "ERROR") {
   148	      status = "ERROR";
   149	    } else {
   150	      status = "PARTIAL";
   151	    }
   152	  }
   153	  if (status === "OK" && items.length === 0) {
   154	    status = "PARTIAL";
   155	  }
   156	  const reason = payload?.meta?.reason || (status === "OK" ? null : payload?.dataQuality || "EMPTY_ITEMS");
   157	  const nextMeta = {
   158	    ...(payload.meta && typeof payload.meta === "object" ? payload.meta : {}),
   159	    status,
   160	    updatedAt,
   161	    reason
   162	  };
   163	  const changed =
   164	    !payload.meta ||
   165	    payload.meta.updatedAt !== nextMeta.updatedAt ||
   166	    payload.meta.status !== nextMeta.status ||
   167	    payload.meta.reason !== nextMeta.reason;
   168	  return { payload: { ...payload, meta: nextMeta }, changed };
   169	}
   170	
   171	export function isMirrorEnvelope(payload) {
   172	  if (!payload || typeof payload !== "object") return false;
   173	  if (!payload.meta || !payload.raw) return false;
   174	  const meta = payload.meta || {};
   175	  return Boolean(
   176	    Object.prototype.hasOwnProperty.call(meta, "provider") ||
   177	      Object.prototype.hasOwnProperty.call(meta, "dataset") ||
   178	      Object.prototype.hasOwnProperty.call(meta, "fetchedAt") ||
   179	      Object.prototype.hasOwnProperty.call(meta, "source") ||
   180	      Object.prototype.hasOwnProperty.call(meta, "runId")
   181	  );
   182	}
   183	
   184	function normalizeEnvelopeMeta(rawPayload, meta, finalPath) {
   185	  const now = new Date().toISOString();
   186	  const metaInput = meta && typeof meta === "object" ? meta : {};
   187	  const raw = rawPayload && typeof rawPayload === "object" ? rawPayload : {};
   188	  const dataset =
   189	    metaInput.dataset ||
   190	    raw.dataset ||
   191	    raw.mirrorId ||
   192	    raw.feature ||
   193	    raw?.meta?.feature ||
   194	    (finalPath ? path.basename(finalPath, ".json") : "unknown");
   195	  const provider =
   196	    metaInput.provider ||
   197	    raw.provider ||
   198	    raw.sourceUpstream ||
   199	    raw.source ||
   200	    raw?.meta?.source ||

## FILE: scripts/validate-feature-registry.mjs
     1	#!/usr/bin/env node
     2	import fs from "node:fs";
     3	import path from "node:path";
     4	
     5	const ROOT = process.cwd();
     6	const REGISTRY_PATH = path.join(ROOT, "feature-registry.json");
     7	
     8	function fail(message) {
     9	  console.error(message);
    10	  process.exit(1);
    11	}
    12	
    13	function loadRegistry() {
    14	  if (!fs.existsSync(REGISTRY_PATH)) {
    15	    fail(`feature-registry missing at ${REGISTRY_PATH}`);
    16	  }
    17	  try {
    18	    const raw = fs.readFileSync(REGISTRY_PATH, "utf8");
    19	    const parsed = JSON.parse(raw);
    20	    if (!Array.isArray(parsed)) {
    21	      fail("feature-registry must be an array");
    22	    }
    23	    return parsed;
    24	  } catch (error) {
    25	    fail(`failed to read/parse feature-registry: ${error?.message || error}`);
    26	  }
    27	}
    28	
    29	function validateEntry(entry, index) {
    30	  const issues = [];
    31	  if (entry.idx !== index) issues.push(`idx mismatch (expected ${index}, got ${entry.idx})`);
    32	  if (!entry.id || typeof entry.id !== "string") issues.push("missing id");
    33	  if (!entry.title || typeof entry.title !== "string") issues.push("missing title");
    34	  if (entry.api !== null && typeof entry.api !== "string") issues.push("api must be string|null");
    35	  if (typeof entry.enabled !== "boolean") issues.push("enabled must be boolean");
    36	  if (!["cockpit", "feature"].includes(entry.kind)) issues.push("kind must be cockpit|feature");
    37	
    38	  if (entry.api && !entry.api.startsWith("/api/")) {
    39	    issues.push("api must start with /api/");
    40	  }
    41	
    42	  return issues;
    43	}
    44	
    45	function main() {
    46	  const registry = loadRegistry();
    47	  const expectedLength = 34;
    48	  if (registry.length !== expectedLength) {
    49	    fail(`registry length ${registry.length} !== ${expectedLength}`);
    50	  }
    51	
    52	  const ids = new Set();
    53	  registry.forEach((entry, index) => {
    54	    const issues = validateEntry(entry, index);
    55	    if (ids.has(entry.id)) {
    56	      issues.push(`duplicate id ${entry.id}`);
    57	    }
    58	    ids.add(entry.id);
    59	    if (issues.length) {
    60	      fail(`entry ${index} (${entry.id || "unknown"}): ${issues.join("; ")}`);
    61	    }
    62	  });
    63	
    64	  console.log("feature-registry valid (34 entries, contiguous idx 0..33)");
    65	}
    66	
    67	main();

## FILE: scripts/validate-mirrors.mjs
     1	import path from "node:path";
     2	import { fileURLToPath } from "node:url";
     3	import fs from "node:fs";
     4	import { loadMirrorEnvelope, validateBasicMirrorShape, isFiniteNumber } from "./utils/mirror-io.mjs";
     5	
     6	const __dirname = path.dirname(fileURLToPath(import.meta.url));
     7	const MIRROR_ROOT = path.resolve(__dirname, "../mirrors");
     8	const now = Date.now();
     9	const warnings = [];
    10	const continuousEmptySoftAllow = new Set(["alpha-radar", "volume-anomaly", "breakout-energy"]);
    11	
    12	if (!fs.existsSync(MIRROR_ROOT)) {
    13	  console.log(`validate-mirrors: skipped (missing ${MIRROR_ROOT})`);
    14	  process.exit(0);
    15	}
    16	
    17	function minutesBetween(a, b) {
    18	  return Math.abs(a - b) / 60000;
    19	}
    20	
    21	function toDate(value) {
    22	  const parsed = Date.parse(value || "");
    23	  return Number.isNaN(parsed) ? null : new Date(parsed);
    24	}
    25	
    26	function checkNumbers(value, errors, pathParts, nullableSet) {
    27	  if (value === null) {
    28	    const key = pathParts[pathParts.length - 1];
    29	    if (!nullableSet.has(key)) {
    30	      errors.push(`null_not_allowed:${pathParts.join(".")}`);
    31	    }
    32	    return;
    33	  }
    34	  if (typeof value === "number") {
    35	    if (!isFiniteNumber(value)) {
    36	      errors.push(`non_finite:${pathParts.join(".")}`);
    37	    }
    38	    return;
    39	  }
    40	  if (Array.isArray(value)) {
    41	    value.forEach((item, idx) => checkNumbers(item, errors, [...pathParts, String(idx)], nullableSet));
    42	    return;
    43	  }
    44	  if (value && typeof value === "object") {
    45	    Object.entries(value).forEach(([key, val]) => checkNumbers(val, errors, [...pathParts, key], nullableSet));
    46	  }
    47	}
    48	
    49	function normalizeDataQuality(rawStatus) {
    50	  const status = String(rawStatus || "").toUpperCase();
    51	  if (status === "LIVE" || status === "OK") return "OK";
    52	  if (status === "PARTIAL") return "PARTIAL";
    53	  if (status === "EMPTY") return "EMPTY";
    54	  if (status === "STALE") return "STALE";
    55	  if (status === "COVERAGE_LIMIT") return "COVERAGE_LIMIT";
    56	  return "EMPTY";
    57	}
    58	
    59	function normalizeMirrorPayload(mirrorId, envelope) {
    60	  const raw = envelope?.raw ?? envelope;
    61	  const envelopeMeta = envelope?.meta ?? null;
    62	  const isEnvelope = envelope?.isEnvelope === true;
    63	  if (!raw) return { mirror: null, errors: ["mirror_missing"] };
    64	  const errors = [];
    65	  if (isEnvelope) {
    66	    if (!envelopeMeta || typeof envelopeMeta !== "object") {
    67	      errors.push("envelope_missing");
    68	    } else {
    69	      ["provider", "dataset", "fetchedAt", "source", "runId", "ttlSeconds"].forEach((field) => {
    70	        if (envelopeMeta[field] === undefined || envelopeMeta[field] === null || envelopeMeta[field] === "") {
    71	          errors.push(`envelope_meta_missing_${field}`);
    72	        }
    73	      });
    74	    }
    75	  }
    76	
    77	  if (raw && typeof raw === "object" && raw.schemaVersion && raw.mirrorId && raw.items) {
    78	    return { mirror: raw, errors };
    79	  }
    80	
    81	  const legacy = raw && typeof raw === "object" ? raw : { items: Array.isArray(raw) ? raw : [] };
    82	  const items = Array.isArray(legacy.items)
    83	    ? legacy.items
    84	    : Array.isArray(legacy?.data?.items)
    85	      ? legacy.data.items
    86	      : Array.isArray(legacy?.rows)
    87	        ? legacy.rows
    88	        : [];
    89	  const meta = legacy.meta || {};
    90	  const nowIso = new Date().toISOString();
    91	  const updatedAt = meta.updatedAt || meta.ts || legacy.updatedAt || nowIso;
    92	  const asOf = legacy.asOf || meta.asOf || updatedAt;
    93	  const dataQuality = normalizeDataQuality(meta.status || legacy.dataQuality || (legacy.ok === false ? "ERROR" : null));
    94	  const legacyErrors = Array.isArray(legacy.errors)
    95	    ? legacy.errors
    96	    : legacy.error
    97	      ? [legacy.error.code || "ERROR"]
    98	      : [];
    99	  const missingSymbols = Array.isArray(legacy.missingSymbols) ? legacy.missingSymbols : [];
   100	  const notes = Array.isArray(legacy.notes) ? legacy.notes : [];
   101	  const context = legacy.context || meta || {};
   102	
   103	  const coerced = {
   104	    schemaVersion: "rv-mirror-v1",
   105	    mirrorId,
   106	    runId: meta.traceId || legacy.traceId || updatedAt,
   107	    updatedAt,
   108	    asOf,
   109	    mode: legacy.mode || meta.mode || "MIRROR",
   110	    cadence: legacy.cadence || meta.cadence || "best_effort",
   111	    trust: legacy.trust || "derived",
   112	    source: legacy.source || "mirror",
   113	    sourceUpstream: legacy.sourceUpstream || meta.source || "unknown",
   114	    dataQuality,
   115	    delayMinutes: meta.ageMinutes ?? 0,
   116	    missingSymbols,
   117	    errors: legacyErrors,
   118	    notes,
   119	    whyUnique: legacy.whyUnique || "",
   120	    context,
   121	    items
   122	  };
   123	
   124	  return { mirror: coerced, errors: [...errors, "coerced_legacy_shape"] };
   125	}
   126	
   127	const failures = [];
   128	
   129	// Only validate mirrors that are actually generated by this workflow
   130	// For event-mirrors workflow, only validate event-related mirrors
   131	const EVENT_MIRROR_IDS = new Set([
   132	  "news",
   133	  "why-moved",
   134	  "hype-divergence",
   135	  "earnings",
   136	  "congress-trading",
   137	  "insider-cluster",
   138	  "analyst-stampede",
   139	  "smart-money",
   140	  "alpha-performance",
   141	  "earnings-reality"
   142	]);
   143	
   144	// Check if we're in event-mirrors context (via env var or script name)
   145	const isEventMirrorsContext = process.env.VALIDATE_EVENT_MIRRORS_ONLY === "1" || 
   146	  process.argv[1]?.includes("validate-mirrors");
   147	
   148	const mirrorIds = fs
   149	  .readdirSync(MIRROR_ROOT)
   150	  .filter((name) => name.endsWith(".json"))
   151	  .map((name) => name.replace(/\.json$/, ""));
   152	
   153	for (const mirrorId of mirrorIds) {
   154	    // Skip validation for mirrors not generated by event-mirrors workflow
   155	    if (isEventMirrorsContext && !EVENT_MIRROR_IDS.has(mirrorId)) {
   156	      continue;
   157	    }
   158	    const filePath = path.join(MIRROR_ROOT, `${mirrorId}.json`);
   159	    const envelope = loadMirrorEnvelope(filePath);
   160	    if (!envelope) {
   161	      failures.push({ mirrorId, error: "mirror_missing", filePath });
   162	      continue;
   163	    }
   164	    const normalized = normalizeMirrorPayload(mirrorId, envelope);
   165	    if (normalized.errors.length && normalized.errors.includes("mirror_missing")) {
   166	      failures.push({ mirrorId, error: "mirror_missing", filePath });
   167	      continue;
   168	    }
   169	    const envelopeErrors = normalized.errors.filter((err) => err.startsWith("envelope_"));
   170	    if (envelopeErrors.length) {
   171	      failures.push({ mirrorId, error: "envelope_invalid", details: envelopeErrors });
   172	    }
   173	    if (normalized.errors.length && !normalized.errors.includes("mirror_missing")) {
   174	      warnings.push({ mirrorId, warning: "shape_coerced", details: normalized.errors });
   175	    }
   176	    const shape = validateBasicMirrorShape(normalized.mirror);
   177	    if (!shape.ok) {
   178	      warnings.push({ mirrorId, warning: "shape_invalid", details: shape.errors });
   179	      if (!normalized.mirror) continue;
   180	    }
   181	
   182	    const items = Array.isArray(normalized.mirror.items) ? normalized.mirror.items : [];
   183	    if (items.length === 0 && !continuousEmptySoftAllow.has(mirrorId)) {
   184	      const payload = { mirrorId, warning: "empty_items", count: items.length };
   185	      warnings.push(payload);
   186	    }
   187	    if (mirrorId === "alpha-radar") {
   188	      if (typeof normalized.mirror.generatedAt !== "string" || !normalized.mirror.generatedAt.trim()) {
   189	        failures.push({ mirrorId, error: "generatedAt_missing" });
   190	      }
   191	      if (!normalized.mirror.data || typeof normalized.mirror.data !== "object") {
   192	        failures.push({ mirrorId, error: "data_missing" });
   193	      }
   194	      const picks = normalized.mirror?.data?.picks;
   195	      const top = Array.isArray(picks?.top) ? picks.top : [];
   196	      if (!top.length) {
   197	        failures.push({ mirrorId, error: "picks_top_missing" });
   198	      } else {
   199	        const sample = top[0] || {};
   200	        const required = [

## FILE: scripts/validate-snapshots.js
     1	import fs from "node:fs";
     2	import path from "node:path";
     3	
     4	const SNAPSHOT_DIR = path.join("public", "data", "snapshots");
     5	
     6	function isNonEmptyString(value) {
     7	  return typeof value === "string" && value.trim().length > 0;
     8	}
     9	
    10	function isNumber(value) {
    11	  return typeof value === "number" && Number.isFinite(value);
    12	}
    13	
    14	function assert(condition, message, errors) {
    15	  if (!condition) errors.push(message);
    16	}
    17	
    18	function validateSnapshot(filePath) {
    19	  const errors = [];
    20	  let payload;
    21	  try {
    22	    payload = JSON.parse(fs.readFileSync(filePath, "utf8"));
    23	  } catch (error) {
    24	    return [`${filePath}: invalid json (${error.message})`];
    25	  }
    26	
    27	  const meta = payload?.meta;
    28	  assert(meta && typeof meta === "object", `${filePath}: meta missing`, errors);
    29	  if (!meta || typeof meta !== "object") return errors;
    30	
    31	  // Snapshot contract (v3):
    32	  // - meta.status/meta.reason/meta.generatedAt/meta.asOf/meta.source/meta.ttlSeconds/meta.runId
    33	  // - meta.freshness/meta.validation/meta.schedule present
    34	  assert(isNonEmptyString(meta.status), `${filePath}: meta.status invalid`, errors);
    35	  assert(isNonEmptyString(meta.reason), `${filePath}: meta.reason invalid`, errors);
    36	  assert(isNonEmptyString(meta.generatedAt), `${filePath}: meta.generatedAt invalid`, errors);
    37	  assert(isNonEmptyString(meta.asOf), `${filePath}: meta.asOf invalid`, errors);
    38	  assert(isNonEmptyString(meta.source), `${filePath}: meta.source invalid`, errors);
    39	  assert(isNumber(meta.ttlSeconds), `${filePath}: meta.ttlSeconds invalid`, errors);
    40	  assert(isNonEmptyString(meta.runId), `${filePath}: meta.runId invalid`, errors);
    41	  assert(meta.freshness && typeof meta.freshness === "object", `${filePath}: meta.freshness missing`, errors);
    42	  assert(meta.validation && typeof meta.validation === "object", `${filePath}: meta.validation missing`, errors);
    43	  assert(meta.schedule && typeof meta.schedule === "object", `${filePath}: meta.schedule missing`, errors);
    44	
    45	  return errors;
    46	}
    47	
    48	function main() {
    49	  if (!fs.existsSync(SNAPSHOT_DIR)) {
    50	    console.error("snapshot directory missing");
    51	    process.exit(1);
    52	  }
    53	
    54	  const files = fs.readdirSync(SNAPSHOT_DIR).filter((name) => name.endsWith(".json"));
    55	  const errors = [];
    56	
    57	  for (const name of files) {
    58	    const filePath = path.join(SNAPSHOT_DIR, name);
    59	    errors.push(...validateSnapshot(filePath));
    60	  }
    61	
    62	  if (errors.length) {
    63	    console.error("Snapshot validation failed:\n" + errors.join("\n"));
    64	    process.exit(1);
    65	  }
    66	
    67	  console.log(`Snapshot validation OK (${files.length} files)`);
    68	}
    69	
    70	main();

## FILE: scripts/validate-symbols.mjs
     1	#!/usr/bin/env node
     2	import fs from "node:fs";
     3	import path from "node:path";
     4	import Ajv from "ajv";
     5	import addFormats from "ajv-formats";
     6	
     7	function readJson(filePath) {
     8	  const raw = fs.readFileSync(filePath, "utf-8");
     9	  return JSON.parse(raw);
    10	}
    11	
    12	function formatAjvErrors(errors = []) {
    13	  return errors.map((err) => {
    14	    const loc = err.instancePath || err.schemaPath || "(root)";
    15	    const msg = err.message || "schema error";
    16	    return `- ${loc} ${msg}`;
    17	  });
    18	}
    19	
    20	function fail(message, details = []) {
    21	  console.error(` ${message}`);
    22	  if (details.length) {
    23	    details.forEach((line) => console.error(line));
    24	  }
    25	  process.exit(1);
    26	}
    27	
    28	const root = process.cwd();
    29	const symbolsPath = path.join(root, "config", "symbols.json");
    30	const schemaPath = path.join(root, "config", "symbols.schema.json");
    31	
    32	if (!fs.existsSync(symbolsPath)) {
    33	  fail(`symbols file missing: ${symbolsPath}`);
    34	}
    35	if (!fs.existsSync(schemaPath)) {
    36	  fail(`symbols schema missing: ${schemaPath}`);
    37	}
    38	
    39	let symbols;
    40	let schema;
    41	try {
    42	  symbols = readJson(symbolsPath);
    43	} catch (error) {
    44	  fail(`unable to parse symbols JSON: ${symbolsPath}`, [String(error?.message || error)]);
    45	}
    46	
    47	try {
    48	  schema = readJson(schemaPath);
    49	} catch (error) {
    50	  fail(`unable to parse symbols schema: ${schemaPath}`, [String(error?.message || error)]);
    51	}
    52	
    53	const ajv = new Ajv({ allErrors: true, strict: false });
    54	addFormats(ajv);
    55	const validate = ajv.compile(schema);
    56	
    57	const valid = validate(symbols);
    58	if (!valid) {
    59	  fail("symbols.json failed schema validation", formatAjvErrors(validate.errors));
    60	}
    61	
    62	const issues = [];
    63	const uuidSet = new Set();
    64	const assetIdSet = new Set();
    65	const activePairSet = new Set();
    66	
    67	symbols.forEach((entry, index) => {
    68	  const label = entry?.asset_id ? `${entry.asset_id} (#${index})` : `index ${index}`;
    69	  const uuid = entry?.uuid;
    70	  const assetId = entry?.asset_id;
    71	  const ticker = entry?.ticker;
    72	  const mic = entry?.mic;
    73	  const active = entry?.active !== false;
    74	
    75	  if (uuidSet.has(uuid)) {
    76	    issues.push(`- duplicate uuid: ${uuid} (${label})`);
    77	  } else {
    78	    uuidSet.add(uuid);
    79	  }
    80	
    81	  if (assetIdSet.has(assetId)) {
    82	    issues.push(`- duplicate asset_id: ${assetId} (${label})`);
    83	  } else {
    84	    assetIdSet.add(assetId);
    85	  }
    86	
    87	  // Enforce unique (ticker, mic) among active symbols. Inactive entries may duplicate.
    88	  if (active) {
    89	    const pairKey = `${ticker}::${mic}`;
    90	    if (activePairSet.has(pairKey)) {
    91	      issues.push(`- duplicate active (ticker, mic): ${ticker}/${mic} (${label})`);
    92	    } else {
    93	      activePairSet.add(pairKey);
    94	    }
    95	  }
    96	});
    97	
    98	if (issues.length) {
    99	  fail("symbols.json failed uniqueness checks", issues);
   100	}
   101	
   102	console.log(" symbols.json validation passed");

## FILE: scripts/validate/market-score-artifact.v1.mjs
     1	#!/usr/bin/env node
     2	
     3	import { readFile } from 'node:fs/promises';
     4	import { join } from 'node:path';
     5	
     6	function assert(condition, message) {
     7	  if (!condition) throw new Error(message || 'assertion_failed');
     8	}
     9	
    10	async function readJson(path) {
    11	  const raw = await readFile(path, 'utf-8');
    12	  return JSON.parse(raw);
    13	}
    14	
    15	function validateSurely(value, min, max, allowNull = false) {
    16	  if (value === null || value === undefined) {
    17	    assert(allowNull, 'value missing but not allowed');
    18	    return;
    19	  }
    20	  assert(typeof value === 'number', 'value must be numeric');
    21	  assert(value >= min && value <= max, `value ${value} outside [${min},${max}]`);
    22	}
    23	
    24	async function main() {
    25	  const baseDir = process.env.RV_ARTIFACT_OUT_DIR
    26	    ? String(process.env.RV_ARTIFACT_OUT_DIR)
    27	    : join(process.cwd(), 'tmp/phase1-artifacts/market-score');
    28	
    29	  const snapshot = await readJson(join(baseDir, 'snapshot.json'));
    30	  const state = await readJson(join(baseDir, 'module-state.json'));
    31	
    32	  assert(snapshot?.schema_version === '3.0', 'snapshot.schema_version must be 3.0');
    33	  assert(snapshot?.module === 'market-score', 'snapshot module must be market-score');
    34	  assert(snapshot?.metadata?.module === 'market-score', 'metadata module must be market-score');
    35	  assert(state?.module === 'market-score', 'state module must be market-score');
    36	  assert(typeof snapshot?.data === 'object', 'data must be an object map');
    37	
    38	  const symbols = Object.keys(snapshot.data || {});
    39	  assert(symbols.length > 0, 'no symbols scored');
    40	
    41	  for (const symbol of symbols) {
    42	    const entry = snapshot.data[symbol];
    43	    assert(entry?.symbol === symbol, `symbol mismatch ${symbol}`);
    44	    validateSurely(entry?.score_short, 0, 100);
    45	    validateSurely(entry?.score_mid, 0, 100);
    46	    validateSurely(entry?.score_long, 0, 100);
    47	    validateSurely(entry?.confidence, 0, 1);
    48	    assert(Array.isArray(entry?.inputs_used), 'inputs_used must be array');
    49	    assert(entry?.version, 'version required');
    50	    assert(typeof entry?.weights_digest === 'string', 'weights_digest string');
    51	    const reasons = entry?.reasons_top || {};
    52	    ['short', 'mid', 'long'].forEach((horizon) => {
    53	      const list = reasons[horizon] || [];
    54	      assert(Array.isArray(list), `${horizon} reasons must be array`);
    55	      assert(list.length <= 5, `${horizon} reasons >5`);
    56	    list.forEach((reason) => {
    57	      assert(reason.metric, 'reason requires metric');
    58	      assert(reason.points !== undefined, 'reason requires points');
    59	      assert(typeof reason.code === 'string' && reason.code.length > 0, 'reason requires code');
    60	      assert(/^[A-Z0-9_]{3,80}$/.test(reason.code), `reason code invalid ${reason.code}`);
    61	    });
    62	    });
    63	  }
    64	
    65	  console.log('OK: market-score artifact validator');
    66	}
    67	
    68	main().catch((err) => {
    69	  console.error('FAIL: market-score artifact validator');
    70	  console.error(err.stack || err.message || String(err));
    71	  process.exit(1);
    72	});

## FILE: scripts/validate/market-stats-artifact.v1.mjs
     1	#!/usr/bin/env node
     2	
     3	import { readFile } from 'node:fs/promises';
     4	import { join } from 'node:path';
     5	
     6	function assert(condition, message) {
     7	  if (!condition) throw new Error(message || 'assertion_failed');
     8	}
     9	
    10	async function readJson(path) {
    11	  const content = await readFile(path, 'utf-8');
    12	  return JSON.parse(content);
    13	}
    14	
    15	(async function main() {
    16	  const baseDir = process.env.RV_ARTIFACT_OUT_DIR
    17	    ? String(process.env.RV_ARTIFACT_OUT_DIR)
    18	    : join(process.cwd(), 'tmp/phase1-artifacts/market-stats');
    19	
    20	  const snapshot = await readJson(join(baseDir, 'snapshot.json'));
    21	  const state = await readJson(join(baseDir, 'module-state.json'));
    22	  const health = await readJson(join(baseDir, 'market-stats-health.json'));
    23	
    24	  assert(snapshot?.schema_version === '3.0', 'snapshot.schema_version must be 3.0');
    25	  assert(snapshot?.metadata?.module === 'market-stats', 'snapshot.metadata.module must be market-stats');
    26	  assert(snapshot?.metadata?.digest, 'snapshot.metadata.digest missing');
    27	  assert(typeof snapshot.data === 'object', 'snapshot.data must exist');
    28	
    29	  assert(state?.schema_version === '3.0', 'state.schema_version must be 3.0');
    30	  assert(state?.module === 'market-stats', 'state.module must be market-stats');
    31	  assert(state?.digest === snapshot.metadata.digest, 'state.digest must match snapshot digest');
    32	  assert(state?.record_count === snapshot.metadata.record_count, 'state.record_count must match');
    33	
    34	  assert(health?.module === 'market-stats', 'health.module must be market-stats');
    35	  assert(['OK', 'DEGRADED', 'FAILED'].includes(health?.run_quality), 'health.run_quality invalid');
    36	  assert(typeof health.coverage_ratio === 'number', 'health.coverage_ratio must be number');
    37	  assert(health.coverage_ratio >= 0 && health.coverage_ratio <= 1, 'health.coverage_ratio must be between 0 and 1');
    38	
    39	  process.stdout.write('OK: market-stats artifact validator\n');
    40	})().catch((err) => {
    41	  process.stderr.write(`FAIL: market-stats artifact validator\n${err.stack || err.message || String(err)}\n`);
    42	  process.exit(1);
    43	});

## FILE: src/lib/envelope.ts
     1	export type MetaStatus = "fresh" | "stale" | "closed" | "pending" | "error";
     2	
     3	export type EnvelopeError = {
     4	  code: string;
     5	  message: string;
     6	  details?: unknown;
     7	};
     8	
     9	export type EnvelopeMeta = {
    10	  status: MetaStatus;
    11	  generated_at: string;
    12	  data_date: string;
    13	  provider: string;
    14	  quality_flags?: string[];
    15	  warnings?: string[];
    16	  timings_ms?: Record<string, number>;
    17	  version?: string;
    18	};
    19	
    20	export type Envelope<T> = {
    21	  ok: boolean;
    22	  data: T | null;
    23	  error?: EnvelopeError | null;
    24	  meta: EnvelopeMeta;
    25	};
    26	
    27	const STATUS_SET = new Set<MetaStatus>([
    28	  "fresh",
    29	  "stale",
    30	  "closed",
    31	  "pending",
    32	  "error"
    33	]);
    34	
    35	const ISO_DATE_RE = /^\d{4}-\d{2}-\d{2}$/;
    36	
    37	function assert(condition: boolean, message: string): asserts condition {
    38	  if (!condition) throw new Error(message);
    39	}
    40	
    41	function isIsoString(value: string): boolean {
    42	  return !Number.isNaN(Date.parse(value));
    43	}
    44	
    45	export function assertEnvelope(value: unknown): asserts value is Envelope<unknown> {
    46	  assert(typeof value === "object" && value !== null, "Envelope must be an object");
    47	  const obj = value as Envelope<unknown>;
    48	  assert(typeof obj.ok === "boolean", "Envelope.ok must be boolean");
    49	  assert("data" in obj, "Envelope.data missing");
    50	  assert("meta" in obj && typeof obj.meta === "object" && obj.meta !== null, "Envelope.meta missing");
    51	
    52	  const meta = obj.meta as EnvelopeMeta;
    53	  assert(typeof meta.status === "string", "Envelope.meta.status missing");
    54	  assert(STATUS_SET.has(meta.status), `Envelope.meta.status invalid: ${meta.status}`);
    55	  assert(typeof meta.generated_at === "string" && isIsoString(meta.generated_at), "Envelope.meta.generated_at must be ISO string");
    56	  assert(typeof meta.data_date === "string", "Envelope.meta.data_date must be string");
    57	  if (meta.data_date) {
    58	    assert(ISO_DATE_RE.test(meta.data_date), "Envelope.meta.data_date must be YYYY-MM-DD");
    59	  }
    60	  assert(typeof meta.provider === "string" && meta.provider.length > 0, "Envelope.meta.provider missing");
    61	
    62	  if (obj.error != null) {
    63	    assert(typeof obj.error === "object", "Envelope.error must be object or null");
    64	    const err = obj.error as EnvelopeError;
    65	    assert(typeof err.code === "string", "Envelope.error.code missing");
    66	    assert(typeof err.message === "string", "Envelope.error.message missing");
    67	  }
    68	}
    69	
    70	export function okEnvelope<T>(data: T, metaPartial: Partial<EnvelopeMeta> & { provider: string }): Envelope<T> {
    71	  const provider = metaPartial.provider;
    72	  assert(typeof provider === "string" && provider.length > 0, "meta.provider is required");
    73	  const envelope: Envelope<T> = {
    74	    ok: true,
    75	    data: data ?? null,
    76	    error: null,
    77	    meta: {
    78	      status: metaPartial.status ?? "fresh",
    79	      generated_at: new Date().toISOString(),
    80	      data_date: metaPartial.data_date ?? "",
    81	      provider,
    82	      quality_flags: metaPartial.quality_flags,
    83	      warnings: metaPartial.warnings,
    84	      timings_ms: metaPartial.timings_ms,
    85	      version: metaPartial.version
    86	    }
    87	  };
    88	  assertEnvelope(envelope);
    89	  return envelope;
    90	}
    91	
    92	export function errorEnvelope(
    93	  code: string,
    94	  message: string,
    95	  metaPartial: Partial<EnvelopeMeta> & { provider: string },
    96	  details?: unknown
    97	): Envelope<null> {
    98	  const provider = metaPartial.provider;
    99	  assert(typeof provider === "string" && provider.length > 0, "meta.provider is required");
   100	  const envelope: Envelope<null> = {
   101	    ok: false,
   102	    data: null,
   103	    error: {
   104	      code,
   105	      message,
   106	      ...(details !== undefined ? { details } : {})
   107	    },
   108	    meta: {
   109	      status: metaPartial.status ?? "error",
   110	      generated_at: new Date().toISOString(),
   111	      data_date: metaPartial.data_date ?? "",
   112	      provider,
   113	      quality_flags: metaPartial.quality_flags,
   114	      warnings: metaPartial.warnings,
   115	      timings_ms: metaPartial.timings_ms,
   116	      version: metaPartial.version
   117	    }
   118	  };
   119	  assertEnvelope(envelope);
   120	  return envelope;
   121	}

## FILE: src/lib/rv-envelope.ts
     1	export type RVMetaStatus = "OK" | "STALE" | "NO_DATA" | "ERROR";
     2	export type RVReasonCode =
     3	  | "UPSTREAM_FAIL"
     4	  | "VALIDATION_FAIL"
     5	  | "BINDING_MISSING"
     6	  | "MISSING_LAST_GOOD"
     7	  | "NO_ITEMS"
     8	  | "EXCEPTION";
     9	
    10	export type RVWarning = { code: RVReasonCode | string; message: string };
    11	export type RVAttempt = { at: string; step: string; ok: boolean; detail?: unknown };
    12	
    13	export type RVMeta = {
    14	  status: RVMetaStatus;
    15	  isStale: boolean;
    16	  generatedAt: string;
    17	  source: string;
    18	  stalenessSec?: number;
    19	  reason?: RVReasonCode | string;
    20	  warnings?: RVWarning[];
    21	  debug?: { attempts?: RVAttempt[] };
    22	};
    23	
    24	export type RVValue<T> =
    25	  | { kind: "DATA"; data: T }
    26	  | { kind: "NO_DATA"; reason: RVReasonCode | string; detail?: unknown };
    27	
    28	export type RVEnvelope<T> = { meta: RVMeta; data: { value: RVValue<T> } };
    29	
    30	export function nowIso() { return new Date().toISOString(); }
    31	
    32	export function makeOk<T>(source: string, payload: T, debug?: RVMeta["debug"]): RVEnvelope<T> {
    33	  return { meta: { status: "OK", isStale: false, generatedAt: nowIso(), source, warnings: [], debug },
    34	           data: { value: { kind: "DATA", data: payload } } };
    35	}
    36	
    37	export function makeStale<T>(source: string, payload: T, reason: string, stalenessSec?: number, debug?: RVMeta["debug"]): RVEnvelope<T> {
    38	  return { meta: { status: "STALE", isStale: true, generatedAt: nowIso(), source, reason, stalenessSec,
    39	                   warnings: [{ code: reason, message: "Served from last_good fallback" }], debug },
    40	           data: { value: { kind: "DATA", data: payload } } };
    41	}
    42	
    43	export function makeNoData<T>(source: string, reason: string, detail?: unknown, debug?: RVMeta["debug"]): RVEnvelope<T> {
    44	  return { meta: { status: "NO_DATA", isStale: true, generatedAt: nowIso(), source, reason,
    45	                   warnings: [{ code: reason, message: "No data available" }], debug },
    46	           data: { value: { kind: "NO_DATA", reason, detail } } };
    47	}
    48	
    49	export function makeError<T>(source: string, reason: string, detail?: unknown, debug?: RVMeta["debug"]): RVEnvelope<T> {
    50	  return { meta: { status: "ERROR", isStale: true, generatedAt: nowIso(), source, reason,
    51	                   warnings: [{ code: reason, message: "Endpoint error" }], debug },
    52	           data: { value: { kind: "NO_DATA", reason, detail } } };
    53	}
